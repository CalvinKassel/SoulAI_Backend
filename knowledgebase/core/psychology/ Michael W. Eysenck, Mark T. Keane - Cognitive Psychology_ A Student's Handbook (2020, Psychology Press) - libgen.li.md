"This edition of Eysenck and Keane has further enhanced the status of
Cognitive Psychology: A Student's Handbook, as a high benchmark that
other textbooks on this topic fail to achieve. It is informative and
innovative, without losing any of its hallmark coverage and
readability." Professor Robert Logie, School of Philosophy, Psychology
and Language Sciences, University of Edinburgh, United Kingdom "The best
student's handbook on cognitive psychology -- an indispensable volume
brought up-to-date in this latest edition. It explains everything from
low-level vision to high-level consciousness, and it can serve as an
introductory text." Professor Philip Johnson-Laird, Stuart Professor of
Psychology, Emeritus, Princeton University, United States "I ﬁrst read
Eysenck and Keane's Cognitive Psychology: A Student's Handbook in its
third edition, during my own undergraduate studies. Over the course of
its successive editions since then, the content -- like the ﬁeld of
cognition itself -- has evolved and grown to encompass current trends,
novel approaches and supporting learning resources. It remains, in my
opinion, the gold standard for cognitive psychology textbooks." Dr
Richard Roche, Senior Lecturer, Department of Psychology, Maynooth
University, Ireland "Eysenck and Keane have once again done an excellent
job, not only in terms of keeping the textbook up-to-date with the
latest studies, issues and debates; but also by making the content even
more accessible and clear without compromising accuracy or
underestimating the reader's intelligence. After all these years, this
book remains an essential tool for students of cognitive psychology,
covering the topic in the appropriate breadth and depth." Dr Gerasimos
Markopoulos, Senior Lecturer, School of Science, Bath Spa University,
United Kingdom "Eysenck and Keane's popular textbook oﬀers comprehensive
coverage of what psychology students need to know about human cognition.
The textbook introduces the core topics of cognitive psychology that
serve as the fundamental building blocks to our understanding of human
behaviour. The authors integrate contemporary developments in the ﬁeld
and provide an accessible entry to neighboring disciplines such as
cognitive neuroscience and neuropsychology." Dr Motonori Yamaguchi,
Senior Lecturer, Department of Psychology, University of Essex, United
Kingdom

"The eighth edition of Cognitive Psychology by Eysenck and Keane
provides possibly the most comprehensive coverage of cognition currently
available. The text is clear and easy to read with clear links to theory
across the chapters. A real highlight is the creative use of up-to-date
real-world examples throughout the book." Associate Professor Rhonda
Shaw, Head of the School of Psychology, Charles Sturt University,
Australia "Unmatched in breadth and scope, it is the authoritative
textbook on cognitive psychology. It outlines the history and major
developments within the ﬁeld, while discussing state-of-the-art
experimental research in depth. The integration of online resources
keeps the material fresh and engaging." Associate Professor Søren Risløv
Staugaard, Department of Psychology and Behavioural Sciences, Aarhus
University, Denmark "Eysenck and Keane's Cognitive Psychology provides
comprehensive topic coverage and up-to-date research. The writing style
is concise and easy to follow, which makes the book suitable for both
undergraduate and graduate students. The authors use real-life examples
that are easily relatable to students, making the book very enjoyable to
read." Associate Professor Lin Agler, School of Psychology, University
of Southern Mississippi Gulf Coast, United States

Cognitive Psychology

The fully updated eighth edition of Cognitive Psychology: A Student's
Handbook provides comprehensive yet accessible coverage of all the key
areas in the ﬁeld ranging from visual perception and attention through
to memory and language. Each chapter is complete with key deﬁnitions,
practical real-life applications, chapter summaries and suggested
further reading to help students develop an understanding of this
fascinating but complex ﬁeld. The new edition includes: ● ● ●

an increased emphasis on neuroscience updated references to reﬂect the
latest research applied 'in the real world' case studies and examples.

Widely regarded as the leading undergraduate textbook in the ﬁeld of
cognitive psychology, this new edition comes complete with an enhanced
accompanying companion website. The website includes a suite of learning
resources including simulation experiments, multiple-choice questions,
and access to Primal Pictures' interactive 3D atlas of the brain. The
companion website can be accessed at: www.routledge.com/cw/eysenck.
Michael W. Eysenck is Professor Emeritus in Psychology at Royal
Holloway, University of London, United Kingdom. He is also Professorial
Fellow at Roehampton University, London. He is the best-selling author
of several textbooks including Fundamentals of Cognition (2018), Memory
(with Alan Baddeley and Michael Anderson, 2020) and Fundamentals of
Psychology (2009). Mark T. Keane is Chair of Computer Science at
University College Dublin, Ireland.

Visit the Companion Website to access a range of interactive teaching
and learning resources

Includes access to Primal Pictures' interactive 3D brain
www.routledge.com/cw/eysenck

PRIMAL PICTURES

Revolutionizing medical education with anatomical solutions to fit every
need For over 27 years, Primal Pictures has led the way in offering
premier 3D digital human anatomy solutions, transforming how educators
teach and students learn the complexities of human anatomy and medicine.
Our pioneering scientific approach puts quality, accuracy and detail at
the heart of everything we do. Primal's experts have created the world's
most medically accurate and detailed 3D reconstruction of human anatomy
using real scan data from the NLM Visible Human Project®, as well as CT
images and MRIs. With advanced academic research and thousands of
development hours underpinning its creation, our model surpasses all
other anatomical resources available. To learn more about Primal's
cutting-edge solution for better learning outcomes and increased student
engagement visit www.primalpictures.com/students

COGNITIVE PSYCHOLOGY A Student's Handbook Eighth Edition

MICHAEL W. EYSENCK AND MARK T. KEANE

Eighth edition published 2020 by Routledge 2 Park Square, Milton Park,
Abingdon, Oxon OX14 4RN and by Routledge 52 Vanderbilt Avenue, New York,
NY 10017 Routledge is an imprint of the Taylor & Francis Group, an
informa business © 2020 Michael W. Eysenck and Mark T. Keane The right
of Michael W. Eysenck and Mark T. Keane to be identiﬁed as authors of
this work has been asserted by them in accordance with sections 77 and
78 of the Copyright, Designs and Patents Act 1988. All rights reserved.
No part of this book may be reprinted or reproduced or utilised in any
form or by any electronic, mechanical, or other means, now known or
hereafter invented, including photocopying and recording, or in any
information storage or retrieval system, without permission in writing
from the publishers. Trademark notice: Product or corporate names may be
trademarks or registered trademarks, and are used only for identiﬁcation
and explanation without intent to infringe. First edition published by
Lawrence Erlbaum Associates 1984 Seventh edition Published by Routledge
2015 Every eﬀort has been made to contact copyright-holders. Please
advise the publisher of any errors or omissions, and these will be
corrected in subsequent editions. British Library
Cataloguing-in-Publication Data A catalogue record for this book is
available from the British Library Library of Congress
Cataloging-in-Publication Data A catalog record has been requested for
this book ISBN: 978-1-13848-221-0 (hbk) ISBN: 978-1-13848-223-4 (pbk)
ISBN: 978-1-35105-851-3 (ebk) Typeset in Times New Roman by Servis
Filmsetting Ltd, Stockport, Cheshire Visit the companion website:
www.routledge.com/cw/eysenck.

To Christine with love (M.W.E.)

What moves science forward is argument, debate, and the testing of
alternative theories . . . A science without controversy is a science
without progress. (Jerry Coyne)

Contents List of illustrations Preface Visual tour (how to use this
book)

xiv xxix xxxi

1 Approaches to human cognition

1

Introduction 1 Cognitive psychology 3 Cognitive neuropsychology 7
Cognitive neuroscience: the brain in action Computational cognitive
science 26 Comparisons of major approaches 33 Is there a replication
crisis? 34 Outline of this book 36 Chapter summary 37 Further reading 39

12

PART I Visual perception and attention

41

2 Basic processes in visual perception

43

Introduction 43 Vision and the brain 44 Two visual systems:
perception-action model 55 Colour vision 64 Depth perception 71
Perception without awareness: subliminal perception 81 Chapter summary
90 Further reading 92

3 Object and face recognition Introduction 94 Pattern recognition 95
Perceptual organisation 96

94

x

Contents

Approaches to object recognition 103 Object recognition: top-down
processes Face recognition 116 Visual imagery 130 Chapter summary 137
Further reading 139

111

4 Motion perception and action

140

Introduction 140 Direct perception 141 Visually guided movement 145
Visually guided action: contemporary approaches 152 Perception of human
motion 157 Change blindness 163 Chapter summary 175 Further reading 176

5 Attention and performance Introduction 178 Focused auditory attention
179 Focused visual attention 183 Disorders of visual attention 196
Visual search 200 Cross-modal eﬀects 208 Divided attention: dual-task
performance "Automatic" processing 226 Chapter summary 231 Further
reading 233

178

212

PART II Memory

237

6 Learning, memory and forgetting

239

Introduction 239 Short-term vs long-term memory 240 Working memory:
Baddeley and Hitch 246 Working memory: individual diﬀerences and
executive functions 254 Levels of processing (and beyond) 262 Learning
through retrieval 265 Implicit learning 269 Forgetting from long-term
memory 278 Chapter summary 293 Further reading 295

Contents

7 Long-term memory systems

296

Introduction 296 Declarative memory 300 Episodic memory 305 Semantic
memory 313 Non-declarative memory 325 Beyond memory systems and
declarative vs non-declarative memory 332 Chapter summary 340 Further
reading 342

8 Everyday memory

344

Introduction 344 Autobiographical memory: introduction 346 Memories
across the lifetime 351 Theoretical approaches to autobiographical
memory 355 Eyewitness testimony 363 Enhancing eyewitness memory 372
Prospective memory 375 Theoretical perspectives on prospective memory
381 Chapter summary 389 Further reading 391

PART III Language

393

9 Speech perception and reading

403

Introduction 403 Speech (and music) perception 404 Listening to speech
408 Context eﬀects 412 Theories of speech perception 417 Cognitive
neuropsychology 429 Reading: introduction 432 Word recognition 436
Reading aloud 442 Reading: eye-movement research 453 Chapter summary 457
Further reading 460

10 Language comprehension Introduction 461 Parsing: overview 462
Theoretical approaches: parsing and prediction 464 Pragmatics 478

461

xi

xii

Contents

Individual diﬀerences: working memory capacity 487 Discourse processing:
inferences 490 Discourse comprehension: theoretical approaches 498
Chapter summary 510 Further reading 512

11 Language production Introduction 514 Basic aspects of speech
production 516 Speech planning 519 Speech errors 521 Theories of speech
production 525 Cognitive neuropsychology: speech production Speech as
communication 543 Writing: the main processes 549 Spelling 558 Chapter
summary 564 Further reading 566

514

536

PART IV Thinking and reasoning

569

12 Problem solving and expertise

573

Introduction 573 Problem solving: introduction 574 Gestalt approach and
beyond: insight and role of experience Problem-solving strategies 588
Analogical problem solving and reasoning 593 Expertise 600 Chess-playing
expertise 601 Medical expertise 604 Brain plasticity 609 Deliberate
practice and beyond 612 Chapter summary 619 Further reading 621

13 Judgement and decision-making Introduction 622 Judgement research 623
Theories of judgement 633 Decision-making under risk 640
Decision-making: emotional and social factors 649 Applied and complex
decision-making 654 Chapter summary 663 Further reading 665

576

622

Contents

14

Reasoning and hypothesis testing

666

Introduction 666 Hypothesis testing 667 Deductive reasoning 672 Theories
of "deductive" reasoning 680 Brain systems in reasoning 690 Informal
reasoning 694 Are humans rational? 701 Chapter summary 708 Further
reading 710

PART V Broadening horizons

713

15 Cognition and emotion

715

Introduction 715 Appraisal theories 719 Emotion regulation 723 Aﬀect and
cognition: attention and memory 730 Aﬀect and cognition: judgement and
decision-making 738 Judgement and decision-making: theoretical
approaches 750 Anxiety, depression and cognitive biases 753 Cognitive
bias modiﬁcation and beyond 761 Chapter summary 764 Further reading 766

16 Consciousness

767

Introduction 767 Functions of consciousness 768 Assessing consciousness
and conscious experience 775 Global workspace and global neuronal
workspace theories 783 Is consciousness unitary? 792 Chapter summary 798
Further reading 799 Glossary References Author index Subject index

801 824 915 931

xiii

Illustrations TABLES 1.1 1.2 1.3 11.1 15.1

Approaches to human cognition Major techniques used to study the brain
Strengths and limitations of major approaches to human cognition
Involvement of working memory components in various writing processes
Eﬀects of anxiety and depression on attentional bias (engagement and
disengagement)

3 16 35 556 757

PHOTOS Chapter 1 • Max Coltheart • The magnetic resonance imaging (MRI)
scanner • Transcranial magnetic stimulation coil • The IBM Watson and
two human contestants (Ken Jennings and Brad Rutter)

8 18 21 27

Chapter 3 • Irving Biederman • Heather Sellers

107 118

Chapter 6 • Alan Baddeley and Graham Hitch • Endel Tulving

246 287

Chapter 7 • Henry Molaison

297

Chapter 8 • Jill Price • World Trade Center attacks on 9/11 • Jennifer
Thompson and Ronald Cotton

348 349 364

Illustrations

Chapter 11 • Iris Murdoch

550

Chapter 12 • Monty Hall • Fernand Gobet • Magnus Carlsen

575 602 613

Chapter 13 • Pat Croskerry • Nik Wallenda

625 647

FIGURES 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 1.10 1.11 1.12 1.13 2.1 2.2
2.3 2.4 2.5 2.6

2.7

2.8 2.9 2.10

An early version of the information processing approach Diagram to
demonstrate top--down processing Test yourself by naming the colours in
each column The four lobes, or divisions, of the cerebral cortex in the
left hemisphere Brodmann brain areas on the lateral and medial surfaces
The brain network and cost eﬃciency The organisation of the "rich club"
The spatial and temporal resolution of major techniques and methods used
to study brain functioning Areas showing greater activation in a dead
salmon when presented with photographs of people than when at rest The
primitive mock neuroimaging device used by Ali et al. (2014)
Architecture of a basic three-layer connectionist network The main
modules of the ACT-R cognitive architecture with their locations within
the brain The basic structure of the standard model of the mind
involving ﬁve independent modules Complex scene that requires prolonged
perceptual processing to understand fully Route of visual signals
Simultaneous contrast involving lateral inhibition Some distinctive
features of the largest visual cortical areas Connectivity within the
ventral pathway on the lateral surface of the macaque brain (a) The
single hierarchical model; (b) the parallel hierarchical model; (c) the
three parallel hierarchical feedforward systems model The percentage of
cells in six diﬀerent visual cortical areas responding selectively to
orientation, direction of motion, disparity and colour Visual motion
inputs Goodale and Milner's (1992) perception-action model showing the
dorsal and ventral streams Lesion overlap in patients with optic ataxia

4 4 5 13 13 14 15 17 25 26 28 30 31 43 45 46 47 48

49

52 53 56 57

xv

xvi

Illustrations

2.11 The Müller-Lyer illusion 58 2.12 The Ebbinghaus illusion 59 2.13
The hollow-face illusion. Left: normal and hollow faces with small
target magnets on the forehead and cheek of the normal face; right:
front view of the hollow mask that appears as an illusory face
projecting forwards 60 2.14 Disruption of size judgements when estimated
perceptually (estimation) or produced by grasping (grasping) in full or
restricted vision 61 2.15 Historical developments in theories linking
perception and action 63 2.16 Schematic diagram of the early stages of
neural colour processing 66 2.17 Photograph of a mug showing enormous
variation in the properties of the reﬂected light across the mug's
surface 67 2.18 "The Dress" made famous by its appearance on the
internet 69 2.19 Observers' perceptions of "The Dress" 69 2.20 An
engraving by de Vries (1604/1970) in which linear perspective creates an
eﬀective three-dimensional eﬀect when viewed from very close but not
from further away 72 2.21 Examples of texture gradients that can be
perceived as surfaces receding into the distance 73 2.22 Kanizsa's
(1976) illusory square 73 2.23 Accuracy of size judgements as a function
of object type 78 2.24 (a) A representation of the Ames room; (b) an
actual Ames room showing the eﬀect achieved with two adults 79 2.25
Perceived distance. Top: stimuli presented to participants; bottom:
example of the stimulus display 81 2.26 The body size eﬀect: what
participants in the doll experiment could see 81 2.27 Estimated
contributions of conscious and subconscious processing to GY's
performance in exclusion and inclusion conditions in his normal and
blind ﬁelds 84 2.28 The areas of most relevance to blindsight are the
lateral geniculate nucleus and middle temporal visual area 86 2.29 The
relationship between response bias in reporting conscious awareness and
enhanced N200 on no-awareness correct trials compared to no-awareness
incorrect trials (UC) 89 3.1 The kind of stimulus used by Navon (1977)
to demonstrate the importance of global features in perception 95 3.2
The CAPTCHA used by Yahoo 97 3.3 The FBI's mistaken identiﬁcation of the
Madrid bomber 98 3.4 Examples of the Gestalt laws of perceptual
organisation: (a) the law of proximity; (b) the law of similarity; (c)
the law of good continuation; and (d) the law of closure 99 3.5 An
ambiguous drawing that can be seen as either two faces or as a goblet
100 3.6 The tendency to perceive an array of empty circles as (A) a
rotated square or (B) a diamond 101 3.7 A task to decide which region in
each stimulus is the ﬁgure 102

Illustrations

3.8 3.9

3.10 3.11 3.12 3.13

3.14 3.15 3.16 3.17 3.18 3.19 3.20

3.21

3.22 3.23 3.24

3.25 4.1 4.2 4.3 4.4 4.5

4.6

High and low spatial frequency versions of a place (a building) Image of
Mona Lisa revealing very low spatial frequencies (left), low spatial
frequencies (centre) and high spatial frequencies (right) An outline of
Biederman's recognition-by-components theory Ambiguous ﬁgures A brick
wall that can be seen as something else Object recognition involving two
diﬀerent routes: (1) a topdown route in which information proceeds
rapidly to the orbitofrontal cortex; (2) a bottom-up route using the
slower ventral visual stream Interactive-iterative framework for object
recognition Recognising an elephant when a key feature (its trunk) is
partially hidden Accuracy and speed of object recognition for birds,
boats, cars, chairs and faces by patient GG and healthy controls
Face-selective areas in the right hemisphere An array of 40 faces to be
matched for identity The model of face recognition put forward by Bruce
and Young (1986) Damage to regions of the inferior occipito-temporal
cortex, the anterior inferior temporal cortex and the anterior temporal
pole The approximate locations of the visual buﬀer in BA17 and BA18, of
long-term memories of shapes in the inferior temporal lobe, and of
spatial representations in the posterior parietal cortex Dwell time for
the four quadrants of a picture during perception and imagery Slezak's
(1991, 1995) investigations into the eﬀects of rotation on object
recognition The extent to which perceived or imagined objects could be
classiﬁed accurately on the basis of brain activity in the early visual
cortex and object-selective cortex Connectivity during perception and
imagery involving (a) bottom-up processing; and (b) top-down processing
The optic-ﬂow ﬁeld as a pilot comes in to land, with the focus of
expansion in the middle Graspable and non-graspable objects having
similar asymmetrical features The visual features of a road viewed in
perspective The far road "triangle" in (A) a left turn and (B) a right
turn Errors in time-to-contact judgements for the smaller and the larger
object as a function of whether they were presented in their standard
size, the reverse size (oﬀ-size) or lacking texture (no-texture) The
dorso-dorsal and ventro-dorsal streams showing their brain locations and
forms of processing

104

105 107 112 114

115 115 116 120 121 124 126

127

132 133 134

135 135 142 143 147 148

150 156

xvii

xviii

Illustrations

4.7 4.8

4.9 4.10 4.11 4.12 4.13 4.14 4.15

4.16

4.17 4.18 5.1 5.2

5.3 5.4

5.5

5.6 5.7

5.8 5.9 5.10

Point-light sequences (a) with the walker visible and (b) with the
walker not visible 157 Human detection and discrimination eﬃciency for
human walkers presented in contour, point lights, silhouette and
skeleton 158 Brain areas involved in biological motion processing 159
The main brain areas associated with the mirror neuron system plus their
interconnections 161 The unicycling clown who cycled close to students
walking across a large square 164 The sequence of events in the
disappearing lighter trick 166 Participants' ﬁxation points at the time
of dropping the lighter 166 Change blindness: an example 168 (a)
Percentage of correct change detection as a function of form of change
and time of ﬁxation; also false alarm rate when there was no change. (b)
Mean percentage correct change detection as a function of the number of
ﬁxations between target ﬁxation and change of target and form of change
169 (a) Change-detection accuracy as a function of task diﬃculty and
visual eccentricity. (b) The eccentricity at which changedetection
accuracy was 85% correct as a function of task diﬃculty 170 An example
of inattentional blindness: a woman in a gorilla suit in the middle of a
game of passing the ball 172 An example of inattentional blindness: the
sequence of events on the initial baseline trials and the critical trial
174 A comparison of Broadbent's theory, Treisman's theory, and Deutsch
and Deutsch's theory 181 Split attention. (a) Shaded areas indicate the
cued locations; the near and far locations are not cued. (b) Probability
of target detection at valid (left or right) and invalid (near or far)
locations 185 A comparison of object-based and space-based attention 187
Object-based and space-based attention. (a) Possible target locations
for a given cue. (b) Performance accuracy at the various target
locations 188 Sample displays for three low perceptual load conditions
in which the task required deciding whether a target X or N was
presented 190 The brain areas associated with the dorsal or
goal-directed attention network and the ventral or stimulus-driven
network 193 A theoretical approach based on several functional networks
of relevance to attention: fronto-parietal; default mode;
cingulo-opercular; and ventral attention 195 An example of
object-centred or allocentric neglect 197 Illegal and dangerous items
captured by an airport security screener 201 Frequency of selection and
identiﬁcation errors when targets were present at trials 201

Illustrations

5.11 Performance speed on a detection task as a function of target
deﬁnition (conjunctive vs single feature) and display size 203 5.12 Eye
ﬁxations made by observers searching for pedestrians 204 5.13 A
two-pathway model of visual search 205 5.14 An example of a visual
search task when considering feature integration theory 208 5.15 An
example of temporal ventriloquism in which the apparent time of onset of
a ﬂash is shifted towards that of a sound presented at a slightly
diﬀerent timing from the ﬂash 210 5.16 Wickens's four-dimensional
multiple-resource model 216 5.17 Threaded cognition theory 218 5.18
Patterns of brain activation: (a) underadditive activation; (b) additive
activation; (c) overadditive activation 220 5.19 Eﬀects of an audio
distraction task on brain activity associated with a straight driving
task 221 5.20 Dual-task (auditory and visual tasks) and single-task
(auditory or visual task) conditions: reaction times for correct
responses only over eight experimental sessions 224 5.21 Response times
on a decision task as a function of memory-set size, display-set size
and consistent vs varied mapping 227 5.22 Factors that are hypothesised
to inﬂuence representational quality within Moors' (2016) theoretical
approach 229 6.1 The multi-store model of memory as proposed by Atkinson
and Shiﬀrin (1968) 240 6.2 Short-term memory performance in conditions
designed to create interference (repeated condition) or minimise
interference (unique condition) 243 6.3 The working memory model showing
the connections among its four components and their relationship to
long-term memory 246 6.4 Phonological loop system as envisaged by
Baddeley (1990) 248 6.5 Sites where direct electrical stimulation
disrupted digit-span performance 249 6.6 Amount of interference on a
spatial task and a visual task as a function of a secondary task
(spatial: movement vs visual: colour discrimination) 250 6.7 Screen
displays for the digit 6 253 6.8 Mean reaction times
quintile-by-quintile on the anti-saccade task by groups high and low in
working memory capacity 256 6.9 Schematic representation of the unity
and diversity of three executive functions 259 6.10 Activated brain
regions across all executive functions in a meta-analysis of 193 studies
260 6.11 Recognition memory performance as a function of processing
depth (shallow vs deep) for three types of stimuli: doors, clocks, and
menus 263 6.12 Distinctiveness. Percentage recall of the critical item
(e.g., kiwi) and of the preceding and following items in the encoding,
retrieval and control conditions 264

xix

xx

Illustrations

6.13 (a) Restudy causes strengthening of the memory trace formed after
initial study; (b) testing with feedback causes strengthening of the
memory trace; and (c) the formation of a second memory trace 266 6.14
(a) Final recall for restudy-only and test-restudy group participants;
(b) recall performance in the CMR group as a function of whether the
mediators were or were not retrieved 267 6.15 Mean recall percentage in
Session 2 on Test 1 and Test 2 as function of retrieval practice or
restudy practice in Session 1 268 6.16 Schematic representation of a
traditional keyboard 270 6.17 Mean number of completions in inclusion
and exclusion conditions as a function of number of trials 273 6.18
Response times for participants showing a sudden drop in reaction times
or not showing such a drop 273 6.19 The striatum is of central
importance in implicit learning 274 6.20 A model of motor sequence
learning 275 6.21 Sequential motor skill learning dependencies 276 6.22
Skilled typists' performance when tested on a traditional keyboard 277
6.23 Forgetting over time as indexed by reduced savings 279 6.24 Methods
of testing for proactive and retroactive interference 281 6.25
Percentage of items recalled over time for the conditions: no proactive
interference, remember and forget 282 6.26 Percentage of words correctly
recalled across 32 articles in the respond, baseline and suppress
conditions 286 6.27 Proportion of words recalled in high- and
low-overload conditions with intra-list cues, strong extra-list cues and
weak extra-list cues 289 7.1 Damage to brain areas within and close to
the medial temporal lobes producing amnesia 298 7.2 The standard account
based on dividing long-term memory into two broad classes: declarative
and non-declarative 300 7.3 Interactions between episodic memories,
semantic memories and gist memories 305 7.4 (a) Locations of the
hippocampus, the perirhinal cortex and the parahippocampal cortex; (b)
the binding-of-item-andcontext model 307 7.5 (A) Left lateral, (B),
medial and (C) anterior views of prefrontal areas having greater
activation to familiarity-based than recollection-based processes and
areas showing the opposite pattern 309 7.6 Sample pictures on the
recognition-memory test 309 7.7 (A) Areas activated for both episodic
simulation and episodic memory; (B) areas more activated for episodic
simulation than episodic memory 312 7.8 Accuracy of (a) object
categorisation and (b) speed of categorisation at the superordinate,
basic and subordinate levels 315 7.9 The hub-and-spoke model 319

Illustrations

7.10 Performance accuracy on tool function and tool manipulation tasks
with anodal transcranial direct current stimulation to the anterior
temporal lobe or to the inferior parietal lobule and in a control
condition 321 7.11 Categorisation performance for pictures and words by
healthy controls and patients with semantic dementia 324 7.12
Percentages of priming eﬀect and recognition-memory performance of
healthy controls and patients 326 7.13 Brain regions showing repetition
suppression or response enhancement in a meta-analysis 328 7.14 Mean
reaction times on the serial reaction time task by Parkinson's disease
patients and healthy controls 330 7.15 A processing-based memory model
334 7.16 Recognition memory for faces presented and tested in a ﬁxed or
variable viewpoint 335 7.17 Brain areas whose activity during episodic
learning predicted increased recognition-memory performance
(task-positive) or decreased performance (task-negative) 337 7.18 A
three-dimensional model of memory: (1) conceptually or perceptually
driven; (2) relational or item stimulus representation; (3) controlled
or automatic/involuntary intention 339 7.19 Process-speciﬁc alliances
including the left angular gyrus are involved in recollection of
episodic memories and semantic processing 339 8.1 Brain regions
activated by autobiographical, episodic retrieval and mentalising tasks
including regions of overlap 347 8.2 Number of internal details speciﬁc
to an autobiographical event recalled at various time delays (by
controls and individuals with highly superior autobiographical memory)
348 8.3 Childhood amnesia based on data reported by Rubin and Schulkind
(1997) 352 8.4 Temporal distribution of autobiographical memories across
the lifespan 354 8.5 The knowledge structures within autobiographical
memory, as proposed by Conway (2005) 357 8.6 The mean number of events
participants could remember from the past 5 days and those they imagined
were likely over the next 5 days 358 8.7 A model of the bidirectional
relationships between neural networks involved in the construction
and/or elaboration of autobiographical memories 360 8.8 Life structure
scores (proportion negative, compartmentalisation, positive redundancy,
negative redundancy) for patients with major depressive disorder,
patients in remission from major depressive disorder and healthy
controls 361 8.9 Four cognitive biases related to autobiographical
memory recall that maintain depression and increase the risk of
recurrence following remission 362

xxi

xxii

Illustrations

8.10 Examples of Egyptian and UK face-matching arrays 366 8.11 Size of
the misinformation eﬀect as a function of detail memorability in the
neutral condition 367 8.12 Extent of misinformation eﬀects as a function
of condition for the original memory and endorsement of the
misinformation presented previously 371 8.13 Eyewitness identiﬁcation:
test of face-recognition performance 371 8.14 A model of the component
processes involved in prospective memory 378 8.15 Mean failures to
resume an interrupted task and mean resumption times for the conditions:
no-interruption, blank-screen interruption and secondary air traﬃc
control task interruption 379 8.16 Self-reported memory vividness,
memory details and conﬁdence in memory for individuals with good and
poor inhibitory control before and after repeated checking 381 8.17 The
dual-pathways model of prospective memory (based on the multi-process
framework) for non-focal and focal tasks separately 383 8.18 Example 1:
top-down monitoring processes operating in isolation. Example 2:
bottom-up spontaneous retrieval processes operating in isolation.
Example 3: dual processes operating dynamically 383 8.19 (a) Sustained
and (b) transient activity in the (c) left anterior prefrontal cortex
for non-focal and focal prospective memory tasks 385 8.20 Frequency of
cue-driven monitoring following the presentation of semantically related
or unrelated cues 386 8.21 Diﬀerent ways the instruction to press Q for
fruit words was encoded 388 9.1 (a) Areas activated during passive music
listening and passive speech listening; (b) areas activated more by
listening to music than speech or the opposite 406 9.2 The main
processes involved in speech perception and comprehension 407 9.3 A
hierarchical approach to speech segmentation involving three levels or
tiers 410 9.4 A model of spoken-word comprehension 412 9.5 Gaze
probability for critical objects over the ﬁrst 1,000 ms since target
word onset for target neutral, competitor neutral, competitor
constraining and unrelated neutral conditions 414 9.6 Mean target
duration required for target recognition for words and sounds presented
in isolation or within a general sentence context 420 9.7 The basic
TRACE model, showing how activation between the three levels (word,
phoneme and feature) is inﬂuenced by bottom-up and top-down processing.
421

Illustrations

9.8

9.9 9.10 9.11 9.12 9.13 9.14

9.15 9.16 9.17 9.18

9.19

9.20 10.1 10.2 10.3

10.4 10.5 10.6 10.7

10.8 10.9 10.10

(a) Actual eye ﬁxations on the object corresponding to a spoken word or
    related to it; (b) predicted eye ﬁxations from the TRACE model Mean
    reaction times for recognition of /t/ and /k/ phonemes in words and
    non-words Fixation proportions to high-frequency target words during
    the ﬁrst 1,000 ms after target onset A sample display showing two
    nouns ("bench" and "rug") and two verbs ("pray" and "run").
    Processing and repetition of spoken words according to the
    three-route framework A general framework of the processes and
    structures involved in reading comprehension Estimated reading
    ability over a 30-month period with initial testing at a mean age of
    66 months for English, Spanish and Czech children McClelland and
    Rumelhart's (1981) interactive activation model of visual word
    recognition The time course of inhibitory and facilitatory eﬀects of
    priming Basic architecture of the dual-route cascaded model The
    three components of the triangle model and their associated neural
    regions: orthography, phonology and semantics Mean naming latencies
    for high-frequency and low-frequency words that were irregular or
    regular and inconsistent Key assumptions of the E-Z Reader model
    Total sentence processing time as a function of sentence type A
    model of language processing involving heuristic and algorithmic
    routes Sentence reading times as a function of the way in which
    comprehension was assessed: detailed questions; superﬁcial questions
    on all trials; or occasional superﬁcial questions The N400 responses
    to a critical word in correct and incorrect sentences Response times
    for literally false, scrambled metaphor, and metaphor sentences
    in (a) written and (b) spoken conditions) Mean reaction times to
    verify metaphor-relevant and metaphor-irrelevant properties Mean
    proportion of statements rated comprehensible with a response
    deadline of 500 or 1600 ms: literal, forward metaphors, reversed
    metaphors and scrambled metaphors Sample displays seen from the
    listener's perspective Proportion of ﬁxation on four objects over
    time A theoretical framework for reading comprehension involving
    interacting passive and reader-initiated processes

422 423 428 428 430 433

434 437 440 443

448

451 455 471 473

474 476 480 482

483 485 486

492

xxiii

xxiv

Illustrations

10.11 Reaction times to name colours when the word presented in colour
was predictable from the preceding text compared to a control condition
496 10.12 The construction--integration model 502 10.13 Forgetting
functions for situation, proposition and surface information over a
4-day period 503 10.14 The RI-Val model showing the eﬀects on
comprehension of resonance, integration and validation over time 506
11.1 Brain areas activated during speech comprehension and production
517 11.2 Correlations between aphasic patients' speech-production
abilities and their ability to detect their own speech-production errors
524 11.3 Speech-production processes for picture naming, with median
peak activation times 532 11.4 Speech-production processes: the timing
of activation associated with diﬀerent cognitive functions 534 11.5
Language-related regions and their connections in the left hemisphere
536 11.6 Semantic and syntactic errors made by: healthy controls and
patients with no damage to the dorsal or ventral pathway, damage to the
ventral pathway only, damage to the dorsal pathway only and damage to
both pathways 540 11.7 A sample array with six diﬀerent garments
coloured blue or green 544 11.8 Architecture of the forward modelling
approach to explaining audience design eﬀects 546 11.9 Hayes' (2012)
writing model: (1) control level; (2) writing process level; and (3)
resource level 552 11.10 The frequency of three major writing processes
(planning, translating and revising) across the three phases of writing
553 11.11 Kellogg's three-stage theory of the development of writing
skill 554 11.12 Brain areas activated during handwriting tasks 559 11.13
The cognitive architectures for (a) reading and (b) spelling 560 11.14
Brain areas in the left hemisphere associated with reading, letter
perception and writing 563 12.1 Explanation of the solution to the Monty
Hall problem 575 12.2 Brain areas involved in (a) mathematical problem
solving; (b) verbal problem solving; (c) visuo-spatial problem solving;
and (d) areas common to all three problem types (conjunction) 577 12.3
The mutilated draughtboard problem 577 12.4 Flow chart of insight
problem solving 580 12.5 (a) The nine-dot problem and (b) its solution
580 12.6 Two of the matchstick problems used by Knoblich et al. (1999)
with cumulative solution rates 581 12.7 The multiplying billiard balls
trick 582 12.8 The two-string problem 583 12.9 Some of the materials for
participants instructed to mount a candle on a vertical wall in
Duncker's (1945) study 585

Illustrations

12.10 Mean percentages of correct solutions as a function of problem
type and working memory capacity 587 12.11 The initial state of the
ﬁve-disc version of the Tower of Hanoi problem 588 12.12 Tower of London
task (two-move and ﬁve-move problems) 590 12.13 A problem resembling
those used on the Raven's Progressive Matrices 594 12.14 Relational
reasoning: the probabilities of successful encoding, inferring, mapping
and applying for lower and high performers 597 12.15 Major processes
involved in performance of numerous cognitive tasks 598 12.16 Summary of
key brain regions and their associated functions in relational reasoning
based on patient and neuroimaging studies 599 12.17 Mean strength of the
ﬁrst-mentioned chess move and the move chosen as a function of problem
diﬃculty by experts and by tournament players 603 12.18 A theoretical
framework of the main cognitive processes and potential errors in
medical decision-making 605 12.19 Eye ﬁxations of a pathologist given
the same biopsy whole-slide image (a) starting in year 1 and (d) ending
in year 4 606 12.20 Brain activation while diagnosing lesions in X-rays,
naming animals and naming letters 608 12.21 Brain image showing areas in
the primary motor cortex with diﬀerences in relative voxel size between
trained children and non-trained controls: (a) changes in relative voxel
size over time; (b) correlation between improvement in motor-test
performance and change in relative voxel size 611 12.22 Brain image
showing areas in the primary auditory area with diﬀerences in relative
voxel size between trained children and non-trained controls: (a)
changes in relative voxel size over time; (b) correlation between
improvement in a melody-rhythm test and change in relative voxel size
612 12.23 Mean chess ratings of candidates, non-candidate grandmasters
and all non-grandmasters as a function of number of games played 616
12.24 The main factors (genetic and environmental) inﬂuencing the
development of expertise 617 13.1 Percentages of correct responses and
various incorrect responses with the false-positive and benign cyst
scenarios 627 13.2 Percentage of correct predictions of the judged
frequencies of diﬀerent causes of death based on the aﬀect heuristic
(overall dread score), aﬀect heuristic and availability 628 13.3
Percentage of correct inferences on four tasks 632 13.4 A hypothetical
value function 642 13.5 Ratings of competence satisfaction for the
sunk-cost option and the alternative option for those selecting each
option 644

xxv

xxvi

Illustrations

13.6 13.7

13.8 13.9 13.10 13.11 14.1 14.2 14.3

14.4

14.5 14.6 14.7 14.8

14.9

14.10 14.11 14.12 15.1

15.2 15.3

15.4

Risk aversion for gains and risk seeking for losses on a money-based
task by ﬁnancial professionals and students Percentages of participants
adhering to cumulative prospect theory, the minimax rule, or unclassiﬁed
with aﬀect-poor and aﬀect-rich problems (a) with or (b) without
numerical information concerning willingness to pay for medication
Proportion of politicians and population samples in Belgium, Canada and
Israel voting to extend a loan programme A model of selective exposure:
defence motivation and accuracy motivation The ﬁve phases of
decision-making according to Galotti's theory Klein's recognition-primed
decision model Mean number of modus ponens inferences accepted as a
function of relative strength of the evidence and strategy The Wason
selection task Percentage acceptance of conclusions as a function of
perceived base rate (low vs high), believability of conclusions and
validity of conclusions Three models of the relationship between the
intuitive and deliberate systems: (a) serial model; (b) parallel model;
and (c) logical intuition model Proportion correct on incongruent
syllogisms as a function of instructions and cognitive ability The
approximate time courses of reasoning and metareasoning processes during
reasoning and problem solving Brain regions most consistently activated
across 28 studies of deductive reasoning Relationships between reasoning
task performance (accuracy) and inferior frontal cortex activity in the
left hemisphere and the right hemisphere in (a) the low-load condition
and (b) the high-load condition Mean responses to the question, "How
much risk do you believe climate change poses to human health, safety or
prosperity?" Eﬀects of trustworthiness and others' opinions on
convincingness ratings Mean-rated argument strength as a function of the
probability of the outcome and how negative the outcome would be
Stanovich's tripartite model of reasoning The two-dimensional framework
for emotion showing the two dimensions of pleasure--misery and
arousal--sleep and the two dimensions of positive aﬀect and negative
aﬀect Brain areas activated by positive, negative and neutral stimuli
Brain areas showing greater activity for top-down than for bottom-up
processing and those showing greater activity for bottom-up than for
top-down processes Multiple appraisal mechanisms used in emotion
generation

645

650 654 659 660 661 676 676

679

685 687 689 690

692

696 700 701 706

716 717

718 720

Illustrations

15.5

15.6

15.7 15.8 15.9

15.10

15.11 15.12 15.13

15.14

15.15 15.16 15.17 15.18

15.19

15.20 15.21 15.22 15.23 15.24 16.1

16.2

Changes in self-reported horror and distress and in galvanic skin
response between pre-training and post-training (for the watch condition
and the appraisal condition) A process model of emotion regulation based
on ﬁve major types of strategy (situation selection, situation
modiﬁcation, attention deployment, cognitive change and response
modulation) Mean level of depression as a function of stress severity
and cognitive reappraisal ability A three-stage neural network model of
emotion regulation The incompatibility ﬂanker eﬀect (incompatible trials
-- compatible trials) on reaction times as a function of mood (happy or
sad) and whether a global, local or mixed focus had been primed on a
previous task Two main brain mechanisms involved in the memoryenhancing
eﬀects of emotion: (1) the medial temporal lobes; (2) the medial,
dorsolateral and ventrolateral prefrontal cortex (a) Free and (b) cued
recall as a function of mood state (happy or sad) at learning and at
recall Two well-known moral dilemma problems: (a) the trolley problem;
and (b) the footbridge problem The dorsolateral prefrontal cortex,
located approximately in Brodmann areas 9 and 46 and the ventromedial
prefrontal cortex located approximately in Brodmann areas 10 and 11
Sensitivity to consequences, sensitivity to moral norms and preference
for inaction vs action as a function of psychopathy (low vs high)
Driverless cars: moral decisions Eﬀects of mood manipulation (anxiety,
sadness or neutral) on percentages of people choosing a high-risk job
option Mean buying price for a water bottle as a function of mood
(neutral vs sad) and self-focus (low vs high) The positive emotion
"family tree" with the trunk representing the neural reward system and
the branches representing nine semi-distinct positive emotions
Probability of selecting a candy bar by participants in a happy or sad
mood as a function of implicit attitudes on the Implicit Association
Test Eﬀects of mood states on judgement and decision-making. The
emotion-imbued choice model The dot-probe task The emotional Stroop task
The impaired cognitive control account put forward by Joormann et
al. (2007) Mean scores for error detection on a proofreading task
comparing unconscious goal vs no-goal control and low vs. high goal
importance Awareness as a social perceptual model of attention

721

725 727 728

733

735 737 738

739

741 742 745 746

748

750 750 752 756 756 761

770 771

xxvii

xxviii

Illustrations

16.3

16.4 16.5

16.6

16.7 16.8

16.9

16.10 16.11

16.12

16.13

16.14

(a) Region in left fronto-polar cortex for which decoding of upcoming
    motor decisions was possible. (b) Decoding accuracy of these
    decisions 774 Undistorted and distorted photographs of the Brunnen
    der Lebensfreude in Rostock, Germany 777 Modulation of the
    appropriate frequency bands of the EEG signal associated with motor
    imagery in one healthy control and three patients 779 Activation
    patterns on a binocular-rivalry task when observers

<!-- -->

(A) reported what they perceived or (B) passively experienced rivalry
    781 Three successive stages of visual processing following stimulus
    presentation 782 Percentage of trials on which participants reported
    awareness of the content of photographs under masked and unmasked
    conditions for animal and non-animal photographs 783 Five hypotheses
    about the relationship between attention and conscious awareness
    identiﬁed by Webb and Graziano 785 Event-related potential waveforms
    in the aware-correct, unaware-correct and unaware-incorrect
    conditions 786 Synchronisation of neural activity across cortical
    areas for consciously perceived words (visible condition) and
    nonperceived words (invisible condition) during diﬀerent time
    periods 787 Integrated brain activity: (a) overall information
    sharing or integration across the brain for vegetative state,
    minimally conscious and conscious brain-damaged patients and healthy
    controls); (b) information sharing (integration) across short,
    medium and long distances within the brain for the four groups 788
    Event-related potentials in the left and right hemispheres to the
    ﬁrst of two stimuli by AC (a patient with severe corpus callosum
    damage) 796 Detection and localisation of circles presented to the
    left or right visual ﬁelds by two patients responding verbally, with
    the left or right hand 797

Preface Producing regular editions of this textbook gives us a front-row
seat from which to observe all the exciting developments in our
understanding of human cognition. What are the main reasons for the
rapid rate of progress within cognitive psychology since the seventh
edition of this textbook? Below we identify two factors that have been
especially important. First, the overarching assumption that the optimal
way to enhance our understanding of cognition is by combining data and
insights from several diﬀerent approaches remains exceptionally
fruitful. These approaches include traditional cognitive psychology;
cognitive neuropsychology (study of brain-damaged patients);
computational cognitive science (development of computational models of
human cognition); and cognitive neuroscience (combining information from
behaviour and from brain activity). Note that we use the term "cognitive
psychology" in a broad or general sense to cover all these approaches.
The above approaches all continue to make extremely valuable
contributions. However, cognitive neuroscience deserves to be singled
out -- it has increasingly been used with great success to resolve
theoretical controversies and to provide novel empirical data that
foster theoretical developments. Second, there has been a steady
increase in cognitive research of direct relevance to real life. This is
reﬂected in a substantial increase in the number of boxes labelled "in
the real world" in this edition compared to the previous one. Examples
include eyewitness conﬁdence, mishearing of song lyrics, multi-tasking,
airport security checks and causes of plane crashes. What is noteworthy
is the increased quality of real-world research (e.g., more
sophisticated experimental designs; enhanced theoretical relevance).
With every successive edition of this textbook, the authors have had to
work harder and harder to keep with huge increase in the number of
research publications in cognitive psychology. For example, the ﬁrst
author wrote parts of the book in far-ﬂung places including Botswana,
New Zealand, Malaysia and Cambodia. His only regret is that book writing
has sometimes had to take precedence over sightseeing! We would both
like to thank the very friendly and eﬃcient staﬀ at Psychology Press
including Sadé Lee and Ceri McLardy.

xxx

Preface

We would also like to thank the anonymous reviewers, that commented on
various chapters. Their comments were very useful when we embarked on
the task of revising the ﬁrst draft of the manuscript. Of course, we are
responsible for any errors and/or misunderstandings that remain. Michael
Eysenck and Mark Keane

Visual tour (how to use this book) TEXTBOOK FEATURES Listed below are
the various pedagogical features that can be found both in the margins
and within the main text, with visual examples of the boxes to look out
for, and descriptions of what you can expect them to contain.

Key terms Throughout the book, key terms are highlighted in the text and
deﬁned in boxes in the margins, helping you to get to grips with the
vocabulary fundamental to the subject being covered.

In the real world Each chapter contains boxes within the main text that
explore "real world" examples, providing context and demonstrating how
some of the theories and concepts covered in the chapter work in
practice.

Chapter summary Each chapter concludes with a brief summary of each
section of the chapter, helping you to consolidate your learning by
making sure you have taken in all of the concepts covered.

Further reading Also at the end of each chapter is an annotated list of
key scholarly books, book chapters, and journal articles that it is
recommended you explore through independent study to expand upon the
knowledge you have gained from the chapter and plan for your
assignments.

xxxii

Visual tour (how to use this book)

Links to companion website features Whenever you see this symbol, look
out for related supplementary material amongst the resources for that
chapter on the companion website at www. routledge.com/cw/eysenck.

Glossary An extensive glossary appears at the end of the book, oﬀering a
comprehensive list that includes all the key terms boxes in the main
text.

Chapter

Approaches to human cognition

1

INTRODUCTION We are now well into the third millennium and there is
ever-increasing interest in unravelling the mysteries of the human brain
and mind. This interest is reﬂected in the substantial upsurge of
scientiﬁc research within cognitive psychology and cognitive
neuroscience. In addition, the cognitive approach has become
increasingly inﬂuential within clinical psychology. In that area, it is
recognised that cognitive processes (especially cognitive biases) play a
major role in the development (and successful treatment) of mental
disorders (see Chapter 15). In similar fashion, social psychologists
increasingly focus on social cognition. This focuses on the role of
cognitive processes in inﬂuencing individuals' behaviour in social
situations. For example, suppose other people respond with laughter when
you tell them a joke. This laughter is often ambiguous -- they may be
laughing with you or at you (Walsh et al., 2015). Your subsequent
behaviour is likely to be inﬂuenced by your cognitive interpretation of
their laughter. What is cognitive psychology? It is concerned with the
internal processes involved in making sense of the environment and
deciding on appropriate action. These processes include attention,
perception, learning, memory, language, problem solving, reasoning and
thinking. We can deﬁne cognitive psychology as aiming to understand
human cognition by observing the behaviour of people performing various
cognitive tasks. However, the term "cognitive psychology" can also be
used more broadly to include brain activity and structure as relevant
information for understanding human cognition. It is in this broader
sense that it is used in the title of this book. Here is a simple
example of cognitive psychology in action. Frederick (2005) developed a
test (the Cognitive Reﬂection Test) that included the following item: A
bat and a ball cost \$1.10 in total. The bat costs \$1.00 more than the
ball. How much does the ball cost? \_\_\_ cents

KEY TERMS Social cognition An approach within social psychology in which
the emphasis is on the cognitive processing of information about other
people and social situations. Cognitive psychology An approach that aims
to understand human cognition by the study of behaviour; a broader
deﬁnition also includes the study of brain activity and structure.

2

Approaches to human cognition

KEY TERM

What do you think is the correct answer? Braňas-Garza et al. (2015)
found in a review of ﬁndings from 41,004 individuals that 68% produced
the wrong answer (typically 10 cents) and only 32% gave the right answer
(5 cents). Even providing ﬁnancial incentives to produce the correct
answer failed to improve performance. The above ﬁndings suggest most
people will rapidly produce an incorrect answer (i.e., 10 cents) that is
easily accessible and are unwilling to devote extra time to checking
that they have the right answer. However, Gangemi et al. (2015) found
many individuals producing the wrong answer had a feeling of error
suggesting they experienced cognitive uneasiness about their answer. In
sum, the intriguing ﬁndings on the Cognitive Reﬂection Test indicate
that we can fail to think eﬀectively even on relatively simple problems.
Subsequent research has clariﬁed the reasons for these deﬁciencies in
our thinking (see Chapter 12). The aims of cognitive neuroscientists
overlap with those of cognitive psychologists. However, there is one
major diﬀerence between cognitive neuroscience and cognitive psychology
in the narrow sense. Cognitive neuroscientists argue convincingly we
need to study the brain as well as behaviour while people engage in
cognitive tasks. After all, the internal processes involved in human
cognition occur in the brain. Cognitive neuroscience uses information
about behaviour and the brain to understand human cognition. Thus, the
distinction between cognitive neuroscience and cognitive psychology in
the broader sense is blurred. Cognitive neuroscientists explore human
cognition in several ways. First, there are brain-imaging techniques of
which functional magnetic resonance imaging (fMRI) is probably the
best-known. Second, there are electrophysiological techniques involving
the recording of electrical signals generated by the brain. Third, many
cognitive neuroscientists study the eﬀects of brain damage on cognition.
It is assumed the patterns of cognitive impairment shown by
brain-damaged patients can inform us about normal cognitive functioning
and the brain areas responsible for various cognitive processes. The
huge increase in scientiﬁc interest in the workings of the brain is
mirrored in the popular media -- numerous books, ﬁlms and television
programmes communicate the more accessible and dramatic aspects of
cognitive neuroscience. Increasingly, media coverage includes coloured
pictures of the brain indicating the areas most activated when people
perform various tasks.

Cognitive neuroscience An approach that aims to understand human
cognition by combining information from behaviour and the brain.

Four main approaches We can identify four main approaches to human
cognition (see Table 1.1). Note, however, there has been a substantial
increase in research combining two (or even more) of these approaches.
We will shortly discuss each approach in turn and you will probably ﬁnd
it useful to refer back to this chapter when reading the rest of the
book. Hopefully, you will ﬁnd Table 1.3 (towards the end of this
chapter) especially useful because it summarises the strengths and
limitation of all four approaches.

Approaches to human cognition

3

TABLE 1.1 APPROACHES TO HUMAN COGNITION

KEY TERM

1.  

Cognitive psychology: this approach involves using behavioural evidence
to enhance our understanding of human cognition. Since behavioural data
are also of great importance within cognitive neuroscience and cognitive
neuropsychology, cognitive psychology's inﬂuence is enormous.

2.  

Cognitive neuropsychology: this approach involves studying brain-damaged
patients to understand normal human cognition. It was originally closely
linked to cognitive psychology but has recently also become linked to
cognitive neuroscience.

Algorithm A computational procedure providing a speciﬁed set of steps to
problem solution; see heuristic.

3.  

Cognitive neuroscience: this approach involves using evidence from
behaviour and the brain to understand human cognition.

4.  

Computational cognitive science: this approach involves developing
computational models to further our understanding of human cognition;
such models increasingly incorporate knowledge of behaviour and the
brain. A computational model takes the form of an algorithm, which
consists of a precise and detailed speciﬁcation of the steps involved in
performing a task. Computational models are designed to simulate or
imitate human processing on a given task.

COGNITIVE PSYCHOLOGY We can obtain some perspective on the contribution
of cognitive psychology by considering what preceded it. Behaviourism
was the dominant approach to psychology throughout the ﬁrst half of the
twentieth century. The American psychologist John Watson (1878--1958) is
often regarded as the founder of behaviourism. He argued that
psychologists should focus on stimuli (aspects of the immediate
situation) and responses (behaviour produced by the participants in an
experiment). This approach appears "scientiﬁc" because it focuses on
stimuli and responses, both of which are observable. Behaviourists
argued that internal mental processes (e.g., attention) cannot be
veriﬁed by reference to observable behaviour and so should be ignored.
According to Watson (1913, p. 165), behaviourism should "never use the
terms consciousness, mental states, mind, content, introspectively
veriﬁable and the like". In stark contrast, as we have already seen,
cognitive psychologists argue it is of crucial importance to study such
internal mental processes. Hopefully, you will be convinced that
cognitive psychologists are correct when you read how the concepts of
attention (Chapter 5) and consciousness (Chapter 16) have been used
fruitfully to enhance our understanding of human cognition. It is often
claimed that behaviourism was overthrown by the "cognitive revolution".
However, the reality was less dramatic (Hobbs & Burman, 2009). For
example, Tolman (1948) was a behaviourist but he did not believe
internal processes should be ignored. He carried out studies in which
rats learned to run through a maze to a goal box containing food. When
Tolman blocked oﬀ the path the rats had learned to use, they rapidly
learned to follow other paths leading in the right general direction.
Tolman concluded the rats had acquired an internal cognitive map
indicating the maze's approximate layout. It is almost as pointless to
ask "When did cognitive psychology start?", as to enquire "How long is a
piece of string?". However, 1956 was crucially

4

Approaches to human cognition

important. At a meeting at the Massachusetts Institute of Technology,
Noam Chomsky presented his theory of language, George Miller discussed
Bottom-up processing the magic number seven in short-term memory
(Miller, 1956) and Alan Processing directly Newell and Herbert Simon
discussed the General Problem Solver (see inﬂuenced by environmental
stimuli; see Gobet and Lane, 2015). In addition, there was the ﬁrst
systematic attempt top-down processing. to study concept formation from
the cognitive perspective (Bruner et al., 1956). The history of
cognitive psychology from the perspective of its Serial processing
Processing in which one classic studies is discussed in Eysenck and
Groome (2015a). process is completed Several decades ago, most cognitive
psychologists subscribed to the before the next one starts;
information-processing approach based loosely on an analogy between see
parallel processing. the mind and the computer (see Figure 1.1). A
stimulus (e.g., a problem Top-down processing or task) is presented,
which causes various internal processes to occur, Stimulus processing
that leading eventually to the desired response or answer. Processing
directly is inﬂuenced by factors aﬀected by the stimulus input is often
described as bottom-up processing. such as the individual's It was
typically assumed only one process occurs at a time: this is serial past
experience and expectations. processing, meaning the current process is
completed before the onset of the next one. The above approach is
drastically oversimpliﬁed. Task processing typically also involves
top-down processing, which is processing inﬂuenced by the individual's
expectations and knowledge rather than simply by the stimulus itself.
Read what it says in the triangle (Figure 1.2). Unless you know the
trick, you probably read it as "Paris in the spring". If so, look again:
the word "the" is repeated. Your expectation it was a wellknown phrase
(i.e., top-down processing) dominated the information available from the
stimulus (i.e., bottom-up processing). The traditional approach was also
oversimpliﬁed in assuming processing is typically serial. In fact, more
than one process typically occurs at the same time -- this is parallel
processing. We are much more likely to use parallel processing when
performing a highly Figure 1.1 practised task than a new one (see
Chapter An early version of the information processing approach. 5). For
example, someone taking their ﬁrst driving lesson ﬁnds it very hard to
control the car's speed, steer accurately and pay attention to other
road users at the same time. In contrast, an experienced driver ﬁnds it
easy. There is also cascade processing: a form of parallel processing
involving an overlap of diﬀerent processing stages when someone performs
a task. More speciﬁcally, later stages of processing are initiated
before one or more earlier stages have ﬁnished. For example, suppose you
are trying to work out Figure 1.2 Diagram to demonstrate top--down
processing. the meaning of a visually presented word.

KEY TERMS

Approaches to human cognition

The most thorough approach would involve identifying all the letters in
the word followed by matching the resultant letter string against words
you have stored in long-term memory. In fact, people often engage in
cascade processing -- they form hypotheses as to the word that has been
presented before identifying all the letters (McClelland, 1979). An
important issue for cognitive psychologists is the task-impurity problem
-- most cognitive tasks require several processes thus making it hard to
interpret the ﬁndings. One approach to this problem is to consider
various tasks all requiring the same process. For example, Miyake et
al. (2000) used three tasks requiring deliberate inhibition of a
dominant response: (1)

(2) 
(3) 

The Stroop task: name the colour in which colour words are presented
(e.g., RED printed in green) and avoid saying the colour word (which has
to be inhibited). You can see for yourself how hard this task is by
naming the colours of the words shown in Figure 1.3. The anti-cascade
task: inhibit the natural tendency to look at a visual cue and instead
look in the opposite direction. People typically take longer to perform
this task than the control task of simply looking at the visual cue. The
stop-signal task: respond rapidly to indicate whether each of a series
of words is an animal or non-animal; on key trials, there was a
computer-emitted tone indicating that the response should be inhibited.

Miyake et al. (2000) found all three tasks involved similar processes.
They used complex statistical techniques (latent variable analysis) to
extract what

Figure 1.3 Test yourself by naming the colours in each column. You
should name the colours rapidly in the ﬁrst three columns because there
is no colour-word conﬂict. In contrast, colour naming should be slower
(and more prone to error) when naming colours in the fourth and ﬁfth
columns.

5

KEY TERMS Parallel processing Processing in which two or more cognitive
processes occur at the same time. Cascade processing Later processing
stages start before earlier processing stages have been completed when
performing a task.

6

Approaches to human cognition

KEY TERMS

was common across the three tasks. This was assumed to represent a
relatively pure measure of the inhibitory process. Throughout this book,
we will discuss many ingenious strategies used by cognitive
psychologists to identify the processes used in numerous tasks.

Ecological validity The applicability (or otherwise) of the ﬁndings of
laboratory studies to everyday settings. Implacable experimenter The
situation in experimental research in which the experimenter's behaviour
is uninﬂuenced by the participant's behaviour.

Strengths Cognitive psychology was for many years the engine room of
progress in understanding human cognition and the other three approaches
listed in Table 1.1 have beneﬁtted from it. For example, cognitive
neuropsychology became important 25 years after cognitive psychology. It
was only when cognitive psychologists had developed reasonable accounts
of healthy human cognition that the performance of brain-damaged
patients could be understood fully. Before that, it was hard to decide
which patterns of cognitive impairment were theoretically important. In
a similar fashion, the computational modelling activities of
computational cognitive scientists are typically heavily inﬂuenced by
precomputational psychological theories. Finally, the great majority of
theories driving research in cognitive neuroscience originated within
cognitive psychology. Cognitive psychology has not only had a massive
inﬂuence on theorising across all four major approaches to human
cognition. It has also had a predominant inﬂuence on the development of
cognitive tasks and on task analysis (how a task is accomplished).

Limitations In spite of cognitive psychology's enormous contributions,
it has several limitations. First, our behaviour in the laboratory may
diﬀer from our behaviour in everyday life. Thus, laboratory research
sometimes lacks ecological validity -- the extent to which laboratory
ﬁndings are applicable to everyday life. For example, our everyday
behaviour is often designed to change a situation or to inﬂuence others'
behaviour. In contrast, the sequence of events in most laboratory
research is based on the experimenter's predetermined plan and is
uninﬂuenced by participants' behaviour. Wachtel (1973) used the term
implacable experimenter to describe this state of aﬀairs. We must not
exaggerate problems associated with lack of ecological validity. As we
will see in this book, there has been a dramatic increase in applied
cognitive psychology in which the emphasis is on investigating topics of
general importance. Such research often has good ecological validity.
Note that it is far better to carry out well-controlled experiments
under laboratory conditions than poorly controlled experiments under
naturalistic conditions. It is precisely because it is considerably
easier for researchers to exercise experimental control in the
laboratory that so much research is laboratory-based. Second, theories
in cognitive psychology are often expressed only in verbal terms
(although this is becoming less common). Such theories are vague, making
it hard to know precisely what predictions follow from them and thus to
falsify them. These limitations can largely be overcome by

Approaches to human cognition

computational cognitive scientists developing cognitive models
specifying precisely any given theory's assumptions. Third, diﬃculties
in falsifying theories have led to a proliferation of diﬀerent theories
on any given topic. For example, there are at least 12 diﬀerent theories
of working memory (see Chapter 6). Another reason for the proliferation
of rather similar theories is the "toothbrush problem" (Mischel, 2008):
no self-respecting cognitive psychologist wants to use anyone else's
theory. Fourth, the ﬁndings obtained using any given task or paradigm
are sometimes speciﬁc to that paradigm and do not generalise to other
(apparently similar) tasks. This is paradigm speciﬁcity. It means some
ﬁndings are narrow in scope and applicability (Meiser, 2011). This
problem can be minimised by developing theories accounting for
performance across several tasks or paradigms. For example, Anderson et
al. (2004; discussed later in this chapter) developed a comprehensive
theoretical architecture or framework known as the Adaptive Control of
Thought-Rational (ACT-R) model. Fifth, cognitive psychologists typically
obtain measures of performance speed and accuracy. These measures are
very useful but provide only indirect evidence about internal cognitive
processes. Most tasks are "impure" in that they involve several
processes, and it is hard to identify the number and nature of processes
involved on the basis of speed and accuracy measures.

COGNITIVE NEUROPSYCHOLOGY Cognitive neuropsychology focuses on the
patterns of cognitive performance (intact and impaired) of brain-damaged
patients having a lesion (structural damage to the brain caused by
injury or disease). According to cognitive neuropsychologists, studying
brain-damaged patients can tell us much about cognition in healthy
individuals. The above idea does not sound very promising, does it? In
fact, however, cognitive neuropsychology has contributed substantially
to our understanding of healthy human cognition. For example, in the
1960s, most memory researchers thought the storage of information in
longterm memory depended on previous processing in short-term memory
(see Chapter 6). However, Shallice and Warrington (1970) reported the
case of a brain-damaged man, KF. His short-term memory was severely
impaired but his long-term memory was intact. These ﬁndings played an
important role in changing theories of healthy human memory. Since
cognitive neuropsychologists study brain-damaged patients, we might
imagine they would be interested in the workings of the brain. In fact,
many cognitive neuropsychologists pay little attention to the brain
itself. According to Coltheart (2015, p. 198), for example, "Even though
cognitive neuropsychologists typically study people with brain damage, .
. . cognitive neuropsychology is not about the brain: it is about
information-processing models of cognition." An increasing number of
cognitive neuropsychologists disagree with Coltheart. They believe we
should consider the brain, using techniques such as magnetic resonance
imaging to identify the brain areas damaged in any given patient. They
are also increasingly willing to study the impact of brain damage on
brain processes using various neuroimaging techniques.

7

KEY TERMS Paradigm speciﬁcity The ﬁndings with a given experimental task
or paradigm are not replicated even when apparently very similar tasks
or paradigms are used. lesion Damage within the brain resulting from
injury or disease; it typically affects a restricted area.

8

Approaches to human cognition

Theoretical assumptions

Max Coltheart. Courtesy of Max Coltheart.

KEY TERM Modularity The assumption that the cognitive system consists of
many fairly independent or separate modules or processors, each
specialised for a given type of processing.

Coltheart (2001) provided a very clear account of the major assumptions
of cognitive neuropsychology. Here we will discuss these assumptions and
brieﬂy consider relevant evidence. One key assumption is modularity,
meaning the cognitive system consists of numerous modules or processors
operating fairly independently or separately of each other. It is
assumed these modules exhibit domain speciﬁcity (they respond to only
one given class of stimuli). For example, there may be a
face-recognition module that responds only when a face is presented.
Modular systems typically involve serial processing with processing
within one module being completed before processing starts in the next
module. As a result, there is very limited interaction among modules.
There is some support for modularity from the evolutionary approach.
Species with larger brains generally have more specialised brain regions
that could be involved in modular processing. However, the notion that
human cognition is heavily modular is hard to reconcile with
neuroimaging evidence. The human brain possesses a moderately high level
of connectivity (Bullmore & Sporns, 2012; see p. 14), suggesting there
is more parallel processing than assumed by most cognitive
neuropsychologists. The second major assumption is that of anatomical
modularity. According to this assumption, each module is located in a
speciﬁc brain area. Why is this assumption important? Cognitive
neuropsychologists are most likely to make progress when studying brain
patients with brain damage limited to a single module. Such patients may
not exist if there is no anatomical modularity. Suppose all modules were
distributed across large brain areas. If so, the great majority of
brain-damaged patients would suﬀer damage to most modules, making it
impossible to work out the number and nature of their modules. There is
evidence of anatomical modularity in the visual processing system (see
Chapter 2). However, there is less support for anatomical modularity
with most complex tasks. For example, consider the ﬁndings of Yarkoni et
al. (2011). Across over 3,000 neuroimaging studies, some brain areas
(e.g., dorsolateral prefrontal cortex; anterior cingulate cortex) were
activated in 20% of them despite the great diversity of tasks involved.
The third major assumption (the "universality assumption") is that
"Individuals . . . share a similar or an equivalent organisation of
their cognitive functions, and presumably have the same underlying brain
anatomy"

Approaches to human cognition

(de Schotten and Shallice, 2017, p. 172). If this assumption (also
common within cognitive neuroscience) is false, we could not readily use
the ﬁndings from individual patients to draw conclusions about the
organisation of other people's cognitive systems or functional
architecture. There is accumulating evidence against the universality
assumption. Tzourio-Mazoyer et al. (2004) discovered substantial
diﬀerences between individuals in the location of brain networks
involved in speech and language. Finn et al. (2015) found clear-cut
diﬀerences between individuals in functional connectivity across the
brain, concluding that "An individual's functional brain connectivity
proﬁle is both unique and reliable, similarly to a ﬁngerprint"
(p. 1669). Duﬀau (2017) reviewed interesting research conducted on
patients during surgery for epilepsy or a tumour. Direct electrical
stimulation, which causes "a genuine virtual transient lesion" (p. 305)
is applied invasively to the cortex. The patient is awakened and given
various cognitive tasks while receiving stimulation. Impaired
performance when direct electrical stimulation is applied to a given
area indicates that area is involved in the cognitive functions assessed
by the current task. Findings obtained using direct electrical
stimulation and other techniques (e.g., fMRI) led Duﬀau (2017) to
propose a two-level model. At the cortical level, there is high
variability across individuals in structure and function of any given
brain areas. At the subcortical level (e.g., in premotor cortex), in
contrast, there is very little variability across individuals. The
ﬁndings at the cortical level seem inconsistent with the universality
assumption. The fourth assumption is subtractivity. The basic idea is
that brain damage impairs one or more processing modules but does not
change or add anything. The ﬁfth assumption (related to subtractivity)
is transparency (Shallice, 2015). According to the transparency
assumption, the performance of a brain-damaged patient reﬂects the
operation of a theory designed to explain the performance of healthy
individuals minus the impact of their lesion. Why are the subtractivity
and transparency assumptions important? Suppose they are incorrect and
brain-damaged patients develop new modules to compensate for their
cognitive impairments. That would greatly complicate the task of
learning about the intact cognitive system by studying brain-damaged
patients. Consider pure alexia, a condition in which brain-damaged
patients have severe reading problems but otherwise intact language
abilities. These patients generally have a direct relationship between
word length and reading speed due to letter-by-letter processing
(Bormann et al., 2015). This indicates the use of a compensatory
strategy diﬀering markedly from the reading processes used by healthy
adults.

Research in cognitive neuropsychology How do cognitive
neuropsychologists set about understanding the cognitive system? Of
major importance is the search for dissociations, which occur when a
patient has normal performance on one task (task X) but is impaired on a
second one (task Y). For example, amnesic patients perform almost
normally on short-term memory tasks but are greatly impaired on many

9

KEY TERM Pure alexia Severe problems with reading but not other language
skills; caused by damage to brain areas involved in visual processing.

10

Approaches to human cognition

KEY TERMS

long-term memory tasks (see Chapter 6). It is tempting (but dangerous!)
to conclude that the two tasks involve diﬀerent processing modules and
that the module(s) needed on long-term memory tasks have been damaged by
brain injury. Why must we avoid drawing sweeping conclusions from
dissociations? Patients may perform well on one task but poorly on a
second one simply because the second task is more complex. Thus,
dissociations may reﬂect diﬀerences in task complexity rather than the
use of diﬀerent modules. One apparent solution to the above problem is
to ﬁnd double dissociations. A double dissociation between two tasks (X
and Y) is obtained when one patient performs normally on task X and is
impaired on task Y but another patient shows the opposite pattern. We
cannot explain double dissociations by arguing that one task is harder.
For example, consider the double dissociation that amnesic patients have
impaired long-term memory but intact short-term memory whereas other
patients (e.g., KF discussed above) have the opposite pattern. This
double dissociation strongly suggests there is an important distinction
between short-term and long-term memory and that they involve diﬀerent
brain regions. The approach based on double dissociations has various
limitations. First, it is generally based on the assumption that
separate modules exist (which may be misguided). Second, double
dissociations can often be explained in various ways and so provide only
indirect evidence for separate modules underlying each task (Davies,
2010). For example, a double dissociation between tasks X and Y implies
the cognitive system used on X is not identical to the one used on Y.
Strictly speaking, the most we can generally conclude is that "Each of
the two systems has at least one sub-system that the other doesn't have"
(Bergeron, 2016, p. 818). Third, it is hard to decide which of the very
numerous double dissociations that have been discovered are
theoretically important. Finally, we consider associations. An
association occurs when a patient is impaired on tasks X and Y.
Associations are sometimes taken as evidence for a syndrome (sets of
symptoms or impairments often found together). However, there is a
serious ﬂaw in the syndrome-based approach. An association may be found
between tasks X and Y because the mechanisms on which they depend are
adjacent anatomically in the brain rather than because they depend on
the same underlying mechanism. Thus, the interpretation of associations
is fraught with diﬃculty.

Double dissociation The ﬁnding that some brain-damaged individuals have
intact performance on one task but poor performance on another task
whereas other individuals exhibit the opposite pattern. Association The
ﬁnding that certain symptoms or performance impairments are consistently
found together in numerous brain-damaged patients. Syndrome The notion
that symptoms that often co-occur have a common origin. Case-series
study A study in which several patients with similar cognitive
impairments are tested; this allows consideration of individual data and
of variation across individuals.

Single case studies vs case series For many years after the rise of
cognitive neuropsychology in the 1970s, most cognitive
neuropsychologists made extensive use of single-case studies. There were
two main reasons. First, researchers can often gain access to only one
patient having a given pattern of cognitive impairment. Second, it was
often assumed every patient has a somewhat diﬀerent pattern of cognitive
impairment and so is unique. As a result, it would be misleading and
uninformative to average the performance of several patients. In recent
years, there has been a move towards the case-series study. Several
patients with similar cognitive impairments are tested. After that,

Approaches to human cognition

the data of individual patients are compared and variation across
patients assessed. The case-series approach is generally preferable to
the single-case approach for various reasons (Lambon Ralph et al., 2011;
Bartolomeo et al., 2017). First, it provides much richer data. With a
case series, we can assess the extent of variation between patients
rather than simply being concerned about the impairment (as in the
single-case approach). Second, with a case series, we can identify (and
then de-emphasise) the ﬁndings from patients who are "outliers". With
the single-case approach, in contrast, we do not know whether the one
and only patient is representative of patients with that condition or is
an outlier.

Strengths Cognitive neuropsychology has several strengths. First, it has
the advantage that it allows us to draw causal inferences about the
relationship between brain areas and cognitive processes and behaviour.
In other words, we can conclude (with moderate but not total conﬁdence)
that a given brain area is crucially involved in performing certain
cognitive tasks (Genon et al., 2018). Second, as Shallice (2015,
pp. 387--388) pointed out, "A key intellectual strength of
neuropsychology . . . is its ability to provide evidence falsifying
plausible cognitive theories." Consider patients reading visually
presented words and non-words aloud. We might imagine patients with
damage to language areas would have problems in reading all words and
non-words. However, some patients perform reasonably well when reading
regular words (with predictable pronunciations) or non-words, but poorly
when reading irregular words (words with unpredictable pronunciations).
Other patients can read regular words but have problems with unfamiliar
words and non-words. These fascinating patterns of impairment have
transformed theories of reading (Coltheart, 2015; see Chapter 9). Third,
cognitive neuropsychology "produces large-magnitude phenomena which can
be initially theoretically highly counterintuitive" (Shallice, 2015,
p. 405). For example, amnesic patients typically have severely impaired
long-term memory for personal events and experiences but an essentially
intact ability to acquire and retain motor skills (Chapter 7). These
strong eﬀects played a major role in memory researchers abandoning the
notion of a single long-term memory system and replacing it with more
complex theories. Fourth, in recent years, cognitive neuropsychology has
increasingly been combined fruitfully with cognitive neuroscience. For
example, cognitive neuroscience has revealed that a given brain injury
or lesion often has widespread eﬀects within the brain. This phenomenon
is known as diaschisis: "the distant neurophysiological changes directly
caused by a focal injury . . . these changes should correlate with
behaviour" (Carrera & Tononi, 2014, p. 2410). Discovering the true
extent of the brain areas adversely aﬀected by a lesion facilitates the
task of relating brain functioning to cognitive processing and task
performance.

11

KEY TERM Diaschisis The disruption to distant brain areas caused by a
localised brain injury or lesion.

12

Approaches to human cognition

Limitations

KEY TERMS Sulcus A groove or furrow in the surface of the brain. Gyrus
Prominent elevated area or ridge on the brain's surface; "gyri" is the
plural. Dorsal Towards the top. Ventral Towards the bottom. Rostral
Towards the front of the brain.

What are the limitations of the cognitive neuropsychological approach?
First, the crucial assumption that the cognitive system is fundamentally
modular is reasonable but too strong. There is less evidence for
modularity among higher-level cognitive processes (e.g., consciousness;
focused attention) than among lower-level processes (e.g., colour
processing; motion processing). If the modularity assumption is
incorrect, this has implications for the whole enterprise of cognitive
neuropsychology (Patterson & Plaut, 2009). Second, other theoretical
assumptions also seem too extreme. For example, evidence discussed
earlier casts considerable doubts on the assumption of anatomical
modularity and the universality assumption. Third, the common assumption
that the task performance of patients provides relatively direct
evidence concerning the impact of brain damage on previously intact
cognitive systems is problematic. Brain-damaged patients often make use
of compensatory strategies to reduce or eliminate the negative eﬀects of
brain damage on cognitive performance. We saw an example of such
compensatory strategies earlier -- patients with pure alexia manage to
read words by using a letter-by-letter strategy rarely used by healthy
individuals. Hartwigsen (2018) proposed a model to predict when
compensatory processes will and will not be successful. According to
this model, general processes (e.g., attention; cognitive control; error
monitoring) can be used to compensate for the disruption of speciﬁc
processes (e.g., phonological processing) by brain injury. However,
speciﬁc processes cannot be used to compensate for the disruption of
general processes. Hartwigsen discussed evidence supporting his model.
Fourth, lesions can alter the organisation of the brain in several ways.
Dramatic evidence for brain plasticity is discussed in Chapter 16.
Patients whose entire left brain hemisphere was removed at an early age
(known as hemispherectomy) often develop good language skills even
though language is typically centred in the left hemisphere (Blackmon,
2016). There is the additional problem that a brain lesion can lead to
changes in the functional connectivity between the area of the lesion
and distant, intact brain areas (Bartolomeo et al., 2017). Thus,
impaired cognitive performance following brain damage may reﬂect
widespread reduced brain connectivity as well as direct damage to a
speciﬁc brain area. This complicates the task of interpreting the
ﬁndings obtained from brain-damaged patients.

Posterior Towards the back of the brain.

COGNITIVE NEUROSCIENCE: THE BRAIN IN ACTION

Lateral Situated at the side of the brain.

Cognitive neuroscience involves the intensive study of brain activity as
well as behaviour. Alas, the brain is extremely complicated (to put it
mildly!). It consists of 100 billion neurons connected in very complex
ways. We must consider how the brain is organised and how the diﬀerent
areas are described to understand research involving functional
neuroimaging. Below we discuss various ways of describing speciﬁc brain
areas.

Medial Situated in the middle of the brain.

Approaches to human cognition

13 Figure 1.4 The four lobes, or divisions, of the cerebral cortex in
the left hemisphere.

Interactive feature: Primal Pictures' 3D atlas of the brain

First, the cerebral cortex is divided into four main divisions or lobes
(see Figure 1.4). There are four lobes in each brain hemisphere:
frontal; parietal; temporal; and occipital. The frontal lobes are
divided from the parietal lobes by the central sulcus (sulcus means
furrow or groove), and the lateral ﬁssure separates the temporal lobes
from the parietal and frontal lobes. In addition, the parietooccipital
sulcus and pre-occipital notch divide the occipital lobes from the
parietal and temporal lobes. The main gyri (or ridges; gyrus is the
singular) within the cerebral cortex are shown in Figure 1.4.
Researchers use various terms to describe accurately the brain area(s)
activated during task performance: ● ● ● ● ● ●

dorsal (or superior): towards the top ventral (or inferior): towards the
bottom anterior (or rostral): towards the front posterior: towards the
back lateral: situated at the side medial: situated in the middle.

The German neurologist Korbinian Brodmann (1868--1918) produced a brain
map based on diﬀerences in the distributions of cell types across
cortical layers (see Figure 1.5).

Figure 1.5 Brodmann brain areas on the lateral (top ﬁgure) and medial
(bottom ﬁgure) surfaces.

14

Approaches to human cognition

KEY TERM

He identiﬁed 52 areas. We will often refer to areas, for example, as
BA17, which means Brodmann Area 17, rather than Brain Area 17! Within
cognitive neuroscience, brain areas are often described with reference
to their main functions. For example, Brodmann Area 17 (BA17) is
commonly called the primary visual cortex because it is strongly
associated with the early processing of visual stimuli.

Connectome A comprehensive wiring diagram of neural connections within
the brain.

Brain organisation In recent years, there has been considerable progress
in identifying the connectome: this is a "wiring diagram" providing a
complete map of the

brain's neural connections. Why is it important to identify the
connectome? First, as we will see, it advances our understanding of how
the brain is organised. Second, identifying the brain's structural
connections facilitates the task of understanding how it functions. More
speciﬁcally, the brain's functioning is strongly constrained by its
structural connections. Third, as we will see, we can understand some
individual diﬀerences in cognitive functioning with reference to
individual diﬀerences in the connectome. Bullmore and Sporns (2012) used
information about the connectome to address issues about brain
organisation. They argued two major principles might determine its
organisation. First, there is the principle of cost control: costs
(e.g., use of energy and space) would be minimised if the brain
consisted of limited, short-distance connections (see Figure 1.6).
Second, there is the principle of eﬃciency (eﬃciency is the ability to
integrate information across the brain). This can be achieved by having
very numerous connections, many of which are long-distance (see Figure
1.6). These two principles are in conﬂict -- you cannot have high
eﬃciency at low cost. You might imagine it would be best if our brains
were organised primarily on the basis of eﬃciency. However, this would
be incredibly costly -- if all 100 billion brain neurons were
interconnected, the brain would need to be 12½ miles wide (Ward, 2015)!
In fact, neurons mostly connect with nearby neurons and no neuron is
connected to more than about 10,000 other neurons. As a result, the
human brain has a near-optimal trade-oﬀ between cost and eﬃciency (see
Figure 1.6). Thus, our brains are reasonably eﬃcient while incurring a
manageable cost.

Figure 1.6 The left panel shows a brain network low in cost efﬁciency;
the right panel shows a brain network high in cost efﬁciency; the middle
panel shows the actual human brain in which there is moderate efﬁciency
at moderate cost. Nodes are shown as orange circles. From Bullmore and
Sporns (2012). Reprinted with permission of Nature Reviews.

Approaches to human cognition

superior frontal

фnorm

rich club

1.15

non-rich club

1.10

rich club

insula

feeder 1.05

local k

1.00 \>14

\<6

0.95 superior parietal precuneus

There is an important distinction between modules (small areas of
tightly clustered connections) and hubs (regions having large numbers of
connections to other regions). This is an eﬃcient organisation as can be
seen by analogy to the world's airports -- the needs of passengers are
best met by having numerous local airports (modules) and relatively few
major hubs (e.g., Heathrow in London; Changi in Singapore; Los Angeles
International Airport). Collin et al. (2014) argued the brain's hubs are
strongly interconnected and used the term "rich club" to refer to this
state of aﬀairs. The organisation of the rich club is shown in Figure
1.7: it includes the precuneus, the superior frontal cortex, insular
cortex and superior parietal cortex. The ﬁgure also shows connections
between rich club nodes, connections between non-rich club nodes (local
connections), and connections between rich club and non-rich club nodes
(feeder connections). What light does a focus on brain network
organisation shed on individual diﬀerences in cognitive ability? Hilger
et al. (2017) distinguished between global eﬃciency (i.e., eﬃciency of
the overall brain network) and nodal eﬃciency (i.e., eﬃciency of speciﬁc
hubs or nodes). Intelligence was unrelated to global eﬃciency. However,
it was positively associated with the eﬃciency of two hubs or nodes: the
anterior insula and dorsal anterior cingulate cortex. The anterior
insula is involved in the detection of taskrelevant stimuli whereas the
dorsal anterior cingulate cortex is involved in performance monitoring.

Techniques for studying brain activity: introduction Technological
advances mean we have numerous exciting ways of obtaining detailed
information about the brain's functioning and structure. In principle,
we can work out where and when speciﬁc cognitive processes occur in the
brain. This allows us to determine the order in which diﬀerent brain
areas become active when someone performs a task. It also allows us to
discover the extent to which two tasks involve the same brain areas.
Information concerning the main techniques for studying brain activity
is contained in Table 1.2. Which technique is the best? There is no
single (or simple) answer. Each technique has its own strengths and
limitations,

15 Figure 1.7 The organisation of the "rich club". It includes the
precuneus, the superior frontal cortex, insular cortex, and superior
parietal cortex. The ﬁgure also shows connections between rich club
nodes, connections between non-rich club nodes (local connections), and
connections between rich club and non-rich club nodes (feeder
connections).

16

Approaches to human cognition

KEY TERMS

TABLE 1.2 MAJOR TECHNIQUES USED TO STUDY THE BRAIN

Single-unit recording An invasive technique for studying brain function,
permitting the study of activity in single neurons. Event-related
potentials (ERPs) The pattern of electroencephalograph (EEG) activity
obtained by averaging the brain responses to the same stimulus (or very
similar stimuli) presented repeatedly. Positron emission tomography
(PET) A brain-scanning technique based on the detection of positrons; it
has reasonable spatial resolution but poor temporal resolution.
Functional magnetic resonance imaging (fMRI) A technique based on
imaging blood oxygenation using an MRI machine; it provides information
about the location and time course of brain processes. Event-related
functional magnetic resonance imaging (efMRI) This is a form of
functional magnetic resonance imaging in which patterns of brain
activity associated with speciﬁc events (e.g., correct vs incorrect
responses on a memory test) are compared. Magnetoencephalography (MEG) A
non-invasive brainscanning technique based on recording the magnetic
ﬁelds generated by brain activity; it has good spatial and temporal
resolution.

•

Single-unit recording: This technique (also known as single-cell
recording) involves inserting a micro-electrode 1/10,000th of a
millimetre in diameter into the brain to study activity in single
neurons. It is very sensitive: electrical charges of as little as
one-millionth of a volt can be detected.

•

Event-related potentials (ERPs): The same stimulus (or very similar
ones) are presented repeatedly, and the pattern of electrical brain
activity recorded by several scalp electrodes is averaged to produce a
single waveform. This technique allows us to work out the timing of
various cognitive processes very precisely but its spatial resolution is
poor.

•

Positron emission tomography (PET): This technique involves the
detection of positrons (atomic particles emitted from some radioactive
substances). PET has reasonable spatial resolution but poor temporal
resolution and measures neural activity only indirectly.

•

Functional magnetic resonance imaging (fMRI): This technique involves
imaging blood oxygenation using a magnetic resonance imaging (MRI)
machine (described on p. 19). fMRI has superior spatial and temporal
resolution to PET, but also provides an indirect measure of neural
activity.

•

Event-related functional magnetic resonance imaging (efMRI): This
"involves separating the elements of an experiment into discrete points
in time, so that the cognitive processes (and associated brain
responses) associated with each element can be analysed independently"
(Huettel, 2012, p. 1152). Event-related fMRI is generally very
informative and has become more popular recently.

•

Magneto-encephalography (MEG): This technique involves measuring the
magnetic ﬁelds produced by electrical brain activity. It provides fairly
detailed information at the millisecond level about the time course of
cognitive processes, and its spatial resolution is reasonably good.

•

Transcranial magnetic stimulation (TMS): This is a technique in which a
coil is placed close to the participant's head and a very brief pulse of
current is run through it. This produces a short-lived magnetic ﬁeld
that generally (but not always) inhibits processing in the brain area
affected. When the pulse is repeated several times in rapid succession,
we have repetitive transcranial magnetic stimulation (rTMS). rTMS is
used very widely. It has often been argued that TMS or rTMS causes a
very brief "lesion". This technique has (jokingly!) been compared to
hitting someone's brain with a hammer. More accurately, TMS often causes
interference because the brain area to which it is applied is involved
in task processing as well as the activity resulting from the TMS
stimulation.

•

Transcranial direct current stimulation (tDCS): A weak electric current
is passed through a given brain area for some time. The electric charge
ﬂows from a positive site (an anode) to a negative one (a cathode).
Anodal tDCS increases cortical excitability and generally enhances
performance. In contrast, cathodal tDCS decreases cortical excitability
and mostly impairs performance.

and so experimenters match the technique to the research question. Of
key importance, these techniques vary in the precision with which they
identify the brain areas active when a task is performed (spatial
resolution) and the time course of such activation (temporal
resolution). Thus, they diﬀer in their ability to provide precise
information concerning where and when brain activity occurs.

Approaches to human cognition

17 Figure 1.8 The spatial and temporal resolution of major techniques
and methods used to study brain functioning. From Ward (2006), adapted
from Churchland & Sejnowski (1988).

Techniques for studying the brain: detailed analysis We have introduced
the main techniques for studying the brain. In what follows, we consider
them in more detail.

Single-unit recording The single-unit (or cell) recording technique is
more ﬁne-grain than any other technique (see Chapter 2). However, it is
invasive and so rarely used with humans. An interesting exception is a
study by Quiroga et al. (2005) on epileptic patients with implanted
electrodes to identify the focus of seizure onset (see Chapter 3). A
neuron in the medial temporal lobe responded strongly to pictures of
Jennifer Aniston (the actor from Friends) but not to pictures of other
famous people. We need to interpret this ﬁnding carefully. Only a tiny
fraction of the neurons in that brain area were studied and it is highly
improbable that none of the others would have responded to Jennifer
Aniston.

Event-related potentials Electroencephalography (EEG) is based on
recordings of electrical brain activity measured at several locations on
the surface of the scalp. Very small changes in electrical activity
within the brain are picked up by scalp electrodes and can be seen on a
computer screen. However, spontaneous or background brain activity can
obscure the impact of stimulus processing on the EEG recording. The
answer to the above problem is to present the same stimulus (or very
similar stimuli) many times. After that, the segment of the EEG
following each stimulus is extracted and lined up with respect to the
time of stimulus onset. These EEG segments are then averaged together to

KEY TERMS Transcranial magnetic stimulation (TMS) A technique in which
magnetic pulses brieﬂy disrupt the functioning of a given brain area. It
is often claimed that it creates a shortlived "lesion". More accurately,
TMS causes interference when the brain area to which it is applied is
involved in task processing as well as activity produced by the applied
stimulation. Transcranial direct current stimulation (tDCS) A technique
in which a very weak electrical current is passed through an area of the
brain (often for several minutes); anodal tDCS often enhances
performance, whereas cathodal tDCS often impairs it.
Electroencephalography (EEG) Recording the brain's electrical potentials
through a series of scalp electrodes.

18

Approaches to human cognition

produce a single waveform. This method produces event-related potentials
from EEG recordings and allows us to distinguish the genuine eﬀects of
stimulation from background brain activity. ERPs have excellent temporal
resolution, often indicating when a given process occurred to within a
few milliseconds. The ERP waveform consists of a series of positive (P)
and negative (N) peaks, each described with reference to the time in
milliseconds after stimulus onset. Thus, for example, N400 is a negative
wave peaking at about 400 ms. Behavioural measures (e.g., reaction
times) typically provide only a single measure of time on each trial,
whereas ERPs provide a continuous measure. However, ERPs do not indicate
with precision which brain regions are most involved in processing, in
part because skull and brain tissue distort the brain's electrical
ﬁelds. In addition, ERPs are mainly of value when stimuli are simple and
the task involves basic processes (e.g., target detection) triggered by
task stimuli. Finally, we cannot study the most complex forms of
cognition (e.g., problem solving) with ERPs because the processes by
participants would typically change with increased practice.

Positron emission tomography (PET) Positron emission tomography (PET) is
based on the detection of positrons -- atomic particles emitted by some
radioactive substances. Radioactively labelled water (the tracer) is
injected into the body and rapidly gathers in the brain's blood vessels.
When part of the cortex becomes active, the labelled water moves there
rapidly. A scanning device measures the positrons emitted from the
radioactive water which leads to pictures of the activity levels in
diﬀerent brain regions. PET has reasonable spatial resolution in that
any active brain area can be located to within 5--10 mm. However, it has
very poor temporal resolution -- PET scans indicate the amount of
activity in any given brain region over approximately 30 seconds. As a
consequence, PET has now largely been superseded by fMRI (see p. 19).

The magnetic resonance imaging (MRI) scanner has proved an extremely
valuable source of data in psychology. Juice Images/Alamy Stock Photo.

Approaches to human cognition

19

Magnetic resonance imaging (MRI and fMRI)

KEY TERMS

Magnetic resonance imaging (MRI) involves using an MRI scanner
containing a very large magnet (weighing up to 11 tons). A strong
magnetic ﬁeld causes an alignment of protons (subatomic particles) in
the brain. A brief radio-frequency pulse is applied, which causes the
aligned protons to spin and then regain their original orientations
giving up a small amount of energy as they do so. The brightest regions
in the MRI are those emitting the greatest energy. MRI scans can be
obtained from numerous angles but tell us only about brain structure
rather than its functions. Happily, MRI can also be used to provide
functional information in the form of functional magnetic resonance
imaging (fMRI). Oxyhaemoglobin is converted into deoxyhaemoglobin when
neurons consume oxygen, and deoxyhaemoglobin produces distortions in the
local magnetic ﬁeld (sorry this is so complex!). This distortion is
assessed by fMRI and provides a measure of the concentration of
deoxyhaemoglobin in the blood. Technically, what is measured in fMRI is
known as BOLD (blood oxygen-level-dependent contrast). Changes in the
BOLD signal produced by increased neural activity take time, so the
temporal resolution of fMRI is 2 or 3 seconds. However, its spatial
resolution is very good (approximately 1 mm). Thus, fMRI has superior
temporal and spatial resolution to PET. Suppose we want to understand
why people remember some items but not others. We can use event-related
fMRI (efMRI), in which we consider

BOLD Blood oxygen-leveldependent contrast; this is the signal measured
by fMRI. Neural decoding Using computer-based analyses of patterns of
brain activity to work out which stimulus an individual is processing.

CAN COGNITIVE NEUROSCIENTISTS READ OUR BRAINS/MINDS? There is much
current interest in neural decoding -- "determining what stimuli or
mental states are represented by an observed pattern of neural activity"
(Tong & Pratte, 2012, p. 483). This decoding involves complex
computer-based analysis of individuals' patterns of brain activity and
has sometimes been described as "brain reading" or "mind reading". Kay
et al. (2008) obtained impressive ﬁndings using neural decoding
techniques. Two participants viewed 1,750 natural images and
brain-activation patterns were obtained using fMRI. Computerbased
approaches then analysed these patterns. After that, the participants
were presented with 120 previously unseen natural images and fMRI data
were collected. These fMRI data permitted correct identiﬁcation of the
image being viewed on 92% of the trials for one participant and 72% for
the other. This is remarkable since chance performance was only 0.8%!
Huth et al. (2016) used more complex stimuli. They presented observers
with clips taken from several movies including Star Trek and Pink
Panther 2 while using fMRI. Decoding accuracy was reasonably successful
in identifying general object categories (e.g., animal), speciﬁc object
categories (e.g., canine) and various actions (e.g., talk; run)
presented in the movie clips. Research on neural decoding can enhance
our understanding of human visual perception. However, successful
decoding of an object using the pattern of brain activation in a given
brain region does not necessarily mean that region is causally involved
in observers' identiﬁcation of that object. Several reasons why we need
to be cautious when interpreting ﬁndings from neural decoding studies
are discussed by Popov et al. (2018). For example, some aspects of brain
activity in response to visual stimuli are irrelevant to the observer's
perceptual representation. In an experiment, computer analysis of brain
activity in macaques successfully classiﬁed various stimuli presented to
them that the macaques themselves could not distinguish (Hung et al.,
2005).

20

Approaches to human cognition

each participant's patterns of brain activation for remembered and
forgotten items. Wagner et al. (1998) recorded fMRI while participants
learned a list of words. There was more brain activity during learning
for words subsequently recognised than those subsequently forgotten.
These ﬁndings suggest forgotten words were processed less thoroughly
than remembered words during learning.

Evaluation fMRI is the dominant technique within cognitive neuroscience.
Its value has increased over the years with the introduction of more
powerful MRI scanners. Initially, most scanners had a ﬁeld strength of
1.5 T but recently scanners with ﬁeld strengths of up to 7 T have become
available. As a result, submillimetre spatial resolution is now possible
(Turner, 2016). What are fMRI's limitations? The main ones are as
follows: (1)

(2) 
(3) 
(4) 

It has relatively poor temporal resolution. As a result, it is
uninformative about the order in which diﬀerent brain regions (and
cognitive processes) are used during performance of a task. However,
other techniques within cognitive neuroscience can be used in
conjunction with fMRI in order to achieve good spatial and temporal
resolution. It provides an indirect measure of underlying neural
activity. "The BOLD signal primarily measures the input and processing
of neural information . . . but not the output signal transmitted to
other brain regions" (Shiﬀerman, 2015, p. 60). Various complex processes
are used by researchers to take account of the fact that all brains
diﬀer. This involves researchers changing the raw fMRI data and poses
the danger that "BOLD-fMRI neuroimages represent mathematical constructs
rather than physiological reality" (Shiﬀerman, 2015). There are
important constraints on the visual stimuli that can be presented to
participants when lying in the scanner and on the types of responses
they can make. There can be particular problems with auditory stimuli
because the scanner is noisy.

Magneto-encephalography The electric currents that the brain generates
are associated with a magnetic ﬁeld. This magnetic ﬁeld is assessed by
magneto-encephalography (MEG) involving at least 200 devices on the
scalp. This technique has very good spatial and temporal resolution.
However, it is extremely expensive and this has limited its use.

Transcranial magnetic stimulation Transcranial magnetic stimulation
(TMS) is a technique in which a coil (often in the shape of a ﬁgure of
eight) is placed close to the participant's head. A very brief (under 1
ms) but large magnetic pulse of current is run

Approaches to human cognition

through it. This creates a short-lived magnetic ﬁeld generally leading
to inhibited processing in the directly aﬀected area (about 1 cc in
extent). More speciﬁcally, the magnetic ﬁeld created leads to electrical
stimulation in the brain. In practice, several magnetic pulses are
typically given in rapid succession -- this is repetitive transcranial
magnetic stimulation (rTMS). Most research has used rTMS but we will
often simply use the more general term TMS. What is an appropriate
control condition against which to compare the eﬀects of TMS or rTMS? We
could compare task performance with and without Transcranial magnetic
stimulation coil. TMS. However, TMS creates a loud noise and muscle
University of Durham/Simon Fraser/Science Photo twitching at the side of
the forehead and these eﬀects Library. might lead to impaired
performance. Applying TMS to a non-critical brain area (irrelevant for
task performance) often provides a suitable control condition. It is
typically predicted task performance will be worse when TMS is applied
to a critical area rather than a non-critical one because it produces a
temporary "lesion" or interference to the area targeted.

Evaluation What are TMS's strengths? First, it permits causal inferences
-- if TMS applied to a particular brain area impairs task performance,
we can infer that brain area is necessary for task performance.
Conversely, if TMS has no eﬀects on task performance, we can conclude
the brain area aﬀected by it is irrelevant. In that respect, it
resembles cognitive neuropsychology. Second, TMS research is more
ﬂexible than cognitive neuropsychology. For example, we can compare any
given individual's performance with and without a "lesion" with TMS.
This is rarely possible with brain-damaged patients. Third, TMS research
is also more ﬂexible than cognitive neuropsychology because the
researcher controls the brain area(s) aﬀected. In addition, the
temporary "lesions" created by TMS typically cover a smaller brain area
than patients' lesions. This is important because the smaller the brain
aﬀected, the easier it generally is to interpret task-performance
ﬁndings. Fourth, with TMS research, we can ascertain when a brain area
is most activated. For example, the presentation of a visual stimulus
leads to processing proceeding rapidly to higher visual levels
(feedforward processing). According to Lamme (2010), conscious visual
perception typically requires subsequent recurrent processing proceeding
in the opposite direction from higher levels to lower ones. Koivisto et
al. (2011) used TMS to disrupt recurrent processing. As predicted, this
impaired conscious visual perception. What are the limitations of TMS
research? First, the eﬀects of TMS are complex and not fully understood.
When TMS was ﬁrst introduced, it was assumed it would disrupt
performance. That is, the most common ﬁnding. However, Luber and Lisanby
(2014) reviewed 61 studies in which performance speed and/or accuracy
was enhanced!

21

22

Approaches to human cognition

How can TMS enhance performance? It sometimes increases neural activity
in areas adjacent to the one stimulated and so increases their
processing eﬃciency (Luber & Lisanby, 2014). There is also much evidence
for compensatory ﬂexibility (Hartwigsen, 2018) -- disruption to
cognitive processing within a given brain area caused by TMS is
compensated for by the recruitment of other brain areas. Second, it is
hard to establish the precise brain areas aﬀected by TMS. For example,
adverse eﬀects of TMS on performance might occur because it interferes
with communication between two brain areas at some distance from the
stimulation point. This issue can be addressed by combining TMS with
neuroimaging techniques to clarify its eﬀects (Valero-Cabré et al.,
2017). Third, TMS can only be applied to brain areas lying beneath the
skull but with overlying muscle. That limits its overall usefulness.
Fourth, there are safety issues with TMS. It has very occasionally
caused seizures in participants despite stringent rules designed to
ensure their safety.

Transcranial direct current stimulation (tDCS) As mentioned earlier,
anodal tDCS increases cortical excitability whereas cathodal tDCS
decreases cortical excitability. The temporal and spatial resolution of
tDCS is less than TMS (Stagg & Nitsche, 2011). However, anodal tDCS has
a signiﬁcant advantage over TMS in that it often facilitates or enhances
cognitive functioning. As a result, anodal tDCS is increasingly used to
reduce adverse eﬀects of brain damage on cognitive functioning (Stagg et
al., 2018). Some of these beneﬁcial eﬀects on cognition are relatively
long-lasting. Another advantage of tDCS is that it typically causes
little or no discomfort. Much progress has been made in understanding
the complex mechanisms associated with tDCS. However, "Knowledge about
the physiological eﬀects of tDCS is still not complete" (Stagg et al.,
2018, p. 144).

Overall strengths Cognitive neuroscience has contributed substantially
to our understanding of human cognition. We discuss supporting evidence
for that statement throughout the book in areas that include perception,
attention, learning, memory, language comprehension, language
production, problem solving, reasoning, decision-making and
consciousness. Here we identify its major strengths. First, cognitive
neuroscience has helped to resolve theoretical controversies and issues
that had proved intractable with purely behavioural studies (Mather et
al., 2013). The main reason is that cognitive neuroscience adds
considerably to the information available to researchers (Poldrack &
Yarkoni, 2016). Below we brieﬂy consider two examples: (1)

Listeners hearing degraded speech ﬁnd it much more intelligible when it
is accompanied by visually presented words matching (rather than not
matching) the auditory input. There has been much theoretical

Approaches to human cognition

(2) 

controversy concerning when this visually presented information
inﬂuences speech perception (see Chapter 9). Does it occur early and so
directly inﬂuence basic auditory processes or does it occur late (after
basic auditory processing has ﬁnished)? Wild et al. (2012) found there
was more activity in brain areas involved in early auditory processing
when the visual input matched the auditory input. This strongly suggests
visual information directly inﬂuences basic auditory processes. There
has been much theoretical controversy as to whether visual imagery
resembles visual perception (see Chapter 3). Behavioural evidence has
proved inconclusive. However, neuroimaging has shown two-thirds of the
brain areas activated during visual perception are also activated during
visual imagery (Kosslyn, 2005). Even brain areas involved in the early
stages of visual perception are often activated during visual imagery
tasks (Kosslyn & Thompson, 2003). Thus, there are important
similarities. Functional neuroimaging has also revealed important
diﬀerences between the processes involved in visual perception and
imagery (Dijkstra et al., 2017b).

Second, the incredible richness of neuroimaging data means cognitive
neuroscientists can (at least in principle) construct theoretical models
accurately mimicking the complexities of brain functioning. In contrast,
cognitive neuropsychology, for example, is less ﬂexible and more
committed to the notion of a modular brain organisation. Third, over
10,000 fMRI studies within cognitive neuroscience have been published.
Many meta-analyses based on these studies have been carried out to
understand brain-cognition relationships (Poldrack & Yarkoni, 2016).
Such meta-analyses "provide highly robust estimates of the neural
correlates of relatively speciﬁc cognitive tasks" (p. 592). At present,
this approach is limited because we do not know the pattern of
activation associated with any given cognitive process -- data are coded
with respect to particular tasks rather than underlying cognitive
processes. Fourth, neuroimaging data can often be re-analysed based on
theoretical developments. For example, early neuroimaging research on
face processing suggested it occurs mostly within the fusiform face area
(see Chapter 3). However, the assumption that face processing involves a
network of brain regions provides a more accurate account (Grill-Spector
et al., 2017). Thus, cognitive neuroscience can be selfcorrecting. More
generally, cognitive neuroscience has shown the assumption of functional
specialisation (each brain area is specialised for a diﬀerent function)
is oversimpliﬁed. We can contrast the notions of functional
specialisation and functional integration (positive correlations of
various brain areas within a network). For example, conscious perception
depends on coordinated activity across several brain regions and so
involves functional integration (see Chapter 16).

Overall limitations We turn now to general issues raised by cognitive
neuroscience. We emphasise fMRI research because that technique has been
used most often.

23

KEY TERM Functional specialisation The assumption that each brain area
or region is specialised for a speciﬁc function (e.g., colour
processing; face processing).

24

Approaches to human cognition

KEY TERM

First, many cognitive neuroscientists over-interpret their ﬁndings by
assuming one-to-one links between cognitive processes and brain areas.
For example, activation in a particular small brain region (a "blob") is
interpreted as being the "love area" and another small region was
interpreted as being the "face processing area". This approach has been
described (unﬂatteringly) as "blobology". Blobology is in decline.
However, there is still undue reliance on reverse inference -- the
involvement of a given cognitive process is inferred from activation
within a given brain region. For example, face recognition is typically
associated with activation within the fusiform face area, which led many
researchers to identify that area as speciﬁcally involved in face
processing. This is incorrect in two ways (see Chapter 3): (1) the
fusiform face area is activated in response to many diﬀerent kinds of
objects as well as faces (Downing et al., 2006); and (2) several other
brain areas (e.g., occipital face area) are also activated during face
processing. Second, cognitive neuroscience is rarely used to test
cognitive theories. For example, Tressoldi et al. (2012) reviewed 199
studies published in 8 journals. They found 89% of these studies focused
on localising the brain areas associated with brain processes and only
11% tested a theory of cognition. There is some validity to Tressoldi et
al.'s (2012) argument. However, it has become less persuasive because of
the rapidly increasing emphasis within cognitive neuroscience on theory
testing. Third, it is hard to bridge the divide between psychological
processes and concepts and patterns of brain activation. As Harley
(2012) pointed out, we may never ﬁnd brain patterns corresponding
closely to psychological processes such as "attention" or "planning".
Harley (2012, p. 1372) concluded as follows: "Our language and thought
may not divide up in the way in which the brain implements these
processes." Fourth, it is sometimes hard to replicate ﬁndings within
cognitive neuroscience. For example, Uttal (2012) compared the ﬁndings
from diﬀerent brain-imaging meta-analyses on a given cognitive function.
More specifically, he identiﬁed the Brodmann areas associated with a
given cognitive function in two meta-analyses. Uttal then worked out the
Brodmann areas activated in both meta-analyses and divided this by the
total number of Brodmann areas identiﬁed in at least one meta-analysis.
If the two meta-analyses were in total agreement, the resultant ﬁgure
would be 100%. The actual ﬁgure varied between 14% and 51%! Uttal's
(2012) ﬁndings seem devastating -- after all, we might expect
meta-analyses based on numerous studies to provide very reliable
evidence. However, many apparent discrepancies occurred mainly because
one meta-analysis reported activation in fewer brain areas than the
other. This often happened because of stricter criteria for deciding a
given brain area was activated (Klein, 2014). Fifth, false-positive
ﬁndings (i.e., mistakenly concluding that random activity in a given
brain area is task-relevant) are common (Yarkoni et al., 2010; see
discussion later on p. 25). There are several reasons for this. For
example, researchers have numerous options when deciding precisely how
to analyse their fMRI data (Poldrack et al., 2017). In addition, most
neuroimaging studies produce huge amounts of data and researchers

Reverse inference As applied to functional neuroimaging, it involves
arguing backwards from a pattern of brain activation to the presence of
a given cognitive process.

Approaches to human cognition

25

sometimes fail to adjust required signiﬁcance levels appropriately.
Bennett et al. (2009) provided an example of a false-positive ﬁnding.
They asked their participant to determine the emotions shown in
photographs. When they did not adjust required signiﬁcance levels, there
was significant evidence of brain activation (see Figure 1.9).
Amusingly, the participant was a dead salmon so we can be certain the
"ﬁnding" was a false positive. Sixth, most brain-imaging techniques
Figure 1.9 reveal only associations between patterns of Areas showing
greater activation in a dead salmon when brain activation and behaviour.
Such asso- presented with photographs of people than when at rest.
ciations are purely correlational and do not From Bennett et al. (2009).
With kind permission of the authors. establish the brain regions
activated are necessary for task performance. For example, brain
activation might also be caused by participants engaging in unnecessary
monitoring of their performance or attending to non-task stimuli.
Seventh, many cognitive neuroscientists previously assumed most brain
activity is driven by environmental or task demands. As a result, we
might expect relatively large increases in brain activity in response to
such demands. That is not the case. The increased brain activity when
someone performs a cognitive task typically adds less than 5% to resting
brain activity. Surprisingly several brain areas exhibit decreased
activity when a cognitive task is performed. Of importance here is the
default mode network (Raichle, 2015). It consists of an interconnected
set of brain regions (including the ventral medial and dorsal medial
prefrontal cortex, and the posterior cingulate cortex) more active
during rest than during performance of a task. Its functions include
mind wandering, worrying and daydreaming. The key point is that patterns
of brain activity in response to any given cognitive task reﬂect
increased activity associated with task processing and decreased
activity associated with reduced activity within the default mode
network. Such complexities complicate the interpretation of neuroimaging
data. Eighth, cognitive neuroscience shares with cognitive psychology
problems of ecological validity (applicability to everyday life) and
paradigm speciﬁcity (ﬁndings not generalising across paradigms). Indeed,
the problem of ecological validity may be greater in cognitive
neuroscience. For example, participants in fMRI studies lie on their
backs in claustroKEY TERM phobic and noisy conditions and have very
restricted movement -- not Default mode network much like everyday life!
Gutchess and Park (2006) found recognition A network of brain memory was
signiﬁcantly worse in an MRI scanner than in an ordiregions that is
active "by default" when an nary laboratory. Presumably the scanner
provided a more distracting or individual is not involved
anxiety-creating environment. in a current task; it is Ninth, we must
avoid what Ali et al. (2014) termed "neuroenchantment" -- associated
with internal exaggerating the importance of neuroimaging to our
understanding of cogprocesses including mind nition. Ali et al. provided
a striking example of neuroenchantment. College wandering, remembering
the past and imagining students were exposed to a crudely built mock
brain scanner (including a the future. discarded hair dryer!) (see
Figure 1.10). They were asked to think about

26

Approaches to human cognition

Figure 1.10 The primitive mock neuroimaging device used by Ali et
al. (2014).

the answers to various questions (e.g., name a country). The mock
neuroimaging device apparently "read their minds" and worked out exactly
what they were thinking. Amazingly, three-quarters of the student
participants believed this was genuine rather than being due to the
researcher's trickery?

COMPUTATIONAL COGNITIVE SCIENCE

KEY TERMS Computational modelling This involves constructing computer
programs that simulate or mimic human cognitive processes. Artiﬁcial
intelligence This involves developing computer programs that produce
intelligent outcomes.

There is an important distinction between computational modelling and
artiﬁcial intelligence. Computational modelling involves programming
computers to model or mimic human cognitive functioning. Thus, cognitive
modellers "have the goal of understanding the human mind through
computer simulation" (Taatgen et al., 2016, p. 1). In contrast,
artiﬁcial intelligence involves constructing computer systems producing
intelligent outcomes but typically in ways diﬀerent from humans.
Consider Deep Blue, the IBM computer that defeated the world chess
champion Garry Kasparov on 11 May 1997. Deep Blue processed up to 200
million positions per second, which is vastly more than human chess
players (see Chapter 12). The IBM computer Watson also shows the power
of artiﬁcial intelligence. This computer competed on the American quiz
show Jeopardy against two of the most successful human contestants ever
on that show: Brad Rutter and Ken Jennings. The competition took place
between 14 and 16 February 2011, and Watson won the \$1 million ﬁrst
prize. Watson had the advantage over Rutter and Jennings of having
access to 10 million documents (200 million pages of content). However,
Watson had the disadvantage of being less sensitive to subtleties
contained in the questions. In the past (and even nowadays), many
experimental cognitive psychologists expressed their theories in vague
verbal statements (e.g., "Information

Approaches to human cognition

27 The IBM Watson and two human contestants (Ken Jennings and Brad
Rutter). Ben Hider/Getty Images.

from short-term memory is transferred to long-term memory"). This made
it hard to provide precise predictions from the theory and to decide
whether the evidence ﬁtted the theory. As Murphy (2011) pointed out,
verbal theories provided theorists with undesirable "wiggle room". In
contrast, a computational model "requires the researchers to be explicit
about a theory in a way that a verbal theory does not" (Murphy, 2011,
p. 300). Implementing a theory as a program is a good way to check it
contains no hidden assumptions or imprecise terms. This often reveals
that the theory makes predictions the theorist had not realised! There
are issues concerning the relationship between the performance of a
computer program and human performance (Costello & Keane, 2000). For
example, a program's speed doing a simulated task can be aﬀected by
psychologically irrelevant features (e.g., the power of the computer).
Nevertheless, the various materials presented to the program should
result in diﬀerences in program operation time correlating closely with
diﬀerences in participants' reaction times with the same materials.

Types of models Most computational models focus on speciﬁc aspects of
human cognition. For example, there are successful computational models
providing accounts of reading words and non-words aloud (Coltheart et
al., 2001; Perry et al., 2007, 2014; Plaut et al., 1996) (see Chapter
9). More ambitious computational models provide cognitive architectures
-- "models of the ﬁxed structure of the mind" (Rosenbloom et al., 2017,
p. 2). Approximately 300 cognitive architectures have been proposed over
the years (Kotseruba & Tsotsos, 2018). Note that a cognitive
architecture typically has to be supplemented with the knowledge
required to perform a given task to produce a fully ﬂedged computational
model (Byrne, 2012). Anderson et al. (2004) proposed an

KEY TERM Cognitive architecture Comprehensive framework for
understanding human cognition in the form of a computer program.

28

Approaches to human cognition

KEY TERMS

especially inﬂuential cognitive architecture in their Adaptive Control
of Thought-Rational (ACT-R) (discussed on p. 30).

Connectionist models Models in computational cognitive science
consisting of interconnected networks of simple units or nodes; the
networks exhibit learning through experience and speciﬁc items of
knowledge are distributed across numerous units.

Connectionism

Connectionist models (also called neural network models) typically
consist of interconnected networks of simple units (or nodes) that
exhibit learning. Connectionist or neural network models use elementary
units or nodes connected together in structures or layers (see Figure
1.11). First, a layer of input nodes codes the input. Second, activation
caused by input coding spreads to a layer of hidden nodes. Third,
activation spreads to a layer of Neural network models output nodes.
Computational models Of major importance, the basic model shown in
Figure 1.11 can learn in which processing simple additions. If input
node 1 is active, output node 1 will also become involves the
simultaneous active. If input nodes 1 and 2 are active, output node 3
will become active. activation of numerous If all input nodes are
active, output node 10 will become active and so on. interconnected
nodes (basic units). The model compares the actual output against the
correct output. If there is a discrepancy, the model learns to adjust
the weights of the connections Nodes between the nodes to produce the
correct output. This is known as backThe basic units within a neural
network model. ward propagation of errors or back-propagation, and it
allows the model to learn the appropriate responses without being
explicitly programmed to Back-propagation do so. A learning mechanism in
connectionist models Numerous connectionist models have been constructed
using the basic based on comparing architecture shown in Figure 1.11.
Recent connectionist models often have actual responses to several
hidden layers (they are called deep neural networks). Connectionist
correct ones. models involve distributed representations whereas other
computational models involve localist representations (Bowers, 2017a).
In the former case, each node or unit responds to multiple stimulus
categories and so a given word or object is represented by the pattern
of activation across many nodes or units. In the latter case, each node
or unit responds most actively to a single meaningful stimulus category
(e.g., a given word or object). Interest in the connectionist approach
was triggered initially by Rumelhart et al. (1986) and McClelland et
al. (1986) with their parallel distributed processing models. These
models (like most models based on distributed representations) exhibit
learning. Other inﬂuential connectionist models are Plaut et al.'s
(1996) reading model (Chapter 9) and McClelland & Elma's (1986) TRACE
model of spoken word recognition (Chapter 9). In contrast, computational
models based on localist representations often do not exhibit learning
because the representations contain all the required information.
Examples of such models in this book include Coltheart et al.'s (2001)
reading model (Chapter 9) and the speech production models of Dell
(1986) and Levelt et al. (1999; see Chapter 11). It has often been
assumed localist models are biologically implausible because they seem
Figure 1.11 Architecture of a basic three-layer connectionist network.
to imply a single neuron responds to stimuli

Approaches to human cognition

from a given category. However, many neurons show considerable
selectivity because they respond to only a very small fraction of
stimuli. For example, consider a study by Quiroga et al. (2005)
mentioned earlier. They presented epileptic patients with 100 images
including famous individuals and landmark buildings. On average,
responsive neurons responded to only approximately 3% of the images. The
issues are complex. However, it is not clear localist models are less
biologically plausible than distributed models (Bowers, 2017b).

Evaluation There are many successful connectionist or neural network
models (some are mentioned above). Such models (discussed at various
points in this book) have provided valuable insights into human
cognition and the models have become increasingly sophisticated over
time. A general strength of neural networks is that they "exhibit robust
ﬂexibility in the face of the challenges posed by the real world"
(Garson, 2016, p. 3). That is one reason why neural networks can perform
numerous diﬀerent kinds of cognitive tasks. Finally, there are
intriguing similarities between the brain, with its numerous units
(neurons) and synaptic connections, and neural networks, with their
units (nodes) and connections. What are the limitations of connectionist
models? First, there is an issue with the common assumption that
connectionist models are distributed. If two words are presented at the
same time, this can lead to superimposing two patterns over the same
units or nodes making it hard (or impossible) to decide which activated
units or nodes belong to which word. This causes superposition
catastrophe (Bowers, 2017a). Second, there are many examples of neural
networks that can make associations and match patterns. However, it has
proved much harder to develop neural networks that can learn general
rules (Garson, 2016). Third, the analogy between neural networks and the
brain is very limited. In essence, the latter is hugely more complex
than the former. Fourth, back-propagation implies learning will be slow,
whereas humans sometimes exhibit one-trial learning (Garson, 2016).
Furthermore, there is little or no evidence of back-propagation in the
human brain (Mayor et al., 2014).

Production systems Production systems consist of numerous "IF . . .
THEN" production rules. Production rules can take many forms. However,
an everyday example is: "If the green man is lit up, then cross the
road." There is also a working memory (i.e., a system holding
information currently being processed).

If information from the environment that "green man is lit up" reaches
working memory, it will match the IF part of the rule in long-term
memory and trigger the THEN part of the rule (i.e., cross the road).
Production systems vary but generally have the following
characteristics: ● ●

numerous IF . . . THEN rules; a working memory containing information;

29

KEY TERMS Production systems These consist of very large numbers of "IF
. . . THEN" production rules and a working memory containing
information. Production rules "IF . . . THEN" or condition-action rules
in which the action is carried out whenever the appropriate condition is
present. Working memory A limited-capacity system used in the processing
and brief holding of information.

30

Approaches to human cognition

●

●

a production system that operates by matching the contents of working
memory against the IF parts of the rules and then executing the THEN
parts; if information in working memory matches the IF parts of two
rules, a conﬂict-resolution strategy selects one.

Adaptive Control of Thought-Rational (ACT-R) and beyond As mentioned
earlier, Anderson et al. (2004) proposed ACT-R, which was subsequently
developed (e.g., Anderson et al., 2008). ACT-R assumes the cognitive
system consists of several modules (relatively independent subsystems).
It combines computational cognitive science with cognitive neuroscience
by identifying the brain regions associated with each module (see Figure
1.12). Four modules are of special importance: (1)

(2) 
(3) 
(4) 

Retrieval module: it maintains the retrieval cues needed to access
information; its proposed location is the inferior ventrolateral
prefrontal cortex. Imaginal module: it transforms problem
representations to assist in problem solving; it is located in the
posterior parietal cortex. Goal module: it keeps tracks of an
individual's intentions and controls information processing; it is
located in the anterior cingulate cortex. Procedural module: it uses
production (IF . . . THEN) rules to determine what action will be taken
next; it is located at the head of the caudate nucleus within the basal
ganglia.

Each module has a buﬀer associated with it containing a limited amount
of important information. How is information from these buﬀers
integrated? According to Anderson et al. (2004, p. 1058): "A central
production system can detect patterns in these buﬀers and take
co-ordinated action."

Figure 1.12 The main modules of the ACT-R (Adaptive Control of
Thought-Rational) cognitive architecture with their locations within the
brain. Reprinted from Anderson et al. (2008). Reprinted with permission
of Elsevier.

Approaches to human cognition

31

If several productions could be triggered by the information contained
in the buﬀers, one is selected based on the value or gain associated
with each outcome plus the amount of time or cost incurred in achieving
that outcome. ACT-R represents an impressive attempt to provide a
theoretical framework for understanding information processing and
performance on numerous cognitive tasks. It is also impressive in
seeking to integrate computational cognitive science with cognitive
neuroscience. What are ACT-R's limitations? First, it is very hard to
test such a wide-ranging theory. Second, areas of prefrontal cortex
(e.g., dorsolateral prefrontal cortex) generally assumed to be of major
importance in cognition are de-emphasised. Third, as discussed earlier,
research within cognitive neuroscience increasingly reveals the
importance to cognitive processing of brain networks rather than speciﬁc
regions. Fourth, in common with most other cognitive architectures,
ACT-R has a knowledge base that is substantially smaller than that
possessed by humans (Lieto et al., 2018). This reduces the applicability
of ACT-R to human cognitive performance.

Standard model of the mind Dozens of cognitive architectures have been
proposed and it is diﬃcult to compare them. Laird et al. (2017; see also
Rosenbloom et al., 2017) recently proposed a standard model emphasising
commonalities among major cognitive architectures including ACT-R (see
Figure 1.13). Figure 1.13 may look unimpressive because it represents
the model at a very general level. However, the model contains numerous
additional assumptions (Laird et al., 2017). First, procedural memory
has special importance because it has access to the whole of working
memory; in contrast, the other modules have access only to speciﬁc
aspects of working memory.

Declarative Long-term Memory

Procedural Long-term Memory

Working Memory

Perception

Motor

Figure 1.13 The basic structure of the standard model involving ﬁve
independent modules. Declarative memory (see Glossary) stores facts and
events whereas procedural memory (see Glossary) stores knowledge about
actions.

32

Approaches to human cognition

Second, the crucial assumption is that there is a cognitive cycle
lasting approximately 50 ms per cycle. What happens is that: "Procedural
memory induces the selection of a single deliberate act per cycle, which
can modify working memory, initiate the retrieval of knowledge from
long-term declarative memory, initiate motor actions . . ., and provide
top-down inﬂuence to perception" (Laird et al., 2017, p. 3). The
cognitive cycle involves serial processing but parallel processing can
occur within any module as well as between them. The standard model is
useful but incomplete. For example, it does not distinguish between
diﬀerent types of declarative memory (e.g., episodic and semantic
memory; see Chapter 7). In addition, it does not account for emotional
inﬂuences on cognitive processing.

Links with other approaches ACT-R represents an impressive attempt to
apply computational models to cognitive neuroscience. There has also
been interest in applying such models to data from brain-damaged
patients. Typically, the starting point is to develop a computational
model accounting for the performance of healthy individuals on some
task. After that, aspects of the computational model or program are
altered to simulate "lesions", and the eﬀects on task performance are
assessed. Finally, the lesioned model's performance is compared against
that of brain-damaged patients (Dell & Caramazza, 2008).

Overall strengths Computational cognitive science has several strengths.
First, the development of cognitive architectures can provide an
overarching framework for understanding the cognitive system. This would
be a valuable achievement given that much research in cognitive
psychology is limited in scope and suﬀers from paradigm speciﬁcity.
Laird et al.'s (2017) standard model represents an important step on the
way to that achievement. Second, the scope of computational cognitive
science has increased. Initially, it was applied mainly to behavioural
data. More recently, however, it has been applied to functional
neuroimaging data (e.g., Anderson et al., 2004) and EEG data (Anderson
et al., 2016a). Why is this important? As Taatgen et al. (2016, p. 3)
pointed out: "The link to neuroimaging is critical in establishing that
the hypothesised processing steps in cognitive models have plausibility
in reality." Third, rigorous thinking is required to develop
computational models because computer programs must contain detailed
information about the processes involved in performing any given task.
In contrast, many theories within traditional cognitive psychology are
vaguely expressed and the predictions following from their assumptions
are unclear. Fourth, progress is increasingly made by using nested
incremental modelling. In essence, a new model builds on the strengths
of previous related models while eliminating (or reducing) their
weaknesses and accounting for additional data. For example, Perry et
al. (2007; Chapter 9) put forward a connectionist dual-process model
(CDP+) of reading aloud that improved on the model on which it was
based.

Approaches to human cognition

Overall limitations What are the main limitations of the computational
cognitive science approach? First, there is Bonini's paradox: as models
become more accurate and complete, they can become as hard to understand
as the complex phenomena they are designed to explain. Conversely,
models easy to understand are typically inaccurate and incomplete. Many
computational modellers have responded to this paradox by focusing on
the essence of the phenomena and ignoring the minor details (Milkowski,
2016, p. 1459). Second, many computational models are hard to falsify.
The ingenuity of computational modellers means many models can account
for numerous behavioural ﬁndings (Taatgen et al., 2016). This issue can
be addressed by requiring computational models to explain neuroimaging
ﬁndings as well as behavioural ones. Third, some computational models
are less successful than they appear. One reason is overﬁtting in which
a model accounts for noise in the data as well as genuine eﬀects
(Ziegler et al., 2010). Overﬁtting often means a model seems to account
very well for a given data set but is poor at predicting new data
(Yarkoni & Westfall, 2017). Fourth, most computational models ignore
motivational and emotional factors. Norman (1980) distinguished between
a cognitive system (the Pure Cognitive System) and a biological system
(the Regulatory System). Computational cognitive science typically
de-emphasises the Regulatory System even though it often strongly
inﬂuences the Pure Cognitive System. This issue can be addressed by
developing computational models indicating how emotions modulate
cognitive processes (Rodriguez et al., 2016). Fifth, many computational
models are very hard to understand (Taatgen et al., 2016). Why is this
so? Addyman and French (2012, p. 332) identiﬁed several reasons:
Everyone still programs in \[their\] own favourite programming language,
source code is rarely made available, . . . even for other modellers,
the profusion of source code in a multitude of programming languages,
writing without programming guidelines, makes it almost impossible to
access, check, explore, re-use or continue to develop \[models\].
Computational modellers often fail to share their source codes and
models because they have perceived ownership over their own research and
are concerned about losing control over it (Fecher et al., 2015).

COMPARISONS OF MAJOR APPROACHES We have discussed the major approaches
to human cognition at length and you may wonder which is the most useful
and informative. However, that is not the best way of thinking about the
issues for various reasons: (1)

An increasing amount of research involves two or more diﬀerent
approaches.

33

34

Approaches to human cognition

KEY TERMS

(2) 

Converging operations An approach in which several methods with
different strengths and limitations are used to address a given issue.
Replication The ability to repeat a previous experiment and obtain the
same (or similar) ﬁndings.

(3) 

Each approach makes its own distinctive contribution and so all are
required. By analogy, it would be pointless asking whether a driver is
more or less useful than a putter for a golfer -- both are essential.
Each approach has its own limitations as well as strengths (see Table
1.2). The optimal solution in such circumstances is to use converging
operations -- several diﬀerent research methods are used to address a
given theoretical issue with the strengths of one method balancing out
the limitations of other methods. If diﬀerent methods produce the same
answer, that provides stronger evidence than could be obtained using a
single method. If diﬀerent methods produce diﬀerent answers, further
research is required to clarify matters. Note that using convergent
operations is more diﬃcult and demanding than using a single approach
(Brase, 2014).

In writing this book, our coverage of each topic emphasises research
most enhancing our understanding. As a result, any given approach (e.g.,
cognitive neuroscience; cognitive neuropsychology) is strongly
represented when we discuss some topics but is much less well
represented with other topics.

IS THERE A REPLICATION CRISIS? Replication (the ability to repeat the
ﬁndings of previous research using the same or similar experimental
methods) is of central importance to psychology (including cognitive
psychology). In recent years, however, there have been concerns about
the extent to which ﬁndings can be replicated, leading Shrout and
Rodgers (2018, p. 487) to refer to "the replication crisis" in
psychology. An important trigger for these concerns was an inﬂuential
article in which the replicability of 100 studies published in leading
psychology journals was assessed (Open Science Collaboration, 2015).
Only 36% of the ﬁndings reported in these studies were replicated.
Within cognitive psychology, only 21 out of 42 ﬁndings (50%) were
replicated. Only 50% of ﬁndings were reproduced! This is perhaps less
problematical than it sounds. The complexities of research mean
individual studies can provide only an estimate of the "true" state of
aﬀairs rather than deﬁnitive evidence (Stanley & Spence, 2014). Why are
there problems with replicating ﬁndings in cognitive psychology (and
psychology generally)? A major reason is the sheer complexity of human
cognition -- cognitive processing and performance are inﬂuenced by
numerous factors (many of which are not controlled or manipulated). As a
result, even replicated ﬁndings often diﬀer considerably in terms of the
size of the eﬀects obtained (Stanley et al., 2018). Another reason is
that experimenters sometimes use questionable research practices
exaggerating the true statistical signiﬁcance of their data. One example
is p-hacking (selective reporting), in which "Researchers conduct many
analyses on the same data set and just report those that are
statistically signiﬁcant" (Simmons et al., 2018, p. 255). Another
example involves researchers proposing hypotheses after research results
are known rather than before as should be the case (Shrout & Rodgers,
2018).

Approaches to human cognition

35

TABLE 1.3 STRENGTHS AND LIMITATIONS OF MAJOR APPROACHES TO HUMAN
COGNITION Strengths

Limitations

Experimental cognitive psychology 1. The ﬁrst systematic approach to
understanding human cognition

1.  Most cognitive tasks are complex and involve many different
    processes

2.  The source of most theories and tasks used by the other approaches

3.  Behavioural evidence provides indirect evidence concerning internal
    processes

4.  It is enormously ﬂexible and can be applied to any aspect of
    cognition

5.  Theories are sometimes vague and hard to test empirically.

6.  It has produced numerous important replicated ﬁndings

7.  Findings sometimes do not generalise because of paradigm speciﬁcity

8.  It has strongly inﬂuenced social, clinical and developmental
    psychology

9.  There is a lack of an overarching theoretical framework

Cognitive neuropsychology 1. Double dissociations have provided strong
evidence for various processing modules

1.  Patients may develop compensatory major strategies not found in
    healthy individuals

2.  Causal links can be shown between brain damage and cognitive
    performance

3.  Most of its theoretical assumptions (e.g., the mind is modular) seem
    too extreme

4.  It has revealed unexpected complexities in cognition 3. Detailed
    cognitive processes and their interconnectedness (e.g., language)
    are often not speciﬁed

5.  It transformed memory and language research

6.  There has been excessive reliance on single-case studies

7.  It straddles the divide between cognitive psychology 5. Brain
    plasticity complicates interpreting ﬁndings and cognitive
    neuroscience Cognitive neuroscience: functional neuroimaging +
    ERPs + TMS

8.  Great variety of techniques offering excellent temporal or spatial
    resolution

9.  Functional neuroimaging techniques provide essentially correlational
    data

10. Functional specialisation and brain integration can be studied

11. Much over-interpretation of data involving reverse inferences

12. TMS is ﬂexible and permits causal inferences

13. There are many false positives and replication failures

14. Rich data permit assessment of integrated brain processing as well
    as specialised functioning

15. It has generated very few new theories

16. Resolution of complex theoretical issues

17. Difﬁculty in relating brain activity to psychological processes

Computational cognitive science 1. Theoretical assumptions are spelled
out with precision

1.  Many computational models do not make new predictions

2.  Comprehensive cognitive architectures have been developed

3.  There is some overﬁtting, which restricts generalisation to other
    data sets

4.  Computational models are increasingly used to model brain damage

5.  It is sometimes hard to falsify computational effects of models

6.  Computational cognitive neuroscience is increasingly 4. Most
    computational models de-emphasise motivational and used to model
    patterns of brain activity emotional factors

7.  The emphasis on parallel processing ﬁts well with functional
    neuroimaging data

8.  Researchers' reluctance to share source codes and models inhibits
    progress

36

Approaches to human cognition

KEY TERM

One answer to problems with replicability is to use meta-analysis, in
which ﬁndings from many studies are combined and integrated using
various statistical techniques. This approach has the advantage of not
exaggerating the importance of any single study, but has various
potential problems (Sharpe, 1997):

Meta-analysis A form of statistical analysis based on combining the
ﬁndings from numerous studies on a given research topic.

(1) 
(2) 
(3) 

The "apples and oranges" problem: very diﬀerent studies are often
included within a meta-analysis. The "ﬁle drawer" problem: it is hard
for researchers to publish non-signiﬁcant ﬁndings. Since meta-analyses
often ignore unpublished ﬁndings, the studies included may be
unrepresentative. The "garbage in -- garbage out" problem: poorly
designed and conducted studies are often included along with
high-quality ones.

The above problems can be addressed. Precise criteria for studies to be
included can reduce the ﬁrst and third problems. The second problem can
be reduced by asking researchers to provide relevant unpublished data.
Watt and Kennedy (2017) identiﬁed a more important problem: many
researchers use somewhat subjective criteria for inclusion of studies in
meta-analyses, favouring those supporting their theoretical position and
rejecting those that do not. This creates conﬁrmation bias (see Chapter
14). The good news is that experimental psychologists (including
cognitive psychologists) have responded very positively to the above
problems. More speciﬁcally, there has been a large increase in
disclosure and preregistration. Disclosure means that researchers
"disclose all of their measures, manipulations, and exclusions" (Nelson
et al., 2018, p. 518). In the case of meta-analyses, it means
researchers making available all the ﬁndings initially considered for
inclusion. That would allow other researchers to conduct their own
meta-analyses and check whether the outcome remains the same.
Pre-registration involves researchers making publicly available all
decisions about sample size, hypotheses, statistical analyses and so on
before an experimental study is carried out. With respect to
meta-analyses, pre-registration involves making public the inclusion
criteria for a metaanalysis, the methods of analysis and so on, before
the ﬁndings of included studies are known (Hamlin, 2017). In sum, there
are some genuine issues concerning the replicability of ﬁndings within
cognitive psychology. However, there are various reasons why there is no
"replication crisis". First, numerous important ﬁndings in cognitive
psychology have been replicated dozens or even hundreds of times as is
clear from a very large number of meta-analytic reviews. Second, as
Nelson et al. (2018, p. 511) pointed out: "The scientiﬁc practices of
experimental psychologists have improved dramatically."

OUTLINE OF THIS BOOK One problem with writing a textbook of cognitive
psychology is that virtually all the processes and systems in the
cognitive system are interdependent. Consider, for example, a student
reading a book to prepare for an examination. The student is learning,
but several other processes are going

Approaches to human cognition

on as well. Visual perception is involved in the intake of information
from the printed page, and there is attention to the content of the
book. In order for the student to beneﬁt from the book, they must
possess considerable language skill, and must have extensive relevant
knowledge stored in long-term memory. There may be an element of problem
solving in the student's attempts to relate the book's content to the
possibly conﬂicting information they have learned elsewhere.
Decision-making may also be involved when the student decides how much
time to devote to each chapter. In addition, what the student learns
depends on their emotional state. Finally, the acid test of whether the
student's learning has been eﬀective comes during the examination
itself, when the material from the book must be retrieved and
consciously evaluated to decide its relevance to the examination
question. The words italicised in the previous three paragraphs indicate
major aspects of human cognition and form the basis of our coverage. In
view of the interdependence of all aspects of the cognitive system, we
emphasise how each process (e.g., perception) depends on other processes
and structures (e.g., attention, long-term memory). This should aid the
task of understanding the complexities of human cognition.

CHAPTER SUMMARY •

Introduction. Cognitive psychology used to be uniﬁed by an approach
based on an analogy between the mind and the computer. This
information-processing approach viewed the mind as a general-purpose,
symbol-processing system of limited capacity. Today there are four main
approaches to human cognition: experimental cognitive psychology;
cognitive neuroscience; cognitive neuropsychology; and computational
cognitive science. These four approaches are increasingly combined to
provide an enriched understanding of human cognition.

•

Cognitive psychology. Cognitive psychology focuses on internal mental
processes whereas behaviourism focused mostly on observable stimuli and
responses. Cognitive psychologists assume top-down and bottom-up
processes are both involved in the performance of cognitive tasks. These
processes can be serial or parallel. Various methods (e.g.,
latent-variable analysis) have been used to address the task impurity
problem and to identify the processes within cognitive tasks. Cognitive
psychology has massively inﬂuenced theorising and the tasks used across
all major approaches to human cognition. In spite of its enormous
contributions, cognitive psychology sometimes lacks ecological validity,
suffers from paradigm speciﬁcity and is theoretically vague.

•

Cognitive neuropsychology. Cognitive neuropsychology is based on various
assumptions including modularity, anatomical

37

38

Approaches to human cognition

modularity, uniformity of functional architecture and subtractivity.
Double dissociations provide reasonable (limited) evidence for separate
modules or systems. The case-study approach is more informative than the
single-case approach. Cognitive neuropsychology is limited for several
reasons: its assumptions are mostly too strong; patients can develop
compensatory strategies, there is brain plasticity; brain damage can
cause widespread reduced connectivity within the brain; and it
underestimates the extent of integrated brain functioning. •

Cognitive neuroscience: the brain in action. Cognitive neuroscientists
study the brain as well as behaviour using techniques varying in spatial
and temporal resolution. Functional neuroimaging techniques provide
basically correlational evidence, but transcranial magnetic stimulation
(TMS) can indicate a given brain area is necessarily involved in a given
cognitive function. The richness of the data obtained from neuroimaging
studies permits the assessment of functional specialisation and brain
integration. Cognitive neuroscience is a ﬂexible and potentially
self-correcting approach. However, correlational ﬁndings are sometimes
overinterpreted, underpowered studies make replication difﬁcult, and
relatively few studies in cognitive neuroscience generate (or even test)
cognitive theories.

•

Computational cognitive science. Computational cognitive scientists
develop computational models to understand human cognition.
Connectionist networks use elementary units or nodes connected together.
They can learn using rules such as backward propagation. Production
systems consist of production or "IF . . . THEN" rules. ACT-R is a
highly developed model based on production systems. Computational models
have increased in scope to provide detailed theoretical accounts of
ﬁndings from cognitive neuroscience and cognitive neuropsychology. They
have shown progress via the use of nested incremental modelling.
Computational models are often hard to falsify, de-emphasise
motivational and emotional factors, and often lack biological
plausibility.

•

Comparisons of different approaches. The major approaches are
increasingly used in combination. Each approach has its own strengths
and limitations, which makes it useful to use converging operations.
When two approaches produce the same ﬁndings, this is stronger evidence
than can be obtained from a single approach on its own. If two
approaches produce different ﬁndings, this indicates further research is
needed to clarify what is happening.

•

Is there a replication crisis? There is increasing evidence that many
ﬁndings in psychology (including cognitive psychology) are hard to
replicate. However, this does not mean there is a

Approaches to human cognition

replication crisis. Meta-analyses indicate that numerous ﬁndings have
been successfully replicated many times. In addition, experimental
research practices have improved considerably in recent years which
should increase successful replications in the future.

FURTHER READING Hartwigsen, G. (2018). Flexible redistribution in
cognitive networks. Trends in Cognitive Sciences, 22, 687--698. Gesa
Hartwigsen discusses several compensatory strategies used by
brain-damaged patients and healthy individuals administered transcranial
magnetic stimulation (TMS). Laird, J.E., Lebiere, C. & Rosenbloom, P.S.
(2017). A standard model of the mind: Toward a common computational
framework across artiﬁcial intelligence, cognitive science,
neuroscience, and robotics. AI Magazine, 38, 1--19. These authors
proposed a standard model based on the commonalities found among
diﬀerent proposed cognitive architectures (e.g., ACT-R; Soar).
Passingham, R. (2016). Cognitive Neuroscience: A very Short
Introduction. Oxford: Oxford University Press. Richard Passingham
provides an accessible account of the essential features of cognitive
neuroscience. Poldrack, R.A., Baker, C.I., Durnez, J., Gorgolewski,
K.J., Matthews, P.M., Munafo, M.R., et al. (2017). Scanning the horizon:
Towards transparent and reproducible neuroimaging research. Nature
Reviews Neuroscience, 18, 115--126. Problems with research in cognitive
neuroscience are discussed and proposals for enhancing the quality and
replicability of such research are put forward. Shallice, T. (2015).
Cognitive neuropsychology and its vicissitudes: The fate of Caramazza's
axioms. Cognitive Neuropsychology, 32, 385--411. Tim Shallice discusses
strengths and limitations of various experimental approaches within
cognitive neuropsychology. Shrout, P.E. & Rodgers, J.L. (2018).
Psychology, science, and knowledge construction: Broadening perspectives
from the replication crisis. Annual Review of Psychology, 69, 487--510.
Patrick Shrout and Joseph Rodgers discuss the numerous ways in which
improving research practices are reducing replication problems. Taatgen,
N.A., van Vugt, M.K., Borst, J.P. & Melhorn, K. (2016). Cognitive
modelling at ICCM: State of the art and future directions. Topics in
Cognitive Science, 8, 259--263. Niels Taatgen and his colleagues discuss
systematic improvements in computational cognitive models. Ward, J.
(2015). The Student's Guide to Cognitive Neuroscience (3rd edn). Hove,
UK: Psychology Press. The ﬁrst ﬁve chapters of this textbook provide
detailed information about the main techniques used by cognitive
neuroscientists.

39

What is "perception"? According to Twedt and Parfitt (2018, p. 1),
"Perception is the study of how sensory information is processed into
perceptual experience . . . all senses share the common goal of picking
up sensory information from the external environment and processing that
information into a perceptual experience." Our main emphasis in this
section of the book is on visual perception, which is of enormous
importance in our everyday lives. It allows us to move around freely, to
see other people, to read magazines and books, to admire the wonders of
nature, to play sports and to watch movies and television. It also helps
to ensure our survival. If we misperceive how close cars are to us as we
cross the road, the consequences could be fatal. Unsurprisingly, far
more of the cortex (especially the occipital lobes at the back of the
head) is devoted to vision than to any other sensory modality. Visual
perception seems so simple and effortless, we typically take it for
granted. In fact, however, it is very complex, and numerous processes
transform and interpret sensory information. Relevant evidence comes
from researchers in artificial intelligence who tried to program
computers to "perceive" the environment. In spite of their best efforts,
no computer can match more than a fraction of the skills of visual
perception that we possess. For example, humans are much better than
computer programs when deciphering distorted interconnected characters
(commonly known as CAPTCHAs) to gain access to an internet website.
There is a rapidly growing literature on visual perception (especially
from the cognitive neuroscience perspective). The next three chapters
provide detailed coverage of the main issues. Chapter 2 focuses on basic
processes in visual perception with an emphasis on the great advances
made in understanding the underlying brain mechanisms. Of importance, we
see in this chapter that the processes leading to object recognition
differ from those guiding vision for action. Finally, this chapter
discusses important aspects of visual perception (e.g., colour
perception; perception without awareness; depth perception).

PART I

Visual perception and attention

42

Visual perception and attention

Chapter 3 focuses on the processing underlying our ability to identify
objects in the world around us. Initially, we discuss perceptual
organisation and how we decide which parts of the visual input belong
together and so form an object. We then move on to theories of object
recognition including a discussion of the relevant behavioural and
neuroscientific evidence. Are the same recognition processes involved
across all types of objects? This issue remains controversial. However,
most experts agree that face recognition differs in important ways from
the recognition of most other objects. Accordingly, face recognition is
discussed separately from the recognition of other objects. The final
part of Chapter 3 is concerned with another controversial issue --
whether the main processes involved in visual imagery are the same as
those involved in visual perception. As you will see, it is arguable
that this controversy has largely been resolved (turn to Chapter 3 to
find out how!). The central focus of Chapter 4 is on how we process a
constantly changing environment and manage to respond appropriately to
those changes. Of major importance is our ability to predict the speed
and direction of objects and to move towards our goal whether walking or
driving. Other topics discussed in Chapter 4 are our ability to reach
for (and grasp) objects and our ability to make sense of other people's
movements. There are major links between visual perception and
attention. The final topic in Chapter 4 is concerned with the notion
that we may need to attend to an object to perceive it consciously.
Attentional failures can prevent us from noticing changes in objects or
the presence of an unexpected object. However, failures to notice
changes in objects also depend on the limitations of peripheral vision.
Issues relating directly to attention are discussed thoroughly in
Chapter 5. This chapter starts with the processes involved in focused
attention in the visual and auditory modalities. We next consider how we
use visual processes when engaged in the everyday task of searching for
some object (e.g., a pair of socks in a drawer). We then consider
research on disorders of visual attention in brain-damaged individuals,
research that has greatly increased our understanding of visual
attention in healthy individuals. After that, we discuss the factors
determining the extent to which we can do two things at once (i.e.,
multi-tasking). This involves a consideration of the role played by
"automatic" processes. In sum, the area spanning visual attention and
attention is among the most exciting and important within cognitive
psychology and cognitive neuroscience. Tremendous progress has been made
in unravelling the complexities of perception and attention over the
past decade. The choicest fruits of that endeavour are set before you in
the four chapters forming this section of the book.

Chapter

Basic processes in visual perception

2

INTRODUCTION Considerable progress has been made in understanding visual
perception in recent years. Much of this progress is due to cognitive
neuroscientists, thanks to whom we now have a good knowledge of the
visual brain. Initially, we consider the main brain areas involved in
vision and their functions. Then we discuss theories of brain systems in
vision, followed by a detailed analysis of basic aspects of visual
perception (e.g., colour perception; depth perception). Finally, we
consider whether perception can occur without conscious awareness. The
specific processes we use in visual perception depend on what we are
looking at and on our perceptual goals (i.e., what we are looking for)
(Hegdé, 2008). On the one hand, we can sometimes perceive the gist of a

Figure 2.1 Complex scene that requires prolonged perceptual processing
to understand fully. Study the picture and identify the animals within
it. Reprinted from Hegdé (2008). Reprinted with permission of Elsevier.

44

KEY TERMS Retinal ganglion cells Retinal cells providing the output
signal from the retina. Retinopy The notion that there is mapping
between receptor cells in the retina and points on the surface of the
visual cortex.

Interactive feature: Primal Pictures' 3D atlas of the brain

Visual perception and attention

natural scene extremely rapidly (Thorpe et al., 1996). Observers saw
photographs containing (or not containing) an animal for only 20 ms.
Eventrelated potentials (ERPs: see Glossary) indicated the presence of
an animal was detected within about 150 ms. On the other hand, look at
the photograph in Figure 2.1 and decide how many animals are present. It
probably took you several seconds to perform this task. Bear in mind the
diversity of visual perception as you read this and the following two
chapters.

VISION AND THE BRAIN In this section we consider the brain systems
involved in visual perception. Visual processing occurs in at least 30
distinct brain areas (Felleman & Van Essen, 1991). The visual cortex
consists of the entire occipital cortex at the back of the brain and
also extends well into the temporal and parietal lobes. To understand
visual processing in the brain fully, however, we first need to consider
briefly what happens between the eye and the cortex.

From eye to cortex There are two types of visual receptor cells in the
retina: cones and rods. Cones are used for colour vision and sharpness
of vision (see section on colour vision, pp. 64--71). Patients with rod
monochromatism have no detectable cone function resulting in total
colour blindness (Tsano & Sharma, 2018). There are 125 million rods
concentrated in the outer regions of the retina. Rods are specialised
for vision in dim light. Many differences between cones and rods stem
from the fact that a retinal ganglion cell receives input from only a
few cones but from hundreds of rods. Thus, only rods produce much
activity in retinal ganglion cells in poor lighting conditions. The main
pathway between the eye and the cortex is the retinageniculate-striate
pathway. It transmits information from the retina to V1 and then V2
(both discussed shortly) via the lateral geniculate nuclei (LGNs) of the
thalamus. The entire retina-geniculate-striate system is organised
similarly to the retinal system. For example, two stimuli adjacent to
each other in the retinal image will also be adjacent at higher levels
within that system. The technical term is retinopy: retinal receptor
cells are mapped to points on the surface of the visual cortex. Each eye
has its own optic nerve and the two optic nerves meet at the optic
chiasm. At this point the axons from the outer halves of each retina
proceed to the hemisphere on the brain hemisphere on the same side,
whereas those from the inner halves cross over and go to the other
hemisphere. As a result, each side of visual space is represented within
the opposite brain hemisphere. Signals then proceed along two optic
tracts within the brain. One tract contains signals from the left half
of each eye and the other signals from the right half (see Figure 2.2).
After the optic chiasm, the optic radiation proceeds to the lateral
geniculate nucleus, which is part of the thalamus. Nerve impulses
finally reach V1 in primary visual cortex within the occipital lobe at
the back of the head before spreading out to nearby visual cortical
areas such as V2.

Basic processes in visual perception

45 Figure 2.2 Route of visual signals. Note that signals reaching the
left visual cortex come from the left sides of the two retinas, and
signals reaching the right visual cortex come from the right sides of
the two retinas.

There are two relatively independent channels or pathways within the
retina-geniculate-striate system: (1) (2)

The parvocellular (or P) pathway: it is most sensitive to colour and to
fine detail; most of its input comes from cones. The magnocellular (or
M) pathway: it is most sensitive to movement information; most of its
input comes from rods.

As stated above, these two pathways are only relatively independent. In
fact, there are numerous interconnections between them and the entire
visual system is extremely complex. For example, there is clear
intermingling of the two pathways in V1 (Leopold, 2012). Ryu et
al. (2018, p. 707) studied brain activity in V1 when random-dot images
were presented: "The local V1 sites receiving those parallel inputs
\[from the P and M pathways\] are densely linked with one another via
horizontal connections \[which\] are organised in complicated yet
systematic ways to subserve the multitude of representational functions
of V1." Finally, there is also a Koniocellular pathway. However, its
functions are still not well understood.

Early visual processing: V1 and V2 We start with three general points.
First, to understand visual processing in the primary visual cortex (V1
or BA17) and the secondary visual cortex (V2 or BA18), we must consider
the notion of a receptive field. The receptive field for any given
neuron is the retinal region where light affects its activity. The
receptive field can also refer to visual space because it is mapped in a
one-to-one manner onto the retinal surface.

KEY TERM Receptive field The region of the retina in which light
influences the activity of a particular neuron.

46

KEY TERM Lateral inhibition Reduction of activity in one neuron caused
by activity in a neighbouring neuron.

Visual perception and attention

Second, neurons often influence each other. For example, there is
lateral inhibition, where reduced activity in one neuron is caused by
activ-

ity in a neighbouring neuron. Lateral inhibition increases the contrast
at the edges of objects, making it easier to identify the dividing line
between objects. The phenomenon of simultaneous contrast depends on
lateral inhibition (see Figure 2.3). The two central squares are
physically identical but the one on the left appears lighter. This
difference is due to simultaneous contrast produced because the left
surround is much darker than the right surround. Third, early visual
processing involves large areas within the primary visual cortex (V1)
and secondary visual cortex (V2). For example, Hegdé and Van Essen
(2000) found in macaques that one-third of V2 cells responded to complex
shapes and differences in size and orientation.

Two pathways As we have just seen, neurons from the P and M pathways
mainly project to V1 (primary visual cortex). What happens after V1? The
P pathway associates with the ventral pathway From Lehar (2008).
Reproduced with permission of the author. or stream that proceeds to the
inferotemporal cortex. In contrast, the M pathway associates with the
dorsal pathway or stream that proceeds to the posterior parietal cortex.
Note the above assertions oversimplify a complex reality. We discuss the
ventral and dorsal pathways in detail shortly. It is assumed the ventral
or "what" pathway culminating in the inferotemporal cortex is mainly
concerned with form and colour processing and with object recognition.
In contrast, the dorsal or "how" pathway culminating in the parietal
cortex is more concerned with motion processing. As we will see later,
there are extensive interactions between the two pathways. The nature of
such interactions was reviewed by Rossetti et al. (2017; see Figure 2.15
in this chapter). Galletti and Fattori (2018) argued that visual
processing is more flexible than implied by the notion of two
interacting pathways or streams. Figure 2.3 The square on the right
looks darker than the identical square on the left because of
simultaneous contrast involving lateral inhibition.

We should not conceive the cortical streams as fixed series of
interconnected cortical areas in which each area belongs to one stream .
. ., but \[rather\] as interconnected neuronal networks, often involving
the same neurons, that are involved in a number of functional processes
and whose activation changes dynamically according to the context.
(p. 203)

Organisation of the visual brain A more detailed picture of the brain
areas involved in visual processing is given in Figure 2.4. V3 is
generally assumed to be involved in form

Basic processes in visual perception

Figure 2.4 Some distinctive features of the largest visual cortical
areas. The relative size of the boxes reflects the relative area of
different regions. The arrows labelled with percentages show the
proportion of fibres in each projection pathway. The vertical position
of each box represents the response latency of cells in each area, as
measured in single-unit recording studies. IT = inferotemporal cortex;
MT = medial or middle temporal cortex; MST = medial superior temporal
cortex. All areas are discussed in detail in the text. From Mather
(2009). Copyright 2009 George Mather. Reproduced with permission.

processing, V4 in colour processing and V5/MT in motion processing (all
discussed in more detail pp. 49--54). The ventral stream includes V1,
V2, V3, V4 and the inferotemporal cortex, whereas the dorsal stream
proceeds from V1 via V3 and MT (medial temporal cortex) to MST (medial
superior temporal cortex). Figure 2.4 reveals three important points.
First, there are complex interconnections among visual cortical areas.
Second, the brain areas within the ventral pathway are more than twice
as large as those within the dorsal pathway. Third, cells in the lateral
geniculate nucleus respond fastest when a visual stimulus is presented
followed by activation of cells in V1. However, cells are activated in
several other areas (V3/V3A; MT; MST) very shortly thereafter. Figure
2.4 shows the traditional hierarchical view of the major brain areas
involved in visual processing. It is supported by anatomical evidence
(see proportions of fibres projecting up the hierarchy in the figure).
Nevertheless, this view is oversimplified. Here we consider three of its
main limitations.

47

48

Visual perception and attention

First, Kravitz et al. (2013) disagreed with the traditional view that
the ventral pathway or stream involves a serial hierarchy proceeding
from simple to complex. Instead, he argued it consists of several
overlapping recurrent networks (see Figure 2.5). There are connections
in both directions between the components within these networks. As
Hegdé (2018, p. 902) argued, "Various regions of the visual system
process information not in a strict hierarchical manner but as parts of
various dynamic brain-wide networks." Second, there is an initial
"feedforward sweep" proceeding through the visual areas starting with V1
and then V2 (shown Figure 2.5 by the directional arrows in Figure 2.4).
Connectivity within the ventral pathway on the lateral surface of the
macaque brain. Brain areas involved include V1, V2, V3 This is followed
by recurrent or top-down and V4, the middle temporal (MT)/medial
superior temporal processing proceeding in the opposite direc(MST)
complex, the superior temporal sulcus (STS) and the tion (not shown in
Figure 2.4). Several theinferior temporal cortex (TE). orists (e.g.,
Lamme, 2018; see Chapter 16) From Kravitz et al. (2013). Reprinted with
permission of Elsevier. assume recurrent processing is of major
importance for conscious visual perception because it integrates
information across different visual areas. Note that visual imagery
depends on several top-down processes resembling those used in visual
perception (see Chapter 3). Hurme et al. (2017) obtained support for the
above assumptions. They applied transcranial magnetic stimulation (TMS;
see Glossary) to V1 at 60 ms to suppress feedforward processing and at
90 ms to suppress recurrent processing. As predicted, early V1 activity
was necessary for conscious and unconscious vision but late V1 activity
was necessary only for conscious vision. Third, Zeki (2016)
distinguished three hierarchical models of the visual brain (see Figure
2.6). Model (a) was proposed first and model (c), the one favoured by
Zeki, was proposed most recently. His central argument is that,
"Parallel processing . . . is much more ubiquitous than commonly
supposed" (p. 2515). Thus, models such as the one shown in Figure 2.4
are inadequate because they de-emphasise parallel processing.

Functional specialisation Zeki (1993, 2001) proposed a functional
specialisation theory where different cortical areas are specialised for
different visual functions. The visual system resembles workers each
working alone to solve part of a complex problem, and it is consistent
with Zeki's (2016) emphasis on parallel processing within the visual
brain. The results of their labours are then combined to produce
coherent visual perception. What are the advantages of functional
specialisation? First, object attributes can occur in unpredictable
combinations (Zeki, 2005). For example, a green object may be a car, a
sheet of paper or a leaf, and a car can be red, black or green. Thus, we
often need to process all of an

Basic processes in visual perception

(a) Single hierarchical model Retina

LGN

Visual association cortex

V1

(b) Parallel hierarchical model through V1

Retina

LGN

V1

V2

V3

V3A

V4

V5

49 Figure 2.6 (a) The single hierarchical model where all brain areas
after V1 are considered jointly as "visual association cortex"; (b) the
parallel hierarchical model which is a hierarchy of processing areas
running serially from V1 through V2 to V3 but with much parallel
processing; (c) the three parallel hierarchical feedforward systems
model with a strong emphasis on parallel rather than serial processing.
From Zeki (2016).

(c) Three parallel hierarchical feedforward systems

V1

V2

V3

LGN

V4

V5

Pulvinar

Retina

object's attributes for accurate perception. Second, the required
processing differs considerably across attributes (Zeki, 2005). For
example, motion processing involves integrating information across time
whereas form or shape processing involves considering the spatial
relationship of elements at a given moment. Here are the main functions
Zeki ascribed to the brain areas shown in Figure 2.3: ●

●

●

V1 and V2: They are involved at an early stage of visual processing.
They contain different groups of cells responsive to colour and form. V3
and V3A: Cells in these areas respond to form (especially the shapes of
objects in motion) but not colour. V4: The majority of cells in this
area respond to colour; many are also responsive to line orientation.

50

Visual perception and attention

KEY TERM

●

Achromatopsia A condition caused by brain damage in which there is very
limited colour perception but form and motion perception are relatively
intact.

V5: This area is specialised for visual motion. In studies with macaque
monkeys, Zeki found all the cells in this area responded to motion but
not colour. In humans, the areas specialised for visual motion are
referred to as MT and MST.

Zeki assumed colour, motion and form are processed in anatomically
separate visual areas. The relevant evidence is discussed below.

Form processing Brain areas involved in form processing in humans
include V1, V2, V3 and V4, culminating in the inferotemporal cortex
(Kourtzi & Connor, 2011). Neurons in the inferotemporal cortex respond
to specific semantic categories (e.g., animals; body parts; see Chapter
3). Neurons in the inferotemporal cortex are also involved in form
processing. Baldassi et al. (2013) found in monkeys that many neurons
within the anterior inferotemporal cortex responded on the basis of form
or shape (e.g., round; star-like; horizontally thin) rather than object
category. Pavan et al. (2017) investigated the role of early visual
areas in form processing using repetitive transcranial magnetic
stimulation (rTMS; see Glossary) to disrupt processing. With static
stimuli, rTMS delivered to early visual areas (V1/V2) disrupted form
processing whereas rTMS delivered to V5/MT did not. If form processing
occurs in different brain areas from colour and motion processing, we
might anticipate some patients would have severely impaired form
processing but intact colour and motion processing. Some support was
reported by Gilaie-Dotan (2016a). She studied LG, a man with visual form
agnosia (see Glossary). LG had deficient functioning within V2 and V3
(although no obvious brain damage) associated with impaired form
processing and object recognition, but relatively intact perception of
colour and biological motion. However, such cases are very rare. As Zeki
(1993) pointed out, brain damage sufficient to almost eliminate form
perception would typically be so widespread that the patient would be
blind.

Colour processing The assumption that V4 (located within the ventral
visual pathway) is specialised for colour processing has been tested in
several ways. These include studying brain-damaged patients, using
brain-imaging techniques, and using transcranial magnetic stimulation to
produce a temporary "lesion" (see pp. 20--22). If V4 is specialised for
colour processing, patients with damage to that area should exhibit
minimal colour perception with fairly intact form and motion perception
and ability to see fine detail. This is approximately the case in
achromatopsia (also known as cerebral achromatopsia) although cases
involving total achromatopsia are very rare (Zihl & Heywood, 2016).
Bouvier and Engel (2006) found in a meta-analysis that a small brain
area within the ventral (bottom) occipital cortex in (or close to) area
V4 was damaged in nearly all cases of achromatopsia. However, the loss
of

Basic processes in visual perception

colour vision was typically only partial, implying other areas are also
directly involved in colour processing. Lafer-Sousa et al. (2016)
identified three brain areas in the ventral visual pathway responding
more strongly to video clips of various objects presented in colour than
in black-and-white. Of importance, different brain areas were associated
with colour and shape processing: colour areas responded comparably to
intact and scrambled objects. Bannert and Bartels (2018) studied brain
activity in several brain areas (including V1, V2, V3 and V4) while
participants viewed abstract colour stimuli or formed visual images of
colour objects (e.g., tomato; banana). The colour of visually presented
stimuli could be worked out from brain activity in every brain area
studied, whereas the colour of imagined stimuli could only be worked out
from brain activity in V4. These findings suggest that a network
including several brain areas is involved in colour processing, but V4
is of special importance within that network. Finally, note that V4 is a
relatively large area. As such, it is involved in the processing of
texture, form and surfaces as well as colour (Winawer & Witthoft, 2015).

Motion processing Area V5 (also known as motion processing area MT) is
heavily involved in motion processing. Functional neuroimaging studies
indicate that motion processing is associated with activity in V5/MT
(Zeki, 2015). However, such studies cannot show V5 (or MT) is necessary
for motion perception. More direct evidence was reported by McKeefry et
al. (2008) using transcranial magnetic stimulation (see Glossary) to
disrupt motion perception. TMS, applied to V5/MT, produced a subjective
slowing of stimulus speed and impaired observers' ability to
discriminate between different speeds. Further evidence of the causal
role of V5 in motion perception was obtained by Vetter et al. (2015).
Observers could not predict the motion of a moving target when TMS was
applied to V5. Additional evidence that the area V5/MT is important in
motion processing comes from research on patients with akinetopsia.
Akinetopsia is an exceptionally rare condition where stationary objects
are perceived fairly normally but motion perception is grossly deficient
(Ardila, 2016). Zihl et al. (1983) studied LM, a woman with akinetopsia
who had suffered bilateral damage to the motion area (V5/MT). She could
locate stationary objects by sight, had good colour discrimination and
her binocular vision was normal. However, her motion perception was
grossly deficient: She had difficulty . . . in pouring tea or coffee
into a cup because the fluid appeared to be frozen, like a glacier. . .
. In a room where more than two people were walking, . . . "people were
suddenly here or there but I have not seen them moving". Zihl and
Heywood (2015) discussed additional findings relating to LM. Even though
her motion perception was extremely poor, she still retained limited
ability to distinguish between moving and stationary stimuli. Heutink et
al. (2018) studied TD, a patient with akinestopsia due to damage to V5.
She was severely impaired at perceiving the direction of

51

KEY TERM Akinetopsia A brain-damaged condition in which motion
perception is severely impaired even though stationary objects are
perceived reasonably well.

52

Visual perception and attention

high-speed visual motion but not low-speed motion, suggesting V5 is less
important for processing low-speed than high-speed motion. V5 (MT) is
not the only brain area involved in motion processing. There is also the
area MST just above V5/MT. Vaina (1998) studied two patients with damage
to MST. Both patients had various problems relating to motion
perception. One patient (RR) "frequently bumped into people, corners and
things in his way, particularly into moving targets (e.g., people
walking)" (Vaina, 1998, p. 498). These findings suggest MST is involved
in the visual guidance of walking. Chaplin et al. (2018) found that the
direction of motion of a stimulus in healthy individuals could be
inferred by taking account of activation within both MT and MST. The
notions that motion perception depends almost exclusively on V5/MT and
MST and that those areas only process information relating to motion are
both oversimplifications for various reasons. First, several areas
outside V5/MT and MST are involved in motion perception. For example,
consider biological motion perception (see Chapter 4). Such perception
involves several additional areas including the superior temporal
sulcus, superior temporal gyrus and inferior frontal gyrus (Thompson &
Parasuraman, 2012; Pavlova et al., 2017). Second, Heywood and Cowey
(1999; see Figure 2.7) found that approximately 60% of cells within
V5/MT respond to binocular disparity (difference between the retinal
images in the left and right eyes; see Glossary) and 50% of cells within
V5/MT respond to stimulus orientation. However, V5/MT is especially
important with respect to direction of motion with approximately 90% of
cells responding. Third, we should distinguish between different types
of motion perception (e.g., first-order and second-order motion
perception). With first-order

Figure 2.7 The percentage of cells in six different visual cortical
areas responding selectively to orientation, direction of motion,
disparity and colour. From Heywood and Cowey (1999).

Basic processes in visual perception

(a) 

Speeded inputs to MT/V5 bypassing hierarchy

rea

m

/ ion nt e t at tion ac

dor sa

l st

op tic

ﬂo w

MT/V5 to MSTd/I Motion pathway outputs according to function

nts/ me ove cking m eye ct tra e obj

M

ST d/

1

LGN

optic ﬂow

Plv left

Figure 2.8 Visual motion inputs proceed rapidly from subcortical areas
and V1 directly to MT/V5 and from there to MST; information is then
transferred to several other brain regions. \[LGN = lateral geniculate
nucleus; Plv = pulvinar\]. From Gilaie-Dotan (2016b). Reprinted with
permission of Elsevier.

kinematics

MT/V5 V1

53

objectness ventr al stre am right

(b) Ventral MT & MST Dorsal

displays, the moving shape differs in luminance (intensity of reflected
light) from its background. For example, the shape might be dark whereas
the background is light. With second-order displays, there is no
difference in luminance between the moving shape and the background. In
everyday life, we encounter second-order displays infrequently (e.g.,
movement of grass in a field caused by the wind). Some patients have
intact first-order motion perception but impaired second-order motion
perception whereas others exhibit the opposite pattern (GilaieDotan,
2016a). Thus, all forms of motion perception do not involve similar
underlying processes. Gilaie-Dotan (2016b) studied motion processing
within the brain (see Figure 2.8). In essence, information about visual
motion inputs bypasses several visual areas (e.g., V2, V4) and rapidly
reaches MT/V5. It then continues rapidly to MST, after which information
is transferred to several other areas. Gilaie-Dotan (2016b, p. 379)
pointed out that visual motion perception "has been continually
associated with and considered part of the dorsal pathway". For example,
Milner and Goodale's (1995, 2008) perceptionaction model emphasises
close links between visual motion processing and perception and the
dorsal ("how" pathway; see pp. 56--57). GilaieDotan accepted the dorsal
pathway is of major importance. However, she argued persuasively that
the ventral ("what") pathway is also involved in motion perception. For
example, efficient detection of visual motion

54

Visual perception and attention

KEY TERM

requires having an intact right ventral visual cortex (Gilaie-Dotan et
al., 2013).

Binding problem The issue of integrating different types of information
to produce coherent visual perception.

Binding problem Zeki's theoretical approach poses the obvious problem of
how information about an object's motion, colour and form is combined
and integrated to produce coherent perception. This is the binding
problem: "How the brain brings together what it has processed . . . in
its different hierarchically organised parallel processing systems . . .
to give us our unitary experience of the visual world" (Zeki, 2016,
p. 3521). One aspect of this problem is that object-related processing
in different visual areas ends at different times, thus making it harder
to integrate these outputs in visual perception. There may be continuous
integration of information starting during early stages of visual
processing. Seymour et al. (2009) presented observers with red or green
dots rotating clockwise or counterclockwise. Colourmotion conjunctions
were processed in several brain areas including V1, V2, V3, V3A/B, V4
and V5/MT+. Seymour et al. (2016) found that binding of information
about object form and colour occurred as early as V2. These findings
contradict the traditional assumption that "The visual system initially
extracts borders between objects and their background and then 'fills
in' colour" (Seymour et al., 2016, p. 1997). Ghose and Ts'o (2017)
reviewed research indicating progressively more integration of different
kinds of information (and thus less functional specialisation) during
visual processing. They concluded: In V2, we see an increase in the
overlap of cortical generated selectivities such as orientation and
colour . . . in V4 we see extensive overlap among colour, size, and
form, and the existence of . . . a combination of colour and orientation
. . . not present in earlier areas. (p. 17) So far we have focused on
increases in integration of information as processing proceeds from
early to late visual areas ( feedforward processing). However, conscious
visual perception generally depends crucially on recurrent processing
(feedback from higher to lower visual brain areas). Observers'
expectations influence recurrent processing and it is arguable that
expectations (e.g., bananas will be yellow) facilitate the binding or
integration of different kinds of visual information. The
binding-by-synchrony hypothesis (e.g., Singer & Gray, 1995) provides an
influential solution to the binding problem. According to this
hypothesis, detectors responding to features of a single object fire in
synchrony. Of relevance, widespread synchronisation of neural activity
is associated with conscious visual awareness (e.g., Gaillard et al.,
2009; Melloni et al., 2007; see Chapter 16). The synchrony hypothesis is
oversimplified. There is the largely unresolved issue of explaining why
and how synchronised activity occurs across visual areas. The fact that
visual object processing occurs in widely distributed areas of the brain
makes it implausible that precise synchrony could be achieved.

Basic processes in visual perception

Finally, note there are various binding problems. As Feldman (2013)
pointed out, one problem is how visual features are bound together.
Another problem is how we bind together information over successive eye
movements to perceive a stable visual world. Within the above broader
context, it is clear several lines of research are relevant. For
example, observers must decide which parts of the visual information
available at any given time belong to the same object. The gestaltists
put forward several laws describing how this happens (see Chapter 3).
Research on visual search (detecting target stimuli among distractors)
is also relevant (see Chapter 5). This research shows the important role
of selective attention in combining features close together in time and
space.

Evaluation Zeki's functional specialisation theory is an ambitious and
influential attempt to provide a coherent theoretical framework. As
discussed later, Zeki's assumption that motion processing typically
proceeds somewhat independently of other types of visual process has
reasonable empirical support. What are the limitations with Zeki's
theoretical approach? First, the brain areas involved in visual
processing are less specialised than implied theoretically. As mentioned
earlier on p. 52, Heywood and Cowey (1999) considered the percentage of
cells in each visual cortical area responding selectively to various
stimulus characteristics (see Figure 2.7). Cells in several areas
responded to orientation, disparity and colour. Specialisation was found
only with respect to responsiveness to direction of stimulus motion in
MT. Second, the visual brain is substantially more complex than assumed
by Zeki. There are far more brain areas devoted to visual processing
than shown in Figure 2.3, and each brain area has connections to
numerous other areas (Baker et al., 2018). For example, V1 is connected
to at least 50 other areas! What is also de-emphasised in Zeki's
approach is the importance of brain networks and the key role played by
recurrent processing. Third, the binding problem (or problems) has not
been solved. However, integrated visual perception undoubtedly depends
on both bottom-up (feedforward) processes and top-down (recurrent)
processes (see Chapter 3).

TWO VISUAL SYSTEMS: PERCEPTION-ACTION MODEL What are the major functions
of the visual system? Historically, the most popular answer was that it
provides us with an internal (and conscious) representation of the
external world. In contrast, Goodale and Milner (1992) and Milner and
Goodale (1995, 2008) argued in their perception-action model, there are
two visual systems each fulfilling a different function or purpose.
First, there is the vision-for-perception (or "what") system based on
the ventral stream or pathway. It is used when we decide whether an
object is a cat or a buffalo or when admiring a magnificent landscape.
Thus, it is used to identify objects.

55

KEY TERM Ventral stream The part of the visual processing system
involved in object perception and recognition and the formation of
perceptual representations.

56

Visual perception and attention

Figure 2.9 Goodale and Milner's (1992) perception-action model showing
the dorsal and ventral streams. (SC = superior colliculus; LGNd = dorsal
lateral geniculate nucleus; V1+ = early visual areas.)

Posterior parietal cortex

Pulvinar Dorsal stream

SC

From de Haan et al. (2018). Reprinted with permission of Elsevier.

Retina

LGNd

V1+

Ventral stream Occipitotemporal cortex

Second, there is the vision-for-action (or "how") system based on the
dorsal stream or pathway (see Figure 2.9) used for visually guided
action.

It is used when running to return a ball at tennis or when grasping an
object. When we grasp an object, we must calculate its orientation and
position with respect to ourselves. Since observers and objects often
move relative to each other, orientation and position need to be worked
out immediately prior to initiating a movement. Milner (2017, p. 1297)
summarised key differences between the two systems: The ventral stream .
. . mediates the transformations of the contents of the visual signal
into the mental furniture that guides memory, recognition and conscious
perception. In contrast, the dorsal stream . . . mediates the visual
guidance of action, primarily in real time. Schenk and McIntosh (2010)
identified four major differences between the two processing streams:

KEY TERMS Dorsal stream The part of the visual processing system most
involved in visually guided action. Allocentric coding Visual or spatial
coding of objects relative to each other; see egocentric coding.
Egocentric coding Visual or spatial coding dependent on the position of
the observer's body; see allocentric coding.

(1) 
(2) 
(3) 
(4) 

The ventral stream underlies vision for perception whereas the dorsal
stream underlies vision for action. There is allocentric coding
(object-centred; coding the locations of objects relative to each other)
in the ventral stream but egocentric coding (body-centred; coding
relative to the observer's own body) in the dorsal stream.
Representations in the ventral stream are sustained over time whereas
those in the dorsal stream are short-lasting. Processing in the ventral
stream generally (but not always) leads to conscious awareness, whereas
processing in the dorsal stream does not.

Two other differences have been suggested. First, processing in the
dorsal stream is faster. Second, ventral stream processing depends more
on input from the fovea (the central part of the retina used for
detecting detail). Milner and Goodale originally implied that the dorsal
and ventral streams were largely independent of each other. However,
they have

Basic processes in visual perception

increasingly accepted that the two streams often interact. For example,
Milner argued the influence of the ventral stream on dorsal stream
processing "seems to carry visual and semantic complexity, thereby
allowing us to bring meaning to our actions" (Milner, 2017, p. 1305).
The key issue of the independence (or interdependence) of the two
streams is discussed on pp. 62--63.

57

KEY TERM Optic ataxia A condition in which there are problems making
visually guided movements in spite of reasonably intact visual
perception.

Findings: brain-damaged patients We can test Milner and Goodale's theory
by studying brain-damaged patients. Patients with damage to the dorsal
pathway should have reasonably intact vision for perception but severely
impaired vision for action. The opposite pattern of intact vision for
action but very poor vision for perception should be found in patients
having damage to the ventral pathway. Thus, there should be a double
dissociation (see Glossary).

Optic ataxia Patients with optic ataxia have damage to the posterior
parietal cortex (forming part of the dorsal stream; see Figure 2.10).
Some evidence suggests patients with optic ataxia are poor at making
precise visually guided movements although their vision and ability to
move their arms are reasonably intact. As predicted, Perenin and
Vighetto (1988) found patients with optic ataxia had great difficulty in
rotating their hands appropriately when reaching towards (and into) a
large oriented slot. Patients with optic ataxia do not all conform to
the simple picture described above. First, somewhat different regions of
posterior parietal cortex are associated with reaching and grasping
movements and some patients have greater problems with one type of
movement than the other (Vesia & Crawford, 2012). Second, it is
oversimplified to assume patients have intact visual perception but
impaired visually guided action. Pisella et al. (2006) obtained much
less evidence for impaired visually guided action in central compared to
peripheral vision. This finding is consistent with evidence indicating
many optic ataxics can drive effectively.

Figure 2.10 Lesion overlap (purple = \>40% overlap; orange = \>60%
overlap) in patients with optic ataxia. (SPL = superior parietal lobule;
SOG = superior occipital gyrus; Pc = precuneus.) From Vesia and Crawford
(2012). Reprinted with permission of Springer.

58

KEY TERM Visual form agnosia A condition in which there are severe
problems in shape perception (what an object is) but apparently
reasonable ability to produce accurate visually guided actions.

Visual perception and attention

Third, patients with optic ataxia have some impairment in vision for
perception (especially in peripheral vision). Bartolo et al. (2018)
found such patients had an impaired ability on the perceptual task of
deciding whether a target was reachable and they also had problems on
tasks requiring vision for action. Thus, patients with optic ataxia have
difficulties in combining information from the dorsal and ventral
streams. Fourth, Rossetti and Pisella (2018) concluded as follows from
their review: "Optic ataxia is not a visuo-motor deficit and there is no
dissociation between perception and action capacities in optic ataxia"
(p. 225).

Visual form agnosia

Interactive exercise: Müller-Lyer

What about patients with damage only to the ventral stream? Of relevance
are some patients with visual form agnosia, a condition involving severe
problems with object recognition even though visual information reaches
the visual cortex (see Chapter 3). The most-studied visual form agnosic
is DF, whose brain damage is in the ventral stream (James et al., 2003).
For example, her activation in that stream was no greater when presented
with object drawings than with scrambled line drawings. However, she
showed high levels of activation in the dorsal stream when grasping for
objects. Goodale et al. (1994) found DF was very poor at a visual
perception task that involved distinguishing between two shapes with
irregular contours. However, she grasped these shapes firmly between her
thumb and index finger. Goodale et al. concluded DF "had no difficulty
in placing her fingers on appropriate opposition points during grasping"
(p. 604). Himmelbach et al. (2012) re-analysed DF's performance based on
data in Goodale et al. (1994). DF's performance was substantially
inferior to that of healthy controls. Similar findings were obtained
when DF's performance on other grasping and reaching tasks was compared
against controls. Thus, DF had greater difficulties with visually guided
action than previously believed. Rossit et al. (2018) found DF had
impaired peripheral (but not central) reaching, which is the pattern
associated with optic ataxia. DF also had significant impairment in the
fast control of reaching movements (also associated with optic ataxia).
Rossit et al. (p. 15) concluded: "We can no longer assume that DF's
dorsal visual stream is intact and that she is spared in visuo-motor
control tasks, as she also presents clear signs of optic ataxia."

Visual illusions

Figure 2.11 The Müller-Lyer illusion.

There are numerous visual illusions, of which the Müller-Lyer (see
Figure 2.11) is one of the most famous. The vertical line on the left
looks longer than the one on the right although they are the same
length. The Ebbinghaus illusion (see Figure 2.12) is also well known.
The central circle surrounded by smaller circles looks smaller than a
central circle of the same size surrounded by larger circles although
the two central circles are the same size.

Basic processes in visual perception

59

How has the human species flourished if our visual perceptual processes
are apparently very prone to error? Milner and Goodale (1995) argued the
vision-for-perception system processes visual illusions and provides
visual judgements. In contrast, we mostly use the vision-for-action
system when walking close to a precipice or dodging cars. These ideas
led to a dramatic prediction: actions (e.g., pointing; grasping) using
the vision-for-action system should be unaffected by most visual
illusions.

Findings Bruno et al. (2008) conducted a meta-analytic review of
Müller-Lyer studies where observers pointed rapidly at one figure (using
the vision-for-action system). The mean illusion effect was 5.5%. In
contrast, the mean illusion effect was 22.4% when observers provided
verbal estimations of length (using the visionfor-perception system).
The perception-action model is supported by this large difference.
However, the model seems to predict there should have been no illusion
effect at all with pointing. With the Ebbinghaus illusion, the illusion
Figure 2.12 The Ebbinghaus illusion. is often much stronger with visual
judgements using the vision-for-perception system than with grasping
movements using the vision-for-action system (Whitwell & Goodale, 2017).
Knol et al. (2017) explored the Ebbinghaus illusion in more detail. As
predicted theoretically, only visual judgements were influenced by the
distance between the target and the context. Support for the
perception-action model has been reported with the hollow-face illusion,
a realistic hollow mask resembling a normal face (see Figure 2.13; visit
the website: www.richardgregory.org/experiments). Króliczak et
al. (2006) placed a target (a small magnet) on the face mask or a normal
face. Here are two tasks they used: (1) (2)

Draw the target position (using the vision-for-perception system). Make
a fast, flicking finger movement to the target (using the
visionfor-action system).

There was a strong illusion effect when observers drew the target
position, whereas their performance was very accurate (i.e.,
illusion-free) when they made a flicking movement. Both findings were as
predicted theoretically. Króliczak et al. (2006) also had a third
condition where observers made a slow pointing finger movement to the
target and so the vision-foraction system was involved. However, there
was a fairly strong illusory effect. Why was this? Actions may involve
the vision-for-perception system

KEY TERM Hollow-face illusion A concave face mask is misperceived as a
normal face when viewed from several feet away.

60

Visual perception and attention

Figure 2.13 Left: normal and hollow faces with small target magnets on
the forehead and cheek of the normal face. Right: front view of the
hollow mask that appears as an illusory face projecting forwards.
Króliczak et al. (2006). Reprinted with permission of Elsevier.

KEY TERM Proprioception An individual's awareness of the position and
orientation of parts of their body.

as well as the vision-for-action system when preceded by conscious
cognitive processes. Various problematical issues for the
perception-action model have accumulated. First, the type of action is
important. Franz and Gegenfurtner (2008) found the mean illusory effect
with the Müller-Lyer was 11.2% with perceptual tasks, compared to 4.4%
with full visual guidance of the hand movement. In contrast, grasping
when observers could not monitor their hand movements was associated
with an illusory effect of 9.4%, perhaps because action programming
required the ventral stream. Second, illusion effects assessed by
grasping movements often decrease with repeated practice (Kopiske et
al., 2017). Kopiske et al. argued people use feedback from their
inaccurate grasping movements on early trials to reduce illusion effects
later on. Third, illusion effects are often greater when grasping or
pointing movements are made following a delay (Hesse et al., 2016). The
ventral stream (vision-for-perception) may be more likely to be involved
after a delay. The various interpretive problems with previous research
led Chen et al. (2018a) to use a different approach. In their key
condition, observers had restricted vision (they viewed a sphere coated
in luminescent paint in darkness through a pinhole). They estimated the
sphere's size by matching the distance between their thumb and
forefinger to that size (perception) or they grasped the sphere
(action). Their non-grasping hand was in their lap or directly below the
sphere. In the latter condition, observers could make use of
proprioception (awareness of the position of one's body parts). Size
judgements were very accurate in perception and action with full vision
(see Figure 2.14). However, the key finding was that proprioceptive
information about distance produced almost perfect performance when
observers grasped the sphere but not when providing a perceptual
estimate. These findings indicate a very clear difference in the
processes underlying vision-for-perception and vision-for-action. In
sum, there is some support for the predictions of the original
vision-action model. However, illusory effects with visual judgements
and with actions are more complex and depend on many more factors than

Basic processes in visual perception

assumed by that model. Attempts by Milner and Goodale to accommodate
such complexities are discussed below.

w i th o Pr

o Pr

Full

no

o Pr

Restricted

no

o Pr

Disruption index (DI)

Full

i th

--0.4

w

(4) 

0.0

o Pr

(3) 

------------------------------------------------------------------------

0.4

no

(2) 

Memory is required (e.g., there is a time lag between the offset of the
stimulus and the start of the grasping movement). Time is available to
plan the forthcoming movement (e.g., Króliczak et al., 2006). Planning
which movement to make is necessary. The action is unpractised or
awkward.

------------------------------------------------------------------------

------------------------------------------------------------------------

o Pr

(1) 

\*\*

0.8

no

Milner and Goodale (2008) argued most tasks requiring observers to grasp
an object involve some processing in the ventral stream in addition to
the dorsal stream. They reviewed research showing that involvement of
the ventral stream is especially likely in the following circumstances:

GRASPING

ESTIMATION \*\*\*

Action planning + motor responses

61

Restricted

Figure 2.14 Disruption of size judgements when estimated perceptually
(estimation) or produced by grasping (grasping) in full or restricted
vision when there was proprioception (withPro) or no proprioception
(noPro). From Chen et al. (2018a). Reprinted with permission of
Elsevier.

According to the perception-action model, actions are most likely to
require the ventral stream when they involve conscious processes. Creem
and Proffitt (2001) supported this notion. They started by
distinguishing between effective and appropriate grasping. For example,
we can grasp a toothbrush effectively by its bristles but appropriate
grasping involves accessing stored knowledge about the object and so
often requires the ventral stream. As predicted, appropriate grasping
was much more adversely affected than effective grasping by disrupting
participants' ability to retrieve object knowledge. van Polanen and
Davare (2015) reviewed research on factors controlling skilled grasping.
They concluded: The ventral stream seems to be gradually more recruited
as information about the object from pictorial cues or memory is needed
to control the grasping movement, or if conceptual knowledge about more
complex objects that are used every day or tools needs to be retrieved
for allowing the most appropriate grasp. (p. 188)

Dorsal stream: conscious awareness According to the two systems
approach, ventral stream processing is generally accessible to
consciousness whereas dorsal stream processing is not. For example, it
is assumed that the ventral stream (and conscious processing) are often
involved in motor planning (Milner & Goodale, 2008). There is some
support for these predictions from the model (Milner, 2012). As we will
see, however, recent evidence mostly provides contrary evidence.

62

Visual perception and attention

Ludwig et al. (2016) assessed the involvement of the dorsal and ventral
streams in conscious visual perception using a different approach. The
visibility of visual targets presented to one eye was manipulated by
varying the extent to which continuous flash suppression (rapidly
changing stimuli presented to the other eye) impaired the processing of
the targets. There were two main findings. First, there was a tight
coupling between visual awareness of target stimuli and ventral stream
processing. Second, there was a much looser coupling between target
awareness and dorsal stream processing. The first finding is consistent
with the two visual systems hypothesis. However, the second finding
suggests dorsal processing is more relevant to conscious visual
perception than assumed by that hypothesis. According to the
perception-action model, manipulations (e.g., continuous flash
suppression) preventing conscious perception should nevertheless permit
more processing in the dorsal than the ventral stream. However,
neuroimaging studies have typically obtained no evidence that neural
activity in the dorsal stream is greater than in the ventral stream when
observers lack conscious awareness of visual stimuli (Hesselmann et al.,
2018).

Two pathways: update The perception-action model was originally proposed
before neuroimaging and other techniques had clearly indicated the great
complexity of the brain networks involved in perception and action (de
Haan et al., 2018). Recent research has led to developments of the
perception-action model in two main ways. First, we now know much more
about the various interactions between processing in the dorsal and
ventral streams. Second, there are more than two visual processing
streams. Rossetti et al. (2017) show how theoretical conceptualisations
of the relationship between visual perception and action have become
more complex (see Figure 2.15). We have seen that the ventral pathway is
often involved in visually guided action. There is also increasing
evidence the dorsal pathway is involved in visual object recognition
(Freud et al., 2016). For example, patients with damage to the ventral
pathway often retain some sensitivity to three-dimensional (3-D)
structural object representations (Freud et al., 2017a). Zachariou et
al. (2017) applied transcranial magnetic stimulation to posterior
parietal cortex within the dorsal pathway to disrupt processing. TMS
disrupted the holistic processing (see Glossary) of faces, suggesting
the dorsal pathway is involved in face recognition. More supporting
evidence was reported by Freud et al. (2016). They studied shape
processing, which is of central importance in object recognition and so
should depend primarily on the ventral pathway. However, the ventral and
dorsal pathways were both sensitive to shape. The observers' ability to
recognise objects correlated with the shape sensitivity of regions
within the dorsal pathway. Thus, dorsal path activation was of direct
relevance to shape and object processing. How many visual processing
streams are there? There is evidence that actions towards objects depend
on two partially separate dorsal streams (Sakreida et al., 2016; see
Chapter 4). First, there is a dorso-dorsal stream (the "grasp" system)
used to grasp objects rapidly. Second, there is a

Basic processes in visual perception

Figure 2.15 Historical developments in theories linking perception and
action. Row 1: the intuitive notion that action is preceded by conscious
perception. Row 2: Goodale and Milner's original two systems' theory.
Row 3: interaction between the two anatomical pathways and perceptual
and visual processes. Row 4: evidence that processing in primary motor
cortex is preceded by interconnections between dorsal (green) and
ventral (red) pathways.

Row 1: VISION PERCEPTION ACTION

Do rs al

Row 2: ACTION VISION

V1

PERCEPTION

Ventr a

l

From Rossetti et al. (2017). Reprinted with permission of Elsevier.

Dorsal xxx

Row 3:

xxx

xxx

xxx

xxx

ACTION

xxx xxx xxx xxx

xxx xxx xxx

VISION

xxx

xxxxxxxx xx

PERCEPTION

xxx xxx

xxx

xxx

xxx

Ventral

xxx

BS

SC

Row 4:

V3d PO

ACTION VISION PERCEPTION

MT V3a periphV4 V2 V4 V3v Pre-strlate

Eye

FEF. SEF PIP POa, UP/IP

V1

63

Post. Parietal

MIP 7a

PFd (46)

7b

PFv (12)

Arm

AIP PMv

M1 Hand Face

Frontal

FST MSSTP S.T.S TEO Inf. Temporal

PNd Cing SMA

TE

Hipp.

ventro-dorsal stream that makes use of memorised object knowledge and
operates more slowly than the first stream. Haak and Beckmann (2018)
investigated the connectivity patterns among 22 visual areas,
discovering these areas "are organised into not two but three visual
pathways: one dorsal, one lateral, and one ventral" (p. 82). Their
findings thus provide some support for the emphasis within the
perception-action model on dorsal and ventral streams. Haak and Beckmann
speculated that the new lateral pathway may "incorporate . . . aspects
of vision, action and language" (p. 81).

Overall evaluation Milner and Goodale's theoretical approach has been
hugely influential. Their central assumption that there are two visual
systems ("what"

64

Visual perception and attention

and "how") is partially correct. It has received inconsistent support
from research on patients with optic ataxia and visual agnosia. Earlier
we discussed achromatopsia (see Glossary) and akinetopsia (see
Glossary). The former condition depends on damage to the ventral pathway
and the latter condition on damage to the dorsal pathway (Haque et al.,
2018). As predicted theoretically, many visual illusions are much
reduced in extent when observers engage in action-based performance
(e.g., pointing; grasping). What are the model's limitations? First,
evidence from brain-damaged patients provides relatively weak support
for it. In fact, "The idea of a double dissociation between optic ataxia
and visual form agnosia, as cleanly separating visuo-motor from visual
perceptual functions, is no longer tenable" (Rossetti et al., 2017,
p. 130). Second, findings based on visual illusions provide only partial
support for the model. The findings generally indicate that illusory
effects are greater with perceptual judgements than actions but there
are many exceptions. Third, the model exaggerates the independence of
the two visual systems. For example, Janssen et al. (2018) reviewed
research on 3-D object perception and found strong effects of the dorsal
stream on the ventral stream. As de Haan et al. indicated, The
prevailing evidence suggests that cross-talk \[interactions between
visual systems\] is the norm rather than the exception . . . \[There
is\] a flexible and dynamic pattern of interaction between visual
processing areas in which visually processing networks may be created
on-the-fly in a highly task-specific manner. (de Haan et al., 2018,
p. 6) Fourth, the notion there are only two visual processing streams is
an oversimplification. Earlier on pp. 62--63 we discussed two attempts
(Haak & Beckmann, 2018; Sakreida et al., 2016) to develop more complete
accounts.

COLOUR VISION Why do we have colour vision? After all, if you watch an
old black-andwhite movie on television you can easily understand the
moving images. One reason is that colour often makes an object stand out
from its surroundings making it easier to identify. Chameleons very
sensibly change colour to blend in with the background, thus reducing
their chances of being detected by predators. Colour perception also
helps us to recognise and categorise objects. For example, it is useful
when deciding whether a piece of fruit is under- or overripe. Predictive
coding (processing primarily aspects of sensory input that violate the
observer's predictions) is also relevant (Huang & Rao, 2011). Colour
vision allows observers to focus rapidly on any aspects of the incoming
visual input (e.g., discolouring) discrepant with predictions based on
ripe fruit. There are three main qualities associated with colour: (1)
(2)

Hue: the colour itself and what distinguishes red from yellow or blue.
Brightness: the perceived intensity of light.

Basic processes in visual perception

(3) 

Saturation: this allow us to determine whether a colour is vivid or
pale; it is influenced by the amount of white present.

Trichromacy theory Retinal cones are specialised for colour vision. Cone
receptors contain light-sensitive photopigment allowing them to respond
to light. According to the trichromatic \[three-coloured\] theory, there
are three kinds of receptors: (1) (2) (3)

One type is especially sensitive to short-wavelength light and generally
responds most strongly to stimuli perceived as blue. A second type of
cone receptor is most sensitive to medium-wavelength light and responds
greatly to stimuli generally seen as yellow-green. A third type of cone
responds most to long-wavelength light such as that reflected from
stimuli perceived as orange-red.

How do we see other colours? According to the theory, most stimuli
activate two or all three cone types. The colour we perceive is
determined by their relative stimulation levels. Evolution has equipped
us with three types of cones because that produces a very efficient
system -- we can discriminate millions of colours even with so few cone
types. Many forms of colour deficiency are consistent with trichromacy
theory. Most individuals with colour deficiency have dichromacy, in
which one cone class is missing. In red-green dichromacy (the most
common form) there are abnormalities in the retinal pigments sensitive
to medium or long wavelengths. Individuals with red-green dichromacy
differ from intact observers in perceiving far fewer colours. However,
their colour constancy (see Glossary) is almost at normal levels (Álvaro
et al., 2017). The density of cones (the retinal cells responsible for
colour vision) is far higher in the fovea (see Glossary) than the
periphery. However, there are enough cones in the periphery to permit
accurate peripheral colour judgements if colour patches are reasonably
large (Rosenholtz, 2016). The crucial role of cones for colour vision
explains the following common phenomenon: "The sunlit world appears in
sparkling colour, but when night falls . . . we see the world in 50
shades of grey" (Kelber et al., 2017, p. 1). In dim light, the cones are
not activated and our vision depends almost entirely on rods.

Opponent-process theory Trichromacy theory does not explain what happens
after activation of the cone receptors. It also fails to account for
negative afterimages. If you stare at a square of a given colour for
several seconds and then shift your gaze to a white surface, you see a
negative afterimage in the complementary colour (complementary colours
produce white when combined). For example, a green square produces a red
afterimage, whereas a blue square produces a yellow afterimage. Hering
(1878) explained negative afterimages. He identified three types of
opponent processes in the visual system. One opponent process (redgreen
channel) produces perception of green when responding one way and red
when responding the opposite way. A second opponent process

65

KEY TERMS Dichromacy A deficiency in colour vision in which one of the
three cone classes is missing. Negative afterimages The illusory
perception of the complementary colour to the one that has just been
fixated; green is the complementary colour to red and blue is
complementary to yellow.

66

Visual perception and attention

(blue-yellow channel) produces perception of blue or yellow in the same
way. The third opponent process (achromatic channel) produces the
perception of white at one extreme and black at the other. What is the
value of these three opponent processes? The three dimensions associated
with opponent processes provide maximally independent representations of
colour information. As a result, opponent processes provide very
efficient encoding of chromatic stimuli. Much research supports the
notion of opponent processes. First, there is strong physiological
evidence for the existence of opponent cells (Shevell & Martin, 2017).
Second, the theory accounts for negative afterimages (discussed above).
Third, the theory claims it is impossible to see blue and yellow
together or red and green, but the other colour combinations can be
seen. That is precisely what Abramov and Gordon (1994) found. Fourth,
opponent processes explain some types of colour deficiency. Redgreen
deficiency occurs when the red-green channel cannot be used, and
blue-yellow deficiency occurs when individuals cannot make effective use
of the blue-yellow channel.

Dual-process theory Hurvich and Jameson (1957) proposed a dual-process
theory combining the ideas discussed so far. Signals from the three
cones types identified by trichromacy theory are sent to the opponent
cells (see Figure 2.16). There are three channels: (1) (2)

Figure 2.16 Schematic diagram of the early stages of neural colour
processing. Three cone classes (red = long; green = medium; blue =
short) supply three "channels". The achromatic (light-dark) channel
receives nonspectrally opponent input from long- and mediumcone classes.
The two chromatic channels receive spectrally opponent inputs to create
the red-green and blue-yellow channels. From Mather (2009). Copyright
2009 George Mather. Reproduced with permission.

The achromatic \[non-colour\] channel combines the activity of the
medium- and long-wavelength cones. The blue-yellow channel represents
the difference between the sum of the medium-and long-wavelength cones
on the one hand and the short-wavelength cones on the other. The
direction of difference determines whether blue or yellow is seen.

Basic processes in visual perception

(3) 

The red-green channel represents the difference between activity levels
in the medium- and long-wavelength cones. The direction of this
difference determines whether red or green is perceived.

Overall evaluation Dual-process theory has much experimental support.
However, it is oversimplified in several ways (Shevell & Martin, 2017).
First, there are complex interactions between the channels. For example,
short-wavelength cones are activated even in conditions where it would
be expected that only the red-green channel (involving medium- and
long-wavelength cones) would be active (Conway et al., 2018). Second,
the proportions of different cone types vary considerably across
individuals but this typically has surprisingly little effect on colour
perception. Third, the arrangement of cone types in the eye is fairly
random. This seems odd because it presumably makes it hard for
colour-opponent processes to work effectively. More generally, much
research has focused on colour perception and other research has focused
on how nerve cells respond to light of different wavelengths. What has
proved difficult is to relate these two sets of findings directly to
each other. So far there is only limited convergence between
psychological and physiological research (Shevell & Martin, 2017).

67

KEY TERMS Colour constancy The tendency for an object to be perceived as
having the same colour under widely varying viewing conditions.
Illuminant A source of light illuminating a surface or object. Mutual
illumination The light reflected from the surface of an object impinges
on the surface of a second object.

Colour constancy Colour constancy is the tendency for a surface

or object to be perceived as having the same colour when there are
changes in the wavelengths contained in the illuminant (the light source
illuminating the surface or object). Colour constancy indicates colour
vision does not depend solely on the wavelengths of the light reflected
from objects. Learn more about colour constancy on YouTube: "This is
Only Red by Vsauce". Why is colour constancy important? If we lacked
colour constancy, the apparent colour of familiar objects would change
dramatically when the lighting conditions altered. This would make it
very hard to recognise objects rapidly and accurately. Attaining
reasonable levels of colour constancy is an impressive achievement. Look
at the object in Figure 2.17. It is immediately recognisable as a blue
mug even though several other colours can be perceived. The wavelengths
of light depend on the mug itself, the illuminant and reflections from
other objects onto the mug's surface (mutual illumination).

Figure 2.17 Photograph of a mug showing enormous variation in the
properties of the reflected light across the mug's surface. The patches
at the top of the figure show image values from the locations indicated
by the arrows. From Brainard and Maloney (2011). Reprinted with
permission of the Association for Research in Vision and Ophthalmology.

68

Visual perception and attention

How good is colour constancy?

Case study: Colour constancy

Colour constancy is often reasonably good. For example, Granzier et al.
(2009a) assessed colour constancy for six similarly coloured papers in
various indoor and outdoor locations differing substantially in lighting
conditions. They found 55% of the papers were identified correctly. This
represents good performance given the similarities among the papers and
the large differences in lighting conditions. Reeves et al. (2008)
distinguished between our subjective experience and our judgements about
the world. For example, as you walk towards a fire, it feels
increasingly hot subjectively. However, how hot you judge the fire to be
is unlikely to change. Reeves et al. found colour constancy with
non-naturalistic (artificial stimuli) was much greater when observers
judged the objective similarity of two stimuli seen under different
illuminants than when rating their subjective similarity. Radonjić and
Brainard's (2016) obtained similar findings with naturalistic stimuli.
However, colour constancy was higher overall with naturalistic stimuli
because such stimuli provided more cues to guide performance.

Estimating scene illumination The wavelengths of light reflected from an
object are greatly influenced by the illuminant (light source). High
levels of colour constancy could be achieved if observers made accurate
illuminant estimates. However, they often do not, especially when the
illuminant's characteristics are unclear (Foster, 2011). For example,
there are substantial individual differences in the perceived illuminant
(and perceived colour) of the famous dress discussed in the Box. Colour
constancy should be high when illuminant estimation is accurate
(Brainard & Maloney, 2011). Bannert and Bartels (2017) tested this
prediction. Observers were presented with visual scenes using three
different illuminants, and cues within the scenes were designed to
facilitate colour constancy. Bannert and Bartels used functional
magnetic resonance imaging (fMRI) to assess the neural encoding of each
scene. What did Bannert and Bartels (2017) find? Their key finding was
that, "The neural accuracy of encoding the illuminant of a scene
\[predicted\] the behavioural accuracy of constant colour perception"
(p. 357). Thus, colour constancy was high when the illuminant was
processed accurately.

Local colour contrast Land (1986) proposed retinex theory, according to
which we perceive a surface's colour by comparing its ability to
reflect, short-, medium- and long-wavelength light against that of
adjacent surfaces. Thus, we make use of local colour contrast. Kraft and
Brainard (1999) studied colour constancy for complex visual scenes.
Under full viewing conditions, colour constancy was 83% even with large
changes in illumination. When local contrast could not be used, however,
colour constancy dropped to 53%. Foster and Nascimento (1994) developed
Land's ideas into an influential theory based on local contrast. We can
see the nature of their big

Basic processes in visual perception

69

IN THE REAL WORLD: WHAT COLOUR IS "THE DRESS"? On 7 February 2015,
Cecilia Bleasdale took a photograph of the dress she intended to wear at
her daughter's imminent wedding (see below) and posted it on the
internet. It caused an almost immediate sensation because observers
disagreed vehemently concerning the dress's colour. What colour do you
think the dress is (see Figure 2.18)? Wallisch (2017) found 59% of
observers said the dress was white and gold and 27% said it was black
and blue. How can we explain these individual differences? Wallisch
argued the illumination of the dress is ambiguous: the upper part of the
dress implies illumination by daylight whereas the lower part implies
artificial illumination. Many theories predict the perceived colour of
an object depends on its assumed illumination (discussed on p. 62). If
so, observers assuming the dress is illuminated by natural light should
perceive it as white and gold. In contrast, those assuming artificial
illumination should perceive it as black and blue. What did Wallisch
(2017) find? As predicted, observers assuming the dress was illuminated
by natural light were much more likely than those assuming artificial
light to perceive the dress as white/gold (see Figure 2.19). 75

Percent reporting white/gold

70

65

60

55

50

45 Natural

Figure 2.18 "The Dress" made famous by its appearance on the internet.
From Rabin et al. (2016).

Artificial light assumption

Unsure

Figure 2.19 The percentage of observers perceiving "The Dress" to be
white and gold depended on whether they believed it to be illuminated by
natural light or by artificial light, and those who were unsure. From
Wallisch et al. (2017).

discovery through an example. Suppose there are two illuminants and two
surfaces. If surface 1 led to the long-wavelength or red cones
responding three times as much with illuminant 1 as illuminant 2, then
the same threefold difference was also found with surface 2. Thus, the
ratio of cone responses was essentially invariant across different
illuminations. Thus,

70

KEY TERM Chromatic adaptation Changes in visual sensitivity to colour
stimuli when the illumination alters.

Visual perception and attention

cone-excitation ratios can be used to eliminate the illuminant's effects
and so increase colour constancy. Much evidence indicates
cone-excitation ratios are important (Foster, 2011, 2018). For example,
Nascimento et al. (2004) obtained evidence suggesting the level of
colour constancy in different conditions could be predicted on the basis
of cone-excitation ratios. Foster and Nascimento's (1994) theory
provides an elegant account of illuminant-independent colour constancy
in simple visual environments. However, it has limited value in complex
visual environments. For example, colour constancy for a given object
can become harder because of reflections from other objects (see Figure
2.17) or because multiple sources of illumination are present together.
The theory is generally less applicable to natural scenes than
artificial laboratory scenes. For example, the illuminant often changes
more rapidly in natural scenes (e.g., clouds change shape, which
influences the shadows they cast) (Nascimento et al., 2016). In
addition, there are dramatic changes in the level and colour of natural
illuminants over the course of the day. In sum, cone-excitation ratios
are most likely to be almost invariant, "provided that sampling is from
points close together in space or time . . ., or from points separated
arbitrarily but undergoing even changes in illumination" (Nascimento et
al., 2016, p. 44).

Effects of familiarity Colour constancy is influenced by our knowledge
of the familiar colours of objects (e.g., bananas are yellow). Hansen et
al. (2006) asked observers to view photographs of fruits and to adjust
their colour until they appeared grey. There was over-adjustment. For
example, a banana still looked yellowish to observers when it was
actually grey, leading them to adjust its colour to a slightly bluish
hue. Such findings may reflect an influence of familiar size on
subjective colour perception. Alternatively, familiar colour may
primarily influence observers' responses rather than their perception
(e.g., our knowledge that bananas are yellow may bias us to report them
as more yellow than they actually appear). Vandenbroucke et al. (2016)
investigated the above issue. Observers viewed an ambiguous colour
intermediate between red and green presented on typically red (e.g.,
tomato) or green (e.g., pine tree) objects. Familiar colour influenced
colour perception. Of most importance, neural responses in various
visual areas (e.g., V4, which is much involved in colour processing)
were influenced by familiar colour. Neural responses corresponded more
closely to those associated with red objects when the object was
typically red than when it was typically green and more closely to those
found with green objects when it was typically green. Thus, familiar
colour had a direct influence on perception early in visual processing.

Chromatic adaptation One reason we have reasonable colour constancy is
because of chromatic adaptation -- an observer's visual sensitivity to a
given illuminant decreases over time. If you stand outside after
nightfall, you may be surprised by the

Basic processes in visual perception

apparent yellowness of the artificial light in people's houses. However,
this is not the case if you spend some time in a room illuminated by
artificial light. Lee et al. (2012b) found some aspects of chromatic
adaptation within six seconds. Such rapid adaptation increases colour
constancy.

Evaluation In view of the complexity of colour constancy, it is
unsurprising the visual system adopts an "all hands on deck" approach in
which several factors contribute to colour constancy. Of major
importance are zone-excitation ratios that remain almost invariant
across changes in illumination. In addition, top-down factors (e.g., our
memory for the familiar colours of common objects) also play a role.
What are the limitations of theory and research on colour constancy?
First, we lack a comprehensive theory of how the various factors
combine. Second, most research has focused on relatively simple
artificial visual environments. In contrast, "The natural world is
optically unconstrained. Surface properties may vary from one point to
another, and reflected light may vary from one instant to the next"
(Foster, 2018, p. B192). As a result, the processes involved in trying
to achieve colour constancy in more complex environments are poorly
understood. Third, more research is needed to understand why colour
constancy depends greatly on the precise instructions given to
observers. Fourth, as Webster (2016, p. 195) pointed out, "There are
pronounced \[individual\] differences in almost all measures of colour
appearance . . . the basis for these differences remains uncertain."

DEPTH PERCEPTION A major accomplishment of visual perception is the
transformation of the two-dimensional retinal image into perception of a
three-dimensional world seen in depth. The construction of 3-D
representations is very important if we are to pick up objects, decide
whether it is safe to cross the road and so on. Depth perception depends
on numerous visual and other cues (discussed below). All cues provide
ambiguous information and so we would be ill-advised to place total
reliance on any single cue. Moreover, different cues often provide
conflicting information. When you watch a movie, some cues (e.g., stereo
ones) indicate everything you see is at the same distance. In contrast,
other cues (e.g., perspective; shading) indicate some objects are
closer. In real life, depth cues are often provided by movement of the
observer or objects in the visual environment and some cues are
non-visual (e.g., object sounds). Here, however, the main focus will be
on visual depth cues available when the observer and environmental
objects are static. Cues to depth perception are monocular, binocular
and oculomotor. Monocular cues require only one eye but can also be used
with two eyes. The fact that the world still retains a sense of depth
with one eye closed indicates clearly that monocular cues exist.
Binocular cues involve both eyes used together. Finally, oculomotor cues
depend on sensations of

71

KEY TERMS Monocular cues Cues to depth that can be used by one eye but
can also be used by both eyes together. Binocular cues Cues to depth
that require both eyes to be used together. Oculomotor cues Cues to
depth produced by muscular contractions of the muscles around the eye;
use of such cues involves kinaesthesia (also known as the muscle sense).

72

Visual perception and attention

KEY TERMS

muscular contractions of the muscles around the eye. Use of these cues
involves kinaesthesia (the muscle sense).

Texture gradient The rate of change of texture density from the front to
the back of a slanting object.

Figure 2.20 An engraving by de Vries (1604/1970) in which linear
perspective creates an effective three-dimensional effect when viewed
from very close but not from further away. From Todorović (2009).
Copyright 1968 by Dover Publications. Reprinted with permission from
Springer.

Monocular cues Monocular cues to depth are called pictorial cues because
they are used by artists. Of particular importance is linear
perspective, which artists use to create the impression of
three-dimensional scenes on two-dimensional canvases. Linear perspective
(based on laws of optics and geometry) is based on various principles.
For example, parallel lines pointing away from us converge (e.g.,
motorway edges) and objects reduce in size as they recede into the
distance. Tyler (2015) argued that linear perspective is only really
effective in creating a powerful 3-D effect when viewed from the point
from which the artist constructed the perspective. This is typically
very close to the picture as can be seen in a drawing by the Dutch
artist Jan Vredeman de Vries (see Figure 2.20). Texture is another
monocular cue. Most objects (e.g., carpets; cobblestone roads) possess
texture, and textured objects slanting away from us have a texture
gradient (Gibson, 1979; see Figure 2.21). This is a gradient (rate of
change) of texture density as you look from the front to the back of a
slanting object with the gradient changing more rapidly for objects
slanted steeply away from the observer. Sinai et al. (1998) found
observers judged the distances of nearby objects better when the ground
was uniformly textured than when there was a gap (e.g., a ditch) in the
texture pattern. Texture gradient is a limited cue because the perceived
slant depends on the direction of the gradient. For reasons that are
unclear, ground patterns are perceived as less slanted than equivalent
ceiling or sidewall patterns (Higashiyama & Yamazaki, 2016).

Basic processes in visual perception

73

Another monocular cue is interposition where a nearer object hides part
of a more distant one. The strength of this cue can be seen in Kanizsa's
(1976) illusory square (see Figure 2.22). There is a strong impression
of a yellow square in front of four purple circles even though many of
its contours are missing. This depends on processes that relatively
"automatically" complete boundaries using the available information
(e.g., incomplete circles). Another useful cue is familiar size
(discussed more fully later). If we know an object's size, we can use
its retinal image size to estimate its distance. However, we can be
misled. Ittelson (1951) had observers view playing cards through a
peephole restricting them to monocular vision. The perceived distance
was determined almost entirely by familiar size. For example, playing
cards Figure 2.21 double the usual size were perceived as being twice as
far Examples of texture gradients that can be perceived as surfaces
receding into the away from the observers than was actually the case.
distance. We turn now to blur. There is no blur at fixation From Bruce
et al. (2003). point and it increases more rapidly at closer distances
than ones further away. Held et al. (2012) found blur was an effective
depth cue (especially at longer distances). However, observers may
simply have learned to respond that the blurrier stimulus was further
away. Langer and Siciliano (2015) provided minimal training and obtained
little evidence blur was used as a depth cue. They argued blur provides
ambiguous information: an object can appear blurred because it is in
peripheral vision rather than because it is far away. Finally, there is
motion parallax, which involves "transformations of the retinal image
that are created . . . both when the observer moves (observer-produced
parallax) and when objects move with respect to the observer
(object-produced parallax)" (Rogers, 2016, p. 1267). For example, when
you look out of the window of a moving train, nearby objects appear to
move in the opposite direction but distant objects in Figure 2.22 the
same direction. Rogers and Graham (1979) found Kanizsa's (1976) illusory
square. motion parallax on its own can produce accurate depth
judgements. Most research demonstrating the value of motion parallax as
a depth cue has used very simple random-dot displays. However,
Buckthought et al. (2017) found comparable effects in more complex and
naturalistic conditions. Cues such as linear perspective, texture
gradient and interposition allow observers to perceive depth even in
two-dimensional displays. KEY TERMS However, research with
computer-generated two-dimensional displays has Motion parallax found
depth is often underestimated (Domini et al., 2011). Such displays A
depth cue based on provide cues to flatness (e.g., binocular disparity,
accommodation and movement in one part of the retinal image relative
vergence, all discussed on pp. 74--75) that may reduce the impact of
cues to another. suggesting depth.

74

Visual perception and attention

KEY TERMS

Binocular cues

Binocular disparity A depth cue based on the slight disparity in the two
retinal images when an observer views a scene; it is the basis for
stereopsis.

Depth perception does not depend solely on monocular and oculomotor
cues. It can also be achieved by binocular disparity, which is the
slight difference or disparity in the images projected on the retinas of
the two eyes when you view a scene (Welchman, 2016). Binocular disparity
produces stereopsis (the ability to perceive the world
three-dimensionally). The great subjective advantage of binocular vision
was described by Susan Barry (2009, pp. 94--132), a neuroscientist who
recovered binocular vision in late adulthood:

Stereopsis Depth perception based on the small discrepancy in the two
retinal images when a visual scene is observed (binocular disparity).
Autostereogram A complex twodimensional image perceived as
threedimensional when not focused on for a period of time. Amblyopia A
condition in which one eye sends an inadequate input to the visual
cortex; colloquially known as lazy eye.

\[I saw\] palpable volume\[s\] of empty space . . . I could see, not
just infer, the volume of space between tree limbs . . . the grape was
rounder and more solid than any grape I had ever seen . . . Objects
seemed more solid, vibrant, and real. Stereopsis is very powerful at
short distances. However, the disparity or discrepancy in the retinal
images of objects decreases by a factor of 100 as their distance from an
observer increases from 2 to 20 metres. Thus, stereopsis rapidly becomes
less available at greater distances. While stereopsis provides valuable
information at short distances, we must not exaggerate its importance.
Bülthoff et al. (1998) found observers' recognition of familiar objects
was not adversely affected when stereoscopic information was scrambled.
Indeed, observers were unaware the depth information was scrambled!
Stereopsis involves matching features in the inputs to the two eyes.
This process is fallible. For example, consider an autostereogram (a
two-dimensional image containing depth information so it appears
threedimensional when viewed appropriately; the Wikipedia entry for
autostereogram provides examples). With autostereograms, the same
repeating 2-D pattern is presented to each eye. If there is a
dissociation of vergence and accommodation, two adjacent patterns will
form an object apparently at a different depth from the background. Some
individuals are better than others at perceiving 3-D objects in
autostereograms because of individual differences in binocular
disparity, vergence and accommodation (Gómez et al., 2012). The most
common reason for impaired stereoscopic depth perception is amblyopia
(one eye exhibits poor visual acuity; also known as lazy eye). However,
deficient stereoscopic depth perception can also result from damage to
various cortical areas (Bridge, 2016). As Bridge concluded, intact
stereoscopic depth perception requires the following: "(i) both eyes
aligned and functional; (ii) control over the eye muscles and vergence
to the images into alignment; (iii) initial matching of retinal images;
and (iv) integration of disparity information" (p. 2).

Oculomotor cues The pictorial cues discussed so far can all be used
equally well by oneeyed individuals as by those with intact vision.
Depth perception also depends on oculomotor cues based on perceiving
muscle contractions

Basic processes in visual perception

around the eyes. One such cue is vergence (the eyes turn inwards to
focus on very close objects than those further away). Another oculomotor
cue is accommodation. It refers to the variation in optical power
produced by the thickening of the eye's lens when someone focuses on a
close object. Vergence and accommodation are both very limited. First,
they only provide information about the distance of a single object at
any given time. Second, they are both of value only when judging the
distance of close objects. Even then, the information they provide is
not very accurate.

Cue combination or integration So far we have considered depth cues one
by one. In the real world, however, we typically have access to many
depth cues. How do we use these cues? One possibility is additivity
(combining or integrating information from all cues) and another
possibility is selection (using information from only a single cue)
(Bruno & Cutting, 1988). How could we maximise the accuracy of our depth
perception? Jacobs (2002) argued we should assign more weight to
reliable cues. Since cues reliable in one context may be less so in a
different context, we should be flexible when assessing cue reliability.
These considerations led Jacobs to propose two hypotheses: (1) (2)

Less ambiguous cues (i.e., those providing consistent information) are
regarded as more reliable than more ambiguous ones. A cue is regarded as
reliable if inferences based on it are consistent with those based on
other available cues.

Other theoretical approaches resemble that of Jacobs (2002). For
example, Rohde et al. (2016, p. 36) discuss Maximum Likelihood
Estimation, which is "a rule used . . . to optimally combine redundant
estimates of a variable \[e.g., object distance\] by taking into
consideration the reliability of each estimate and weighting them
accordingly". We can extend this approach to include prior knowledge
(e.g., natural light typically comes from above; many familiar objects
have a typical size). Finally, there are ideal-observer models (e.g.,
Landy et al., 2011; Jones, 2016). Many of these models are based on the
Bayesian approach (see Chapter 13), in which initial probabilities are
altered by new data or information (e.g., presentation of cues).
Ideal-observer models involve making assumptions about the optimal way
of combining the cue and other information available and comparing that
against observers' actual performance. As we will see, experimentation
has benefitted from advances in virtual reality technologies. These
advances permit researchers to control visual cues very precisely, thus
permitting clear-cut tests of many hypotheses.

Findings Evidence supporting Jacobs' (2002) first hypothesis was
reported by Triesch et al. (2002). Observers in a virtual reality
situation tracked an object defined by colour, shape and size. On each
trial, two attributes were unreliable or inconsistent (their values
changed frequently). Observers attached

75

KEY TERMS Vergence A cue to depth based on the inward focus of the eyes
with close objects. Accommodation A depth cue based on changes in
optical power produced by thickening of the eye's lens when an observer
focuses on close objects.

76

KEY TERM Haptic Relating to the sense of touch.

Visual perception and attention

increasing weight to the reliable or consistent cue and less to the
unreliable cues during each trial. Evidence supporting Jacobs' (2002)
second hypothesis was reported by Atkins et al. (2001). Observers in a
virtual reality environment viewed and grasped elliptical cylinders.
There were three cues to cylinder depth: texture, motion and haptic
(relating to the sense of touch). When the haptic and texture cues
indicated the same cylinder depth but the motion cue indicated a
different depth, observers made increasing use of the texture cue and
decreasing use of the motion cue. When the haptic and motion cues
indicated the same cylinder depth but the texture cue did not, observers
increasingly relied on the motion cue rather than the texture cue. Thus,
whichever visual cue correlated with the haptic cue was preferred, and
this preference increased with practice. Much research suggests
observers integrate cue information according to the additivity notion:
they take account of most (or all) cues but attach additional weight to
more reliable ones (Landy et al., 2011). However, these conclusions are
based primarily on studies involving only small conflicts in the
information provided by each cue. What happens when two or more cues are
in strong conflict? Observers typically rely heavily (or even
exclusively) on only one cue, i.e., they use the selection strategy as
defined by Bruno and Cutting (1988; see p. 75). This makes sense.
Suppose one cue suggests an object is 10 metres away but another cue
suggests it is 90 metres away. It is probably not sensible to split the
difference and decide it is 50 metres away! We use the selection
strategy at the movies -- perspective and texture cues produce a 3-D
effect, whereas we largely ignore cues (e.g., binocular disparity)
indicating everything on the screen is the same distance from us.
Relevant evidence was reported by Girshick and Banks (2009) in a study
on slant perception. When there was a small conflict between the
information provided by binocular disparity and texture gradient cues,
observers used information from both. However, when there was a large
conflict between these cues, perceived slant was determined exclusively
by one cue (binocular disparity or texture gradient). Interestingly, the
observers were not consciously aware of the large conflict between the
cues. Do observers combine information from different cues to produce
optimal performance (i.e., accurate depth perception)? Lovell et
al. (2012) compared the effects of binocular disparity and shading on
depth perception. Overall, binocular disparity was the more informative
cue to depth, but Lovell et al. tested the effects of making it less
reliable. Information from the cues was combined optimally, with
observers consistently attaching more weight to reliable cues. Many
other studies have also reported that observers' depth perception is
close to optimal. However, there are several studies where observers
performed less impressively (Rahnev & Denison, 2018). For example, Chen
and Tyler (2015) carried out a similar study to that of Lovell et
al. (2012). Observers' depth judgements were strongly influenced by
shading but made very little use of binocular disparity information.

Basic processes in visual perception

77

Evaluation

KEY TERM

Much has been learned about the numerous cues observers use to estimate
depth or distance. Information from different depth cues is typically
combined or integrated in studies assessing depth perception. There is
also evidence that one cue often dominates the others when different
cues conflict strongly. Overall, as Brenner and Smeets (2018, p. 385)
concluded, "By combining the many sources of information in a clever
manner people obtain quite reliable judgments that are not too sensitive
to violations of the assumptions of the individual sources of depth
information." More specifically, observers generally attach most weight
to cues providing reliable information consistent with that provided by
other cues. If a cue becomes more or less reliable over time, observers
generally increase or decrease its weighting appropriately. Overall,
depth perception often appears close to optimal. What are the
limitations of theory and research on cue integration? First, we
typically estimate distance in real-life settings where numerous cues
are present and there are no large conflicts among them. In contrast,
laboratory settings often provide only a few cues and these cues
sometimes provide very discrepant information. The unfamiliarity of
laboratory settings may sometimes cause suboptimal performance by
observers and reduce generalisation to everyday life (Landy et al.,
2011). Second, the assumption that observers process several essentially
independent cues before integrating all the information is dubious. It
may apply when observers view a very limited and artificial visual
display. However, natural environments typically provide observers with
very rich information. In such environments, visual processing probably
depends more on a global assessment of the overall structure of the
environment and less on processing of specific depth cues than usually
assumed (Sedgwick & Gillam, 2017). There are also issues concerning the
meaning of the word "cue". For example, "Stereopsis is not a cue. It
encompasses all the ways images of a scene differ in the two eyes"
(Sedgwick & Gillam, 2017, p. 81). Third, ideal-observer models differ in
the assumptions used to compute "ideal" performance and the meaning of
"optimal" combining of cues in depth perception (Rahnev & Denison,
2018). Most models focus on the accuracy of depth-perception judgements.
However, there are circumstances (e.g., presence of a fierce wild
animal) where rapid if somewhat inaccurate judgements are preferable.
More generally, humans focus on "computational efficiency" -- our goal
is to maximise reward while minimising the computational costs of visual
processing (Summerfield & Li, 2018). Thus, optimality of
depth-perception judgements does not depend solely on performance
accuracy.

Size constancy Objects are perceived to have a given size regardless of
the size of the retinal image.

Size constancy Size constancy is the tendency for any given object to
appear the same

size whether its size in the retinal image is large or small. For
example, if

78

Visual perception and attention

someone walks towards you, their retinal image increases progressively
but their apparent size remains the same. Why do we show size constancy?
Many factors are involved. An object's apparent distance is especially
important when judging its size. For example, an object may be judged to
be large even though its retinal image is very small provided it is far
away. According to the size-distance invariance hypothesis (Kilpatrick &
Ittelson, 1953), perceived size is proportional to perceived distance.

Findings Haber and Levin (2001) argued that an object's perceived size
depends on memory of its familiar size as well as perceptual information
concerning its distance. Initially, observers estimated the sizes of
common objects with great accuracy from memory. Then they saw various
objects at close (0--50 metres) or distant (50--100 metres) viewing
range and made size judgements. Some familiar objects were almost
invariant in size (e.g., bicycle) or of varying size (e.g., television
set); there were also unfamiliar stimuli (e.g., ovals). What findings
would we expect? If familiar size is important, size judgements should
be more accurate for objects of invariant size than those of variable
size, with size judgements least accurate for unfamiliar objects. If
distance perception is all-important (and known to be more accurate for
nearby objects), size judgements should be better for all object
categories at close viewing range. Haber and Levin (2001) found that
size judgements were much better with objects having an invariant size
than those having a variable size (see Figure 2.23). In addition, the
viewing distance had a minimal effect on size judgements. Both of these
findings are contrary to predictions from the size-distance invariance
hypothesis. If size judgements depend on perceived distance, size
constancy should not be found when an object's perceived distance
differs considerably from

Figure 2.23 Accuracy of size judgements as a function of object type
(unfamiliar; familiar variable size; familiar invariant size) and
viewing distance (0--50 metres vs 50--100 metres). Based on data in
Haber and Levin (2001).

Basic processes in visual perception

79 Figure 2.24 (a) A representation of the Ames room; (b) an actual Ames
room showing the effect achieved with two adults. Photo Peter
Endig/dpa/Corbis.

its actual distance. The Ames room (Ames, 1952; see Figure 2.24)
provides a good example. It has a peculiar shape: the floor slopes and
the rear wall is not at right angles to the adjoining walls.
Nevertheless, the Ames room creates the same retinal image as a normal
rectangular room when viewing monocularly through a peephole. The fact
that one end of the rear wall is much further away from the viewer is
disguised by making it much higher. The cues suggesting the rear wall is
at right angles to observers are so strong they mistakenly assume two
adults standing in the corners by the

KEY TERM Ames room A very distorted room that nevertheless looks normal
under certain viewing conditions.

80

KEY TERMS Honi phenomenon The typical apparent size changes when an
individual walks along the rear wall of the Ames room are reduced when
female observers view a man to whom they are very close emotionally.
Open-object illusion The misperception that objects with missing
boundaries are larger than objects the same size without missing
boundaries. Body size effect An illusion in which misperception of one's
own bodily size causes the perceived size of objects to be misjudged.

Visual perception and attention

rear wall are at the same distance (see photograph). They thus estimate
the size of the nearer adult as much greater than that of the adult
further away. See the Ames room on YouTube: "Ramachandran -- Ames room
illusion explained". The illusion effect with the Ames room is so great
someone walking backwards and forwards in front of the rear wall seems
to grow and shrink as they move! Thus, perceived distance apparently
determines perceived size. However, this effect is reduced when the
person walking along the rear wall is a man and the observer is a female
having a close emotional relationship with him. This is known as the
Honi phenomenon because it was first experienced by a woman (whose
nickname was Honi) when she saw her husband in the Ames room. Similarly
dramatic findings were reported by Glennerster et al. (2006).
Participants walked through a virtual-reality room as it expanded or
contracted considerably. Even though they had detailed information from
motion parallax and motion to indicate the room's size was changing, no
participants noticed the changes! There were large errors in
participants' judgements of the sizes of objects at longer distances
because of their powerful expectation the size of the room would not
alter. Some evidence discussed so far has been consistent with the
assumption of the size-distance invariance hypothesis that perceived
size depends on perceived distance. However, many other findings are
inconsistent (Kim, 2017b). For example, Kim et al. (2016) obtained size
and distance estimates from observers for objects placed in various
tunnels. Size and distance were perceived independently (i.e., depended
on different factors). In contrast, the size-distance invariance
hypothesis predicts that perceived size and perceived distance should
depend on each other and thus should not be independent. Kim (2018)
obtained similar findings when observers viewed a virtual object
presented stereoscopically. Their size judgements were more accurate
than their distance judgements, with each judgement depending on its own
information source. More evidence inconsistent with the size-distance
invariance hypothesis was reported by Makovski (2017). Participants were
presented with stimuli such as those shown in Figure 2.25 on a monitor.
Even though perceived distance was the same for all stimuli, "open"
objects (having missing boundaries) were perceived as much larger than
"closed" objects (with all boundaries intact). This is the open-object
illusion in which observers extend the missing boundaries. This may
resemble our common perception that open windows make a room seem
larger. Van der Hoort et al. (2011) found evidence for the body size
effect, in which the size of a body mistakenly perceived to be one's own
influences the perceived sizes of objects. Participants equipped with
head-mounted displays connected to CCTV cameras saw the environment from
the perspective of a doll (see Figure 2.26). The doll was small or
large. Van der Hoort et al. (2011) found objects were perceived as
larger and further away when the doll was small than when it was large.
These effects were greater when participants misperceived the body as
their own (this was achieved by having the bodies of the participants
and the doll

Basic processes in visual perception

touched at the same time). Thus, size and distance perception depend
partly on our lifelong experience of seeing everything from the
perspective of our own body. Tajadura-Jiménez et al. (2018) extended the
above findings. Participants experienced having the body of a 4-yearold
child or an adult with the body scaled down to match the height of the
child's body. Object size was overestimated more in the child-body
condition, indicating that object size is influenced by higher-level
cognitive processes (i.e., age perception).

A

B

81

C

D

Evaluation Size perception and size constancy sometimes depend on
perceived dis- Figure 2.25 tance. Some of the strongest evidence Top:
stimuli presented to participants; bottom: example of the comes from
research where misper- stimulus display. ceptions of distance (e.g., in
the From Makovski (2017). Ames room; in virtual environments) produce
systematic distortions in perceived size. However, several other factors
also influence size perception. These include familiar size, one's
perceived body size and whether objects do (or do not) contain missing
boundaries. What are the limitations of research and theory on size
perception? First, psychologists have discovered fewer sources of
information accounting for size perception than depth perception. In
addition, as Kim (2017b, Figure 2.26 p. 2) pointed out, "The efficacy of
the few information sources that have What participants in the been
identified for size perception is questionable." Second, while the doll
experiment could see. size-distance invariance hypothesis remains
influential, there is a "vast lit- From the viewpoint of a erature
demonstrating independence of perceived size and distance" (Kim, small
doll, objects such as a hand look much larger 2018, p. 17).

PERCEPTION WITHOUT AWARENESS: SUBLIMINAL PERCEPTION Can we perceive
aspects of the visual world without any conscious awareness we are doing
so? In other words, is there such a thing as subliminal perception
(stimulus perception occurring even though the stimulus is below the
threshold of conscious awareness)? Common sense suggests the answer is
"No". However, much research evidence suggests the answer is "Yes".
However, we must use terms carefully. A thermostat responds
appropriately to temperature changes and so could be said to exhibit
unconscious perception! Much important evidence has come from blindsight
patients with damage to early visual cortex (V1), an area of crucial
importance to

than when seen from the viewpoint of a large doll. This exemplifies the
body size effect. From Van der Hoort et al. (2011). Public Library of
Science. With kind permission from the author.

KEY TERM Subliminal perception Perceptual processing occurring below the
level of conscious awareness that can nevertheless influence behaviour.

82

KEY TERM Blindsight The ability to respond appropriately to visual
stimuli in the absence of conscious visual experience in patients with
damage to the primary visual cortex.

Visual perception and attention

visual perception (discussed on pp. 45--46). Blindsight refers to
patients' ability to "detect, localise, and discriminate visual stimuli
in their blind field, despite denying being able to see the stimuli"
Mazzi et al. (2016, p. 1). In what follows, we initially consider
blindsight patients. After that, we discuss evidence of subliminal
perception in healthy individuals.

Blindsight Many British soldiers in the First World War who had been
blinded by gunshot wounds that destroyed their primary visual cortex (V1
or BA17) were treated by George Riddoch, a captain in the Royal Army
Medical Corps. These soldiers responded to motion in those parts of the
visual field in which they claimed to be blind. The apparently
paradoxical nature of their condition was neatly captured by Weiskrantz
et al. (1974), who coined the term "blindsight". How is blindsight
assessed? Various approaches have been taken but there are generally two
measures. First, there is a forced-choice test in which patients guess
(e.g., stimulus present or absent?) or point at stimuli they cannot see.
Second, there are patients' subjective reports that they cannot see
stimuli presented to their blind region. Blindsight is typically defined
by an absence of self-reported visual perception accompanied by
above-chance performance on the forced-choice test.

IN THE REAL WORLD: BLINDSIGHT PATIENT DB Much early research on
blindsight involved a patient, DB. He was blind in the lower part of his
left visual field as a result of surgery involving removal of part of
his right primary visual cortex (BA17) to relieve his frequent severe
migraine. DB was studied intensively by Larry Weiskrantz. DB is one of
the most thoroughly studied blindsight patients (see Weiskrantz, 2010,
for a historical review). He underwent surgical removal of the right
occipital cortex, including most of the primary visual cortex, to
relieve very severe migraine attacks. DB could detect the presence of an
object and could indicate its approximate location by pointing. He could
also discriminate between moving and stationary objects and could
distinguish vertical from horizontal lines. However, DB's abilities were
limited -- he could not distinguish between different-sized rectangles
or between triangles having straight and curved sides. Such findings
suggest DB processed only low-level features of visual stimuli and could
not discriminate form. We have seen DB showed some ability to perform
various visual tasks. However, he reported no conscious experience in
his blind field. According to Weiskrantz et al. (1974, p. 721), "When he
was shown a video film of his reaching and judging orientation of lines
\[by presenting it to his intact visual field\], he was openly
astonished." Campion et al. (1983) pointed out that DB and other
blindsight patients are only partially blind. They favoured the
stray-light hypothesis, according to which patients respond to light
reflected from the environment onto areas of the visual field still
functioning. This hypothesis implies DB should have shown reasonable
visual performance when objects were presented to his blind spot (the
area where the optic nerve passes through the retina). However, DB could
not detect objects presented to his blind spot.

Basic processes in visual perception

We must not exaggerate patients' preserved visual abilities. Indeed,
their visual abilities in their blind field are so poor that a seeing
person with comparable impairment would be legally classified as blind.

What do blindsight patients experience? It is surprisingly hard to
decide exactly what blindsight patients experience when presented with
visual stimuli to their blind field. For example, the blindsight patient
GY described his experiences as "similar to that of a normally sighted
man who, with his eyes shut against sunlight, can perceive the direction
of motion of a hand waved in front of him" (Beckers & Zeki, 1995,
p. 56). On another occasion GY was asked about his qualia (sensory
experiences). He said, "That \[experience of qualia\] only happens on
very easy trials, when the stimulus is very bright. Actually, I'm not
sure I really have qualia then" (Persaud & Lau, 2008, p. 1048). There is
an important distinction between type-1 and type-2 blindsight. Type-1
blindsight occurs when patients have no conscious awareness of visual
stimuli presented to the blind field. In contrast, type-2 blindsight
occurs when patients have some residual awareness (although very
different from that of healthy individuals). For example, a patient, EY,
"sensed a definite pinpoint of light", although "it looks like nothing
at all" (Weiskrantz, 1980). Another patient, GY, said, "You don't
actually ever sense anything or see anything . . . it's more an
awareness but you don't see it" (Weiskrantz, 1997). Many patients
exhibit type-1 blindsight on some occasions but type-2 blindsight on
others.

Findings: evidence for blindsight Numerous studies have assessed the
perceptual abilities of blindsight patients. Here we briefly consider
three illustrative studies. As indicated already, blindsight patients
often perform better when guessing an object's direction of motion than
its perceptual qualities (e.g., form; colour). For example, Chabanat et
al. (2019) studied a blindsight patient, SA. He was correct 98% of the
time when reporting an object's direction of motion but performed at
chance level when reporting its colour. GY (discussed earlier) is a
much-studied blindsight patient. He has extensive damage to the primary
visual cortex in the left hemisphere. In one study (Persaud & Cowey,
2008), GY was presented with a stimulus in the upper or lower part of
his visual field. On inclusion trials, he was instructed to report the
part of the visual field to which the stimulus had been presented. On
exclusion trials, GY was instructed to report the opposite of its actual
location (e.g., "up" when it was in the lower part). GY tended to
respond with the real rather than the opposite location on exclusion and
inclusion trials suggesting he had access to location information but
lacked any conscious awareness of it (see Figure 2.27). In contrast,
healthy individuals showed a large difference in performance on
inclusion and exclusion trials indicating they had conscious access to
location information.

83

84

Visual perception and attention

Figure 2.27 Estimated contributions of conscious and subconscious
processing to GY's performance in exclusion and inclusion conditions in
his normal and blind fields. Reprinted from Persaud and Cowey (2008).
Reprinted with permission from Elsevier.

Persaud et al. (2011) manipulated the stimuli presented to GY so his
visual performance was comparable in both fields. However, GY indicated
conscious awareness of far more stimuli in the intact field than the
blind one (43% of trials vs 3%, respectively). GY had substantially more
activation in the prefrontal cortex and parietal areas to targets
presented in the intact field suggesting those targets were processed
much more thoroughly.

Blindsight vs degraded conscious vision Some researchers argue
blindsight patients exhibit degraded vision rather than a total absence
of conscious awareness of "blind" field stimuli. For example, Overgaard
et al. (2008) asked a blindsight patient, GR, to decide whether a
triangle, circle or square had been presented to her blind field. In one
experiment, GR simply responded "yes" or "no". In another experiment,
Overgaard et al. used a 4-point Perceptual Awareness Scale: "clear
image", "almost clear image", "weak glimpse" and "not seen". Using the
yes/no measure, GR indicated she had not seen the stimulus on 79% of
trials. However, she identified it correctly 46% of the time. These
findings suggest the presence of type-1 blindsight. With the 4-point
scale, in contrast, GR was correct 100% of the time when she had a clear
image, 72% of the time when her image was almost clear, 25% when she had
a weak glimpse and 0% when the stimulus was not seen. If the "clear
image" and "almost clear image" data are combined, GR claimed awareness
of the stimulus on 54% of trials, on 83% of which she was correct. Thus,
the use of a sensitive method (the 4-point scale) suggested much of GR's
apparent blindsight reflected degraded conscious vision. Ko and Lau
(2012) argued blindsight patients have more conscious visual experience
than usually assumed. Their key assumption was as follows: "Blindsight
patients may use an unusually conservative criterion for detection,
which results in them saying 'no' nearly all the time to the question of
'do you see something?'" (Ko & Lau, 2012, p. 1402). This excessive
caution may occur in part because damage to the prefrontal cortex
impairs their ability to set the criterion for visual detection
appropriately. Their excessive conservatism or caution may explain why
the reported visual experience of blindsight patients is so discrepant
from their forced-choice perceptual performance.

Basic processes in visual perception

Ko and Lau's (2012) theoretical position is supported by Overgaard et
al.'s (2008) finding (discussed on p. 84) that blindsight patients were
very reluctant to admit to having seen stimuli presented to their blind
field. They also cited research supporting their assumption that
blindsight patients often have prefrontal damage. Mazzi et al. (2016)
carried out a study resembling that of Overgaard et al. (2008) on
another blindsight patient, SL, showing no activity in the primary
visual cortex (V1). SL decided which of two features (e.g., red or green
colour) was present in a stimulus. When she indicated whether she had
seen the stimulus or was merely guessing, her guessing performance was
significantly above chance suggestive of type-1 blindsight. However,
when she indicated her awareness using the 4-point Perceptual Awareness
Scale, her visual performance was at chance level when she reported no
awareness of the stimulus. These findings suggest an absence of
blindsight. The title of Mazzi et al.'s article provides the take-home
message: "Different measures tell a different story" (p. 1). What can we
conclude? Overgaard and Mogensen (2015, p. 37) argued that
"rudimentarily analysed visual information is available in blindsight"
but typically does not lead to conscious awareness. However, such
information can produce conscious awareness if the patient uses much
effort and top-down control. Two findings support this approach. First,
blindsight patients generally do not regard their experiences as
"visual" because they differ so much from normal visual perception.
Second, there is much evidence (Overgaard & Mogensen, 2015) that
blindsight patients show enhanced visual performance (and sometimes
subjective awareness) after training. This occurs because they make
increasingly effective use of the rudimentary visual information
available to them.

Blindsight and the brain As indicated above, the main brain damage in
blindsight patients is to V1 (the primary visual cortex). As we saw
earlier on p. 47 in the chapter, visual processing typically proceeds
from V1 (BA17) to other brain areas (e.g., V2, V3, V4; see Figure 2.4).
Of importance, stimuli presented to the "blind" field often produce some
activation in these other brain areas. However, this activation is not
associated with visual awareness in blindsight patients. On p. 48 in the
chapter we discussed research by Hurme et al. (2017) designed to clarify
the role of V1 (the primary visual cortex) in the visual perception of
healthy individuals. Transcranial magnetic stimulation applied to the
primary visual cortex to reduce its efficiency disrupted unconscious and
conscious vision. In a similar study, Hurme et al. (2019) found TMS
applied to V1 prevented conscious and unconscious motion perception in
healthy individuals. In view of the above findings, how is it that many
blindsight patients provide evidence of unconscious visual and motion
processing? Part of the answer lies within the lateral geniculate
nucleus of the thalamus, an intermediate relay station between the eye
and V1 (see Figure 2.28). Ajina et al. (2015) divided patients with V1
damage into those with or without blindsight. All those with blindsight
had intact connections between LGN and

85

Visual perception and attention

Figure 2.28 The areas of most relevance to blindsight are the lateral
geniculate nucleus (LGN) and middle temporal visual area (MT/V5). The
structure close to the LGN is the pulvinar.

Pulvinar

Do

rsa

MT/V5 V3

PLdm

PM

Plp

rea

m

V2

PLvl

From Tamietto and Morrone (2016).

l st

Plm Pl cm Plcl

V1

V2 V3

Superior colliculus

V4 LGN TE

TEO

Ve nt ra ls tre am

86

MT/V5 (blue arrow in the figure) whereas those connections were impaired
in patients without blindsight. This finding is important given the
crucial importance of MT/V5 for motion perception. Celeghin et
al. (2019) reported a meta-analysis (see Glossary) providing a fuller
account of the brain areas associated with patients' visual processing.
They identified 14 such areas. Some of these areas (e.g., the LGN; the
pulvinar) are critical for non-conscious motion perception, whereas
others (e.g., superior temporal gyrus; amygdala) are involved in
non-conscious emotion processing. Overall, the meta-analysis strongly
suggested that blindsight typically consists of several non-conscious
visual abilities rather than one. Of interest, prefrontal areas (e.g.,
dorsolateral prefrontal cortex) often associated with conscious visual
perception (see Chapter 16) were not activated during visual processing
by blindsight patients. These findings support the view that visual
processing in these patients is typically unaccompanied by conscious
experience. Finally, Celeghin et al. (2019) discussed evidence that
there is substantial reorganisation of brain connectivity in many
blindsight patients following damage to V1 (primary visual cortex). For
example, consider the blindsight patient, GY, whose left V1 was
destroyed. He has nerve fibre connections between the undamaged right
lateral geniculate nucleus and the contralesional (opposite side of the
body) visual motion area MT/V5 (Bridge et al., 2008) -- connections not
present in healthy individuals. Such reorganisation helps to explain the
visual abilities displayed by blindsight patients.

Evaluation Much has been learned about the nature of blindsight. First,
two main types of blindsight have been identified. Second, evidence for
the existence

Basic processes in visual perception

of blindsight often depends on the precise measure of visual awareness
used. Third, brain connections important in blindsight (e.g., between
the lateral geniculate nucleus and MT/V5) have been discovered. Fourth,
the visual abilities of many blindsight patients probably depend on the
reorganisation of connections within the brain following damage to the
primary visual cortex. Fifth, the assumption that visual processing is
rudimentary in blindsight patients explains many findings. Sixth,
research on blindsight has shed light on the many visual pathways that
bypass V1 but whose functioning can be overshadowed by pathways
involving V1 (Celeghin et al., 2019). What are the limitations of
research in this area? First, there are considerable differences among
blindsight patients with several apparently possessing some conscious
visual awareness in their allegedly blind field. Second, many blindsight
patients have more conscious visual experience in their "blind" field
than appears from yes/no judgements about stimulus awareness. This
probably happens because they are excessively cautious about claiming to
have seen a stimulus (Mazzi et al., 2016; Overgaard et al., 2008).
Third, the extent to which blindsight patients have degraded vision
remains controversial. Fourth, the existence of reorganisation within
the brain in blindsight patients (e.g., Bridge et al., 2008) may limit
the applicability of findings from such patients to healthy individuals.

Subliminal perception In research on subliminal perception in visually
intact individuals, a performance measure of perception (e.g., enhanced
speed or accuracy of responding) is typically compared with an awareness
measure. We can distinguish between subjective and objective measures of
awareness: subjective measures involve self-reports concerning
observers' awareness, whereas objective measures involve forced-choice
responses (e.g., did the stimulus belong to category A or B?)
(Hesselmann, 2013). As Shanks (2017, p. 752) argued, "Unconscious
processing \[subliminal perception\] is inferred when abovechance
performance is combined with null awareness." For example, Naccache et
al. (2002) had observers decide rapidly whether a visible target digit
was smaller or larger than 5. Unknown to them, an invisible masked digit
on the same side of 5 as the target (congruent) or the other side
(incongruent) was presented immediately before the target. There were
two main findings. First, responses to the target digits were faster on
congruent than incongruent trials (performance measure). Second, no
participants reported seeing any masked digits (subjective awareness
measure) and their performance was at chance level when guessing whether
masked digits were below or above 5 (objective awareness measure). These
findings suggested the existence of subliminal perception.

Findings Persaud and McLeod (2008) tested the notion that only
information perceived with awareness can control our actions. They
presented the letter "b" or "h" for 10 ms (short interval) or 15 ms
(long interval). In the key condition, participants were instructed to
respond with the letter not presented.

87

88

Visual perception and attention

For example, if they were aware "b" had been presented, they would say
"h". The rationale was that only participants consciously aware of the
letter could inhibit saying it. Persaud and McLeod (2008) found
participants responded correctly with the non-presented letter on 83% of
long-interval trials indicating reasonable conscious awareness. In
contrast, participants responded correctly on only 43% of short-interval
trials (significantly below chance) suggesting some stimulus processing
but an absence of conscious awareness. An important issue is whether
perceptual awareness is all-or-none (i.e., present or absent) or graded
(i.e., varying in extent). Evidence suggesting it is graded was reported
by Sandberg et al. (2010). One of four shapes was presented very briefly
followed by masking. Observers made a behavioural response (deciding
which shape had been presented) followed by one of three subjective
measures: (1) clarity of perceptual experience (the Perceptual Awareness
Scale); (2) confidence in their decision; and (3) wagering variable
amounts of money on having made the correct decision. What did Sandberg
et al. (2010) find? First, above-chance task performance sometimes
occurred without reported awareness with all three subjective measures.
Second, the Perceptual Awareness Scale predicted performance better than
the other measures, probably because it was the most sensitive measure
of conscious experience. The partial awareness hypothesis (Kouider et
al., 2010) potentially explains graded perceptual experience. According
to this hypothesis, perceptual awareness can be limited to low-level
features (e.g., colour) while excluding high-level features (e.g., face
identity). Supportive evidence was reported by Gelbard-Sagiv et
al. (2016) with faces coloured blue or green. They used continuous flash
suppression (CFS): a stimulus presented to one eye cannot be seen
consciously when rapidly changing patterns are presented to the other
eye. Observers often had conscious awareness of the colour of faces they
could not identify. Koivisto and Grassini (2016) presented stimuli to
one of four locations. Observers then made a forced-choice responses
concerning the stimulus location and rated their subjective visual
awareness of the stimulus on a 3-point version of the Perceptual
Awareness Scale (discussed above). Of central importance was the
no-awareness category (i.e., "I did not see any stimulus"). The finding
that observers were correct on 38% of trials associated with no
awareness (chance performance = 25%) was apparent evidence for
subliminal perception. However, there is an alternative explanation.
According to Koivisto and Grassini (2016, p. 241), the above finding
occurred mainly when "observers were very weakly aware of the stimulus,
but behaved conservatively and claimed not having seen it". This
conservatism is known as response bias. Two findings supported this
explanation. First, nearly all the observers showed response bias on
no-awareness trials (see Figure 2.29). Second, Koivisto and Grassini
(2016) used event-related potentials. The N200 (a negative wave 200 ms
after stimulus presentation) is typically substantially larger for
stimuli associated with awareness. Of key importance, the N200 was
greater on no-awareness correct trials than

Basic processes in visual perception

Figure 2.29 The relationship between response bias in reporting
conscious awareness (C) and enhanced N200 on no-awareness correct trials
compared to no-awareness incorrect trials (UC).

--6 r = --0.53

UC (µV)

--4

From Koivisto and Grassini (2016). Reprinted with permission of
Elsevier.

--2

0

2 --0.5

89

0

0.5

1

1.5

C

no-awareness incorrect trials for observers with high-response bias but
not those with low-response bias (see Figure 2.29). In sum, Koivisto and
Grassini (2016) provided a coherent explanation for the finding that
visual performance was well above chance on no-awareness trials.
Observers often had weak conscious awareness on correct no-awareness
trials (indicated by the N200 findings). Such weak conscious awareness
occurred most frequently among those most biased against claiming to
have seen the stimulus. Neuroimaging research has consistently shown
that stimuli of which the observers are unaware nevertheless produce
activation in several brain areas. In one study (Rees, 2007), activation
was assessed in brain areas associated with face processing and with
object processing while invisible pictures of faces or houses were
presented. The identity of the picture (face vs house) could be
predicted with almost 90% accuracy from patterns of brain activation.
Thus, subliminal stimuli can be processed reasonably thoroughly by the
visual system. Research focusing on differences in brain activation
between conditions where there is (or is not) conscious perceptual
awareness is discussed thoroughly in Chapter 16. Here we will mention
two major findings. First, there is much less integrated or synchronised
brain activation when there is no conscious perceptual awareness (e.g.,
Godwin et al., 2015; Melloni et al., 2007). Second, activation of areas
within the prefrontal cortex (involved in integrating brain activity) is
much greater for consciously perceived visual stimuli than those not
consciously perceived (e.g., Gaillard et al., 2009; Godwin et al.,
2015). What do these findings mean? They strongly suggest processing is
predominantly limited to low-level features (e.g., colour; motion) when
stimuli are not consciously perceived, which is consistent with the
partial awareness hypothesis (Kouider et al., 2010).

90

Visual perception and attention

Evaluation Evidence for unconscious or subliminal perception has been
reported in numerous studies using numerous tasks. Some evidence is
behavioural (e.g., Naccache et al., 2002; Persaud & McLeod, 2008) and
some is based on patterns of brain activity (e.g., Melloni et al., 2007;
Rees, 2007). The latter line of research suggests there can be
considerable low-level processing of visual stimuli in the absence of
conscious visual awareness. In spite of limitations of research in this
area (see below), there is reasonably strong evidence for subliminal
perception. What are the limitations of research on subliminal
perception? First, measures of conscious awareness vary in sensitivity.
As a consequence, it is relatively easy for researches to apparently
demonstrate the existence of subliminal perception by using an
insensitive measure (Rothkirch & Hesselmann, 2017). Second, many
researchers focus on observers whose verbal reports show a lack of
awareness. That would be appropriate if such reports were totally
reliable. However, such reports are somewhat unreliable meaning that
some of them would report awareness if they provided a second verbal
report (Shanks, 2017). In addition, limitations of attention and memory
may sometimes cause observers' reports to omit some of their conscious
experience from verbal reports (Lamme, 2010). Third, many claimed
demonstrations of subliminal perception are flawed because of the
typical failure to consider and/or control response bias (Peters et al.,
2016). In essence, observers with response bias may claim to have no
conscious awareness of visual stimuli when they actually have partial
awareness (Koivisto and Grassini, 2016). Fourth, Breitmeyer (2015)
identified 24 different methods used to make visual stimuli inaccessible
to visual awareness. Neuroimaging and other techniques have been used to
estimate the amount of unconscious processing associated with each
method. Some methods (e.g., object-substitution masking: a visual
stimulus is replaced by dots surrounding it) are associated with much
more unconscious processing than others (e.g., binocular rivalry, see
Glossary). Of key relevance here, the likelihood of obtaining evidence
for subliminal perception depends substantially on the method used to
suppress visual awareness.

CHAPTER SUMMARY •

Vision and the brain. In the retina, there are cones (specialised for
colour vision) and rods (specialised for motion detection). The
retina-geniculate-striate pathway between the eye and cortex is divided
into partially separate P and M pathways. The dorsal stream (associated
with the M pathway) terminates in the parietal cortex and the ventral
stream (associated with the P pathway) terminates in the inferotemporal
cortex. There are numerous interactions between the two pathways and the
two streams.

Basic processes in visual perception

According to Zeki's functional specialisation theory, different cortical
areas are specialised for different visual functions (e.g., form;
colour; motion). This is supported by findings from patients with
selective visual deficits (e.g., achromatopsia; akinetopsia). However,
much visual processing depends on large brain networks rather than
specific areas and Zeki de-emphasised the importance of top-down
(recurrent) processing. It remains unclear how we integrate the outputs
of different visual processes (the binding problem). However, selective
attention, synchronised neural activity and combining bottom-up
(feedforward) processing and top-down (recurrent) processing all play a
role. •

Two visual systems: perception-action model. Milner and Goodale
identified a vision-for-perception system based on the ventral stream
and a vision-for-action system based on the dorsal stream. There is
limited (and inconsistent) support for the predicted double dissociation
between patients with optic ataxia (damage to the dorsal stream) and
visual form agnosia (damage to the ventral stream). Illusory effects
found when perceptual judgements are made (ventral stream) are often
much reduced when grasping or pointing responses are used (dorsal
stream). However, such findings are often hard to interpret, and
visually guided action often relies more on the ventral stream than
acknowledged theoretically. More generally, the two visual systems
interact with each other much more than previously assumed and there are
probably more than two visual pathways.

•

Colour vision. Colour vision helps us detect objects and make fine
discriminations among them. According to dual-process theory, there are
three types of cone receptors and three types of opponent processes
(green-red; blue-yellow; white-black). This theory explains negative
afterimages and colour deficiencies but is oversimplified. Colour
constancy occurs when a surface's perceived colour remains the same when
the illuminant changes. Colour constancy is influenced by our ability to
assess the illuminant accurately; local colour contrast; familiarity of
object colour; chromatic adaptation; and cone-excitation ratios. Most
theories are more applicable to colour vision with simple artificial
stimuli than complex objects in the natural world.

•

Depth perception. There are numerous monocular cues to depth (e.g.,
linear perspective; texture; familiar size) plus oculomotor and
binocular cues. Cues are sometimes combined additively in depth
perception. However, more weight is generally given to reliable cues
than unreliable ones with weightings changing if a cue's reliability
alters. However, one cue often dominates all others when different cues
conflict strongly. It is often assumed that observers generally combine
cues near-optimally, but it is hard to

91

92

Visual perception and attention

define "optimality". The assumption that observers process several
independent cues prior to integrating all the information is probably
wrong in natural environments providing rich information about overall
environmental structure. Size perception is sometimes strongly
influenced by perceived distance as predicted by the size-distance
invariance hypothesis. However, the impact of familiar size on depth
perception cannot be explained by that hypothesis. More generally,
perceived size and perceived distance often depend on different factors.
•

Perception without awareness: subliminal perception. Patients with
extensive damage to V1 sometimes suffer from blindsight. This is a
condition involving some ability to respond to visual stimuli in the
absence of normal conscious visual awareness (especially motion
detection). There is no conscious awareness in type-1 blindsight but
some residual awareness in type-2 blindsight. Blindsight patients are
sometimes excessively cautious when reporting their conscious
experience. The visual abilities of some blindsight patients probably
depend on reorganisation of brain connections following brain damage.
There is much behavioural and neuroimaging evidence for subliminal
perception in visually intact individuals. However, there are problems
of interpretation caused by insensitive (and unreliable) measures of
self-reported awareness. Some observers may show apparent subliminal
perception because they have a response bias leading them to claim no
conscious awareness of visual stimuli of which they actually have
limited awareness.

FURTHER READING Brenner, E. & Smeets, J.B.J. (2018). Depth perception.
In J.T. Serences (ed.), Stevens' Handbook of Experimental Psychology and
Cognitive Neuroscience, Vol. 2: Sensation, Perception, and Attention
(4th edn; 385--414). New York: Wiley. The authors provide a
comprehensive account of theory and research on depth perception. de
Haan, E.H.F., Jackson, S.R. & Schenk, T. (2018). Where are we now with
"what" and "how"? Cortex, 98, 1--7. Edward de Haan and his colleagues
provide an evaluation of the perception-action model Goldstein, E.B. &
Brockmole, J. (2017). Sensation and Perception (10th edn). Boston:
Cengage. There is coverage of key areas within visual perception in this
introductory textbook. Naccache, L. (2016). Chapter 18: Visual
consciousness: A "re-updated" neurological tour. Neurology of
Consciousness (2nd edn; pp. 281--295). Lionel Naccache provides a
theoretical framework within which to understand blindsight and other
phenomena associated with visual consciousness. Shanks, D.R. (2017).
Regressive research: The pitfalls of post hoc data selection in the
study of unconscious mental processes. Psychonomic Bulletin & Review,
24, 752--775. David Shanks discusses some issues relating to research
claiming to provide evidence for subliminal perception.

Basic processes in visual perception Tang, F. (2018). Foundations of
vision. In J.T. Serences (ed.), Stevens' Handbook of Experimental
Psychology and Cognitive Neuroscience, Vol. 2: Sensation, Perception,
and Attention (4th edn; pp. 1--62). New York: Wiley. Frank Tong provides
a comprehensive account of the visual system and its workings. Witzel,
C. & Gegenfurtner, K.R. (2018). Colour perception: Objects, constancy,
and categories. Annual Review of Vision Science, 4, 475--499. Christoph
Witzel and Karl Gegenfurtner discuss our current knowledge of colour
perception.

93

Chapter

3

Object and face recognition

INTRODUCTION Tens of thousands of times every day we identify or
recognise objects in the world around us. At this precise moment, you
are looking at this book. If you raise your eyes, perhaps you can see a
wall and windows. Object recognition typically happens so effortlessly
it is hard to believe it is actually a complex achievement. Evidence of
its complexity comes from numerous unsuccessful attempts to program
computers to "perceive" the environment. However, computer programs that
are reasonably effective at recognising complicated two-dimensional
patterns have been developed. Why is visual perception so complex?
First, objects often overlap and so we must decide where one object ends
and the next one starts. Second, numerous objects (e.g., chairs; trees)
vary enormously in their visual properties (e.g., colour; size; shape)
and so it is hard to assign such diverse stimuli to the same category.
Third, we recognise objects almost regardless of orientation (e.g., we
can easily identify a plate that appears elliptical). We can go beyond
simply identifying objects. For example, we can generally describe what
an object would look like from different angles, and we also know its
uses and functions. All in all, there is much more to object recognition
than might be supposed (than meets the eye?). What is discussed in this
chapter? The overarching theme is to unravel the mysteries associated
with recognising three-dimensional objects. However, we initially
discuss how two-dimensional patterns are recognised. Then the focus
shifts to how we decide which parts of the visual world belong together
and thus form separate objects. This is a crucial early stage in object
recognition. After that, general theories of object recognition are
evaluated against the available neuroimaging and behavioural evidence.
Face recognition (vitally important in our everyday lives) differs in
important ways from object recognition. Accordingly, we discuss face
recognition in a separate section. Finally, we consider whether the
processes involved in visual imagery resemble those involved in visual
perception.

Object and face recognition

Other issues relating to object recognition (e.g., depth perception;
size constancy) were discussed in Chapter 2.

PATTERN RECOGNITION We spend much of our time (e.g., when reading)
engaged in pattern recognition -- the identification or categorisation
of two-dimensional

95

KEY TERM Pattern recognition The ability to identify or categorise
twodimensional patterns (e.g., letters; fingerprints).

patterns. Much research has considered how alphanumeric patterns
(alphabetical and numerical symbols) are recognised. A key issue is the
flexibility of the human perceptual system (e.g., we can recognise the
letter "A" rapidly and across wide variations in orientation, typeface,
size and writing style). Patterns can be regarded as consisting of a set
of specific features or attributes (Jain & Duin, 2004). For example, the
key features of the letter "A" are two straight lines and a connecting
cross-bar. An advantage of this feature-based approach is that visual
stimuli varying greatly in size, orientation and minor details can be
identified as instances of the same pattern. Many feature theories
assume pattern recognition involves processing specific features
followed by more global or general processing to integrate feature
information. However, Navon (1977) argued global processing often
precedes more specific processing. He presented observers with stimuli
such as the one shown in Figure 3.1. On some trials, they decided
whether the large letter was an "H" or an "S"; on others, they decided
Interactive exercise: Navon whether the small letters were Hs or Ss.
Navon (1977) found performance speed with the small letters was greatly
slowed when the large letter differed from the small letters. However,
decision speed with the large letters was uninfluenced by the nature of
the small letters. Navon concluded we often see the forest (global
structure) before the trees (features). There are limitations with
Navon's (1977) research and conclusions. First, Dalrymple et al. (2009)
found performance was faster at the level of the small letters than the
large letter when the small letters were relatively large and spread
out. Thus, attentional processes influence performance. Second, Navon
failed to distinguish adequately between encoding (neuronal responses
triggered by visual stimuli) and decoding (conscious perception of those
stimuli) (Ding et al., 2017). Encoding typically progresses from
lower-level representations of simple features to higher-level
representations of more complex features (Felleman & Van Essen, 1991).
In contrast, Ding et al. (2017, p. E9115) found, "The brain prioritises
decoding of higher-level features because they are . . . more invariant
and categorical, and thus easier to . . . maintain in noisy working
memory." Thus, Navon's (1977) conclusions may be more applicable to
visual decoding Figure 3.1 (conscious perception) than the preceding The
kind of stimulus used by Navon (1977) to demonstrate the importance of
global features in perception. internal neuronal responses.

96

Visual perception and attention

Feature detectors If presentation of a visual stimulus leads to detailed
processing of its basic features, we should be able to identify cortical
cells involved in such processing. Hubel and Wiesel (1962) studied cells
in parts of the occipital cortex involved in visual processing. Some
cells responded in two different ways to a spot of light depending on
which part of the cell was affected: (1) (2)

An "on" response with an increased rate of firing when the light was on.
An "off" response with the light causing a decreased rate of firing.

Hubel and Wiesel (e.g., 1979) discovered two types of neuron in the
primary visual cortex: simple cells and complex cells. Simple cells have
"on" and "off" rectangular regions. These cells respond most to dark
bars in a light field, light bars in a dark field, or straight edges
between areas of light and dark. Any given cell responds strongly only
to stimuli of a particular orientation and so its responses could be
relevant to feature detection. Complex cells resemble simple cells in
responding maximally to straight-line stimuli in a particular
orientation. However, complex cells have large receptive fields and
respond more to moving contours. Each complex cell is driven by several
simple cells having the same orientation preference and closely
overlapping receptive fields (Alonso & Martinez, 1998). There are also
end-stopped cells. Their responsiveness depends on stimulus length and
orientation. In sum, Hubel and Wiesel envisaged, "A hierarchically
organised visual system in which more complex visual features are built
(bottom-up) from more simple ones" (Ward, 2015, p. 111). Hubel and
Wiesel's account is limited in several ways: (1)

(2) 
(3) 
(4) 

The cells they identified provide ambiguous information because they
respond comparably to different stimuli (e.g., a horizontal line moving
rapidly and a nearly horizontal line moving slowly). Observers must
combine information from numerous neurons to remove ambiguities. Neurons
differ in their responsiveness to different spatial frequencies and
several phenomena in visual perception depend on this differential
responsiveness (discussed on pp. 104--105). As Schulz et al. (2015,
p. 1022) pointed out, "The responses of cortical neurons \[in the
primary visual cortex\] to repeated presentations of a stimulus are
highly variable." This variability complicates pattern recognition.
Pattern recognition and object recognition depend on top-down processes
triggered by expectations and context (e.g., Goolkasian & Woodberry,
2010; discussed on pp. 111--116) as well as on the bottom-up processes
emphasised by Hubel and Wiesel.

PERCEPTUAL ORGANISATION Our visual environment is typically complex and
confusing with many objects overlapping others, thus making it hard to
achieve perceptual segregation of visual objects. How this is done was
first studied systematically

Object and face recognition

97

IN THE REAL WORLD: HOW CAN WE DISCOURAGE SPAMMERS? Virtually everyone
has received a substantial amount of spam (unwanted KEY TERM emails).
Spammers use bots (robots running automated tasks over CAPTCHA the
internet) to send emails to thousands of individuals for various A
Completely Automated money-making purposes (e.g., fake sweepstake
entries). Turing Test to tell A CAPTCHA (Completely Automated Turing
test to tell Computers Computers and Humans and Humans Apart) is
commonly used to discourage spammers. The Apart involving distorted
characters connected intention is to ensure a website user is human by
providing a test together is often used humans can solve but automated
computer-based systems cannot. The to establish that the user CAPTCHA in
Figure 3.2 is typical in consisting of distorted characters of an
internet website connected together horizontally. In principle, the
study of CAPTCHAs is human rather than an can shed light on the
strengths of human pattern recognition. automated system. Computer
programs to solve CAPTCHAs generally involve a segmentation phase to
locate the characters followed by a recognition phase where each
character is identified. Many computer programs can recognise individual
characters even when very distorted but their performance is much worse
at segmenting connected characters. Overall, the performance of most
computer programs at solving CAPTCHAs Figure 3.2 The CAPTCHA used by
Yahoo. was poor until fairly recently. Nachar et al. (2015) devised a
computer From Gao et al. (2012). program focusing on edge corners (an
edge corner is the intersection of two straight edges). Such corners are
relatively unaffected by the distortions and overlaps of characters
found in CAPTCHAs. Nachar et al.'s approach proved successful, allowing
them to solve 57% of CAPTCHAs resembling the one shown in Figure 3.2.
There are two take-home messages. First, the difficulties encountered in
devising computer programs to solve CAPTCHAs indicate humans have
excellent pattern-recognition abilities. Second, edge corners provide an
especially valuable source of information in pattern recognition. Of
relevance, successful camouflage in many species depends heavily on
markings that break up an animal's edges, making it less visible
(Webster, 2015).

IN THE REAL WORLD: FINGERPRINTING An important form of real-world
pattern recognition involves experts matching a criminal's fingerprints
(latent print) against stored fingerprint records. Automatic fingerprint
identification systems (AFISs) scan huge databases. This typically
produces a small number of possible matches to the fingerprint obtained
from the crime scene ranked by similarity to the criminal's fingerprint.
Experts then decide which database fingerprint (if any) matches the
criminal's. We might imagine experts are much better at fingerprint
matching than novices because their analytic (slow, deliberate)
processing is superior. However, Thompson and Tangen (2014) found
experts greatly outperformed novices when pairs of fingerprints were
presented for only 2 seconds, forcing them to rely heavily on
non-analytic (fast and relatively "automatic") processing. However, when
fingerprint pairs were presented for 60 seconds, experts showed a
greater performance

98

Visual perception and attention

improvement than novices (19% vs 7%, respectively). Thus, experts have
superior analytic and non-analytic processing. According to
signal-detection theory, experts may surpass novices in their ability to
discriminate between matching and non-matching prints. Alternatively,
they may simply have a more lenient response bias than novices. If so,
they would tend to respond "match" to every pair of prints. Good
discrimination is associated with many "hits" (responding "match" on
match trials) plus a low false-alarm rate (not responding "match" on
non-match trials). In contrast, a lenient response criterion is
associated with many false alarms. Thompson et al. (2014) found novices
made false alarms on 57% of trials on which two prints were similar but
did not match, whereas experts did so on only 1.65% of trials. Thus,
experts have a much more conservative response criterion as well as much
better discrimination between matching and non-matching prints. It is
often assumed expert fingerprint identification is very accurate.
However, experts listing the minutiae (features) on fingerprints on two
occasions showed total agreement between their assessments only 16% of
the time (Dror et al., 2012). Nevertheless, experts are much less likely
than non-experts to decide incorrectly that two fingerprints from the
same person are from different individuals (Champod, 2015). Fingerprint
identification is often complex. As an example, try to decide whether
the fingerprints in Figure 3.3 come from the same person. Four
fingerprinting experts said the fingerprint on the right was from the
same person as the one on the left (Ouhane Daoud, the bomber involved in
the terrorist attack in Madrid on 11 March 2004). In fact, the one on
the right came from Brandon Mayfield, an American lawyer who was falsely
arrested. Experts' mistakes are often due to the incompleteness of the
fingerprints found at crime scenes. However, top-down processes also
contribute. Experts' errors often involve forensic confirmation bias:
"an individual's pre-existing beliefs, expectations, motives, and
situational context influence the collection, perception, and
interpretation of evidence" (Kassin et al., 2013, p. 45). Dror et
al. (2006) found evidence of forensic confirmation bias. Experts were
asked to judge whether two fingerprints matched having been told,
incorrectly, that they were the ones mistakenly matched by the FBI as
the Madrid bomber. In fact, these experts had judged these fingerprints
to be a clear and definite match several years earlier. The misleading
information provided led 60% of them to judge the prints to be definite
non-matches! Thus, top-down processes triggered by contextual
information can distort fingerprint identification. Langenburg et
al. (2009) studied the effects of context (e.g., alleged conclusions of
internationally respected experts) on fingerprint identification.
Experts and non-experts were both influenced by contextual information
(and so showed confirmation bias). However, non-experts were influenced
more. The above studies on confirmation bias manipulated context very
directly and explicitly. Searston et al. (2016) found a more subtle
context effect based on familiarity. Novice parFigure 3.3 ticipants were
presented initially with a series The FBI's mistaken identification of
the Madrid bomber. of cases and fingerprint pairs and given feed- The
fingerprint from the crime scene is on the left. The back as to whether
the fingerprints matched fingerprint of the innocent suspect (positively
identified by or not. Then they were presented with various fingerprint
experts) is on the right. cases very similar to those seen previously
From Dror et al. (2006). Reprinted with permission from Elsevier.

Object and face recognition

99

and decided whether the fingerprint pairs matched. The participants
exhibited response bias during the second part of the experiment: their
decisions (i.e., match or no-match) tended to correspond to the correct
decisions associated with similar (but not identical) cases encountered
earlier. In sum, experts typically outperform novices at fingerprint
matching because they have superior discrimination ability and a more
conservative response criterion. However, even experts are influenced by
irrelevant or misleading contextual information and often show evidence
of confirmation bias. Worryingly, among forensic experts (including
fingerprinting experts), only 52% regarded bias as a matter for concern
and even fewer (26%) believed their own judgements were influenced by
bias.

by the gestaltists, German psychologists (including Koffka, Köhler and
Wertheimer) who emigrated to the United States between the two World
Wars. Their fundamental principle was the law of Prägnanz -- we
typically perceive the simplest possible organisation of the visual
field. Most of the gestaltists' other laws can be subsumed under the law
of Prägnanz. Figure 3.4(a) illustrates the law of proximity (visual
elements close in space tend to be grouped together). Figure 3.4b shows
the law of similarity (similar elements tend to be grouped together). We
see two crossing lines in Figure 3.4(c) because, according to the law of
law continuation, we group together those elements requiring the fewest
changes or interruptions in straight or smoothly curving lines. Finally,
Figure 3.4(d) illustrates the law of closure: the missing parts of a
figure are filled in to complete the figure (here a circle). We might
dismiss these principles as "mere textbook curiosities" (Wagemans et
al., 2012a, p. 1180). However, the various grouping principles "pervade
virtually all perceptual experiences because they determine the objects
and parts that people perceive in their environment" (Wagemans et al.,
2012a, p. 1180). The gestaltists emphasised figure-ground segmentation
in perception. The figure is perceived as having a distinct form or
shape whereas the ground lacks form. In addition, the figure is
perceived as being in

KEY TERMS Law of Prägnanz The notion that the simplest possible
organisation of the visual environment is perceived; proposed by the
gestaltists. Figure-ground segmentation The perceptual organisation of
the visual field into a figure (object of central interest) and a ground
(less important background).

Figure 3.4 Examples of the Gestalt laws of perceptual organisation: (a)
the law of proximity; (b) the law of similarity; (c) the law of good
continuation; and (d) the law of closure.

100

Visual perception and attention

Figure 3.5 An ambiguous drawing that can be seen as either two faces or
as a goblet.

front of the ground and the contour separating the figure from ground
"belongs" to the figure. Check these claims with the faces-goblet
illusion (see Figure 3.5). When the goblet is perceived as the figure,
it seems to be in front of a dark background. Faces are in front of a
light background when forming the figure. What determines which region
is identified as the figure and which as the ground? Regions that are
convex (curving outwards), small, surrounded and symmetrical are most
likely to be perceived as figures (Wagemans et al., 2012a). For example,
Fowlkes et al. (2007) found with images of natural scenes that regions
identified by observers as figures were generally smaller and more
convex than ground regions. Finally, the gestaltists argued perceptual
grouping and organisation are innate or intrinsic to the brain. As a
result, they deemphasised the importance of past experience.

Findings The gestaltists' approach was limited because they mostly used
artificial figures, making it important to see whether their findings
apply to more realistic stimuli. Geisler et al. (2001) used pictures to
study the contours of flowers, rivers, trees and so on. They discovered
object contours could be calculated accurately using two principles that
were different from those emphasised by the gestaltists: (1) (2)

Adjacent segments of any contour typically have very similar
orientations. Segments of any contour that are further apart generally
have somewhat different orientations.

Geisler et al. (2001) asked observers to decide which of two complex
patterns presented together contained a winding contour. Task
performance was well predicted by the two key principles described
above. Elder and Goldberg (2002) analysed the statistics of natural
contours and obtained findings largely consistent with Gestalt laws.
Proximity was a very powerful cue when deciding which contours belonged
to which objects. There was also a small contribution from similarity
and good continuation. Numerous cues influence figure-ground
segmentation and the perception of object boundaries with natural
scenes. Mély et al. (2016) found colour and luminance (see Glossary)
strongly influenced the perception of object boundaries. There was more
accurate perception of object boundaries when several cues were combined
than that found for any single cue in isolation.

Object and face recognition

In sum, there is some support for Gestalt laws in natural scene
perception. However, figure-ground segmentation is more complex in
natural scenes than most artificial figures, and so the Gestalt approach
is oversimplified. The gestaltists failed to discover several principles
of perceptual organisation. For example, Palmer and Rock (1994) proposed
the principle of uniform connectedness. According to this principle, any
connected region having uniform visual properties (e.g., colour;
texture; lightness) tends to be organised as a single perceptual unit.
Palmer and Rock found grouping by uniform connectedness dominated
proximity and similarity when there was a conflict. Pinna et al. (2016)
argued that the gestaltists de-emphasised the role of dissimilarity in
perceptual organisation. Consider Figure 3.6. The perception of the
empty circles as a rotated square or a diamond is strongly influenced by
the location of the dissimilar element (i.e., the black circle). This
illustrates the principle of accentuation: "Elements group in the same
oriented direction of the dissimilar element placed . . . outside a
whole set of continuous/homogeneous components" (Pinna et al., 2016,
p. 21). Much processing involved in perceptual organisation occurs very
rapidly. Williford and von der Heydt (2016) discovered signals from
neurons in V2 (see Chapter 2) relating to figure-ground organisation
emerged within 70 ms of stimulus presentation for complex natural scenes
as well as for simple figures. This extremely rapid processing is
consistent with the gestaltists' assumption that perceptual organisation
is due to innate factors but may also reflect massive experience in
object recognition. The role of learning was discussed by Bhatt and
Quinn (2011). Infants as young as 3 or 4 months show grouping by
continuation, proximity and connectedness, which is apparently
consistent with the Gestalt position. However, other grouping principles
(e.g., closure) were used only later in infancy, and infants typically
made increased use of grouping principles over time. Thus, learning is
important.

A

B

Figure 3.6 The dissimilar element (black circle) accentuates the
tendency to perceive the array of empty circles as (A) a rotated square
or (B) a diamond. From Pinna et al., 2016.

101

KEY TERM Uniform connectedness The notion that adjacent regions in the
visual environment having uniform visual properties (e.g., colour) are
perceived as a single perceptual unit.

102

Visual perception and attention

According to the gestaltists, perceptual grouping occurs rapidly and
should be uninfluenced by attentional processes. The evidence is mixed.
Rashal et al. (2017) conducted several experiments. Attention was not
required with grouping by proximity or similarity in colour. However,
attention was required with grouping by similarity in shape. In general,
attention was more likely to be required when the processes involved in
perceptual grouping were relatively complex. Overall, the processes
involved in perceptual grouping are much more complicated and variable
than the gestaltists had assumed. The gestaltists also assumed
figure-ground segmentation is innate and so not reliant on past
experience or learning. Barense et al. (2012) reported contrary
evidence. Amnesic patients (having severe memory problems) and healthy
controls were presented with various stimuli, some containing parts of
well-known objects (see Figure 3.7). In other stimuli, the object parts
were rearranged. The task was to decide which region of each stimulus
was the figure. The healthy controls identified the regions containing
familiar objects as figures more often than those containing rearranged
parts. In contrast, the amnesic patients showed no difference between
the two types of stimuli because they experienced difficulty in
identifying the objects presented. Thus, figure-ground segmentation can
depend on past experience and memory (i.e., object familiarity).
Experimental stimuli: Intact familiar conﬁgurations Several recent
theories explain perceptual grouping and figure-ground segmentation. For
example, consider Froyen et al.'s (2015) Bayesian hierarchical grouping
model, according to which observers initially form "beliefs" concerning
the objects to be expected in the current context. In addition, their
visual system assumes the visual image consists of a mixture of objects.
The information availControl stimuli: Part-rearranged novel
conﬁgurations able in the image is then used to change the subjective
probabilities of different grouping hypotheses to make optimal use of
that information. Of key importance, observers use their learned
knowledge of patterns and objects (e.g., visual elements close together
generally belong to the same object). The above approach exemplifies
theories based on Bayesian inference (see Glossary). Their central
assumption is that the initial subjective probabilities associated with
variFigure 3.7 ous hypotheses as to the organisation of The top row
shows intact familiar shapes (from left to right: objects within a
visual image change on the a guitar, a standing woman, a table lamp).
The bottom row basis of the information it provides. This shows the same
objects but with the parts rearranged. The approach is much more
realistic than the task was to decide which region in each stimulus was
the gestaltists' relatively cut-and-dried approach. figure. From Barense
et al. (2012). Reprinted with permission of Oxford University Press.

Object and face recognition

Evaluation What are the strengths of the Gestalt approach? First, the
gestaltists focused on key issues (e.g., figure-ground segmentation).
Second, nearly all their grouping laws (and the notion of figure-ground
segmentation) have stood the test of time and are applicable to natural
scenes as well as artificial figures. Third, the notion that observers
perceive the simplest possible organisation of the visual environment
has proved very fruitful. Many recent theories are based on the
assumption that striving for simplicity is central to visual perception
(Jäkel et al., 2016). What are the approach's limitations? First, the
gestaltists deemphasised the importance of past experience and learning.
As Wagemans et al. (2012b, p. 1229) pointed out, the gestaltists
"focused almost exclusively on processes intrinsic to the perceiving
organism . . . The environment itself did not interest \[them\]".
Second, the gestaltists produced descriptions of important perceptual
phenomena but not adequate explanations. Recently, however, such
explanations have been provided. Third, nearly all the evidence the
gestaltists provided was based on two-dimensional drawings. The greater
complexity of real-world scenes (e.g., important parts of objects hidden
or occluded) means additional explanatory assumptions are required.
Fourth, the gestaltists did not discover all the principles of
perceptual organisation. Among such undiscovered principles are uniform
connectedness, the principle of accentuation and generalised common fate
(e.g., when elements of a visual scene become brighter or darker
together, they are grouped together). More generally, the gestaltists
did not appreciate the sheer complexity of the processes involved in
perceptual grouping. Fifth, the gestaltists focused mostly on drawings
involving only one Gestalt law. With natural scenes, several laws often
operate simultaneously and interact in complex ways not predicted by the
gestaltists (Jäkel et al., 2016). Sixth, the gestaltists' approach was
too inflexible. They did not realise perceptual grouping and
figure-ground segregation depend on complex interactions between basic
(and possibly innate) processes and past experience (Rashal et al.,
2017).

APPROACHES TO OBJECT RECOGNITION Object recognition (identifying objects
in the visual field) is enormously important if we are to interact
effectively with the environment. We start with basic aspects of the
human visual system followed by major theories of object recognition.

Perception-action model Milner and Goodale's (1995, 2008)
perception-action model (discussed in Chapter 2) is relevant to
understanding object perception. It is based on a distinction between
ventral (or "what") and dorsal (or "how") streams (see

103

104

Visual perception and attention

Figure 2.9), with the latter providing visual guidance for action (e.g.,
grasping). They argued object recognition and perception depend
primarily on the ventral stream. This stream is hierarchically
organised. Visual processing basically proceeds from the retina through
several areas including the lateral geniculate nucleus, V1, V2 and V4,
culminating in the inferotemporal cortex. The importance of the ventral
stream is indicated by research showing object recognition can be
reasonably intact after damage to the dorsal stream (Goodale & Milner,
2018). However, object recognition involves numerous interactions
between the ventral and dorsal streams (Freud et al., 2017b).

Spatial frequency Visual perception develops over time even though it
seems instantaneous (Hegdé, 2008). The visual processing involved in
object recognition typically proceeds in a coarse-to-fine way with
initial coarse or general processing followed by fine or detailed
processing. As a result, we can perceive visual scenes at a very general
level and/or at a fine-grained level. How does coarse-to-fine processing
occur? Numerous cells in the primary visual cortex respond to high
spatial frequencies and capture fine detail in the visual image.
Numerous others respond to low spatial frequencies and capture coarse
information in the visual image. Low spatial frequency information
(often relating to motion and/ or spatial location) is transmitted
rapidly to higher-order brain areas via the fast magnocellular system
using the dorsal visual stream (discussed in Chapter 2). Awasthi et
al. (2016) used red light to produce magnocellular suppression. As
predicted, this interfered with the low spatial frequency components of
face perception. In contrast, high spatial frequency information (often
relating to colour, shape and other aspects of object recognition) is
transmitted relatively slowly via the parvocellular system using the
ventral visual stream (see Chapter 2). This speed difference explains
why coarse processing typically precedes fine processing, although
conscious perception is typically based on integrated low and high
spatial information. We can observe the effects of varying spatial
frequency by comparing images consisting only of low or high spatial
frequency (see Figure 3.8). You probably agree it is considerably easier
to achieve object recognition with the high spatial frequency image.

Findings

Figure 3.8 High and low spatial frequency versions of a place (a
building). From Awasthi et al. (2016).

Musel et al. (2012) presented participants with very brief (150 ms)
scenes proceeding from coarse (low spatial frequency) to fine (high
spatial frequency) or vice versa (sample videos can be viewed at
DOI.10.1371/ journal.pone.003893). Performance (deciding whether each
scene was an outdoor or indoor

Object and face recognition

105 Figure 3.9 Image of Mona Lisa revealing very low spatial frequencies
(left), low spatial frequencies (centre) and high spatial frequencies
(right). From Livingstone (2000). By kind permission of Margaret
Livingstone.

one) was faster with the coarse-to-fine sequence, a finding subsequently
replicated by Kauffmann et al. (2015). These findings suggest the visual
processing of natural scenes is predominantly coarse to fine. This
sequence may be more effective because low spatial frequency information
is used to generate plausible interpretations of the visual input. There
is considerable evidence that global (general) processing often precedes
local (specific) processing (discussed on p. 95). Much research has
established an association between processing low spatial frequencies
and global perception and between processing high spatial frequencies
and local perception. However, use of low and high spatial frequency
information in visual processing is often very flexible and is
influenced by task demands. Flevaris and Robertson (2016, p. 192)
reviewed research showing, "Attention to global and local aspects of a
display biases the flexible selection of relatively lower and relatively
higher SFs \[spatial frequencies\] during image processing." Finally, we
can explain the notoriously elusive smile of Leonardo da Vinci's Mona
Lisa with reference to spatial frequencies. Livingston (2000) produced
images of that painting with different spatial frequencies. Mona Lisa's
smile is much more obvious in the two low spatial frequency images (see
Figure 3.9). Livingston pointed out that our central or foveal vision is
dominated by higher spatial frequencies compared with our peripheral
vision. As a result, "You can't catch her smile by looking at her mouth.
She smiles until you look at her mouth" (p. 1299).

Historical background: Marr's computational approach David Marr (1982)
proposed a very influential theory. He argued object recognition
involves various processing stages and is much more complex than had
previously been thought. More specifically, Marr claimed observers
construct various representations (descriptions) providing increasingly
detailed information about the visual environment: ●

Primal sketch: this provides a two-dimensional description of the main
light intensity changes in the visual input, including information about
edges and contours.

106

Visual perception and attention

●

●

2½-D sketch: this incorporates a description of the depth and
orientation of visible surfaces using information from shading, texture,
motion and binocular disparity. It resembles the primal sketch in being
viewer-centred or viewpoint-dependent (i.e., it is influenced by the
angle from which the observer sees objects or the environment). 3-D
model representation: this describes objects' shapes and their relative
positions three-dimensionally; it is independent of the observer's
viewpoint and so is viewpoint-invariant.

Why has Marr's theoretical approach been so influential? First, he
successfully combined ideas from neurophysiology, anatomy and computer
vision (Mather, 2015). Second, he was among the first to realise the
enormous complexity of object recognition. Third, his distinction
between viewpoint-dependent and viewpoint-invariant representations
triggered much subsequent research (discussed on pp. 109--111). What are
the limitations of Marr's approach? First, he focused excessively on
bottom-up processes. Marr (1982, p. 101) admitted, "Top-down processing
is sometimes used and necessary." However, he de-emphasised the major
role expectations and knowledge play in object recognition (discussed in
detail on pp. 111--116). Second, Marr assumed that "Vision tells the
truth about what is out there" (Mather, 2015, p. 44). In fact, there are
numerous exceptions. For example, people observed from a tall building
(e.g., the Eiffel Tower) seem very small. Another example is the
vertical-horizontal illusion -- observers typically overestimate the
length of a vertical line when it is compared against a horizontal line
of the same length (e.g., Gavilán et al., 2017). Third, many processes
proposed by Marr are incredibly complex computationally. As Mather
(2015, p. 44) pointed out, "The computations required to produce
view-independent 3-D object models are now thought by many researchers
to be too complex."

Biederman's recognition-by-components theory Biederman's (1987)
recognition-by-components theory developed Marr's theoretical approach.
His central assumption was that objects consist of basic shapes or
components known as "geons" (geometric ions); examples include blocks,
cylinders, spheres, arcs and wedges. Biederman claimed there are
approximately 36 different geons, which sounds suspiciously low to
provide descriptions of all objects. However, geons can be combined in
almost endless ways. For example, a cup is an arc connected to the side
of a cylinder. A pail involves the same two geons but with the arc
connected to the top of the cylinder. Figure 3.10 shows the key features
of recognition-by-components theory. We have already considered the
stage where the components or geons of an object are determined. When
this information is available, it is matched with stored object
representations or structural models consisting of information about the
nature of the relevant geons, their orientations, sizes and so on.
Whichever stored representation fits best with the geonbased information
obtained from the visual object determines which object is identified by
observers.

Object and face recognition

As indicated in Figure 3.10, the first step in object recognition is
edge extraction in which various aspects of the visual stimulus (e.g.,
luminance; texture; colour) are processed, leading to a description of
the object resembling a line drawing. After that, decisions are made as
to how the object should be segmented to establish its geons. Which edge
information should observers focus on? According to Biederman (1987),
non-accidental image properties are crucial. These are aspects of the
visual image that are invariant across different viewing angles.
Examples include whether an edge is straight or curved and whether a
contour is concave (hollow) or convex (bulging) with the former of
particular importance. Biederman assumed objects' geons of a visual
object are constructed from various non-accidental or invariant
properties. This part of the theory leads to the key prediction that
object recognition is typically viewpoint-invariant (i.e., objects can
be recognised equally easily from nearly all viewing angles). The
argument is that object recognition depends crucially on the
identification of geons, which can be identified from numerous
viewpoints. Thus, object recognition is difficult only when one or more
geons are hidden from view. How do we recognise objects in suboptimal
viewing conditions (e.g., an intervening object obscures part of the
target object)? First, non-accidental properties can still be detected
even when only parts of edges are visible. Second, if the concavities of
a contour are visible, there are mechanisms for restoring the missing
parts of the contour. Third, we can recognise many objects when some
geons are missing because there is much redundant information under
optimal viewing conditions.

107

Irving Biederman. University of Southern California.

Findings Non-accidental properties play a vital role in object
recognition (Parker & Serre, 2015). For example, it is easier to
distinguish between two objects differing in non-accidental properties.
In addition, neuroimaging studies

Figure 3.10 An outline of Biederman's recognition-by-components theory.
Adapted from Biederman (1987).

108

Visual perception and attention

reveal greater neural responses to changes in non-accidental properties
than other visual changes. Rolls and Mills (2018) developed a model of
object recognition showing how non-accidental properties of objects can
promote viewpoint-invariant object recognition. There is general
agreement that an object's contour or outline is important in object
recognition. For example, camouflage in many animal species is achieved
by markings breaking up and distorting contour information (Webster,
2015). There is also general agreement that concavities and convexities
are especially informative regions of an object's contour. However, the
evidence relating to Biederman's (1987) assumption that concavity is
more important than convexity in object recognition is mixed
(Schmidtmann et al., 2015). In their own study, Schmidtmann et
al. (2015) focused specifically on shape recognition using unfamiliar
shapes. Shape recognition depended more on information about convexities
than concavities (although concavity information had some value). They
argued convexity information is likely to be more important because
convexities reveal an object's outer boundary. According to the theory,
object recognition depends on edge rather than surface information
(e.g., colour). However, Sanocki et al. (1998) argued that
edge-extraction processes are less likely to produce accurate object
recognition when objects are presented in the context of other objects
rather than on their own. This is because it can be hard to decide which
edges belong to which objects when several objects are presented
together. Sanocki et al. presented observers briefly with objects, with
line drawings, or full-colour photographs of objects. As predicted,
object recognition was much worse with the line drawings than the
full-colour photographs when objects were presented in context. A key
theoretical prediction is that object recognition is typically
viewpoint-invariant. Biederman and Gerhardstein (1993) supported this
prediction when familiar objects presented at different angles were
named rapidly. However, numerous other studies have failed to obtain
evidence for viewpoint-invariance. This is especially the case with
unfamiliar objects differing from familiar objects in not having
previously been viewed from multiple viewpoints (discussed in next
section on pp. 109--111).

Evaluation Biederman's (1987) recognition-by-components theory has been
very influential. It indicates how we can identify objects despite
substantial differences among the members of most categories in shape,
size and orientation. The assumption that non-accidental properties of
stimuli and geons play a role in object recognition has received much
support. What are the theory's limitations? First, it focuses
predominantly on bottom-up processes triggered directly by the stimulus
input. As a result, it de-emphasises the impact on object recognition of
top-down processes based on expectation (Trapp & Bar, 2015; discussed
further on pp. 111--116). Second, the theory accounts only for fairly
unsubtle perceptual discriminations. It cannot explain how we decide
whether an animal is, for example, a particular breed of dog or cat.
Third, the notion that

Object and face recognition

objects consist of invariant geons is too inflexible. As Hayward and
Tarr (2005, p. 67) pointed out, "You can take almost any object, put a
working light-bulb on the top, and call it a lamp."

Does viewpoint influence object recognition? Form a visual image of a
bicycle. Your image probably involved a side view with both wheels
clearly visible. We can use this example to discuss a theoretical
controversy. Consider an experiment where some participants see a
photograph of a bicycle in the typical (or canonical) view as in your
visual image, whereas others see a photograph of the same bicycle viewed
end-on or from above. Would those given the typical view identify the
object as a bicycle fastest? We will address the above question shortly.
Before that, we must discuss two key terms mentioned earlier. If object
recognition is equally rapid and easy regardless of viewing angle, it is
viewpoint-invariant. In contrast, if object recognition is faster and
easier when objects are seen from certain angles, it is viewer-centred
or viewpoint-dependent. Another important distinction is between
categorisation (e.g., is the object a dog?) and identification (e.g., is
the object a poodle?), which requires within-category discriminations.

Findings Milivojevic (2012) reviewed behavioural research in this area.
Object recognition is typically uninfluenced by an object's orientation
when categorisation is required (i.e., it is viewpoint-invariant). In
contrast, object recognition is significantly slower if an object's
orientation differs from its canonical or typical viewpoint when
identification is required (i.e., it is viewer-centred). Hamm and
McMullen (1998) reported supporting findings. Changes in viewpoint had
no effect on speed of object recognition when categorisation was
required (e.g., deciding an object was a car). However, there were clear
effects of changing viewpoint with identification (e.g., deciding
whether an object was a taxi). Small (or non-significant) effects of
object orientation on categorisation time do not necessarily indicate
orientation has not affected internal processing. Milivojevic et
al. (2011) found stimulus orientation had only small effects on speed
and accuracy of categorisation. However, early components of the
event-related potentials (ERPs; see Glossary) were larger when stimuli
were not in the upright position. Thus, stimulus orientation had only
modest effects on task performance but perceptual processing was less
demanding with upright stimuli. Neuroimaging research has enhanced our
understanding of object recognition (Milivojevic, 2012). With
categorisation tasks, brain activation is mostly very similar regardless
of object orientation. However, orientation influences brain activity
early in processing suggesting initial processing is
viewpoint-dependent. With identification tasks, there is typically
greater activation of areas within the inferior temporal cortex when
objects are not in their typical or canonical orientation (Milivojevic,
2012). This finding is unsurprising

109

110

Visual perception and attention

since the inferotemporal cortex is heavily involved in object
recognition (Gauthier & Tarr, 2016). Identification may require
additional processing (e.g., more detailed processing of object
features) for objects presented in unusual orientations. Learning
influences the extent to which object recognition is viewpoint-dependent
or viewpoint-invariant. Zimmermann and Eimer (2013) presented unfamiliar
faces on 640 trials. Face recognition was viewpoint-dependent initially
but became more viewpoint-invariant thereafter. Learning caused more
information about each face to be stored in long-term memory and this
facilitated rapid access to visual face memory regardless of facial
orientation. Etchells et al. (2017) also studied the effects of learning
on face recognition. During learning, observers were repeatedly shown
one or two views of unfamiliar faces. Subsequently they were shown a
novel view of these faces. There was evidence of viewpoint-invariant
face recognition when learning had been based on two different views but
not when it had been based on only a single view. Related research was
reported by Weibert et al. (2016). They found evidence of a
viewpoint-invariant response in face-selective regions of the medial
temporal lobe with familiar (but not unfamiliar) faces. Thus,
viewpoint-invariant responses during object recognition are more
frequent for faces for which observers have stored considerable relevant
information. Evidence of viewpoint-dependent or viewpoint-invariant
responses within the brain often depends on the precise brain areas
studied. Erez et al. (2016) found viewpoint-dependent responses in
several visual areas (e.g., fusiform face area) but viewpoint-invariant
responses in the perirhinal cortex. There is more evidence for
viewpoint-invariant brain responses late rather than early in visual
processing. Why is that? As Erez et al. (p. 2271) argued,
"Representations of low-level features are transformed into more complex
and invariant representations as information flows through successive
stages of \[processing\]." Most research is limited because object
recognition is typically assessed in only one context, which may prompt
either viewpoint-invariant or viewpoint-dependent recognition
performance. Tarr and Hayward (2017) argued this approach can
misleadingly suggest observers store only viewpoint-invariant or
viewpoint-dependent information. Accordingly, they used various
contexts. Observers originally learned the identities of novel objects
that could be discriminated by viewpoint-invariant information. As
predicted, they exhibited viewpoint-invariant object recognition when
tested. When the testing context was changed to make it hard to continue
to use that approach, observers shifted to exhibiting viewpointdependent
behaviour. The central conclusion from the above findings is that:
"Object representations are neither viewpoint-dependent nor
viewpoint-invariant, but rather encode multiple kinds of information . .
. deployed in a flexible manner appropriate to context and task" (Tarr &
Hayward, 2017, p. 108). Thus, visual object representations contain
richer and more variegated information than typically assumed on the
basis of limited testing conditions.

Object and face recognition

Conclusions As Gauthier and Tarr (2016, p. 179) concluded: "Depending on
the experimental conditions and which parts of the brain we look at, one
can obtain data supporting both the structural-description (i.e., the
viewpointinvariant) and the view-based \[viewpoint-dependent\]
approaches." There has been progress in identifying factors (e.g., is
categorisation or identification required? is the object familiar or
unfamiliar?) influencing whether object recognition is
viewpoint-invariant or viewpoint-dependent. Gauthier and Tarr (2016,
p. 379) argued researchers should address the following question: "What
is the nature of the features that comprise high-level visual
representations and lead to image-dependence or image-invariance?" Thus,
we should focus more on why object recognition is viewpoint-invariant or
viewpoint-dependent. As yet, "The exact and fine-grained features of
object representations are still unknown and are not easily resolved"
(Gauthier & Tarr, 2016, p. 379).

OBJECT RECOGNITION: TOP-DOWN PROCESSES Historically, most theorists
(e.g., Marr, 1982; Biederman, 1987) studying object recognition
emphasised bottom-up processes. Apparent support can be found in the
hierarchical nature of visual processing. As Yardley et al. (2012, p. 4)
pointed out, Traditionally, visual object recognition has been taken as
mediated by a hierarchical, bottom-up stream that processes an image by
systematically analysing its individual elements and relaying this
information to the next areas until the overall form and identity are
determined. The above account, assuming a feedforward hierarchy of
processing stages from visual cortex through to inferotemporal cortex,
is oversimplified. There are as many backward projecting neurons
(associated with top-down processing) as forward projecting ones
throughout most of the visual system (Gilbert & Li, 2013). Up to 90% of
the synapses from incoming neurons to primary visual cortex (involved in
early visual processing) originate in the cortex and thus reflect
top-down processes. Recurrent processing (a form of top-down processing)
from higher to lower brain areas is often necessary for conscious visual
perception (van Gaal & Lamme, 2012; see Chapter 16). Top-down processes
should have their greatest impact on object recognition when bottom-up
processes are relatively uninformative (e.g., when observers are
presented with degraded or briefly presented stimuli). Support for this
prediction is discussed on p. 112.

Findings Evidence for the involvement of top-down processes in visual
perception was reported by Goolkasian and Woodberry (2010). They
presented observers with ambiguous figures immediately preceded by
primes relevant to one interpretation (see Figure 3.11). The primes
systematically biased the interpretation of the ambiguous figures via
top-down processes.

111

112

Visual perception and attention

Young boy

Peacock feathers Words on a page

Figure 3.11 Ambiguous figures (e.g., Eskimo/Indian, Liar/ Face) were
preceded by primes (e.g., Winter Scene, Tomahawk) relevant to one
interpretation of the following figure. From Goolkasian and Woodberry
(2010). Reprinted with permission from the Psychonomic Society 2010.

Viggiano et al. (2008) obtained strong evidence that top-down processes
within the prefrontal cortex influence object recognition. Observers
viewed blurred or non-blurred photographs of living and non-living
objects. On some trials, repetitive transcranial magnetic stimulation
(rTMS; see Glossary) was applied to the dorsolateral prefrontal cortex
to disrupt topdown processing. rTMS slowed object recognition time only
with blurred photographs. Thus, top-down processes were directly
involved in object recognition when the sensory information available to
bottom-up processes was limited.

Controversy Firestone and Scholl (2016) argued in a review, "There is .
. . no evidence for top-down effects of cognition on visual perception."
They claimed that top-down processes often influence response bias,
attention or memory rather than perception itself.

Object and face recognition

First, consider ambiguous or reversible figures (e.g., the faces-goblet
illusion shown in Figure 3.5). Observers alternate between the two
possible interpretations (e.g., faces vs goblet). The dominant one at
any moment depends on their direction of attention but not necessarily
on top-down processes (Long & Toppino, 2004). Second, Auckland et
al. (2007) presented observers briefly with a target object (e.g.,
playing cards) surrounded by four context objects. When the context
objects were semantically related to the target (e.g., dice; chess
pieces; plastic chips; dominoes), the target was recognised more often
than when they were semantically unrelated. This finding depended in
part on response bias (i.e., guesses based on context) rather than
perceptual information about the target. (More evidence of response bias
is discussed in the Box). Firestone and Scholl's (2016) article has
provoked much controversy. Lupyan (2016, p. 40) attacked their tendency
to attribute apparent topdown effects on perception to attention, memory
and so on: "This 'It's not perception, it's just X' reasoning assumes
that attention, memory, and so forth be cleanly split from perception
proper." In fact, all these processes interact dynamically and so
attention, perception and memory are not clearly separate.

113

KEY TERM Shooter bias The tendency for unarmed black individuals to be
more likely than unarmed white individuals to be shot.

IN THE REAL WORLD: SHOOTER BIAS Shooter bias is shown by "More shooting
errors for unarmed black than white suspects" (Cox & Devine, 2016,
p. 237). Black Americans are more than twice as likely as white
Americans to be unarmed when killed by the police (Ross, 2015). For
example, on 22 November 2014, a police officer in Cleveland, Ohio, shot
dead a 12-year-old black male (Tamir Rice) playing with a replica
pistol. Shooter bias may reflect top-down influences on visual
perception. Payne (2006) presented a white or black face followed by the
very brief presentation of a gun or tool. When participants made a rapid
response, they indicated falsely they had seen a gun more often when the
face was black. Shooter bias reflects top-down effects based on
inaccurate racial stereotypes associating black individuals with threat
(e.g., Azevedo et al., 2017). This bias might be due to direct top-down
effects on perception: objects are more likely to be misperceived as
guns if held by black individuals. Alternatively, shooter bias may
reflect response bias (the expectation someone has a gun is greater if
that person is black rather than white): there is no effect on
perception but shooters require less perceptual evidence to shoot a
black individual. Azevedo et al. (2017) found a briefly presented weapon
(a gun) was more accurately perceived when preceded by a black face than
a white one. However, the opposite was the case when a tool was
presented. These findings were due to response bias rather than
perception. Moore-Berg et al. (2017) asked non-black participants to
decide rapidly whether or not to shoot an armed or unarmed white or
black person of high or low socio-economic status. There was shooter
bias: participants were biased towards shooting if the individual was
black, of low socio-economic status, or both. This shooter bias mostly
reflected a response bias against shooting a white person of high
socio-economic status (probably because of a low level of perceived
danger).

114

Visual perception and attention

Further findings Howe and Carter (2016) identified two perception-like
phenomena driven by topdown processes. First, there are visual
hallucinations which are found in schizophrenic patients. Hallucinations
are experienced as actual perceptions even though the relevant object is
not present and so they cannot depend on bottom-up processes. Second,
there is visual imagery (discussed on pp. 130--137). Visual imagery
involves several processes involved in visual perception. Like
hallucinations, visual imagery occurs in the absence of bottom-up
processes because the relevant object is absent. Lupyan (2017) discussed
numerous topdown effects on visual perception in studies avoiding the
problems identified by Firestone and Scholl (2016). Look at Figure 3.12,
which apparently shows an ordinary brick wall. If that is what you see,
have another look. This Figure 3.12 time see whether you can spot the
object A brick wall that can be seen as something else. mentioned at the
end of the Conclusions From Plait (2016). section. Once you have spotted
the object, it becomes impossible not to see it afterwards. Here we have
powerful effects of top-down processing on perception based on knowledge
of what is in the photograph.

Conclusions As Firestone and Scholl (2016) argued, it is hard to
demonstrate top-down processes directly influence perception rather than
attention, memory or response bias. However, many studies have shown
such a direct influence. As Yardley et al. (2012, p. 1) pointed out,
"Perception relies on existing knowledge as much as it does on incoming
information." Note, however, the influence of top-down processes is
generally greater when visual stimuli are degraded. By the way, the
hard-to-spot object in the photograph is a cigar!

Theories emphasising top-down processes Bar et al. (2006) found greater
activation of the orbitofrontal cortex (part of the prefrontal cortex)
when object recognition was hard than when it was easy. This activation
occurred 50 ms before activation in recognition-related regions of the
temporal cortex, and so seemed important for object recognition. In Bar
et al.'s model, object recognition depends on top-down processes
involving the orbitofrontal cortex and bottom-up processes involving the
ventral visual stream (see Figure 3.13; and Chapter 2).

Object and face recognition

Trapp and Bar (2015) developed this model claiming that visual input
rapidly elicits various hypotheses concerning what has been presented.
Subsequent top-down processes associated with the orbitofrontal cortex
select relevant hypotheses and suppress irrelevant ones. More
specifically, the orbitofrontal cortex uses contextual information to
generate hypotheses and resolve competition among hypotheses. Palmer
(1975) showed the importance of context. He presented a picture of a
scene (e.g., a kitchen) followed by the very brief presentation of the
picture of an object. The object was recognised more often when relevant
to the context (e.g., a loaf) than when irrelevant (e.g., a drum).

Interactive-iterative framework Baruch et al. (2018) argued that
previous theorists had not appreciated the full complexities of
interactions between bottom-up and topdown processes in object
recognition. They rectified this situation with their
interactiveiterative framework (see Figure 3.14). According to this
framework, observers typically form hypotheses concerning object
identity based on their goals, knowledge and the environmental context.
Of importance, these hypotheses are often formed before the object is
presented. Observers discriminate among competing hypotheses by
attending to a distinguishing feature of the object. For example, if
your tentative hypothesis was elephant, you might allocate attention to
the expected location of its trunk. If that failed to provide the
necessary information because that area was partially hidden (see Figure
3.15), you might then attend to other features (e.g., size and shape of
the leg; skin texture). In sum, Baruch et al. (2018) emphasised two
related top-down processes strongly influencing object recognition.
First, observers form hypotheses about the possible identity of an
object prior to (or in interaction with) the visual input. Second,
observers direct their attention to object parts likely to be maximally
informative concerning its identity.

115

Figure 3.13 In this modified version of Bar et al.'s (2006) theory, it
is assumed that object recognition involves two different routes: (1) a
top-down route in which information proceeds rapidly to the
orbitofrontal cortex, which is involved in generating predictions about
the object's identity; (2) a bottom-up route using the slower ventral
visual stream. From Yardley et al. (2012). Reprinted with permission
from Springer.

Pre-existing dynamically changing context

Goals, knowledge and context-based expectancies

Hypothesis/es regarding object identity

Object identified?

yes Response

no

Visual data extraction

Guidance of attention to distinguishing features Potential conflict
Capture of attention by salient features

Visual input

Top-down Bottom-up

Figure 3.14 Interactive-iterative framework for object recognition with
top-down processes shown in dark green and bottom-up processes in brown.
From Baruch et al. (2018). Reprinted with permission of Elsevier.

116

Visual perception and attention

Findings According to the interactive-iterative framework, expectations
can exert topdown influences on processing even before a visual stimulus
is presented. Kok et al. (2017) obtained support for this prediction.
Observers expecting a given stimulus produced a neural signal resembling
that generated by the actual presentation of the stimulus shortly before
it was presented. Baruch et al. (2018) tested various predictions from
their theoretical framework. In one experiment, participants decided
which of two types of artificial fish (tass or grout) Figure 3.15 had
been presented. The two fish types difRecognising an elephant when a key
feature (its trunk) is fered with respect to distinguishing features
partially hidden. associated with the tail and the mouth, with From
Baruch et al. (2018). Reprinted with permission of Elsevier. the tail
being easier to discriminate. As predicted, participants generally
attended more to the tail than the mouth region from stimulus onset.
When much of the tail region was hidden from view, participants
redirected their attention to the mouth region.

Summary Numerous theorists have argued that object recognition depends
on top-down processes as well as bottom-up ones. Baruch et al.'s (2018)
interactive-iterative framework extends such ideas by identifying how
these two types of processes interact. Of central importance, top-down
processes influence the allocation of attention, and the allocation of
attention influences subsequent bottom-up processing.

FACE RECOGNITION There are two main reasons for devoting a section to
face recognition. First, recognising faces is of enormous importance to
us, since we generally identify individuals from their faces. Form a
visual image of someone important in your life -- it probably contains
detailed information about their face. Second, face recognition differs
importantly from other forms of object recognition. As a result, we need
theories specifically devoted to face recognition rather than simply
relying on theories of object recognition.

KEY TERM Holistic processing Processing that involves integrating
information from an entire object (especially faces).

Face vs object recognition How does face recognition differ from object
recognition? There is more holistic processing in face recognition.
Holistic processing involves "integration across the area of the face,
or processing of the relationships between features as well as, or
instead of, the features themselves" (Watson & Robbins, 2014, p. 1).
Holistic processing is faster because facial features

Object and face recognition

are processed in parallel rather than individually. Caharel et
al. (2014) found faces can be categorised as familiar or unfamiliar
within approximately 200 ms. Holistic processing is also more reliable
than feature processing because individual facial features (e.g., mouth
shape) are subject to change. Relevant evidence comes from the face
inversion effect: faces are much harder to identify when presented
inverted or upside-down rather than upright (Bruyer, 2011). This effect
probably reflects difficulties in processing inverted faces
holistically. There are surprisingly large effects of face inversion
within the brain -- Rosenthal et al. (2017, p. 4823) found face
inversion "induces a dramatic functional reorganisation across related
brain networks". In contrast, adverse effects of inversion are often
much smaller with non-face objects. For example, Klargaard et al. (2018)
found there was a larger inversion effect for faces than for cars.
However, it can be argued we possess expertise in face recognition and
so we should consider individuals possessing expertise with non-face
objects. The findings are mixed. Rossion and Curran (2010) found car
experts had a much smaller inversion effect for cars than faces.
However, those with the greatest expertise showed a greater inversion
effect for cars. In contrast, Weiss et al. (2016) found horse experts
had no inversion effect for horses. More evidence suggesting faces are
special comes from the part-whole effect -- it is easier to recognise a
face part when presented within a whole face rather than in isolation.
Farah (1994) studied this effect using drawings of faces and houses.
Participants' ability to recognise face parts was much better when whole
faces were presented rather than only a single feature (i.e., the
part-whole effect). In contrast, recognition performance for house
features was very similar in whole and single-feature conditions.
Richler et al. (2011) explored the hypothesis that faces are processed
holistically by using composite faces. Composite faces consist of a top
half and a bottom half that may or may not be from the same face. The
task was to decide whether the top halves of two successive composite
faces were the same or different. Performance was worse when the bottom
halves of the two composite faces were different. This composite face
effect suggests people find it hard to ignore the bottom halves and thus
that face processing is holistic. Finally, accurate face recognition is
so important to humans we might expect to find holistic processing of
faces even in young children. As predicted, children aged between 3 and
5 show holistic processing (McKone et al., 2012). In sum, face
recognition (even in young children) involves holistic processing.
However, it remains unclear whether the processing differences between
faces and other objects occur because faces are special or because we
have dramatically more expertise with faces than most other object
categories. Relevant evidence was reported by Ross et al. (2018). When
participants were presented with car pictures, car experts formed more
holistic representations within the brain than did car novices. The role
played by expertise is discussed further shortly.

117

KEY TERM Face inversion effect The finding that faces are much harder to
recognise when presented upside down; the effect of inversion is less
marked (or absent) with other objects. Part-whole effect The finding
that a face part is recognised more easily when presented in the context
of a whole face rather than on its own.

118

Visual perception and attention

KEY TERM

Prosopagnosia

Prosopagnosia A condition (also known as face blindness) in which there
is a severe impairment in face recognition but much less impairment of
object recognition; it is often the result of brain damage (acquired
prosopagnosia) but can also be due to impaired development of
facerecognition mechanisms (developmental prosopagnosia).

Much research has involved brain-damaged patients with severely impaired
face processing. Such patients suffer from prosopagnosia
(pros-uh-pagNO-see-uh) coming from the Greek words for "face" and
"without knowledge". Prosopagnosia is also known as "face blindness".
Prosopagnosia is a heterogeneous or diverse condition with the precise
problems of face and object recognition varying across patients. It can
be caused by brain damage (acquired prosopagnosia) or can occur in the
absence of any obvious brain damage (developmental prosopagnosia).
Acquired prosopagnosics differ in terms of their specific
face-processing deficits and brain areas involved (discussed later).
Studying prosopagnosics is of direct relevance to the issue of whether
face recognition involves specific or specialised processes absent from
object recognition. If prosopagnosics invariably have great impairments
in object recognition, it would suggest face and object recognition
involve similar processes. In contrast, if some prosopagnosics have
intact object recognition, it would imply the processes underlying the
two forms of recognition are different. Farah (1991) reviewed research
on patients with acquired prosopagnosia. All these patients also had
more general problems with object recognition. However, some exceptions
have been reported. Moscovitch

IN REAL LIFE: HEATHER SELLERS We can understand the profound problems
prosopagnosics suffer in everyday life by considering Heather Sellers
(see YouTube: "You Don't Look Like Anyone I Know"). She is an American
woman with severe prosopagnosia. When she was a child, she became
separated from her mother at a grocery store. When reunited with her
mother, she did not initially recognise her. Heather Sellers still has
difficulty in recognising her own face. Heather: "A few times I have
been in a crowded elevator with mirrors all found and a woman will move,
and I will go to get out the way and then realise 'oh that woman is
me'." Such experiences made her very anxious. Surprisingly, Heather
Sellers was 36 before she realised she had prosopagnosia. Why was this?
Heather Sellers. As a child, she became very skilled at identifying
Patricia Roehling. people by their hair style, body type, clothing,
voice and gait. In spite of these skills, she has occasionally failed to
recognise her own husband! According to Heather Sellers, "Not being able
to reliably know who people are -- it feels terrible like failing all
the time."

Object and face recognition

et al. (1997) studied CK, a man with object agnosia (impaired object
recognition). He performed comparably to healthy controls on several
facerecognition tasks including photos, caricatures and cartoons. Geskin
and Behrmann (2018) reviewed the literature on patients with
developmental prosopagnosia. Out of 238 cases, 80% had impaired object
recognition but 20% did not. Thus, several patients had impaired face
recognition but not object recognition. We would have a double
dissociation (see Glossary) if we could find individuals with
developmental object agnosia but intact face recognition. Germine et
al. (2011) found a female (AW), who had preserved face recognition but
impaired object recognition for many categories of objects. Overall, far
more individuals have impaired face recognition (prosopagnosia) but
relatively intact object recognition than have impaired object
recognition but intact face recognition. These findings suggest that,
"Face recognition is an especially difficult instance of object
recognition where both systems \[i.e., face and object recognition\]
rely on a common mechanism" (Geskin & Behrmann, 2018, p. 18). Face
recognition is hard in part because it involves distinguishing among
broadly similar category members (e.g., two eyes; nose; mouth). In
contrast, object recognition often only involves identifying the
relevant category (e.g., cat; car). According to this viewpoint,
prosopagnosics would perform poorly if required to make finegrained
perceptual judgments with objects. An alternative interpretation
emphasises expertise (Wang et al., 2016). Nearly everyone has more
experience (and expertise) at recognising faces than the great majority
of other objects. It is thus possible that brain damage in
prosopagnosics affects areas associated with expertise generally rather
than specifically faces (the expertise hypothesis is discussed on
pp. 122--124).

Findings In spite of their poor conscious or explicit recognition of
faces, many prosopagnosics show evidence of covert recognition (face
processing without conscious awareness). For example, Eimer et
al. (2012) found developmental prosopagnosics were much worse than
healthy controls at explicit recognition of famous faces (27% vs 82%
correct, respectively). However, famous faces produced brain activity in
half the developmental prosopagnosics indicating the relevant memory
traces were activated (covert recognition). These prosopagnosics have
very poor explicit recognition performance because brain areas
containing more detailed information about the famous individuals were
not activated. Busigny et al. (2010b) compared the first two
interpretations discussed above by using object-recognition tasks
requiring complex within-category distinctions for several categories:
birds, boats, cars, chairs and faces. A male patient (GG) with acquired
prosopagnosia was as accurate as controls with each non-face category
(see Figure 3.16). However, he was substantially less accurate than
controls with faces (67% vs 94%, respectively). Thus, GG apparently has
a face-specific impairment rather than a general inability to recognise
complex stimuli.

119

120

Visual perception and attention

Figure 3.16 Accuracy and speed of object recognition for birds, boats,
cars, chairs and faces by patient GG and healthy controls. From Busigny
et al. (2012b). Reprinted with permission from Elsevier.

Busigny et al. (2010a) reviewed previous findings suggesting many
patients with acquired prosopagnosia have essentially intact object
recognition. However, this research was limited because the difficulty
of the recognition decisions required of the patients was not controlled
systematically. Busigny et al. manipulated the similarity between target
items and distractors on an object-recognition task. Increasing
similarity had comparable effects on PS (a patient with acquired
prosopagnosia) and healthy controls. In contrast, PS performed very
poorly on a face-recognition task which was very easy for healthy
controls. Why is face recognition so poor in prosopagnosics? Busigny et
al. (2010b) tested the hypothesis that they have great difficulty with
holistic processing. A prosopagnosic patient (GG) did not show the face
inversion or composite face effects suggesting he does not perceive
individual faces holistically (an ability enhancing accurate face
recognition). In contrast, GG's object recognition was intact perhaps
because holistic processing was not required. Van Belle et al. (2011)
also investigated the deficient holistic processing hypothesis. GG's
face-recognition performance was poor when holistic processing was
possible. However, it was intact when it was not possible to use
holistic processing (only one part of a face was visible at a time).
Finally, we consider the expertise hypothesis. According to this
hypothesis, faces differ from most other categories of objects in that
we have more expertise in identifying faces. As a result, apparent
differences between faces and other objects in processes and brain
mechanisms may mostly reflect differences in expertise. This hypothesis
is discussed further below on pp. 122--124. Barton and Corrow (2016)
reported evidence consistent with this hypothesis in patients with
acquired prosopagnosia who had expertise in car recognition and reading
prior to their brain damage. These patients had impairments in car
recognition and aspects of visual word reading suggesting they had
problems with objects for which they had possessed expertise (i.e.,
objects of expertise). Contrary evidence was reported by Weiss et
al. (2016), who studied a patient (OH) with developmental prosopagnosia.
In spite of severely impaired face-recognition ability, she displayed
superior recognition skills for horses (she had spent 15 years working
with them). Thus, visual expertise can be acquired independently of the
mechanisms responsible for expertise in face recognition.

Object and face recognition

In sum, the finding that many prosopagnosics have face-specific
impairments is consistent with the hypothesis that face recognition
involves special processes. However, more general recognition
impairments have also often been reported and are apparently
inconsistent with that hypothesis. There is also some support for the
expertise hypothesis but again the findings are mixed.

Fusiform face area If faces are processed differently to other objects,
we would expect to find brain regions specialised for face processing.
The fusiform face area (FFA) in the ventral temporal cortex has (as its
name strongly implies!) been identified as such a brain region. The
fusiform face area is indisputably involved in face processing. Downing
et al. (2006) found the fusiform face area responded more strongly to
faces than any of 18 object categories (e.g., tools; fruits;
vegetables). However, other brain regions, including the occipital face
area (OFA) and the superior temporal sulcus (STS) are also
face-selective (Grill-Spector et al., 2017; see Figure 3.17). Such
findings indicate that face processing depends on one or more brain
networks rather than simply on the fusiform face area. Even though
several brain areas are face-selective, the fusiform face area has been
regarded as having special importance. For example, Axelrod and Yovel
(2015) considered brain activity in several faceselective regions when
observers were shown photos of Leonardo DiCaprio and Brad Pitt. The
fusiform face area was the only region in which the pattern of brain
activity differed significantly between these actors. However, Kanwisher
et al. (1997) found only 80% of their participants had greater
activation within the fusiform face area to faces than to other objects.
In sum, the fusiform face area plays a major role in face processing and
recognition for most (but probably not all) individuals. However, face
(a) Dorsal

(b) Ventral

OFA

FFA

ATL-FA

IFG-FA

pSTS-FA OFA aSTS-FA

Figure 3.17 Face-selective areas in the right hemisphere. OFA =
occipital face area; FFA = fusiform face area; pSTS-FA and aSTS-FA =
posterior and anterior superior temporal sulcus face areas; IFG-FA =
inferior frontal gyrus face area; ATL-FA = anterior temporal lobe face
area. From Duchaine and Yovel (2015).

121

KEY TERM Fusiform face area An area that is associated with face
processing; the term is somewhat misleading given that the area is also
associated with processing other categories of objects.

Interactive feature: Primal Pictures' 3D atlas of the brain

122

Visual perception and attention

processing depends on a brain network, including several areas in
addition to the fusiform face area (see Figure 3.17). Note also that the
fusiform face area is activated when we process numerous types of
non-face objects. Finally, face-processing deficits in prosopagnosics
are not limited to the fusiform face area. For example, developmental
prosopagnosics had less selectivity for faces than healthy controls in
12 different face areas (including the fusiform face area) (Jiahui et
al., 2018).

Expertise hypothesis According to advocates of the expertise hypothesis
(e.g., Wang et al., 2016; discussed on p. 119), major differences
between face and object processing should not be taken at face value
(sorry!). According to this hypothesis, the brain and processing
mechanisms allegedly specific to faces are also involved in processing
and recognising all object categories for which we possess expertise.
Thus, we should perhaps relabel the fusiform face area as the "fusiform
expertise area". Why is expertise so important in determining face and
object processing? One reason is that expertise leads to greater
holistic or integrated processing. For example, chess experts can very
rapidly use holistic processing based on their relevant stored knowledge
to understand complex chess positions (see Chapter 12). Three main
predictions follow from the expertise hypothesis: (1) (2) (3)

Holistic or configural processing is not unique to faces but should be
found for any objects of expertise. The fusiform face area should be
highly activated when observers recognise the members of any category
for which they possess expertise. If the processing of faces and of
objects of expertise involves similar processes, then processing objects
of expertise should interfere with face processing.

Findings The first prediction is plausible. Wallis (2013) tested a model
of object recognition to assess the effects of prolonged exposure to any
given stimulus category. The model predicted that many phenomena
associated with face processing (e.g., holistic processing; inversion
effect) would be found for any stimulus category for which observers had
expertise. Repeated simultaneous presentation of the same features
(e.g., nose; mouth; eyes) gradually increases holistic processing.
Wallis concluded a single model can explain object and face recognition.
There is some support for the first prediction in research on detection
of abnormalities in medical images (see Chapter 12). Kundel et
al. (2007) found experts generally fixated on an abnormality in under 1
second suggesting they used very fast, holistic processes. However, as
we saw earlier, experts with non-face objects often have a small
inversion effect (assumed to reflect holistic processing). McKone et
al. (2007) found such experts

Object and face recognition

rarely show the composite effect (also assumed to reflect holistic
processing; discussed on p. 117). We turn now to the second prediction.
In a review, McKone et al. (2007) found a modest tendency for the
fusiform face area to be more activated by objects of expertise than
other objects. However, larger activation effects for objects of
expertise were found outside the fusiform face area than inside it.
Support for the second prediction was reported by McGugin et al. (2014):
activation to car stimuli within the fusiform face area was greater in
participants having greater car expertise. McGugin et al. (2018) argued
that we can test the second prediction by comparing individuals varying
in face-recognition ability (or expertise). As predicted, those with
high face-recognition ability exhibited more face-selective activation
within the fusiform face area than those having low ability. Bilalić
(2016) found chess experts had more activation in the fusiform face area
than non-experts when viewing chess positions but not single chess
pieces. He concluded, "The more complex the stimuli, the more likely it
is that the brain will require the help of the FFA in grasping its
essence" (p. 1356). It is important not to oversimplify the issues here.
Even if face processing and processing of other objects of expertise
both involve the fusiform face area, the two forms of processing may use
different neurons in different combinations (Grill-Spector et al.,
2017). We turn now to the third prediction. McKeeff et al. (2010) found
that car experts were slower than novices when searching for face
targets among cars but not among watches. Car and face expertise may
have interfered with each other because they depend on similar
processes. Alternatively, car experts may have been more likely than car
novices to attend to distracting cars because they find such stimuli
more interesting. McGugin et al. (2015) also tested the third
prediction. Overall, car experts had greater activation than car novices
in face-selective areas (e.g., fusiform face area) when processing cars.
Of key importance, that difference was greatly reduced when faces were
also presented. Thus, interference was created when participants
processed objects belonging to two different categories of expertise
(i.e., cars and faces).

Evaluation There is some support for the expertise hypothesis with
respect to all three predictions. However, the extent of that support
remains controversial. One reason is that it is hard to assess expertise
level accurately or to control it. It is certainly possible that many
(but not all) processing differences between faces and other objects are
due to greater expertise with faces. This would imply that faces are
less special than often assumed. According to the expertise hypothesis,
we are face experts. This may be true of familiar faces, but it is
certainly not true of unfamiliar faces (Young & Burton, 2018). Evidence
of the problems we experience in recognising unfamiliar faces is
contained in the Box on passport control.

123

124

Visual perception and attention

IN REAL LIFE: PASSPORT CONTROL Look at the 40 faces displayed below (see
Figure 3.18). How many different individuals are shown? Provide your
answer before reading on.

Figure 3.18 An array of 40 face photographs to be sorted into piles for
each of the individuals shown in the photographs. From Jenkins et
al. (2011). Reproduced with permission from the Royal Society.

In a study by Jenkins et al. (2011) using a similar stimulus array,
participants on average decided 7.5 different individuals were shown.
However, the actual number for the array used by Jenkins et al. and the
one shown in Figure 3.18 is only two! The two individuals (A and B) are
arranged as shown below: A

B A

A

A

B A

B A

B

A

A

A

A

B B B A

B

B B B A

A

A

A

B A

A

B B B B B

A

B A

B B A

Perhaps we are poor at matching unfamiliar faces because we rarely
perform this task in everyday life. White et al. (2014) addressed this
issue in a study on passport officers averaging 8 years of service.
These passport officers indicated on each trial whether a photograph was
that of a physically present person. Overall, 6% of valid photos were
rejected and 14% of fraudulent photos were wrongly accepted. Thus,
individuals with specialist training and experience are not exempt from
problems in matching unfamiliar faces. The main problem is that there is
considerable variability in how an individual looks in different photos
(discussed further on p. 127).

Object and face recognition

125

In another experiment, White et al. (2014) compared the performance of
passport officers and students on a matching task with unfamiliar faces.
The two groups were comparable with 71% correct performance on match
trials and 89% on non-match trials. Thus, training and experience were
irrelevant. In White et al.'s (2014) research, 50% of the photos were
invalid (non-matching). This is (hopefully!) a massively higher
percentage of invalid photos than typically found at passport control.
Papesh and Goldinger (2014) compared performance when actual mismatches
occurred on 50% or 10% of trials. In the 50% condition, mismatches were
missed on 24% of trials, whereas they were missed on 49% of trials in
the 10% condition. Participants had a low expectation of mismatches in
the 10% condition and so were very cautious about deciding two photos
were of different individuals (i.e., they had a very cautious response
criterion indicating response bias). Papesh et al. (2018) replicated the
above findings. They attempted to improve performance in the condition
where mismatches occurred on only 10% of trials by introducing blocks
where mismatches occurred on 90% of trials. However, this manipulation
had little effect because participants were reluctant to abandon their
very cautious response criterion. How can we provide better security at
passport control? Increased practice at matching unfamiliar faces is not
the answer -- White et al. (2014) found performance was unrelated to the
number of years passport officers had served. A promising approach is to
find individuals having an exceptional ability to recognise faces
(super-recognisers). Robertson et al. (2016) asked participants to
decide whether face pairs depicted the same person. Mean accuracy was
96% for previously identified police super-recognisers compared to only
81% for police trainees. Why do some individuals have very superior
face-recognition ability? Wilmer et al. (2010) found the
face-recognition performance of monozygotic (identical) twins was much
closer than that of dizygotic (fraternal) twins, indicating
face-recognition ability is strongly influenced by genetic factors.
Face-recognition ability correlated very modestly with other forms of
recognition (e.g., abstract art images), suggesting it is very specific.
In similar fashion, Turano et al. (2016) found good and poor face
recognisers did not differ with respect to car-recognition ability.

Theoretical approaches Bruce and Young's (1986) model has been the most
influential theoretical approach to face processing and recognition and
so we start with it. It is a serial stage model consisting of eight
components (see Figure 3.19): (1) (2) (3) (4) (5) (6) (7)

Structural encoding: this produces various descriptions or
representations of faces. Expression analysis: people's emotional states
are inferred from their facial expression. Facial speech analysis:
speech perception is assisted by lip reading (see Chapter 9). Direct
visual processing: specific facial information is processed selectively.
Face recognition units: these contain structural information about known
faces; this structural information emphasises the less changeable
aspects of the face and is fairly abstract. Person identity nodes: these
provide information about individuals (e.g., occupation; interests).
Name generation: a person's name is stored separately.

Interactive exercise: Face recognition

KEY TERM Super-recognisers Individuals with an outstanding ability to
recognise faces.

126

Visual perception and attention

(8) 

Cognitive system: this contains additional information (e.g., most
actors have attractive faces); it influences which components receive
attention.

What predictions follow? First, there should be major differences in the
processing of familiar and unfamiliar faces because various components
(face recognition units; person identity nodes; name generation) are
involved only when processing familiar faces. Thus, it is much easier to
recognise familiar faces, especially when faces are seen from an unusual
angle. Second, separate processing routes are involved in working out
facial identity (who is it?) and facial expression (what is he/she
feeling?). The former processing route (including the occipital face
area and the fusiform face area) focuses on relatively unchanging
aspects of faces, whereas the latter (involving the superior temporal
sulcus) deals with more changeable aspects. This separation between
processes responsible for recognising identity and expression makes
sense -- if there were no separation, we would have great problems
recognising familiar faces with unusual expressions (Young, 2018).
Third, when we see a familiar face, familFigure 3.19 iarity information
from the face recognition The model of face recognition put forward by
Bruce and unit should be accessed first. This is followed Young (1986).
by information about that person (e.g., occuAdapted from Bruce and Young
(1986). Reprinted with permission of pation) from the person identity
node and Elsevier. then that person's name from the name generation
component. As a result, we can find a face familiar while unable to
recall anything else about that person, or we can recall personal
information about a person while being unable to recall their name.
However, a face should never lead to recall of the person's name in the
absence of other information. Fourth, the model assumes face processing
involves several stages. This implies the nature of face-processing
impairments in brain-damaged patients depends on which stages of
processing are impaired. DaviesThompson et al. (2014) developed the
model to account for three forms of face impairment (see Figure 3.20).

Findings According to the model, it is easier to recognise familiar
faces than unfamiliar ones for various reasons. Of special importance,
we possess much more structural information about familiar faces. This
structural information

Object and face recognition

Early perceptual encoding

Perceptual encoding of dynamic structure

Perceptual encoding of static structure

Expression analysis

Facial memories

Voice & gait analysis

Biographic information

Semantic data

Name input

Pole aLT FFA OFA

Damage results in: Apperceptive prosopagnosia Associative prosopagnosia
Person-specific amnesia

Figure 3.20 Damage to regions of the inferior occipito-temporal cortex
(including fusiform face area (FFA) and occipital face area (OFA)) is
associated with apperceptive prosopagnosia (blue); damage to anterior
inferior temporal cortex (aLT) is associated with associative
prosopagnosia (red); and damage to the anterior temporal pole is
associated with person-specific amnesia (green). Davies-Thompson et
al. (2014) discuss evidence consistent with their model. From
Davies-Thompson et al. (2014).

(associated with face recognition units) relates to relatively
unchanging aspects of faces and gradually accumulates with increasing
familiarity with any given face. However, the differences in ease of
recognition between familiar and unfamiliar faces are greater than
envisaged by Bruce and Young (1986). Jenkins et al. (2011) found 40 face
photographs showing only two different unfamiliar individuals were
thought to show almost four times that number (discussed on p. 124). The
two individuals were actually two Dutch celebrities almost unknown in
Britain. When Jenkins et al. (2011) repeated their experiment with Dutch
participants, nearly all performed the task perfectly because the faces
were so familiar. Why is unfamiliar face recognition so difficult? There
is considerable within-person variability in facial images, which is why
different photographs of the same unfamiliar individual often look as if
they come from different individuals (Young & Burton, 2017, 2018).
Jenkins and Burton (2011) argued we could improve identification of
unfamiliar faces by averaging across several photographs of the same
individual and so greatly reducing image variability. Their findings
supported this prediction. Burton et al. (2016) shed additional light on
the complexities of recognising unfamiliar faces. In essence, how one
person's face varies across images differs from how someone else's face
varies. Thus, the characteristics that vary or remain constant across
images differ from one individual to another.

127

128

Visual perception and attention

The second prediction is that different routes are involved in the
processing of facial identity and facial expression. There is some
support for this prediction. Fox et al. (2011) found patients with
damage to the face-recognition network had impaired identity perception
but not expression perception. In contrast, a patient with damage to the
superior temporal sulcus had impaired expression perception but
reasonably intact identity perception. Sliwinska and Pitcher (2018)
confirmed the role played by the superior temporal sulcus. Transcranial
magnetic stimulation (TMS; see Glossary) applied to this area impaired
recognition of facial expression. However, the two routes are not
entirely independent. Judgements of facial expression are strongly
influenced by irrelevant identity information (Schweinberger & Soukup,
1998). Redfern and Benton (2017) asked participants to sort cards of
faces into piles, one for each perceived identity. One pack contained
expressive faces and the other neutral faces. With expressive faces,
faces belonging to different individuals were more likely to be placed
in the same pile. Thus, expressive facial information can influence (and
impair) identity perception. Fitousi and Wenger (2013) asked
participants to respond positively to a face that had a given identity
and emotion (e.g., a happy face belonging to Kiera Knightley). Facial
identity and facial expression were not processed independently although
they should have been according to the model. Another issue is that the
facial expression route is more complex than assumed theoretically. For
example, damage to the amygdala produces greater deficits in recognising
fear and anger than other emotions (Calder & Young, 2005). Young and
Bruce (2011) admitted they had not expected deficits in emotion
recognition in faces to vary across emotions. The third prediction is
that we always retrieve personal information (e.g., occupation) about a
person before recalling their name. Young et al. (1985) asked people to
record problems they experienced in face recognition. There were 1,008
such incidents but people never reported putting a name to a face while
knowing nothing else about that person. In contrast, there were 190
occasions on which someone remembered a reasonable amount of information
about a person but not their name (also as predicted by the model).
Several other findings support the third prediction (Hanley, 2011).
However, the notion that names are always recalled after personal
information is too rigid. Calderwood and Burton (2006) asked fans of the
television series Friends to recall the name or occupation of the main
characters when shown their faces. Names were recalled faster than
occupations (against the model's prediction). Fourth, we relate
face-processing impairments to Bruce and Young's (1986) serial stage
model. We consider three such impairments (discussed by Davies-Thompson
et al., 2014; see Figure 3.20) with reference to Figure 3.19: (1)

Patients with impaired early stages of face processing: such patients
(categorised as having apperceptive prosopagnosia) have "an inability to
form a sufficiently accurate representation of the face's structure from
visual data" (Davies-Thompson et al., 2014, p. 161). As a result, faces
are often not recognised as familiar.

Object and face recognition

(2) 
(3) 

129

Patients with impaired ability to access facial memories in face
recognition units although early processing of facial structure is
relatively intact: such patients have associative prosopagnosia: they
have greater problems with memory than perception. Patients with
impaired access to biographical information stored in person identity
nodes: such patients have person-specific amnesia and differ from those
with associative prosopagnosia because they often cannot recognise other
people by any cues (including spoken names or voices).

So far we have applied Bruce and Young's (1986) model to acquired
prosopagnosia. However, we can also apply the model to developmental
prosopagnosia (in which face-recognition mechanisms fail to develop
normally). Parketny et al. (2015) presented previously unfamiliar faces
to developmental prosopagnosics and recorded event-related potentials
(ERPs) while they performed an easy face-recognition task. They focused
on three ERP components: (1) (2) (3)

N170: this early component (about 170 ms) reflects processes involved in
perceptual structural face processing. N250: this component (about 250
ms) reflects a match between a presented face and a stored face
representation. P600: this component (about 600 ms) reflects attentional
processes associated with face recognition.

What did Parketny et al. (2015) find? Recognition times were 150 ms
slower in the developmental prosopagnosics than healthy controls. N170
was broadly similar in both groups with respect to timing and magnitude.
N250 was 40 ms slower in the prosopagnosics than controls but of
comparable magnitude. Finally, P600 was significantly smaller in the
prosopagnosics than controls and was delayed by 80 ms. In sum,
developmental prosopagnosics show relatively intact early face
processing but are slower and less efficient later in processing. ERPs
provide an effective way of identifying those aspects of face processing
adversely affected in prosopagnosia.

Evaluation Bruce and Young (1986) provided a comprehensive framework
emphasising the wide range of information that can be extracted from
faces. It was remarkably innovative in identifying the major processes
and structures involved in face processing and recognition and
incorporating them within a plausible serial stage approach. Finally,
the model enhanced our understanding of why familiar faces are much
easier to recognise than unfamiliar ones. What are the model's
limitations? First, the complexities involved in recognising unfamiliar
faces (e.g., coping with the great variability in a given individual's
facial images) were not fully acknowledged. As Young and Burton (2017,
p. 213) pointed out, it was several years after 1986 before researchers
appreciated that "humans' relatively poor performance at unfamiliar-face
recognition is as much a problem of perception as of memory".

Case study: Model of face processing

130

KEY TERMS Aphantasia The inability to form mental images of objects when
those objects are not present. Hallucinations Perceptual experiences
that appear real even though the individuals or objects perceived are
not present.

Visual perception and attention

Second, the model's account of the processing of facial expression is
oversimplified. For example, the processing of facial expression is less
independent of the processing of facial identity than assumed
theoretically. According to the model, damage to the expression analysis
component should produce impaired ability to recognise all facial
expressions. In fact, many brain-damaged patients have much greater
impairment in facial recognition of some emotions than others (Young,
2018). Third, the model was somewhat vague about the precise information
stored in the face recognition units and the person identity nodes.
Fourth, it was wrong to exclude gaze perception from the model because
it provides useful information about what an observer is attending to
(Young & Bruce, 2011). Fifth, Bruce and Young (1986) focused on general
factors influencing face recognition. However, as discussed earlier,
there are substantial individual differences in face-recognition ability
with a few individuals (super-recognisers) having outstanding ability.
These individual differences depend mostly on genetic factors (Wilmer,
2017) not considered within the model.

VISUAL IMAGERY Close your eyes and imagine the face of someone you know
very well. What did you experience? Many people claim forming visual
images is like "seeing with the mind's eye", suggesting there are
important similarities between imagery and perception. Mental imagery is
typically regarded as involving conscious experience. However, we could
also regard imagery as a form of mental representation (an internal
cognitive symbol representing aspects of external reality) (e.g.,
Pylyshyn, 2002). We would not necessarily be consciously aware of images
as mental representations. Galton (1883) supported the above viewpoint.
He found many individuals reported no conscious imagery when imagining a
definite object (e.g., their breakfast table). Zeman et al. (2015)
studied several individuals lacking visual imagery and coined the term
aphantasia to refer to this condition. If visual imagery and perception
are similar, why do we very rarely confuse them? One reason is that we
are generally aware of deliberately constructing images (unlike with
visual perception). Another reason is that images contain much less
detail. For example, people rate their visual images of faces as similar
to photographs lacking sharp edges and borders (Harvey, 1986). However,
many people sometimes confuse visual imagery and perception. Consider
hallucinations in which perception-like experiences occur in the absence
of the appropriate environmental stimulus. Visual hallucinations occur
in approximately 27% of schizophrenic patients but also in 7% of the
general population. Waters et al. (2014) discussed research showing
visual hallucinations in schizophrenics are often associated with
activity in the primary visual cortex, suggesting hallucinations involve
many processes associated with visual perception. One reason
schizophrenics are susceptible to visual hallucinations is because of
distortions in top-down processing (e.g., forming strong expectations of
what they will see).

Object and face recognition

In Anton's syndrome ("blindness denial"), blind people are unaware that
they are blind and sometimes confuse imagery for actual perception.
Goldenberg et al. (1995) described a patient whose primary visual cortex
had been nearly wholly destroyed. Nevertheless, she generated such vivid
visual images that she mistook them for genuine visual perception. The
brain damage in patients with Anton's syndrome typically includes large
parts of the visual cortex (Gandhi et al., 2016). There is also Charles
Bonnet syndrome, defined as "consistent or periodic complex visual
hallucinations that occur in visually impaired individuals" (Yacoub &
Ferrucci, 2011, p. 421). However, patients are generally aware the
hallucinations are not real and so they are actually
pseudo-hallucinations. When patients hallucinate, they have increased
activity in brain areas specialised for visual processing (e.g.,
hallucinations in colour are associated with activity in
colour-processing areas) (ffytche et al., 1998). Painter et al. (2018)
identified a major reason for this elevated activity. Stimuli presented
to intact regions of the retina cause extreme excitability
(hyperexcitability) within early visual cortex. Visually impaired
individuals with hallucinations show greater hyperexcitability than
those without.

131

KEY TERMS Anton's syndrome A condition found in some blind people in
which they misinterpret their visual imagery as visual perception.
Charles Bonnet syndrome A condition in which individuals with eye
disease form vivid and detailed visual hallucinations sometimes mistaken
for visual perception. Depictive representation A representation (e.g.,
visual image) resembling a picture in that objects within it are
organised spatially.

Why is visual imagery useful? What functions are served by visual
imagery? According to Moulton and Kosslyn (2009, p. 1274), visual
imagery "allows us to answer 'what if' questions by making explicit and
accessible the likely consequences of being in a specific situation or
performing a specific action". For example, professional golfers use
mental imagery to predict what would happen if they hit a certain shot.
Pearson and Kosslyn (2015) pointed out that many visual images contain
rich information that is accessible when required. For example, what is
the shape of a cat's ears? You may be able to answer the question by
constructing a visual image. More generally, visual imagery supports
numerous cognitive functions. These include creative insight,
attentional search, guiding deliberate action, short-term memory storage
and long-term memory retrieval (Mitchell & Cusack, 2016).

Research activity: Mental imagery

Imagery theories Kosslyn (e.g., 1994; Pearson & Kosslyn, 2015) proposed
an influential theory based on the assumption that visual imagery
resembles visual perception. It was originally called perceptual
anticipation theory because image generation involves processes used to
anticipate perceiving visual stimuli. According to the theory, visual
images are depictive representations. What is a depictive
representation? In such a depiction, "each part of the representation
corresponds to a part of the represented object such that the distances
among the parts in the representation correspond to the actual distances
among the parts" (Pearson & Kosslyn, 2015, p. 10089). Thus, for example,
a visual image of a desk with a computer on top and a cat

Interactive exercise: Kosslyn -- mental imagery

132

Visual perception and attention

sleeping underneath would have the computer at the top and the cat at
the bottom. Where are depictive representations formed? Kosslyn argued
they are created in early visual cortex (BA17 and BA18; see Figure 3.21)
within a visual buffer. The visual buffer is a short-term store for
visual information only and is of major importance in visual perception
and imagery. There is also an "attention window" selecting some visual
information in the visual buffer and passing it on to other brain areas
for further processing. This attention window is flexible -- it can be
adjusted to include more, or less, visual Figure 3.21 information. The
approximate locations of the visual buffer in BA17 Processing in the
visual buffer depends and BA18, of long-term memories of shapes in the
inferior primarily on external stimulation during pertemporal lobe, and
of spatial representations in the posterior parietal cortex, according
to Kosslyn and Thompson's (2003) ception. However, such processing
involves anticipation theory. non-pictorial information stored in
long-term memory during imagery. Shape information is stored in the
inferior temporal lobe whereas spatial representations are stored in
posterior parietal cortex (see Figure 3.21). In sum, visual perception
mostly involves bottom-up processing whereas visual imagery depends on
top-down processing. Pylyshyn (e.g., 2002) argued visual imagery differs
substantially from visual perception. According to his propositional
theory, performance on mental imagery tasks does not involve depictive
or pictorial representations. Instead, it involves tacit knowledge
(knowledge inaccessible to conscious awareness). Tacit knowledge is
"Knowledge of what things would look like to subjects in situations like
the ones in which they are to imagine themselves" (Pylyshyn, 2002,
p. 161). Thus, performance on an imagery task relies on relevant stored
knowledge rather than visual images. Within this theoretical framework,
it is improbable that early visual cortex would be involved on an
imagery task.

Imagery resembles perception KEY TERMS Visual buffer Within Kosslyn's
theory, a short-term visual memory store involved in visual imagery and
perception. Binocular rivalry When two different visual stimuli are
presented one to each eye, only one stimulus is seen; the seen stimulus
alternates over time.

If visual perception and imagery involve similar processes, they should
influence each other. There should be facilitation if the contents of
perception and imagery are the same but interference if they differ.
Pearson et al. (2008) reported a facilitation effect with binocular
rivalry -- when a different stimulus is presented to each eye, only one
is consciously perceived at any given moment. The act of imagining a
specific pattern strongly influenced which stimulus was subsequently
perceived and this facilitation depended on the similarity between the
imagined and presented stimuli. The findings were remarkably similar
when the initial stimulus was perceived rather than imagined. Baddeley
and Andrade (2000) reported an interference effect. Participants rated
the vividness of visual and auditory images while performing a second
task involving visual/spatial processes. This task reduced

Object and face recognition

TOP LEFT

TOP RIGHT

Dwell time Perception = 4% Imagery = 8%

Dwell time Perception = 77% Imagery = 64%

White space Dwell time Perception = 2% Imagery = 5%

BOTTOM LEFT

BOTTOM RIGHT

Dwell time Perception = 1% Imagery = 4%

Dwell time Perception = 10% Imagery = 12%

the vividness of visual imagery more than that of auditory imagery
because similar processes were involved on the visual/spatial and visual
imagery tasks. Laeng et al. (2014) asked participants to view pictures
of animals and to follow each one by forming a visual image of that
animal. There was a striking similarity in eye fixations devoted to the
various areas of each picture in both conditions (see Fig. 3.22).
Participants having the greatest similarity in dwell time between
perception and imagery showed the best memory for the size of each
animal. According to Kosslyn's theoretical position, much processing
associated with visual imagery occurs in early visual cortex (BA17 and
BA18) plus several other areas. In a review, Kosslyn and Thompson (2003)
found 50% of studies using visual-imagery tasks reported activation in
early visual cortex. Significant findings were most likely when the task
involved inspecting the fine details of images or focusing on an
object's shape. In a meta-analysis (see Glossary), Winlove et al. (2018)
found the early visual cortex (V1) was typically activated during visual
imagery. Consistent with Kosslyn's theory, activation in the early
visual cortex is greater among individuals reporting vivid visual
imagery. The neuroimaging evidence discussed above is limited -- it is
correlational and so the activation associated with visual imagery may
not be directly relevant to the images that are formed. Naselaris et
al. (2015) reported more convincing evidence. Participants formed images
of five artworks. It was possible to some extent to identify the
imagined artworks from hundreds of other artworks through careful
analysis of activity in the early visual cortex. Some of this activity
corresponded to the processing of low-level visual features (e.g.,
space; orientation).

133 Figure 3.22 Dwell time for the four quadrants of a picture during
perception and imagery. From Laeng et al. (2014). Reprinted with
permission of Elsevier.

134

Visual perception and attention

Further neuroimaging support for the notion that imagery closely
resembles perception was reported by Dijkstra et al. (2017a). They found
"the overlap in neural representations between imagery and perception .
. . extends beyond the visual cortex to include also parietal and
premotor/ frontal areas" (p. 1372). Of most importance, the greater the
neural overlap between imagery and perception throughout the entire
visual system, the more vivid was the imagery experience.

Imagery does not resemble perception Look at Figure 3.23. Start with the
object on the left and form a clear image of it. Then close your eyes,
mentally rotate the image by 90o clockwise and decide what you see. Then
repeat the exercise with the other objects. Finally, rotate the book
through 90o. You probably found it very easy to identify the objects
when perceiving them but impossible when only imagining rotating them.
Slezak (1991, 1995) used stimuli closely resembling those in Figure 3.23
and found no observers reported seeing the objects. Thus, the
information within images is much less detailed and flexible than visual
information. Lee et al. (2012) identified important differences between
imagery and perception. Observers viewed or imagined common objects
(e.g., car; umbrella) while activity in the early visual cortex and
areas associated with later visual processing (object-selective regions)
was assessed. Attempts were made by the researchers to identify the
objects being imagined or perceived on the basis of activation in those
areas. What did Lee et al. (2012) find? First, activation in all brain
areas was considerably greater when participants perceived rather than
imagined objects. Second, objects being perceived or imagined were
identified with above-chance accuracy based on patterns of brain
activation except for imagined objects in the primary visual cortex (V1;
see Figure 3.24). Third, the success rate in identifying perceived
objects was greater based on brain activation in areas associated with
early visual processing than those associated with later processing.
However, the opposite was the case with imagined objects (see Figure
3.24). Thus, object processing in the early visual cortex is very
limited during imagery but is extremely important during perception.
Imagery for objects depends mostly on top-down processes based on object
knowledge rather than processing in the early visual cortex. Figure 3.23
Most cognitive neuroscience research has Slezak (1991, 1995) asked
participants to memorise one of focused on the brain areas activated
during the above images. They then imagined rotating the image 90
degrees clockwise and reported what they saw. None of them visual
perception and imagery. It is also reported seeing the figures that can
be seen clearly if you important to focus on connectivity between rotate
the page by 90 degrees clockwise. brain areas. Dijkstra et al. (2017b)
considered Left image from Slezak (1995), centre image from Slezak
(1991), right connectivity among four brain areas of central image
reprinted from Pylyshyn (2002), with permission from Elsevier and the
author. importance in perception and imagery: early

Object and face recognition

Figure 3.24 The extent to which perceived (left side of figure) or
imagined (right side of figure) objects could be classified accurately
on the basis of brain activity in the early visual cortex and
object-selective cortex. ES =extrastriate retinotopic cortex; LO =
lateral occipital cortex; pFs = posterior fusiform sulcus.

## 

## 

## 

Classiﬁcation performance (%)

Classiﬁcation performance (%)

## 

\*\*

\*\*

60 \*\*

\*\*

40 20 0

V1 ES Retinotopic

20 \*\*

\*\*

- 10

LO pFs Objectselective

0

Chance

From S.H. Lee et al. (2012). Reproduced with permission from Elsevier.

V1 ES Retinotopic

LO pFs Objectselective

7

Bottom-up

IPS IFG

OCC

Probability density

(a) 

FG

6 5 4 3 2 1 0 --0.5

Perception

0

0.5 1 1.5 Posterior estimate

2

Imagery

IFG

OCC

FG

Probability density

IPS

Figure 3.25 Connectivity during perception and imagery involving (a)
bottom-up processing; and (b) top-down processing. Posterior estimates
indicate connectivity strength (the further from 0 the stronger). The
meanings of OCC, FG, IPS and IFG are given in the text. From Dijkstra et
al. (2017b).

6

(b) 

Top-down

135

5 4 3 2 1 0 --0.5

0

0.5 1 1.5 Posterior estimate

2

visual cortex (OCC), fusiform gyrus (FG; late visual cortex), IPS
(intraparietal sulcus) and IFG (inferior frontal gyrus). The first two
are mostly associated with bottom-up processing whereas the second two
are mostly associated with top-down processing. Dijkstra et al.'s
(2017b) key findings are shown in Figure 3.25. First, perception was
associated with reasonably strong bottom-up brain connectivity and weak
top-down brain connectivity. Second, imagery was associated with
non-significant bottom-up connectivity but very strong top-down
connectivity. Thus, top-down connectivity from frontal to early visual
areas

136

Visual perception and attention

is a common mechanism during perception and imagery. However, there is
much stronger top-down connectivity during imagery to compensate for the
absence of bottom-up connectivity. Individuals having the greatest
topdown connectivity during imagery reported the most vivid images.
Dijkstra et al. (2018) studied the time course for the development of
visual representations in perception and in imagery using
magnetoencephalography (MEG; see Glossary). With perception, they
confirmed that visual representations develop through a series of
processing stages (see Chapter 2). With imagery, in contrast, the entire
visual representation appeared to be activated simultaneously,
presumably because all the relevant information was retrieved together
from memory.

Brain damage If visual perception and visual imagery involve the same
mechanisms, we might expect brain damage to have comparable effects on
perception and imagery. That is often the case. However, there are
numerous exceptions (Bartolomeo, 2002, 2008). Moro et al. (2008) studied
two brain-damaged patients with intact visual perception but impaired
visual imagery. They were both very poor at drawing objects from memory
but could copy the same objects when shown a drawing. These patients
(and others with impaired visual imagery but intact visual perception)
have damage to the left temporal lobe. Visual images are probably
generated from information about concepts (including objects) stored in
the temporal lobes (Patterson et al., 2007). However, this generation
process is less important for visual perception. Bridge et al. (2012)
studied a young man, SBR, who had virtually no primary visual cortex and
nearly total blindness. However, he had vivid visual imagery and his
pattern of cortical activation when engaged in visual imagery resembled
that of healthy controls. Similar findings were reported with a
70-year-old woman, SH, who became blind at the age of 27. She had intact
visual imagery predominantly involving areas outside the early visual
cortex. Of relevance, she had greater connectivity between some visual
networks in the brain than most individuals. How can we interpret the
above findings? Visual perception mostly involves bottom-up processes
triggered by the stimulus whereas visual imagery primarily involves
top-down processes based on object knowledge. Thus, it is unsurprising
brain areas involved in early visual processing are more important for
perception than imagery whereas brain areas associated with storage of
information about visual objects are more important for imagery.

Evaluation Much progress has been made in understanding the relationship
between visual imagery and visual perception. Similar processes are
involved in imagery and perception and they are both associated with
somewhat similar patterns of brain activity. In addition, the predicted
facilitatory and interfering effects between imagery and perception
tasks have been reported. These findings are more consistent with
Kosslyn's theory than Pylyshyn's.

Object and face recognition

On the negative side, visual perception and visual imagery are less
similar than assumed by Kosslyn. For example, there is the neuroimaging
evidence reported by Lee et al. (2012) and the frequent dissociations
between perception and imagery found in brain-damaged patients. Of most
importance, visual perception involves strong bottom-up connectivity and
weak top-down connectivity, whereas visual imagery involves very strong
top-down connectivity but negligible bottom-up connectivity (Dijkstra et
al., 2017b).

CHAPTER SUMMARY •

Pattern recognition. Pattern recognition involves processing of specific
features and global processing. Feature processing generally (but not
always) precedes global processing. Several types of cells (e.g., simple
cells; complex cells; end-stopped cells) are involved in feature
processing. There are complexities in pattern recognition due to
interactions among cells and the influence of top-down processes.
Evidence from computer programs to solve CAPTCHAs suggests humans are
very good at processing edge corners. Fingerprint identification is
sometimes very accurate; however, even experts show confirmation bias
(distorted performance caused by contextual information). Fingerprint
experts are much better than novices at discriminating between matches
and non-matches and also adopt a more conservative response bias.

•

Perceptual organisation. The gestaltists proposed several principles of
perceptual grouping and emphasised the importance of figure-ground
segmentation. They argued that perceptual grouping and figure-ground
segregation depend on innate factors. They also argued we perceive the
simplest possible organisation of the visual field. The gestaltists
provided descriptions rather than explanations. Their approach
underestimated the complex interactions of factors underlying perceptual
organisation. The gestaltists de-emphasised the role of experience and
learning in perceptual organisation. However, recent theories based on
Bayesian inference (e.g., the Bayesian hierarchical grouping model) have
emphasised learning processes and fully acknowledge the importance of
learning.

•

Approaches to object recognition. Visual processing typically involves a
coarse-to-fine processing sequence: low spatial frequencies in visual
input (associated with coarse processing) are conveyed to higher visual
areas faster than high spatial frequencies (associated with fine
processing). Biederman assumed in his recognitionby-components theory
that objects consist of geons (basic shapes). An object's geons are
determined by edge-extraction processes and the resultant geon-based
description is viewpoint-invariant. Biederman's theory de-emphasises the
role of top-down processes.

137

138

Visual perception and attention

Object recognition is sometimes viewpoint-invariant (as predicted by
Biederman) with easy categorical discriminations, but it is more
typically viewer-centred when identification is required. Object
representations often contain viewpoint-dependent and
viewpoint-invariant information. •

Object recognition: top-down processes. Top-down processes are more
important in object recognition when observers view degraded or briefly
presented stimuli. Topdown processes sometimes influence attention,
memory or response bias rather than perception itself. However, there
are also direct effects of top-down processes on object recognition.
According to the interactive-iterative framework (Baruch et al., 2018),
top-down and bottom-up processes interact with top-down processes (e.g.,
attention) influencing subsequent bottom-up processing.

•

Face recognition. Face recognition involves more holistic processing
than object recognition. Deficient holistic processing partly explains
why prosopagnosic patients have much greater problems with face
recognition than object recognition. Face processing involves a brain
network including the fusiform face and occipital face areas. However,
much of this network is also used in processing other objects
(especially when recognising objects for which we have expertise). Bruce
and Young's model assumes several serial processing stages. Research on
prosopagnosics supports this assumption because the precise nature of
their face-recognition impairments depends on which stage(s) are most
affected. The model also assumes there are major differences in the
processing of familiar and unfamiliar faces. This assumption has
received substantial support. However, Bruce and Young did not fully
appreciate that unfamiliar faces are hard to recognise because of the
great variability of any given individual's facial images. The model
assumes there are two independent processing routes (for facial
expression and facial identity), but they are not entirely independent.
The model ignores the role played by genetic factors in accounting for
individual differences in face-recognition ability.

•

Visual imagery. Visual imagery allows us to predict the visual
consequences of performing certain actions. According to Kosslyn's
perceptual anticipation theory, visual imagery closely resembles visual
perception. In contrast, Pylyshyn, in his propositional theory, argued
visual imagery involves making use of tacit knowledge and does not
resemble visual perception. Visual imagery and perception influence each
other as predicted by Kosslyn's theory. Neuroimaging studies and studies
on braindamaged patients indicate similar areas are involved in imagery

Object and face recognition

and perception. However, areas involved in top-down processing (e.g.,
left temporal lobe) are more important in imagery than perception, and
areas involved in bottom-up processing (e.g., early visual cortex) are
more important in perception. More generally, bottom-up brain
connectivity is far more important in perception than imagery, whereas
top-down brain connectivity is far more important in imagery than
perception.

FURTHER READING Baruch, O., Kimchi, R. & Goldsmith, M. (2018). Attention
to distinguishing features in object recognition: An
interactive-iterative framework. Cognition, 170, 228--244. Orit Baruch
and colleagues provide a theoretical framework for understanding how
bottom-up and top-down processes interact in object recognition.
Dijkstra, N., Zeidman, P., Ondobaka, S., van Gerven, M.A.J. & Friston,
K. (2017b). Distinct top-down and bottom-up brain connectivity during
visual perception and imagery. Scientific Reports, 7 (Article 5677). In
this article, Nadine Dijkstra and her colleagues clarify the roles of
top-down and bottom-up processes in visual perception and imagery.
Firestone, C. & Scholl, B.J. (2016). Cognition does not affect
perception: Evaluating the evidence for "top-down" effects. Behavioral
and Brain Sciences, 39, 1--77. The authors argue that top-down processes
do not directly influence visual perception. Read the open peer
commentary following the article, however, and you will see most experts
disagree. Gauthier, I. & Tarr, M.J. (2016). Visual object recognition:
Do we (finally) know more now than we did? Annual Review of Vision
Science, 2, 377--396. Isabel Gauthier and Michael Tarr provide a
comprehensive overview of theory and research on object recognition.
Grill-Spector, K., Weiner, K.S., Kay, K. & Gomez, J. (2017). The
functional neuroanatomy of human face perception. Annual Review of
Vision Science, 3, 167--196. This article by Kalanit Grill-Sector and
colleagues contains a comprehensive account of brain mechanisms
underlying face perception. Wagemans, J. (2018). Perceptual
organisation. In J.T. Serences (ed.), Stevens' Handbook of Experimental
Psychology and Cognitive Neuroscience, Vol. 2: Sensation, Perception,
and Attention (4th edn; pp. 803--822). New York: Wiley. Johan Wagemans
reviews various theoretical and empirical approaches to understanding
perceptual organisation. Young, A.W. (2018). Faces, people and the
brain: The 45th Sir Frederic Bartlett lecture. Quarterly Journal of
Experimental Psychology, 71, 569--594. Andy Young provides a very
interesting account of theory and research on face perception.

139

Chapter

4

Motion perception and action

INTRODUCTION Most research on perception discussed in previous chapters
involved presenting a visual stimulus and assessing aspects of its
meaning. What was missing (but is an overarching theme of this chapter)
is the time dimension. In the real world, we move around and/or people
or objects in the environment move. The resulting changes in the visual
information available to us are very useful in ensuring we perceive the
environment accurately and also respond appropriately. This emphasis on
change and movement necessarily leads to a consideration of the
relationship between perception and action. In sum, our focus in this
chapter is on how we process (and respond to) a constantly changing
environment. The first theme addressed in this chapter is the perception
of movement. This includes our ability to move successfully within the
visual environment and predict accurately when moving objects will reach
us. The second theme is concerned with more complex issues -- how do we
act appropriately on the environment and the objects within it? Of
relevance are theories (e.g., the perception-action theory; the
dual-process approach) distinguishing between processes and systems
involved in visionfor-perception and those involved in vision-for-action
(see Chapter 2). Here we consider theories providing more detailed
accounts of vision-foraction and/or the workings of the dorsal pathways
allegedly underlying vision-for-action. The third theme focuses on the
processes involved in making sense of moving objects (especially other
people). It thus differs from the first theme in which moving stimuli
are considered mostly in terms of predicting when they will reach us.
There is an emphasis on the perception of biological movement when the
available visual information is impoverished. We also consider the role
of the mirror neuron system in interpreting human movement. Finally, we
consider our ability (or failure!) to detect changes in objects within
the visual environment over time. Unsurprisingly, attention importantly
determines which aspects of the environment are consciously

Motion perception and action

detected. This issue provides a useful bridge between the areas of
visual perception and attention (the subject of the next chapter).

DIRECT PERCEPTION James Gibson (1950, 1966, 1979) put forward a radical
approach to visual perception that was largely ignored at the time.
Until approximately 40 years ago, it was assumed the main purpose of
visual perception is to allow us to identify or recognise objects. This
typically involves relating information extracted from the visual
environment to our stored knowledge of objects (see Chapter 3). Gibson
argued that this approach is limited -- in evolutionary terms, vision
developed so our ancestors could respond rapidly to the environment
(e.g., hunting animals; escaping from danger). Gibson (1979, p. 239)
argued that perception involves "keeping in touch with the environment".
This is sufficient for most purposes because the information provided by
environmental stimuli is much richer than previously believed. We can
relate Gibson's views to Milner and Goodale's (1995, 2008)
vision-for-action system (see Chapter 2). According to both theoretical
accounts, there is an intimate relationship between perception and
action. Gibson regarded his theoretical approach as ecological. He
emphasised that perception facilitates interactions between the
individual and their environment. Here is the essence of his direct
theory of perception: When I assert that perception of the environment
is direct, I mean that it is not mediated by retinal pictures, neural
pictures, or mental pictures. Direct perception is the activity of
getting information from the ambient array of light. I call this a
process of information pickup that involves . . . looking around,
getting around, and looking at things. (Gibson, 1979, p. 147) We will
briefly consider some of Gibson's theoretical assumptions: ●

●

The pattern of light reaching the eye is an optic array. It contains all
the visual information from the environment striking the eye. The optic
array provides unambiguous or invariant information about the layout of
objects. This information comes in many forms including optic flow
patterns and affordances (see below) and texture gradients (discussed in
Chapter 2).

Gibson produced training films in the Second World War describing how
pilots handle taking off and landing. Of crucial importance is optic
flow -- the changes in the pattern of light reaching observers when they
move or parts of the visual environment move. When pilots approach a
landing strip, the point towards which they are moving (focus of
expansion) appears motionless with the rest of the visual environment
apparently moving away from that point (see Figure 4.1). The further
away any part of the landing strip is from that point, the greater is
its apparent speed of movement. Wang et al. (2012) simulated the pattern
of optic flow that would be experienced if individuals moved forwards in
a stationary environment.

141

KEY TERMS Optic array The structural pattern of light falling on the
retina. Optic flow The changes in the pattern of light reaching an
observer when there is movement of the observer and/or aspects of the
environment. Focus of expansion The point towards which someone in
motion is moving; it does not appear to move.

Case study: Gibson's theory of direct perception affordances

142

Visual perception and attention

Figure 4.1 The optic-flow field as a pilot comes in to land, with the
focus of expansion in the middle. From Gibson (1950). Wadsworth, a part
of Cengage Learning, Inc. 2014 American Psychological Association.
Reproduced with permission.

Their attention was attracted towards the focus of expansion, thus
showing its psychological importance. (More is said later about optic
flow and the focus of expansion.) Gibson (1966, 1979) argued certain
higher-order characteristics of the visual array (invariants) remain
unaltered as observers move around their environment. Invariants (e.g.,
the focus of expansion) are important because they remain the same over
different viewing angles. The focus of expansion is an invariant feature
of the optic array.

Affordances

KEY TERMS Invariants Properties of the optic array that remain constant
even though other aspects vary; part of Gibson's theory. Affordances The
potential uses of an object which Gibson claimed are perceived directly.

According to Gibson (1979), the potential uses of objects (their
affordances) are directly perceivable. For example, a ladder "affords"
ascent or descent. Gibson believed that "affordances are opportunities
for action that exist in the environment and do not depend on the
animal's mind . . . they do not cause behaviour but simply make it
possible" (Withagen et al., 2012, p. 251). In Gibson (1979, p. 127),
affordances are what the environment "offers the animal, what it
provides or furnishes". Evidence for the affordance of "climbability" of
steps varying in height was reported by Di Stasi and Guardini (2007).
The step height judged the most "climbable" was the one that would have
involved the minimum expenditure of energy. Gibson argued an object's
affordances are perceived directly or automatically. In support, Pappas
and Mack (2008) found images of objects presented below the level of
conscious awareness nevertheless produced motor priming. For example,
the image of a hammer caused activation in brain areas involved in
preparing to use a hammer. Wilf et al. (2013) focused on the affordance
of graspability with participants lifting their arms to perform a
reach-like movement with graspable and non-graspable objects (see Figure
4.2). Muscle activity started faster for graspable than non-graspable
objects suggesting that the affordance of graspability triggers rapid
activity in the motor system.

Motion perception and action

Nongraspable

Graspable

Nongraspable

Graspable

143 Figure 4.2 Graspable and nongraspable objects having similar
asymmetrical features. From Wilf et al. (2013). Reprinted with
permission.

Gibson's approach to affordances is substantially oversimplified. For
example, an apparently simple task such as cutting up a tomato involves
selecting an appropriate tool, deciding on how to grasp and manipulate
the tool, and monitoring movement execution (Osiurak & Badets, 2016). In
other words, "People reason about physical object properties to solve
everyday life activities" (Osiurak & Badets, 2016, p. 540). This is
sharply different to Gibson's emphasis on the ease and immediacy of tool
use. When individuals observe a tool, Gibson assumed this provided them
with direct access to knowledge about how to manipulate it and this
manipulation knowledge gave access to the tool's functions. This
assumption exaggerates the importance of manipulation knowledge. For
example,

144

Visual perception and attention

Garcea and Mahon (2012) found function judgements about tools were made
faster than manipulation judgements, whereas Gibson's approach implies
that manipulation judgements should have been faster. Finally, Gibson
argued stored knowledge is not required for individuals to make
appropriate movements with respect to objects (e.g., tools). In fact,
individuals often make extensive use of motor and function knowledge
when dealing with objects (Osiurak & Badets, 2016). For example, making
tea involves filling the kettle with water, boiling the water, finding
some milk and so on. Foulsham (2015) discussed research showing there
are only small individual differences in the pattern of eye fixations
when people make tea. Such findings strongly imply they use stored
information about the sequence of motor actions involved in tea-making.

Evaluation What are the strengths of Gibson's ecological approach?
First, "Gibson's realisation that natural scenes are the ecologically
valid stimulus that should be used for the study of vision was of
fundamental importance" (Bruce & Tadmor, 2015, p. 32). Second, and
related to the first point, Gibson disagreed with the previous emphasis
on static observers looking at static visual displays. Foulsham and
Kingstone (2017) compared the eye fixations of participants walking
around a university campus with those of other participants viewing
static pictures of the same scene. The eye fixations were significantly
different: those engaged in walking focused more on features (e.g., the
path) important for locomotion whereas those viewing static pictures
focused centrally within each picture. Third, Gibson was far ahead of
his time. There is support for two visual systems (Milner & Goodale,
1995, 2008; see Chapter 2): a visionfor-perception system and a
vision-for-action system. Before Gibson, the major emphasis was on the
former. In contrast, he argued our perceptual system allows us to
respond rapidly and accurately to environmental stimuli without using
memory, which is a feature of the latter system. What are the
limitations of Gibson's approach? First, Gibson attempted to specify the
visual information used to guide action but ignored many of the
processes involved (see Chapters 2 and 3). For example, Gibson assumed
the perception of invariants occurred almost "automatically", but it
actually requires several complex processes. Second, Gibson's argument
that we do not need to assume the existence of internal representations
(e.g., object knowledge) is flawed. The logic of Gibson's position is
that: "There are invariants specifying a friend's face, a performance of
Hamlet, or the sinking of the Titanic, and no knowledge of the friend,
of the play, or of maritime history is required to perceive these
things" (Bruce et al., 2003, p. 410). Evidence refuting Gibson's
argument was reviewed by Foulsham (2015; discussed above). Third, and
related to the second point, Gibson de-emphasised the role of top-down
processes (based on our knowledge and expectations) in visual
perception. Such processes are especially important when the visual
input is impoverished (see Chapter 3).

Motion perception and action

Fourth, Gibson's views on the effects of motion on perception were
oversimplified. For example, when moving towards a goal, we use more
information sources than Gibson assumed (discussed below).

VISUALLY GUIDED MOVEMENT From an ecological perspective, it is important
to understand how we move around the environment. For example, what
information do we use when walking towards our current goal or target?
We must ensure we are not hit by cars when crossing the road and when
driving we must avoid hitting other cars. Playing tennis well involves
predicting exactly when and where the ball will strike our racquet. The
ways visual perception plays a crucial role in facilitating our
locomotion and ensuring our safety are discussed in the next section.

Heading and steering When we want to reach some goal (e.g., a gate at
the end of a field), we use visual information to move directly towards
it. Gibson (1950) emphasised the importance of optic flow (see Glossary;
discussed on pp. 141--142). When we move forwards in a straight line,
the point towards which we are moving (the focus of expansion) appears
motionless. In contrast, the area around that point seems to expand.
Gibson (1950) proposed a hypothesis, according to which, if we are not
moving directly towards our goal, we use the focus of expansion and
optic flow to bring our heading (point of expansion) into alignment with
our goal. This is known as the global radial outflow hypothesis.
Gibson's approach works well in principle when applied to an individual
trying to move straight from A to B. However, matters are more complex
when we cannot move directly to our goal (e.g., driving around a bend in
the road; avoiding obstacles). Another complexity is that observers
often make head and eye movements. In sum, the retinal flow field
(changes in the pattern of light on the retina) is influenced by
rotation in the retinal image produced by following a curved path and/or
eye and head movements. The above complexities mean it is often hard to
use information from retinal flow to determine our direction of heading.
It has often been claimed that a copy of motor commands (preprogramming)
to move the eye and head (efference copy) is used by observers to
compensate for the effects of eye and head movements on the retinal
image. However, Feldman (2016) argued this approach is insufficient on
its own because it de-emphasises the brain's active involvement in
relating perception and action.

Findings: heading Gibson emphasised the role of optic flow in allowing
individuals to move directly towards their goal. Relevant information
includes the focus of expansion (see Glossary) and the direction of
radial motion (e.g., expansion within optic flow). Strong et al. (2017)
obtained evidence indicating the importance of both factors and also
established they depend on separate brain areas. More specifically, they
used transcranial magnetic stimulation

145

KEY TERMS Retinal flow field The changing patterns of light on the
retina produced by movement of the observer relative to the environment
as well as by eye and head movements. Efference copy An internal copy of
a motor command (e.g., to the eyes); it can be used to identify movement
within the retinal image that is not due to object movement in the
environment.

146

Visual perception and attention

(TMS; see Glossary) to disrupt key brain areas. TMS applied to area V3A
impaired perception of the focus of expansion but not direction of
radial motion, with the opposite pattern being obtained when TMS was
applied to the motion area V5/MT+ (see Chapter 2). As indicated above,
eye and/or head movements make it harder to use optic flow effectively
for heading. Bremmer et al. (2010) considered this issue in macaque
monkeys presented with distorted visual flow fields simulating the
combined effects of self-motion and an eye movement. Their key finding
was that numerous cells in the medial superior temporal area
successfully compensated for this distortion. According to Gibson, a
walker tries to make the focus of expansion coincide with the body
moving straight ahead. If a walker wore prisms producing a 9° error in
their perceived visual direction, the focus of expansion should be
misaligned compared to their expectation. As a result, there should be a
correction process, a prediction confirmed by Herlihey and Rushton
(2012). Also as predicted, walkers denied access to information about
retinal motion failed to show any correction. Factors additional to the
optic flow information emphasised by Gibson are also used when making
heading judgements. This is unsurprising given the typical richness of
the available environmental information. van den Berg and Brenner (1994)
noted we only require one eye to use optic flow information. However,
they discovered heading judgements were more accurate when observers
used both eyes. Binocular disparity (see Glossary) in the two-eye
condition provided useful additional information about the relative
depths of objects. Cormack et al. (2017) introduced the notion of a
binoptic flow field to describe the 3-D information available to
observers (but de-emphasised by Gibson). Gibson assumed optic-flow
patterns generated by self-motion are of fundamental importance when we
head towards a goal. However, motion is not essential for accurate
perception of heading. The judgements of heading direction made by
observers viewing two static photographs of a real-world scene in rapid
succession were reasonably accurate in the absence of opticflow
information (Hahn et al., 2003). These findings can be explained in
terms of retinal displacement -- objects closer to the direction of
heading show less retinal displacement as we move closer to the target.
Snyder and Bischof (2010) argued that information about the direction of
heading is provided by two systems. One system uses movement information
(e.g., optic flow) rapidly and fairly automatically (as proposed by
Gibson). The other system uses displacement information more slowly and
requires greater processing resources. It follows that performing a
second task at the same time as making judgements about direction of
heading should have little effect on those judgements if movement
information is available. In contrast, a second task should impair
heading judgements when only displacement information is available. The
evidence supported both predictions.

Heading: future path Wilkie and Wann (2006) argued judgements of heading
(the direction in which someone is moving) are of little relevance if
they are moving along a

Motion perception and action

147

curved path. With curved paths, path judgements (identifying future
points along one's path) were much more accurate than heading
judgements. According to the above analysis, we might expect individuals
(e.g., drivers) to fixate some point along their future path when it is
curved. This is the future path strategy. In contrast, Land and Lee
(1994) argued (with supportive evidence) that drivers approaching a bend
focus on the tangent point -- the point on the inside edge of the road
at which its direction appears to reverse (see Figure 4.3). The tangent
point has two potential advantages. First, it is easy to identify and
track. Second, road curvature can easily be worked out by considering
the angle between the direction of heading and the tangent point. Kandil
et al. (2009) found most drivers negotiating 270° bends at a motorway
junction fixated the tangent point much more often than the future path
(75% vs 14%, respectively). Other research suggests the tangent point is
less important. For example, Itkonen et al. (2015) instructed drivers to
"drive as they Road position normally would" or "look at the tangent
point". Eye movements differed markedly in the two conditions -- drivers
were much more Figure 4.3 likely to fixate points along the future path
in The visual features of a road viewed in perspective. The the former
condition. tangent point is marked by the filled circle on the inside
edge How can we interpret the above appar- of the road, and the desired
future path is shown by the ently inconsistent findings? Lappi et
al. (2013) dotted line. According to the future-path theory, drivers
should hypothesised drivers often fixate the tangent gaze along the line
marked "active gaze". Wilkie et al. (2010). Reprinted with permission
from point when approaching and entering a bend From Springer-Verlag.
but fixate the future path further into the bend. They argued the
tangent point provides relatively precise information and so drivers use
it when uncertainty about the precise nature of the curve or bend is
maximal (i.e., when approaching and entering it). Lappi et al. (2013)
obtained supporting evidence for the above hypothesis. Drivers'
fixations while driving along a lengthy curve formed by the slip road to
a motorway were predominantly on the path ahead rather than the tangent
point after the first few seconds (see short clips of drivers' eye
movements while performing this task at 10.1371/journal.pone.0068326).
KEY TERM The evidence discussed so far does not rule out optic flow as a
factor Tangent point influencing drivers' steering. Mole et al. (2016)
manipulated optic-flow From a driver's speed in a simulated driving
situation. This produced steering errors perspective, the point
(understeering or oversteering) when going around bends even when full
on a road at which the direction of its inside information about road
edges was available. Thus, optic flow influenced edge appears to
reverse. driving performance.

148

Visual perception and attention

IN THE REAL WORLD: ON-ROAD DRIVING Much research on drivers' gaze
patterns lacks ecological validity (see Glossary). Drivers are typically
in a simulator and the environment through which they drive is somewhat
oversimplified. Accordingly, Lappi et al. (2017) studied the gaze
patterns of a 43-year-old male driving school instructor driving on a
rural road in Finland. His eye movements revealed a more complex picture
than most previous research. What did Lappi et al. (2017) discover? Here
are four major findings: (1) The driver's gaze shifted very frequently
from one feature of the visual environment to another and he made many
head movements. (2) The driver's gaze was predominantly on the far road
(see Figure 4.4). This preview of the road ahead allowed him to make use
of anticipatory control. (3) In bends, the driver's gaze was mostly
within the far road "triangle" formed by the tangent point (TP), the
lane edge opposite the TP and the occlusion point (OP; the point where
the road disappears from view). In general terms, the OP is used to
anticipate the road ahead whereas the TP is used for more immediate
compensatory steering control. (4) The driver fixated specific targets
(e.g., traffic signs; other road users) very rapidly, suggesting his
peripheral vision was very efficient.

(A) 
(B) 

Figure 4.4 The far road "triangle" in (A) a left turn and (B) a right
turn. From Lappi et al. (2017).

In sum, drivers' gaze patterns are more complex than implied by previous
research. Drivers do not constantly fixate any given feature (e.g.,
tangent point) passively. Instead, they "sample visual information as
needed, leading to input that is intermittent, and determined by the
active observer . . . rather than imposed by the environment" (Lappi et
al., 2017, p. 11). Drivers' eye movements are determined in part by
control mechanisms (e.g., path planning) (Lappi & Mole, 2018). These
mechanisms are responsive to drivers' goals. For example, professional
racing drivers have the goal of driving as fast as possible whereas many
ordinary drivers have the goal of driving safely.

Evaluation Gibson's views concerning the importance of optic-flow
information have deservedly been very influential. Such information is
especially useful when individuals can move directly towards their goal
rather than following a curved or indirect path. Indeed, the evidence
suggests optic flow is often

Motion perception and action

the dominant source of information determining judgements of heading
direction. Drivers going around bends use optic-flow information. They
also make some use of the tangent point. This is a relatively simple
feature of the visual environment and its use by drivers is in the
spirit of Gibson's perspective. What are the limitations of Gibson's
approach and other related approaches? (1)

(2) 
(3) 
(4) 

Individuals moving directly towards a target use several kinds of
information (e.g., binocular disparity; retinal displacement) ignored by
Gibson. The tangent point is used infrequently when individuals move
along a curved path: they more often fixate points lying along the
future path. Drivers going around bends use a greater variety of
information sources than implied by Gibson's approach. Of most
importance, drivers' eye movements are strongly influenced by active,
top-down processes (e.g., motor control) not included within Gibson's
theorising. More specifically, drivers' eye movements depend on their
current driving goals as well as the environmental conditions. Research
and theorising have de-emphasised meta-cognition (beliefs about one's
own performance). Mole and Lappi (2018) found drivers often made
inaccurate meta-cognitive judgements of their own driving performance
(e.g., they tended to exaggerate the importance of driving speed in
determining performance). Such inaccurate judgements probably often lead
to impaired driving performance.

Time to contact In everyday life, we often need to predict the moment of
contact between us and some object. These situations include ones where
we are moving towards an object (e.g., a wall) and those in which an
object (e.g., a ball) is approaching us. We might work out the time to
contact by dividing our estimate of the object's distance by our
estimate of its speed. However, this would be complex and error-prone
because information about speed and distance is not directly available.
Lee (1976, 2009) argued that there is a simpler way to work out the time
to contact or collision. If we approach it (or it approaches us) at
constant velocity, we can use tau. Tau is defined as the size of an
object's retinal image divided by its rate of expansion. The faster the
rate of expansion, the less time there is to contact. When driving, the
rate of decline of tau over time (tau-dot) indicates whether there is
sufficient braking time to stop before contact or collision. Lee (1976)
argued drivers brake to hold constant the rate of change of tau. This
tau-dot hypothesis is consistent with Gibson's approach because it
assumes tau-dot is an invariant available to observers from optic flow.
Lee's theoretical approach has been highly influential. However, his
emphasis on tau has limited applicability in various ways (Tresilian,
1999). First, tau ignores acceleration in object velocity. Second, tau
only provides information about the time to contact or collision with
the eyes. Thus, drivers might find the front of their car smashed in if
they relied solely on

149

150

Visual perception and attention

tau! Third, tau is accurate only when applied to spherically symmetrical
objects: do not rely on it when catching a rugby ball! Harrison et
al. (2016) argued that people's behaviour is often influenced by factors
other than their estimate of the time to contact. For example, consider
someone deciding whether to cross a road when there is an approaching
car. Their decision is often influenced by judgements of their physical
mobility and their personality (e.g., cautious or impetuous) (see
p. 151).

Findings According to Lee's (1976) theory, observers can often judge
time to contact accurately based on using tau relatively
"automatically". If so, observers' time-to-contact judgements might not
be impaired if they performed a cognitively demanding task while
observing an object's movement. Baurès et al. (2018) obtained support
for this prediction. Indeed, time-tocontact judgements were more
accurate when observers performed a secondary task, perhaps because this
made it less likely they would attend to potentially misleading
information (e.g., expectations about an object's movements). According
to Lee (1976), judgements of the time to contact when catching a ball
should depend crucially on the rate of expansion of the ball's retinal
image. Savelsbergh et al. (1993) used a deflating ball having a
significantly slower rate of expansion than an ordinary ball. The
prediction was that peak grasp closure should occur later to the
deflating ball. This prediction was confirmed. However, the actual
slowing was much less than predicted (30 ms vs 230 ms). Participants
minimised the distorting effects of manipulating the rate of expansion
by using additional sources of information (e.g., depth cues). Hosking
and Crassini (2010) had participants judge time to contact for familiar
objects (tennis ball and football) presented in their standard size or
with their sizes reversed. They also used unfamiliar black spheres.
Contrary to Lee's hypothesis, time-to-contact judgments were influenced
by familiar size (especially when the object was a very large tennis
ball) leading participants to overestimate time to contact (see Figure
4.5). Tau is available in monocular vision. However, observers often
make use of inforFigure 4.5 Errors in time-to-contact judgements for the
smaller and mation available in binocular vision, espethe larger object
as a function of whether they were presented cially binocular disparity
(see Chapter 2). in their standard size, the reverse size (off-size) or
lacking Fath et al. (2018) discussed research showing texture
(no-texture). Positive values indicate that responses binocular
information sometimes provides were made too late and negative values
that they were made more accurate judgements than tau of time to too
early. contact (e.g., when viewing small objects or From Hosking and
Crassini (2010). With kind permission from Springer Science+Business
Media. rotating non-spherical objects).

Motion perception and action

In their own research, Fath et al. (2018) assessed accuracy of
time-tocontact judgements when observers viewed fast- or slow-moving
objects. They used three conditions varying in the amount of information
available to observers: (1) monocular flow information only (permitting
assessment of tau); (2) binocular disparity information only; (3) all
sources of information available. Fath et al. predicted that binocular
disparity information would be less likely to be used with fast-moving
objects than slow-moving ones because it is relatively time-consuming to
calculate changes in binocular disparity over time. What did Fath et
al. (2018) find? First, with fast objects, time-tocontact judgements
were more accurate with monocular flow information only than with
binocular disparity information only. Second, with slow objects, the
opposite findings were obtained. Third, accuracy of time-tocontact
judgements when all sources of information were available were
comparable to accuracy in the better of the single-source conditions
with fast and with slow objects. DeLucia (2013) found observers
mistakenly predicted a large approaching object would reach them sooner
than a closer small approaching object: the size-arrival effect. This
effect occurred because observers attached more importance to relative
size than tau. We turn now to research on drivers' braking decisions.
Lee's (1976) notion that drivers brake to hold constant the rate of
change of tau was tested by Yilmaz and Warren (1995). They told
participants to stop at a stop sign in a simulated driving task. As
predicted, there was generally a linear reduction in tau during braking.
However, some participants showed large rather than gradual changes in
tau shortly before stopping. Tijtgat et al. (2008) found individual
differences in stereo vision influenced drivers' braking behaviour to
avoid a collision. Drivers with weak stereo vision started braking
earlier than those with normal stereo vision and their peak deceleration
also occurred earlier. Those with weak stereo vision found it harder to
calculate distances causing them to underestimate the time to contact.
Thus, deciding when to brake does not depend only on tau or tau-dot.
Harrison et al. (2016) argued that Lee's (1976) theoretical approach is
limited in two important ways when applied to drivers' braking
behaviour. First, it ignores physical limitations in the real world. For
example, tau-dot specifies to a driver the deceleration during braking
required to avoid collision. However, this strategy will not work if the
driver's braking system makes the required deceleration unachievable.
Second, individuals differ in the emphasis they place on minimisation of
costs (e.g., preferred safety margin). According to Harrison et al.,
these limitations suggest drivers' braking behaviour is influenced by
their sensitivity to relevant affordances (possibilities for action)
such as their knowledge of the dynamics of the braking system in their
car.

Evaluation The notion that tau is used to make time-to-contact
judgements is simple and elegant. There is much evidence that such
judgements are often strongly influenced by tau. Even when competing
factors affect time-to-contact

151

152

Visual perception and attention

judgements, tau often has the greatest influence on those judgements.
Tau is also often used when drivers make decisions about when to brake.
What are the limitations of theory and research in this area? First,
time-to-contact judgements are typically more influenced by tau or
tau-dot in relatively uncluttered laboratory environments than
naturalistic conditions (Land, 2009). Second, tau is not the only factor
determining timeto-contact judgements. As Land (2009, p. 853) pointed
out, "The brain will accept all valid cues in the performance of an
action, and weight them according to their current reliability." These
cues can include object familiarity, binocular disparity and relative
size. It clearly makes sense to use all the available information in
this way. Third, the tau hypothesis ignores the emotional value of the
approaching object. Time-to-contact judgements are shorter for
threatening pictures than neutral ones (Brendel et al., 2012). This
makes evolutionary sense -- it could be fatal to overestimate how long a
very threatening object (e.g., a lion) will take to reach you! Fourth,
braking behaviour involves factors additional to tau and tau-dot. For
example, there are individual differences in preferred safety margin.
Rock et al. (2006) identified an alternative braking strategy in a
real-world driving task in which drivers directly estimated the constant
ideal deceleration required to stop at a given point.

VISUALLY GUIDED ACTION: CONTEMPORARY APPROACHES The previous section
focused mainly on the issue of how we use visual information when moving
through the environment. Here we consider similar issues but the
emphasis shifts towards processes involved in successful goal-directed
action towards objects. For example, how do we reach for a cup of
coffee? This issue was addressed by Milner and Goodale (1995, 2008) in
their perception-action model (see Chapter 2). Contemporary approaches
that have developed and extended the perception-action model are
discussed below.

Role of planning: planning-control model

Interactive exercise: Planning control

Glover (2004) proposed a planning-control model of goal-directed action
towards objects. According to this model, we initially use a planning
system followed by a control system but the two systems often overlap in
time. Here are the main features of the two systems: (1)

Planning system ● It is used mostly before the initiation of movement. ●
It selects an appropriate target (e.g., cup of coffee), decides how it
should be grasped and works out the timing of the movement. ● It is
influenced by factors such as the individual's goals, the nature of the
target object, the visual context and various cognitive processes. ● It
is relatively slow because it uses much information and is influenced by
conscious processes.

Motion perception and action

(2) 

Control system ● It is used during the carrying out of a movement. ● It
ensures movements are accurate, making adjustments, if necessary, based
on visual feedback. Efference copy (see Glossary) is used to compare
actual with desired movement. Proprioception is also involved. ● It is
influenced by the target object's spatial characteristics (e.g., size;
shape; orientation) but not by the surrounding context. ● It is fairly
fast because it uses little information and is not susceptible to
conscious influence.

According to the planning-control model, most errors in human action
stem from the planning system. In contrast, the control system typically
ensures actions are accurate and achieve their goal. Many visual
illusions occur because of the influence of visual context. Since
information about visual context is used only by the planning system,
responses to visual illusions should typically be inaccurate if they
depend on the planning system but accurate if they depend on the control
system. There are similarities between the planning-control model and
Milner and Goodale's perception-action model. However, Glover (2004)
focused more on the processing changes occurring during action
performance.

Findings Glover et al. (2012) compared the brain areas involved in
planning and control using a planning condition (prepare to reach and
grasp an object but remain still) and a control condition (reach out
immediately for the object). There was practically no overlap in the
brain areas associated with planning and control. This finding supports
the model's assumption that planning and control processes are separate.
According to the planning-control model, various factors (e.g., semantic
properties of the visual scene) influence the planning process
associated with goal-directed movements but not the subsequent control
process. This prediction was tested by Namdar et al. (2014).
Participants grasped an object in front of them using their thumb and
index finger. The object had a task-irrelevant digit (1, 2, 8 or 9) on
it. As predicted, numerically larger digits led to larger grip apertures
during the first half of the movement trajectory but not the second half
(involving the control process). According to Glover (2004), action
planning involves conscious processing followed by rapid non-conscious
processing during action control. These theoretical assumptions can be
tested by requiring participants to carry out a second task while
performing an action towards an object. According to the model, this
second task should disrupt planning but not control. However, Hesse et
al. (2012) found a second task disrupted planning and control when
participants made grasping movements towards objects. Thus, planning and
control can both require attentional resources. According to the model,
visual illusions occur because misleading visual context influences the
initial planning system rather than the later

153

KEY TERM Proprioception An individual's awareness of the position and
orientation of parts of their body.

154

Visual perception and attention

control system. Roberts et al. (2013) required participants to make
rapid reaching movements to a Müller-Lyer figure. Vision was available
only during the first 200 ms of movement or the last 200 ms. The
findings were opposite to those predicted theoretically -- performance
was more accurate with early vision than late vision. Elliott et
al. (2017) explained the above findings with their multiple process
model. According to this model, performance was good when early vision
was available because of a control system known as impulse control.
Impulse control "entails an early, and continuing, comparison of
expected sensory consequences to perceived sensory consequences to
regulate limb direction and velocity during the distance-covering phase
of the movement" (p. 108).

Evaluation Glover's (2004) planning-control model has proved successful
in various ways. First, it successfully developed the common assumption
that motor movements towards an object involve successive planning and
control processes. Second, the assumption cognitive processes are
important in action planning is correct. Third, there is evidence (e.g.,
Glover et al., 2012) that separate brain areas are involved in planning
and control. What are the model's limitations? First, the planning
system involves several very different processes: "goal determination;
target identification and selection; analysis of object affordances
\[potential object uses\]; timing; and computation of the metrical
properties of the target such as its size, shape, orientation and
position relative to the body" (Glover et al., 2012, p. 909). This
diversity sheds doubt on the assumption there is a single planning
system. Second, the model argues control occurs late during
object-directed movements and is influenced by visual feedback. However,
there appears to be a second control process (called impulse control by
Elliott et al., 2017) operating throughout the movement trajectory and
not influenced by visual feedback. Third, and related to the second
point, the model presents an oversimplified picture of the processes
involved in goal-directed action. More specifically, the processing
involved in producing goal-directed movements is far more complex than
implied by the notion of a planning process followed by a control
process. For example, planning and control processes are often so
intermixed that "the distinction between movement planning and movement
control is blurred" (Gallivan et al., 2018, p. 519). Fourth, complex
decision-making processes are often involved when individuals plan
goal-directed actions in the real world. For example, when planning,
tennis players players must often decide between a simple shot
minimising energy expenditure and risk or injury or a more ambitious
shot that might immediately win the current point (Gallivan et al.,
2018). Fifth, the model is designed to account for planning and control
processes when only one object is present or of interest. In contrast,
visual scenes in everyday life are often far more complex and contain
several objects of potential relevance (see below).

Motion perception and action

155

Role of planning: changing action plans We all have considerable
experience of changing, modifying and abandoning action plans with
respect to objects in the environment. How do we resolve competition
among action plans? According to Song (2017, p. 1), "Critical is the
existence of parallel motor planning processes, which allow efficient
and timely changes." What evidence indicates we often process
information about several different potential actions simultaneously?
Suppose participants are given the task of reaching rapidly towards a
target in the presence of distractors (Song & Nakayama, 2008). On some
trials, their reach is initially directed towards the target. On other
trials, their initial reach is directed towards a distractor but this is
corrected in mid-flight producing a strongly curved trajectory. Song and
Nakayama's key finding was that corrective movements occurred very
rapidly following the onset of the initial movement. This finding
strongly implies that the corrective movement had been planned prior to
execution of the initial incorrect movement. Song (2017) discussed
several other studies where similar findings were obtained. He
concluded, "The sensori-motor system generates multiple competing plans
in parallel before actions are initiated . . . this concurrent
processing enables us to efficiently resolve competition and select one
appropriate action rapidly" (p. 6).

Brain pathways In their perception-action model, Milner and Goodale
(1995, 2008) distinguished between a ventral stream or pathway and a
dorsal stream or pathway (see Chapter 2). In approximate terms, the
ventral stream is involved in object perception whereas the dorsal
stream "is generally considered to mediate the visual guidance of
action, primarily in real time" (Milner, 2017, p. 1297). Much recent
research has indicated that the above theoretical account is
oversimplified (see Chapter 2). Of central importance is the
accumulating evidence that there are actually two somewhat separate
dorsal streams (Osiurak et al., 2017; Sakreida et al., 2016): (1) (2)

The dorso-dorsal stream: processing in this stream relates to the online
control of action and is hand-centred; it has been described as the
"grasp" system (Binkofski & Buxbaum, 2013). The ventro-dorsal stream:
processing in this stream is offline and relies on memorised knowledge
of objects and tools and is object-centred; it has been described as the
"use" system (Binkofski & Buxbaum, 2013).

Sakreida et al. (2016) identified several other differences between
these two streams (see Figure 4.6). In essence, object processing within
the dorsodorsal stream is variable because it is determined by the
immediately accessible properties of an object (e.g., its size and
shape). Such processing is fast and "automatic". In contrast, processing
within the ventro-dorsal stream is stable because it is determined by
memorised object knowledge.

Interactive feature: Primal Pictures' 3D atlas of the brain

Central sulcus

Dorso-dorsal VARIABLE

From Sakreida et al. (2016). Reprinted with permission of Elsevier.

STABLE Ventro-dorsal

• Fast and "automatic" online processing during actual object
interaction • Variation of object properties (e.g., size, shape, weight,
or orientation) during task performance • Low working memory load • Slow
and "non-automatic" "oﬄine" processing of memorised object knowledge •
Constant object properties during active or observed object-related
reaching, grasping or pointing • High working memory load

• Structurebased actions/ "Grasp" system by Buxbaum and Kalénine •
Reaching circuit by Jeannerod • Grasping circuit by Jeannerod

Related concepts

Figure 4.6 The dorso-dorsal and ventro-dorsal streams showing their
brain locations and forms of processing.

Visual perception and attention

Continuum

156

• Functionbased actions/ "Use" system by Buxbaum and Kalénine

Such processing is slow and more cognitively demanding than processing
within the dorso-dorsal stream.

Findings

KEY TERM Limb apraxia A condition caused by brain damage in which
individuals have impaired ability to make skilled goal-directed
movements towards objects even though they possess the physical ability
to perform them.

Considerable neuroimaging evidence supports the proposed distinction
between two dorsal streams. Martin et al. (2018, p. 3755) reviewed
research indicating the dorso-dorsal stream "traverses from visual area
V3a through V6 toward the superior parietal lobule, and . . . reaches
the dorsal premotor cortex". In contrast, the ventro-dorsal stream
"encompasses higher-order visual areas like MT/V5+, the inferior
parietal lobule . . . as well as the ventral premotor cortex and
inferior frontal gyru" (p. 3755). Sakreida et al. (2016) conducted a
meta-analytic review based on 71 neuroimaging studies and obtained
similar findings. Evidence from brain-damaged patients is also
supportive of the distinction between two dorsal streams. First, we
consider patients with damage to the ventro-dorsal stream. Much research
has focused on limb apraxia, a disorder where patients often fail to
make precise goal-directed actions in spite of possessing the physical
ability to perform those actions (Pellicano et al., 2017). More
specifically, "Reaching and grasping actions in LA \[limb apraxia\] are
normal when vision of the limb and target is available, but typically
degrade when they must be performed 'off-line', as when subjects are
blindfolded prior to movement execution" (Binkovski & Buxbaum, 2013,
p. 5). This pattern of findings is expected if the dorsodorsal stream is
intact in patients with limb apraxia. Second, we consider patients with
damage to the dorso-dorsal stream. Much research here has focused on
optic ataxia (see Glossary). As predicted, patients with optic ataxia
have impaired online motor control and so exhibit inaccurate reaching
towards (and grasping of) objects.

Evaluation Neuroimaging research has provided convincing evidence for
the existence of two dorsal processing streams. The distinction between
dorso-dorsal and ventro-dorsal streams has also been supported by
studies on brain-damaged

Motion perception and action

157

patients. More specifically, there is some evidence for a double
dissociation (see Glossary) between the impairments exhibited by
patients with limb apraxia and optic ataxia. What are the limitations of
research in this area? First, the ventral stream (strongly involved in
object recognition) is also important in visually guided action (Osiurak
et al., 2017). However, precisely how this stream interacts with the
dorso-dorsal and ventro-dorsal streams is unclear. Second, there is some
overlap in the brain between the dorso-dorsal and ventro-dorsal streams
and so it is important not to exaggerate their independence. Third,
there is a lack of consensus concerning the precise functions of the two
dorsal streams (see Osiurak et al., 2017, and Sakreida et al., 2016).

PERCEPTION OF HUMAN MOTION We are very good at interpreting other
people's movements. We can decide very rapidly whether someone is
walking, running or limping. Our initial focus is on two key issues.
First, how successfully can we interpret human motion with very limited
visual information? Second, do the processes involved in perception of
human motion differ from those involved in perception of motion in
general? If the answer to this question is positive, we also need to
consider why the perception of human motion is special. As indicated
already, our focus is mostly on the perception of human motion. However,
there are many similarities between the perception of human and animal
motion, and we will sometimes use the term "biological motion" to refer
generally to the perception of animal motion. Finally, we discuss an
important theoretical approach based on the notion that the same brain
system or network is involved in perceiving and understanding human
actions and in performing those same actions.

Perceiving human motion Suppose you were presented with point-light
displays, as was done initially by Johansson (1973). Actors were dressed
entirely in black with lights attached to their joints (e.g., wrists;
knees; ankles). They were filmed moving around a darkened room so only
the lights were visible to observers watching the film (see Figure 4.7
and "Johansson Motion Perception Part 1" on YouTube).What do you think
you would perceive in those circumstances?

Figure 4.7 Point-light sequences (a) with the walker visible and (b)
with the walker not visible. Shiffrar and Thomas (2013). With permission
of the authors.

Figure 4.8 Human detection and discrimination efficiency for human
walkers presented in contour, point lights, silhouette and skeleton.
From Lu et al. (2017).

Visual perception and attention

1.2

Human efficiency (%)

158

Detection Discrimination

0.6

0

Contour

Point light

Silhouette

Skeleton

In fact, Johansson found observers perceived the moving person
accurately with only six lights and a short segment of film. In
subsequent research, Johansson et al. (1980) found observers perceived
human motion with no apparent difficulty when viewing a pointlight
display for only one-fifth of a second! Ruffieux et al. (2016) studied a
patient, BC, who was cortically blind but had a residual ability to
process motion. When presented with two point-light displays (one of a
human and one of an animal) at the same time, he generally correctly
identified the human. The above findings imply we are very efficient at
processing impoverished point-light displays. However, Lu et al. (2017)
reported some contrary evidence. Observers were given two tasks: (1)
detecting the presence of a human walker; (2) discriminating whether a
human walker was walking leftward or rightward. The walker was presented
in point lights, contour, silhouette or as a skeleton. Detection
performance was relatively good for the point-light display but
discrimination performance was not (see Figure 4.8). Performance was
high with the skeleton display because it provided detailed information
about the connections between joints.

Top-down or bottom-up processes? Johansson (1975) argued the ability to
perceive biological motion is innate, describing the processes involved
as "spontaneous" and "automatic". Support was reported by Simion et
al. (2008) in a study on newborns (1--3 days). These newborns preferred
to look at a display showing biological motion more than one that did
not. Remarkably, Simion et al. used pointlight displays of chickens of
which the newborns had no previous experience. These findings suggest
the perception of biological motion involves basic bottom-up processes.
Evidence that learning plays a role was reported by Pinto (2006).
Three-month-olds were equally sensitive to motion in point-light humans,
cats and spiders. In contrast, 5-month-olds were more sensitive to
displays of human motion. Thus, the infant visual system becomes
increasingly specialised for perceiving human motion.

Motion perception and action

159

If the detection of biological motion were "automatic", it would be
relatively unaffected by attention. However, in a review Thompson and
Parasuraman (2012) concluded attention is required, especially when the
available visual information is ambiguous or competing information is
present. Mayer et al. (2015) presented circular arrays of between two
and eight video clips. In one condition, observers decided rapidly
whether any clip showed human motion; in another condition, they decided
whether any clips showed machine motion. There were two key findings.
First, detection times increased with array size for both human and
machine motion, suggesting attention is required to detect both types of
motion. Second, the effects of array size on detection times were much
greater for machine motion. Thus, searching is more efficient for human
than machine motion suggesting human motion perception may be special
(see below).

Is human motion perception special? Much evidence indicates we are
better at detecting human motion than motion in other species (Shiffrar
& Thomas, 2013). Cohen (2002) assessed observers' sensitivity to human,
dog and seal motion using point-light displays. Performance was best
with human motion and worst with seal motion. Of importance, the same
pattern of performance was found in seal trainers and dog trainers.
Thus, the key factor is not simply visual experience; instead, we are
more sensitive to observed motions resembling our own repertoire of
actions. We can also consider whether human motion perception is special
by considering the brain. There has been an increasing recognition that
many brain areas are involved in biological motion processing (see
Figure 4.9). The pathway from the fusiform gyrus (FFG) to the superior
temporal sulcus *IFG INS (STS) is of particular importance, as are
top-down processes from the insula (INS), the STS and the* 9 STS
inferior frontal gyrus (IFG). Much research indicates the central
importance Crus I 8 of the superior temporal sulcus. Grossman et al. 6
10 4 11 (2005) applied repetitive transcranial magnetic stimulation
(rTMS; see Glossary) to that area to disrupt MTC FFG processing. This
caused a substantial reduction in observers' sensitivity to biological
motion. GilaieOCC Dotan et al. (2013) found grey matter volume in the
superior temporal sulcus correlated positively with the detection of
biological (but not non-biological) motion. Evidence from brain-damaged
patients indi- Figure 4.9 Brain areas involved in biological motion
processing cates that perceiving biological motion involves dif- (STS =
superior temporal sulcus; IFG = inferior frontal ferent processes from
those involved in perceiving gyrus; INS = insula; Crus 1 = left lateral
cerebellar object motion generally. Vaina et al. (1990) studied lobule;
MTC = middle temporal cortex; OCC = early a patient, AF, with damage to
the posterior visual visual cortex; FFG = fusiform gyrus). pathways. He
performed poorly on basic motion From Sokolov et al. (2018).

160

Visual perception and attention

tasks but was reasonably good at detecting biological motion from
point-light displays. In contrast, Saygin (2007) found in stroke
patients with damage in the temporal and premotor frontal areas that
their perception of biological motion was more impaired than
non-biological motion.

Why is biological motion perception special? We could explain the
special nature of biological motion perception in three ways (Shiffrar &
Thomas, 2013). First, biological motion is the only type of motion
humans can produce as well as perceive. Second, most people spend more
time perceiving and trying to understand other people's motion than any
other form of visual motion. Third, other people's movements provide a
rich source of social and emotional information. We start with the first
reason (discussed further on pp. 161--162). The relevance of motor
skills to the perception of biological motion was shown by Kloeters et
al. (2017). Patients with Parkinson's disease (which impairs movement
execution) had significantly inferior perception of human movement with
point-light displays compared to healthy controls. More dramatically,
paraplegics with severe spinal injury were almost three times less
sensitive than healthy controls to human movement in point-light
displays. We must not exaggerate the importance of motor involvement in
biological motion perception. A man, DC, born without upper limbs,
identified manual actions shown in videos and photographs as well as
healthy controls (Vannuscorps et al., 2013). Motor skills may be most
important in biological motion perception when the visual information
presented is sparse or ambiguous (e.g., as with point-light displays).
Jacobs et al. (2004) obtained support for the second reason listed
above. Observers' ability to identify walkers from point-light displays
was much better when the walker was observed for 20 hours a week rather
than 5 hours. In our everyday lives, we often recognise individuals in
motion by integrating information from biological motion with
information from the face and the voice within the superior temporal
sulcus (Yovel & O'Toole, 2016). Successful integration of these
different information sources clearly depends on learning and
experience. We turn now to the third reason mentioned earlier. Charlie
Chaplin showed convincingly that bodily movements can convey social and
emotional information. Atkinson et al. (2004) found observers performed
well at identifying emotions from point-light displays (especially for
fear, sadness and happiness). Part of the explanation for these findings
is that angry individuals walk especially fast whereas fearful or sad
ones walk very slowly (Barliya et al., 2013). We can explore the role of
social factors in biological motion detection by studying adults with
autism spectrum disorder who have severely impaired social interaction
skills. The findings are somewhat inconsistent However, adults with
autism spectrum disorder generally have a reasonably intact ability to
detect human motion in point-light displays but exhibit impaired emotion
processing in such displays (see Bakroon & Lakshminarayanan, 2018 for a
review).

Motion perception and action

161

Mirror neuron system Research on monkeys in the 1990s transformed our
PMd understanding of biological motion. Gallese et al. (1996) assessed
monkeys' brain activity while they performed AIP SI M1 a given action
and while they observed another monkey PF perform the same action. They
found 17% of neurons in PMv area F5 of the premotor cortex were
activated in both pMT G/STS conditions. Such findings led theorists to
propose a mirror neuron system consisting of neurons activated during
both observation and performance of actions (see Keysers et al., 2018,
for a review). Visual input There have been numerous attempts to
identify a Mirror network mirror neuron system in humans. Our current
underMotor output standing of brain areas associated with the mirror
neuron system is shown in Figure 4.10. Note that the mirror neuron
system consists of an integrated network rather Figure 4.10 than
separate brain areas (Keysers et al., 2018). The main brain areas
associated with the Most research is limited because it shows only that
mirror neuron system (MNS) plus their the same brain areas are involved
in action perception interconnections (red). Areas involved in visual
and production. Perry et al. (2018) used more precise input (blue; pMTG
= posterior mid-temporal methods to reveal a more complex picture within
areas gyrus; STS = superior temporal gyrus) and motor assumed to form
part of the mirror neuron system. Some output (green; M1 = primary motor
cortex) are small areas were activated during both observing actions
also shown. AIP = anterior intraparietal areas; PF = area within the
parietal lobe; PMv and and imitating them, thus providing evidence for a
human PMd = ventral and dorsal premotor cortex; neuron system. However,
other adjacent areas were acti- SI = primary somato-sensory cortices.
vated only during observing or action imitation. From Keysers et
al. (2018). Reprinted with permission More convincing evidence for a
human mirror of Elsevier. neuron system was reported by de la Rosa et
al. (2016). They focused on activation in parts of the inferior frontal
gyrus (BA44/45) corresponding to area F5 in monkeys. Their key finding
was that 52 voxels (see Glossary) within BA44/45 responded to both
action perception and action production. Before proceeding, we should
note the term "mirror neuron system" is somewhat misleading because
mirror neurons do not provide us with an exact motoric coding of
observed actions. As Williams (2013, p. 2962) wittily remarked, "If only
this was the case! I could become a Olympic iceskater or a concert
pianist!"

Findings We have seen that neuroimaging studies have indicated that the
mirror neuron system is activated during motor perception and action.
Such evidence is correlational, and so does not demonstrate that the
mirror neuron system is necessary for motor perception and action
understanding. More direct evidence comes from research on brain-damaged
patients. Binder et al. (2017) studied left-hemisphere stroke patients
with apraxia (impaired ability to perform planned actions) having damage
within the mirror neuron system (e.g., inferior frontal gyrus). These
patients had comparable deficits in action imitation, action recognition
and action

KEY TERM Mirror neuron system Neurons that respond to actions whether
performed by oneself or someone else; it is claimed these neurons assist
in imitating (and understanding) the actions of others.

162

KEY TERM Apraxia A condition caused by brain damage in which there is
greatly reduced ability to perform purposeful or planned bodily
movements in spite of the absence of muscular damage.

Visual perception and attention

comprehension. The co-existence of these deficits was precisely as
predicted. Another predicted finding was that left-hemisphere stroke
patients without apraxia had less brain damage in core regions of the
mirror neuron system than those with apraxia. Another approach to
demonstrating the causal role of the mirror neuron system is to use
experimental techniques such as transcranial direct current stimulation
(tDCS; see Glossary). Avenanti et al. (2018) assessed observers' ability
to predict which object would be grasped after seeing the start of a
reaching movement. Task performance was enhanced when anodal tDCS was
used to facilitate neural activity within the mirror neuron system,
whereas it was impaired when cathodal tDCS was used to inhibit such
neural activity.

Findings: functions of the mirror neuron system What are the functions
of the mirror neuron system? It has often been assumed mirror neurons
play a role in working out why someone else is performing certain
actions as well as deciding what those actions are. For example, Eagle
et al. (2007, p. 131) claimed the mirror neuron system is involved in
"the automatic, unconscious, and non-inferential simulation in the
observer of the actions, emotions, and sensations carried out and
expressed by the observed". Rizzolatti and Sinigaglia (2016) argued that
full understanding of another person's actions requires a multi-level
process. The first level involves identifying the outcome of the
observed action and the emotion being displayed by the other person.
This is followed by the observer representing the other person's
desires, beliefs and intentions. The mirror neuron system is primarily
involved at the first level but may provide an input to subsequent
processes. Lingnau and Petris (2013) argued that understanding another
person's actions often requires complex cognitive processes as well as
simpler processes within the mirror neuron system. Observers saw
point-light displays of human actions and some were asked to identify
the goal of each action. Areas within the prefrontal cortex (associated
with high-level cognitive processes) were more activated when goal
identification was required. These findings can be explained within the
context of Rizzolatti and Sinigaglia's (2016) approach discussed above.
Wurm et al. (2016) distinguished between two forms of motion perception
and understanding. They used the example of observers understanding that
someone is opening a box. If they have a general or abstract
understanding of this action, their understanding should generalise to
other boxes and other ways of opening a box. In contrast, if they only
have a specific or concrete understanding of the action, their
understanding will not generalise. Wurm et al. (2016) found specific or
concrete action understanding could occur within the mirror neuron
system. However, more general or abstract understanding involved
high-level perceptual regions (e.g., the lateral parieto-temporal
cortex) outside the mirror neuron system. In sum, the mirror neuron
system is of central importance with respect to some (but not all)
aspects of action understanding. More specifically,

Motion perception and action

additional (more "cognitive") brain areas are required if action
understanding is complex (Lingnau & Petris, 2013) or involves
generalising from past experience (Wurm et al., 2016). It is also likely
that imitating someone else's actions often involves processes (e.g.,
person-perception processes) additional to those directly involving the
mirror neuron system (Ramsey, 2018).

Overall evaluation Several important research findings have been
obtained. First, we have an impressive ability to perceive human or
biological motion even with very limited visual input. Second, the brain
areas involved in human motion perception differ somewhat from those
involved in perceiving motion in general. Third, perception of human
motion is special because it is the only type of motion we can both
perceive and produce. Fourth, a mirror neuron system allows us to
imitate and understand other people's movements. Fifth, the core brain
network of the mirror neuron system has been identified. Its causal role
has been established through studies on brain-damaged patients and
research using techniques such as transcranial direct current
stimulation. What are the limitations of research in this area? First,
much remains unclear about interactions of bottom-up and top-down
processes in the perception of biological motion. Second, the mirror
neuron system does not account for all aspects of action understanding.
As Gallese and Sinigaglia (2014, p. 200) pointed out, action
understanding "involves representing to which . . . goals the action is
directed; identifying which beliefs, desires, and intentions specify
reasons explaining why the action happened; and realising how those
reasons are linked to the agent and to her action". Third, nearly all
studies on the mirror neuron system have investigated its properties
with respect only to hand actions. However, somewhat different mirror
neuron networks are probably associated with hand-and-mouth actions
(Ferrari et al., 2017a). Fourth, it follows from theoretical approaches
to the mirror neuron system that an observer's ability to understand
another person's actions should be greater if they both execute any
given action in a similar fashion. This prediction has been confirmed
(Macerollo et al., 2015). Such research indicates the importance of
studying individual differences in motor actions, which have so far been
relatively neglected.

CHANGE BLINDNESS We have seen that a changing visual environment allows
us to move in the appropriate direction and to make coherent sense of
our surroundings. However, as we will see, our perceptual system does
not always respond appropriately to changes in the visual environment.
Have a look around you (go on!). You probably have a strong impression
of seeing a vivid and detailed picture of the visual scene. As a result,
you are probably confident you could immediately detect any reasonably
large change in the visual environment. In fact, that is often not the
case.

163

164

KEY TERMS Change blindness Failure to detect various changes (e.g. in
objects) in the visual environment. Inattentional blindness Failure to
detect an unexpected object appearing in the visual environment. Change
blindness blindness The tendency of observers to overestimate greatly
the extent to which they can detect visual changes and so avoid change
blindness.

Visual perception and attention

Change blindness, which is "the failure to detect changes in visual
scenes" (Ball et al., 2015, p. 2253) is the main phenomenon we will
discuss. We also consider inattentional blindness, "the failure to
consciously perceive otherwise salient events when they are not
attended" (Ward & Scholl, 2015, p. 722). Research on change blindness
focuses on dynamic processes over time. It has produced striking and
counterintuitive findings leading to new theoretical thinking about the
processes underlying conscious visual awareness. Change blindness and
inattentional blindness both depend on a mixture of perceptual and
attentional processes. It is thus appropriate to discuss these phenomena
at the end of our coverage of perception and immediately prior to the
start of our coverage of attention. You have undoubtedly experienced
change blindness at the movies caused by unintended continuity mistakes
when a scene has been reshot. For example, in the film Skyfall, James
Bond is followed by a white car. Mysteriously, this car suddenly becomes
black and then returns to being white! For more examples, type "Movie
continuity mistakes" into YouTube. We greatly exaggerate our ability to
detect visual changes. Levin et al. (2002) asked observers to watch
videos involving two people in a restaurant. In one video, the plates
change from red to white and in another a scarf worn by one person
disappeared. Levin et al. found 46% of observers claimed they would have
noticed the change in the colour of the plates without being forewarned
and the figure was 78% for the disappearing scarf. In a previous study,
0% of observers detected either change! Levin et al. introduced the term
change blindness blindness to describe our wildly optimistic beliefs
about our ability to detect visual changes. In the real world, we are
often aware of visual changes because we detect motion signals
accompanying the change. Laboratory researchers have used various ways
to prevent observers from detecting motion signals. One way is to make
the change during a saccade (rapid movement of the eyes). Another way is
to have a short gap between the original and changed displays (the
flicker paradigm). Suppose you walked across a large square close to a
unicycling clown wearing a vivid purple and yellow outfit, large shoes
and a bright red nose (see Figure 4.11). Would you spot him? I imagine
your answer is "Yes". However, Hyman et al. (2009) found only 51% of
people walking on their own spotted the clown. Those failing to spot the
clown exhibited inattentional blindness.

Figure 4.11 The unicycling clown who cycled close to students walking
across a large square. From Hyman et al. (2009).

Change blindness vs inattentional blindness Change blindness and
inattentional blindness both involve a failure to detect some visual
event

Motion perception and action

165

occurring in plain sight. Unsurprisingly, failures of attention often
play an important role in causing both forms of blindness. However,
there are major differences between the two phenomena (Jensen et al.,
2011). First, consider the effects of instructing observers to look for
unexpected objects or visual changes. Target detection in change
blindness paradigms is often hard even with such instructions. In
contrast, target detection in inattentional blindness paradigms becomes
trivially easy. Second, change blindness involves the use of memory to
compare prechange and post-change stimuli, whereas inattentional
blindness does not. Third, inattentional blindness mostly occurs when
the observer's attention is engaged in a demanding task (e.g., chatting
on a mobile phone) unlike change blindness. In sum, more complex
processing is typically required for successful performance in change
blindness tasks. More specifically, observers must engage successfully
in five separate processes for change detection to occur (Jensen et al.,
2011): (1) (2) (3) (4) (5)

Attention must be paid to the change location. The pre-change visual
stimulus at the change location must be encoded into memory. The
post-change visual stimulus at the change location must be encoded into
memory. The pre- and post-change representations must be compared. The
discrepancy between the pre- and post-change representations must be
recognised at the conscious level.

IN THE REAL WORLD: IT'S MAGIC! Magicians benefit from the phenomena of
inattentional blindness and change blindness (Kuhn & Martinez, 2012).
Most magic tricks involve misdirection which is designed "to disguise
the method and thus prevent the audience from detecting it" (Kuhn &
Martinez, 2012, p. 2). Many people believe misdirection involves the
magician manipulating the audience's attention away from some action
crucial to the trick's success. That is often (but not always) the case.

Inattentional blindness Kuhn and Findlay (2010) studied inattentional
blindness using a disappearing lighter (see Figure 4.12 for details).
There were three main findings. First, of the observers who detected the
drop, 31% were fixating close to the magician's left hand when the
lighter was dropped from that hand. However, 69% were fixating some
distance away and so detected the drop in peripheral vision (see Figure
4.13). Second, the average distance between fixation and the drop was
the same in those who detected the drop in peripheral vision and those
who did not. Third, the time taken after the drop to fixate the left
hand was much less in observers using peripheral vision to detect the
drop than those failing to detect it (650 ms vs 1,712 ms). What do the
above findings mean? The lighter drop can be detected by overt attention
(attention directed to the fixation point) or covert attention
(attention directed away from the fixation point). Covert attention was
surprisingly effective because the human visual system can readily
detect movement in peripheral vision (see Chapter 2).

166

Visual perception and attention

Figure 4.12 The sequence of events in the disappearing lighter trick:
(a) the magician picks up a lighter with his left hand and (b) lights
it; (c) and (d) he pretends to take the flame with his right hand and
(e) gradually moves it away from the hand holding the lighter; (f) he
reveals his right hand is empty while the lighter is dropped into his
lap; (g) the magician directs his gaze to his left hand and (h) reveals
that his left hand is also empty and the lighter has disappeared. From
Kuhn and Findlay (2010). Reprinted with permission of Taylor & Francis.

Most people underestimate the importance of peripheral vision to trick
detection. Across several magic tricks (including the lighter trick and
other tricks involving change blindness), Ortega et al. (2018) found
under 30% of individuals thought they were likely to detect how a trick
worked using peripheral vision. In fact, however, over 60% of the tricks
where they detected the method involved peripheral vision! Thus, most
people exaggerate the role of central vision in understanding magic
tricks.

Change blindness

Figure 4.13 Participants' fixation points at the time of dropping the
lighter for those detecting the drop (triangles) and those missing the
drop (circles). From Kuhn and Findlay (2010). Reprinted with permission
of Taylor & Francis.

Smith et al. (2012) used a magic trick in which a coin was passed from
one hand to the other and then dropped. Observers guessed whether the
coin landed heads or tails. On one trial, the coin was switched (e.g.,
from a £1 coin to a 2p coin). All observers fixated the coin throughout
the time it was visible but about 90% failed to detect the coin had
changed! Thus, an object can be attended to without some of the features
irrelevant to the current task being processed sufficiently to prevent
change blindness.

Motion perception and action

167

Kuhn et al. (2016) used a trick in which a magician made the colour of
playing cards change. Explicit instructions to observers to keep their
eyes on the cards influenced overt attention but failed to reduce change
blindness.

Conclusions The success of many magic tricks depends less on where
observers are fixating (overt attention) than we might think. Observers
can be deceived even when their overt attention is directed to the
crucial location. In addition, they often avoid change blindness or
inattentional blindness even when their overt attention is directed some
distance away from the crucial location. Such findings are typically
explained by assuming the focus of covert attention often differs from
that of overt attention. More generally, peripheral vision is often of
more importance to the detection of magic tricks than most people
believe.

Change blindness underestimates visual processing Ball and Busch (2015)
distinguished between two types of change detection: (1) seeing the
object that changed; (2) sensing there has been a change without
conscious awareness of which object has changed. Several coloured
objects were presented in pre- and post-change displays. If the
post-change display contained a colour not present in the pre-change
display, observers often sensed change had occurred without being aware
of what had changed. When observers show change blindness, it does not
necessarily mean there was no processing of the change. Ball et
al. (2015) used object changes where the two objects were semantically
related (e.g., rail car changed to rail) or unrelated (e.g., rail car
changed to sausage). Use of event-related potentials (ERPs; see
Glossary) revealed a larger negative wave when the objects were
semantically unrelated even when observers exhibited change blindness.
Thus, there was much unconscious processing of the pre- and post-change
objects.

What causes change blindness? There is no single (or simple) answer to
the question "What causes change blindness?". However, two major
competing theories both provide partial answers. First, there is the
attentional approach (e.g., Rensink et al., 1997). According to this
approach, change detection requires selective attention to be focused on
the object that changes. Attention is typically directed to only a
limited part of visual space, and changes in unattended objects are
unlikely to be detected. Second, there is a theoretical approach
emphasising the importance of peripheral vision (Rosenholtz, 2017a,b;
Sharan et al., 2016 unpublished). It is based on the assumption that
visual processing occurs in parallel across the entire visual field
(including peripheral vision). According to this approach, "Peripheral
vision is a limiting factor underlying standard demonstrations of change
blindness" (Sharan et al., 2016, p. 1).

168

Visual perception and attention

Attentional approach Change blindness often depends on attentional
processes. We typically attend to regions of a visual scene likely to
contain salient or important information. Spot the differences between
the pictures in Figure 4.14. Observers took an average of 10.4 seconds
with the first pair of pictures but only 2.6 with the second pair
(Rensink et al., 1997). The height of the railing is less important than
the helicopter's position. Hollingworth and Henderson (2002) recorded
eye movements while observers viewed visual scenes (e.g., kitchen;
living room). It was assumed the object fixated at any moment was the
being attended. There were two potential changes in each scene: ●

●

Figure 4.14 (a) The object that is changed (the railing) undergoes a
shift in location comparable to that of the object that is changed (the
helicopter) in (b). However, the change is much easier to see in (b)
because the changed object is more important. From Rensink et
al. (1997). Copyright 1997 by SAGE. Reprinted by permission of SAGE
Publications.

Type change: an object was replaced by one from a different category
(e.g., a plate replaced by a bowl). Token change: an object was replaced
by an object from the same category (e.g., a plate replaced by a
different plate).

Motion perception and action

169

What did Hollingworth and Henderson (2002) find? First, there was much
greater change detection when the changed object was fixated prior to
the change than when it was not fixated (see Figure 4.15a). Second,
there was change blindness for 60% of objects fixated prior to changing.
Thus, attention to the to-be-changed object was necessary (but not
sufficient) for change detection. Third, change detection was much
greater when the object type changed rather than simply token change
because type changes are more dramatic and obvious.

Evaluation The attentional approach has various successes to its credit.
First, change detection is greater when target stimuli are salient or
important and so attract attention. Second, change detection is
generally greater when the to-be-changed object has been fixated
(attended to) prior to the change. What are the limitations with the
attentional approach? First, the notion that narrow-focused attention
determines our visual experience is

Figure 4.15 (a) Percentage of correct change detection as a function of
form of change (type vs token) and time of fixation (before vs after
change); also false alarm rate when there was no change. (b) Mean
percentage correct change detection as a function of the number of
fixations between target fixation and change of target and form of
change (type vs token). Both from Hollingworth and Henderson (2002).
Copyright 2002 American Psychological Association. Reproduced with
permission.

170

KEY TERM Visual crowding The inability to recognise objects in
peripheral vision due to the presence of neighbouring objects.

Visual perception and attention

hard to reconcile with our strong belief that experience spans the
entire field of view (Cohen et al., 2016). Second, "A selective
attention account is hard to prove or disprove, as it relies on largely
unknown attentional loci as well as poorly understood effects of
attention" (Sharan et al., 2016). Third, change blindness is sometimes
poorly predicted by the focus of overt attention (indexed by eye
fixations) (e.g., Smith et al., 2012; Kuhn et al., 2016). Such findings
are often explained by covert attention, but this is typically not
measured directly. Fourth, the attentional approach implies incorrectly
that very little useful information is extracted from visual areas
outside the focus of attention (see below).

Peripheral vision approach Visual acuity is greatest in the centre of
the visual field (the fovea; see Glossary). However, peripheral vision
(all vision outside the fovea) typically covers the great majority of
the visual field (see Chapter 2). As Rosenholtz (2016, p. 438) pointed
out, it is often assumed "Peripheral vision is impoverished and all but
useless". This is a great exaggeration even though acuity and colour
perception are much worse in the periphery than the fovea. In fact,
peripheral vision is often most impaired by visual crowding:
"identification of a peripheral object is impaired by nearby objects"
(Pirkner & Kimchi, 2017, p. 1) (see Chapter 5). According to Sharan et
al. (2016, p. 3), "The hypothesis that change blindness may arise in
part from limitations of peripheral vision is quite different from usual
explanations of the phenomenon \[which attribute it to\] a mix of
inattention and lack of details stored in memory." Sharan et al. (2016)
tested the above hypothesis. Initially, they categorised
change-detection tasks as easy, medium and hard on the basis of how
rapidly observers detected the change. Then they presented these tasks
to different observers who fixated at various degrees of visual angle
(eccentricities) from the area that changed. There were two key
findings:

(2) 

Figure 4.16 (a) Change-detection accuracy as a function of task
difficulty and visual eccentricity. (b) The eccentricity at which
change-detection accuracy was 85% correct as a function of task
difficulty. From Sharan et al. (2016).

Accuracy

(a) 

Change-detection performance was surprisingly good even when the change
occurred well into peripheral vision. Peripheral vision plays a major
role in determining change-detection performance -- hard-to-detect
changes require closer fixations than those that are easy to detect. + 1
+++ (b) 8 ++++ +++ + Easy ++++++ + + 7 0.9 + + + + Medium ++ + + + ++ 6
Hard + + + +++++ 0.8 + + ++ + + 5 + + ++ + 0.7 4 + + ++ + + 3 + + 0.6 ++
++ 2 + ++ + 0.5 + + + 1 + 0.4 0 0 5 10 15 20 Eccentricity (deg)

p = 0.019 p = 0.013

Eccentricity (deg)

(1) 

Easy

Medium

Hard

Motion perception and action

Further evidence that much information is extracted from peripheral as
well as foveal vision was reported by Clarke and Mack (2015). On each
trial, two real-world scenes were presented with an interval of 1,500 ms
between them. When this interval was unfilled, only 11% of changes were
detected. However, when a cue indicating the location of a possible
change was presented 0, 300 or 1,000 ms after the offset of the first
scene, change-detection rates were much higher. They were greatest in
the 0 ms condition (29%) and lowest in the 1,000 ms condition (18%).
Thus, much information about the first scene (including information from
peripheral vision) was stored briefly in iconic memory (see Glossary and
Chapter 6). If peripheral vision provides observers with general or gist
information, they might detect global scene changes without detecting
precisely what had changed. Howe and Webb (2014) obtained support for
this prediction. Observers were presented with an array of 30 discs (15
red, 15 green). On 24% of trials when three discs changed colour,
observers detected the array had changed but could not identify the
discs involved.

Evaluation The peripheral vision approach has proved successful in
various ways. First, visual information is often extracted from across
the entire visual field as predicted by this approach (but not the
attentional approach). This supports our strong belief that we perceive
most of the immediate visual environment. Second, this approach
capitalises on established knowledge concerning peripheral vision.
Third, this approach has been applied successfully to explain
visual-search performance (see Chapter 5). What are the limitations of
this approach? First, it de-emphasises attention's role in determining
change blindness, and does not provide a detailed account of how
attentional and perceptual processes are integrated. Second, Sharan et
al. (2016) discovered change detection was sometimes difficult even
though the change could be perceived easily in peripheral vision. This
indicates that other factors (as yet unidentified) are also involved.
Third, the approach does not consider failure to compare pre- and
post-change representations as a reason for change blindness (see
below).

Comparison of pre- and post-change representations Change blindness can
occur because observers fail to compare their preand post-change
representations. Angelone et al. (2003) presented a video in which the
identity of the central actor changed. On a subsequent line-up task to
identify the pre-change actor, observers showing change blindness
performed comparably to those showing change detection (53% vs 46%,
respectively). Varakin et al. (2007) extended the above research in a
real-world study in which a coloured binder was switched for one of a
different colour while observers' eyes were closed. Some observers
exhibited change blindness even though they remembered the colours of
the pre- and post-change binders and so had failed to compare the two
colours. Other observers showing change blindness had poor memory for
the pre- and post-change colours and so failed to represent these two
pieces of information in memory.

171

172

Visual perception and attention

KEY TERM

Is change blindness a defect?

Serial dependence Systematic bias of current visual perception towards
recent visual input.

Is change blindness an unfortunate defect? Fischer and Whitney (2014)
argued the answer is "No". The visual world is typically relatively
stable over short time periods. As a result, it is worthwhile for us to
sacrifice perceptual accuracy occasionally to ensure we have a
continuous, stable perception of our visual environment. Fischer and
Whitney (2014) supported their argument by finding the perceived
orientation of a grating was biased in the direction of a previously
presented grating, an effect known as serial dependence. Manassi et
al. (2018) found serial dependence for an object's location -- when an
object that had been presented previously was re-presented, it was
perceived as being closer to its original location than was actually the
case. Serial dependence probably involves several stages of visual
perception and may also involve memory processes (Bliss et al., 2017).
In sum, the visual system's emphasis on perceptual stability inhibits
our ability to detect changes within the visual scene.

Inattentional blindness and its causes The most famous study on
inattentional blindness was reported by Simons and Chabris (1999). In
one condition, observers watched a video where students dressed in white
(the white team) passed a ball to each other and the observers counted
the number of passes (see the video at www.simonslab. com/videos.html).
At some point, a woman in a black gorilla suit walks into camera shot,
looks at the camera, thumps her chest and then walks off (see Figure
4.17). Altogether she is on screen for 9 seconds. Very surprisingly,
only 42% of observers noticed the gorilla! This is a striking example of
inattentional blindness. Why was performance so poor in the above
experiment? Simons and Chabris (1999) obtained additional relevant
evidence. In a second condition, observers counted the number of passes
made by students dressed in black. Here 83% of observers detected the
gorilla's presence. Thus, observers were more likely to attend to the
gorilla when it resembled task-relevant stimuli (i.e., in colour). It is
generally assumed detection performance is good when observers count
black team passes because of selective attention to black objects.
Indeed, Rosenholtz et al. (2016) found that observers counting black
team passes had eye fixations closer to the gorilla than those counting
white team Figure 4.17 passes. However, Rosenholtz et al. also Frame
showing a woman in a gorilla suit in the middle of a game found that
observers counting black team of passing the ball. passes (but whose
fixation patterns resemFrom Simons & Chabris (1999). Figure provided by
Daniel Simons, www. dansimons.com/www.theinvisiblegorilla.com. bled
those of observers counting white

Motion perception and action

team passes) had unusually poor detection performance (54% compared to a
typical 80%). Thus, detection performance may depend on the strengths
and limitations of peripheral vision as well as failures of selective
attention. The presence of inattentional blindness can lead us to
underestimate the amount of processing of the undetected stimulus.
Schnuerch et al. (2016) found categorising attended stimuli was slower
when the meaning of an undetected stimulus conflicted with that of the
attended stimulus. Thus, the meaning of undetected stimuli was processed
despite inattentional blindness. Other research using event-related
potentials (reviewed by Pitts, 2018) has shown that undetected stimuli
typically receive moderate processing. How can we explain inattentional
blindness? As we have seen, explanations often emphasise the role of
selective attention or attentional set. Simons and Chabris' (1999)
findings indicate the importance of similarity in stimulus features
(e.g., colour) between task stimuli and the unexpected object. However,
Most (2013) argued that similarity in semantic category is also
important. Participants tracked numbers or letters. On the critical
trial, an unexpected stimulus (the letter E or number 3) was visible for
7 seconds. The letter and number were visually identical except they
were mirror images of each other. What did Most (2013) find? There was
much less inattentional blindness when the unexpected stimulus belonged
to the same category as the tracked objects. Thus, inattentional
blindness can depend on attentional sets based on semantic categories
(e.g., letters; numbers). Légal et al. (2017) investigated the role of
demanding top-down attentional processes in producing inattentional
blindness using Simons and Chabris' (1999) gorilla video. Some observers
counted the passes made by the white team (standard task) whereas others
had the more attentionally demanding task of counting the number of
aerial passes as well as total passes. As predicted, there was much more
evidence of inattentional blindness (i.e., failing to detect the
gorilla) when the task was more demanding. Légal et al. (2017) reduced
inattentional blindness in other conditions by presenting
detection-relevant words subliminally (e.g., identify; notice) to
observers prior to watching the video. This increased detection rates
for the gorilla in the standard task condition from 50% to 83%. Overall,
the findings indicate that manipulating attentional processes can have
powerful effects on inattentional blindness. Compelling evidence that
inattentional blindness depends on top-down processes that strongly
influence what we expect to see was reported by Persuh and Melara
(2016). Observers fixated a central dot followed by the presentation of
two coloured squares and decided whether the colours were the same. On
the critical trial, the dot was replaced by Barack Obama's face (see
Figure 4.18). Amazingly, 60% of observers failed to detect this
unexpected stimulus presented in foveal vision: Barack Obama blindness.
Of these observers, a below-chance 8% identified Barack Obama when
deciding whether the unexpected stimulus was Angelina Jolie, a lion's
head, an alarm clock or Barack Obama (see Figure 4.18). Persuh and
Melara's (2016) findings are dramatic because they indicate
inattentional blindness can occur even when the novel stimulus is
presented on its own with no competing stimuli. These findings suggest
there

173

174

Visual perception and attention

Figure 4.18 The sequence of events on the initial baseline trials and
the critical trial. From Persuh and Melara (2016).

are important differences in the processes underlying inattentional
blindness and change blindness: the latter often depends on visual
crowding (see Glossary), which is totally absent in Persuh and Melara's
study.

Evaluation Several factors influencing inattentional blindness have been
identified. These factors include the similarity (in terms of stimulus
features and semantic category) between task stimuli and the unexpected
object; the attentional demands of the task; and observers' expectations
concerning what they will see. If there were no task requiring
attentional resources and creating expectations, there would undoubtedly
be very little inattentional blindness (Jensen et al., 2011). What are
the limitations of research in this area? First, it is typically unclear
whether inattentional blindness is due to perceptual failure or to
memory failure (i.e., the unexpected object is perceived but rapidly
forgotten). However, Ward and Scholl (2015) found that observers showed
inattentional blindness even when observers were instructed to report
immediately seeing anything unexpected. This finding strongly suggests
that inattentional blindness reflects deficient perception rather than
memory failure. Second, observers typically engage in some processing of
undetected stimuli even when they fail to report the presence of such
stimuli (Pitts, 2018). More research is required to clarify the extent
of non-conscious processing of undetected stimuli. Third, it is likely
that the various factors influencing inattentional blindness interact in
complex ways. However, most research has considered only a single factor
and so the nature of such interactions has not been established.

Motion perception and action

CHAPTER SUMMARY •

Introduction. The time dimension is very important in visual perception.
The changes in visual perception produced as we move around the
environment and/or environmental objects move promote accurate
perception and facilitate appropriate actions.

•

Direct perception. Gibson argued perception and action are closely
intertwined and so research should not focus exclusively on static
observers perceiving static visual displays. According to his direct
theory, an observer's movement creates optic flow providing useful
information about the direction of heading. Invariants, which are
unchanged as people move around their environment, have particular
importance. Gibson claimed the uses of objects (their affordances) are
perceived directly. He underestimated the complexity of visual
processing, minimising the role of object knowledge in visual
perception, with the effects of motion on perception being more complex
than he realised.

•

Visually guided movement. The perception of heading depends in part on
optic-flow information. However, there are complexities because the
retinal flow field is determined by eye and head movements as well as by
optic flow. Heading judgements are also influenced by binocular
disparity and the retinal displacement of objects as we approach them.
Accurate steering on curved paths (e.g., driving around a bend)
sometimes involves focusing on the tangent point (e.g., point on the
inside edge of the road at which its direction seems to reverse).
However, drivers sometimes fixate a point along the future path. More
generally, drivers' gaze patterns are flexibly determined by control
mechanisms that are responsive to their goals. Calculating time to
contact with an object often involves calculating tau (the size of the
retinal image divided by the object's rate of expansion). Drivers often
use tau-dot (rate of decline of tau over time) to decide whether there
is sufficient braking time to stop before contact. Observers often make
use of additional sources of information (e.g., binocular disparity;
familiar size; relative size) when working out time to contact. Drivers'
braking decisions also depend on their preferred margin of safety and
the effectiveness of the car's braking system.

•

Visually guided action: contemporary approaches. The planningcontrol
model distinguishes between a slow planning system used mostly before
the initiation of movement and a fast control system used during
movement execution. As predicted, separate brain areas are involved in
planning and control. However, the definition of "planning" is very
broad, and the notion that planning always precedes control is
oversimplified. Recent evidence indicates

175

176

Visual perception and attention

that visually guided action depends on three processing streams
(dorso-dorsal; the ventro-dorsal; and ventral, which is discussed more
fully in Chapter 2) each making a separate contribution. This
theoretical approach is supported by studies on brain-damaged patients
and by neuroimaging research. •

Perception of human motion. Human motion is perceived even when only
impoverished visual information is available. Perception of human and
biological motion involves bottom-up and top-down processes with the
latter most likely to be used with degraded visual input. The perception
of human motion is special because we can produce as well as perceive
human actions and because we devote considerable time to making sense of
it. It has often been assumed that our ability to imitate and understand
human motion depends on a mirror neuron system (an extensive brain
network). This system's causal involvement in action perception and
understanding has been shown in research on brain-damaged patients and
studies using techniques to alter its neural activity. The mirror neuron
system is especially important in the understanding of relatively simple
actions. However, additional high-level cognitive processes are often
required if action understanding is complex or involves generalising
from past experience.

•

Change blindness. There is convincing evidence for change blindness and
inattentional blindness. Change blindness depends on attentional
processes: it occurs more often when the changed object does not receive
attention. However, change blindness can occur for objects that are
fixated and it also depends on the limitations of peripheral vision. The
visual system's emphasis on continuous, stable perception probably plays
a part in making us susceptible to change blindness. Inattentional
blindness depends very strongly on top-down processes (e.g., selective
attention) and can be found even when only the novel stimulus is present
in the visual field.

FURTHER READING Binder, E., Dovern, A., Hesse, M.D., Ebke, M., Karbe,
H., Salinger, J. et al. (2017). Lesion evidence for a human mirror
neuron system. Cortex, 90, 125--137. Ellen Binder and colleagues discuss
the nature of the mirror neuron system based on evidence from
brain-damaged patients. Keysers, C., Paracampo, R. & Gazzola, V. (2018).
What neuromodulation and lesion studies tell us about the function of
the mirror neuron system and embodied cognition. Current Opinion in
Psychology, 24, 35--40. This article provides a succinct account of our
current understanding of the mirror neuron system. Lappi, O. & Mole, C.
(2018). Visuo-motor control, eye movements, and steering: A unified
approach for incorporating feedback, feedforward, and internal models.
Psychological Bulletin, 144, 981--1001. Otto Lappi and Callum Mole
provide

Motion perception and action a comprehensive theoretical account of
driving behaviour that emphasises the importance of top-down control
mechanisms in influencing drivers' eye fixations. Osiurak, F., Rossetti,
Y. & Badets, A. (2017). What is an affordance? 40 years later.
Neuroscience and Biobehavioral Reviews, 77, 403--417. François Osiurak
and colleagues discuss Gibson's notion of affordances in the contest of
contemporary research and theory. Rosenholtz, R. (2017a). What modern
vision science reveals about the awareness puzzle: Summary-statistic
encoding plus decision limits underlie the richness of visual perception
and its quirky failures. Vision Sciences Society Symposium on Summary
Statistics and Awareness, preprint arXiv:1706.02764. Ruth Rosenholtz
provides an excellent account of the role played by peripheral vision in
change blindness and other phenomena. Sakreida, K., Effnert, I., Thill,
S., Menz, M.M., Jirak, D., Eickhoff, C.R. et al. (2016). Affordance
processing in segregated parieto-frontal dorsal stream sub-pathways.
Neuroscience and Biobehavioral Reviews, 69, 80--112. The pathways within
the brain involved in goal-directed interactions with objects are
discussed in the context of a meta-analytic review.

177

Chapter

5

Attention and performance

INTRODUCTION Attention is invaluable in everyday life. We use attention
to avoid being hit by cars when crossing the road, to search for missing
objects and to perform two tasks together. The word "attention" has
various meanings but typically refers to selectivity of processing as
emphasised by William James (1890, pp. 403--404): Attention is . . . the
taking into possession of the mind, in clear and vivid form, of one out
of what seem several simultaneously possible objects or trains of
thought. Focalisation, concentration, of consciousness are of its
essence.

KEY TERMS Focused attention A situation in which individuals try to
attend to only one source of information while ignoring other stimuli;
also known as selective attention. Divided attention A situation in
which two tasks are performed at the same time; also known as
multi-tasking.

William James distinguished between "active" and "passive" modes of
attention. Attention is active when controlled in a top-down way by the
individual's goals or expectations. In contrast, attention is passive
when controlled in a bottom-up way by external stimuli (e.g., a loud
noise). This distinction remains theoretically important (e.g., Corbetta
& Shulman, 2002; see discussion, pp. 192--196). Another important
distinction is between focused and divided attention. Focused attention
(or selective attention) is studied by presenting individuals with two
or more stimulus inputs at the same time and instructing them to respond
to only one. Research on focused or selective attention tells us how
effectively we can select certain inputs and avoid being distracted by
non-task inputs. It also allows us to study the selection process and
the fate of unattended stimuli. Divided attention is also studied by
presenting at least two stimulus inputs at the same time. However,
individuals are instructed they must attend (and respond) to all
stimulus inputs. Divided attention is also known as multi-tasking (see
Glossary). Studies of divided attention provide useful information about
our processing limitations and the capacity of our attentional
mechanisms.

Attention and performance

There is a final important distinction (the last one, I promise you!)
between external and internal attention. External attention is "the
selection and modulation of sensory information" (Chun et al., 2011). In
contrast, internal attention is "the selection, modulation, and
maintenance of internally generated information, such as task rules,
responses, long-term memory, or working memory" (Chun et al., 2011,
p. 73). The connection to Baddeley's working memory model is especially
important (e.g., Baddeley (2012); see Chapter 6). The central executive
component of working memory is involved in attentional control and is
crucially involved in internal and external attention. Much attentional
research has two limitations. First, the emphasis is on attention to
externally presented task stimuli rather than internally generated
stimuli (e.g., worries; self-reflection). One reason is that it is
easier to assess and to control external attention. Second, what
participants attend to is determined by the experimenter's instructions.
In contrast, what we attend to in the real world is mostly determined by
our current goals and emotional states. Two important topics related to
attention are discussed elsewhere. Change blindness (see Glossary),
which shows the close links between attention and perception, is
considered in Chapter 4. Consciousness (including its relationship to
attention) is discussed in Chapter 16.

FOCUSED AUDITORY ATTENTION Many years ago, British scientist Colin
Cherry (1953) became fascinated by the cocktail party problem -- how can
we follow just one conversation when several people are talking at once?
As we will see, there is no simple answer. McDermott (2009) identified
two problems listeners face when attending to one voice among many.
First, there is sound segregation: the listener must decide which sounds
belong together. This is complex: machine-based speech recognition
programs often perform poorly when attempting to achieve sound
segregation with several sound sources present together (Shen et al.,
2008). Second, after segregation has been achieved, the listener must
direct attention to the sound source of interest and ignore the others.
McDermott (2009) pointed out that auditory segmentation is often harder
than visual segmentation (deciding which visual features belong to which
objects; see Chapter 3). There is considerable overlap of signals from
different sound sources in the cochlea whereas visual objects typically
occupy different retinal regions. There is another important issue --
when listeners attend to one auditory input, how much processing is
there of the unattended input(s)? As we will see, various answers have
been proposed. Cherry (1953) addressed the issues discussed so far (see
Eysenck, 2015, for an evaluation of his research). He studied the
cocktail party problem using a dichotic listening task in which a
different auditory message was presented to each ear and the listener
attended to only one. Listeners engaged in shadowing (repeating the
attended message aloud as it was presented) to ensure their attention
was directed to that message. However, the shadowing task has two
potential disadvantages: (1) listeners do not

179

KEY TERMS Cocktail party problem The difficulties involved in attending
to one voice when two or more people are speaking at the same time.
Dichotic listening task A different auditory message is presented to
each ear and attention has to be directed to one message. Shadowing
Repeating one auditory message word for word as it is presented while a
second auditory message is also presented; it is used on the dichotic
listening task.

180

Visual perception and attention

normally engage in shadowing and so the task is artificial; and (2) it
increases listeners' processing demands. Listeners solved the cocktail
party problem by using differences between the auditory inputs in
physical features (e.g., sex of speaker; voice intensity; speaker
location). When these physical differences were eliminated by presenting
two messages in the same voice to both ears at once, listeners found it
very hard to separate out the messages based on differences in meaning.
Cherry (1953) found very little information seemed to be extracted from
the unattended message. Listeners seldom noticed when it was spoken
backwards or in a foreign language. However, physical changes (e.g., a
pure tone) were nearly always detected. The conclusion that unattended
information receives minimal processing was supported by Moray (1959),
who found listeners remembered very few words presented 35 times each.

Where is the bottleneck? Early vs late selection

Interactive exercise: Treisman

Many psychologists have argued we have a processing bottleneck
(discussed below). A bottleneck in the road (e.g., where it is
especially narrow) can cause traffic congestion, and a bottleneck in the
processing system seriously limits our ability to process two (or more)
simultaneous inputs. However, it would sometimes solve the cocktail
problem by permitting listeners to process only the desired voice. Where
is the bottleneck? Broadbent (1958) argued a filter (bottleneck) early
in processing allows information from one input or message through it
based on the message's physical characteristics. The other input remains
briefly in a sensory buffer and is rejected unless attended to rapidly
(see Figure 5.1). Thus, Broadbent argued there is early selection.
Treisman (1964) argued the bottleneck's location is more flexible than
Broadbent suggested (see Figure 5.1). She claimed listeners start with
processing based on physical cues, syllable pattern and specific words
and then process grammatical structure and meaning. Later processes are
omitted or attenuated if there is insufficient processing capacity to
permit full stimulus analysis. Treisman (1964) also argued top-down
processes (e.g., expectations) are important. Listeners performing the
shadowing task sometimes say a word from the unattended input. Such
breakthroughs mostly occur when the word on the unattended channel is
highly probable in the context of the attended message. Deutsch and
Deutsch (1963) argued all stimuli are fully analysed, with the most
important or relevant stimulus determining the response. Thus, they
placed the bottleneck much later in processing than did Broadbent (see
Figure 5.1).

Findings: unattended input Broadbent's approach predicts little or no
processing of unattended auditory messages. In contrast, Treisman's
approach suggests flexibility in the processing of unattended messages,
whereas Deutsch and Deutsch's approach implies reasonably thorough
processing of such messages. Relevant findings are discussed below.

Attention and performance

181

Treisman and Riley (1969) asked listeners to shadow one of two auditory
messages. They stopped shadowing and tapped when they detected a target
in either message. Many more target words were detected on the shadowed
message. Aydelott et al. (2015) asked listeners to perform a task on
attended target words. When unattended words related in meaning were
presented shortly before the target words themselves, performance on the
target words was enhanced when unattended words were presented as loudly
as attended ones. Thus, the meaning of unattended words was processed.
There is often more processing of unattended words that have a special
significance for the listener. For example, Li et al. (2011) obtained
evidence that unattended weight-related words (e.g., fat; chunky) were
processed more thoroughly by women dissatisfied with their weight.
Conway et al. (2001) found listeners often detected their own name on
the unattended message. This was especially the case if they had low
working memory capacity (see Glossary) indicative of poor attentional
control. Coch et al. (2005) asked listeners to attend to one of two
auditory inputs and to detect targets presented on either input.
Event-related potentials (ERPs; see Glossary) provided a measure of
processing activity. ERPs 100 ms after target presentation were greater
when the target was presented on the attended rather than the unattended
message. This suggests there was more processing of the attended than
unattended targets. Greater brain activation for attended than
unattended auditory stimuli may reflect enhanced processing for attended
stimuli and/or suppressed processing for unattended stimuli. Horton et
al. (2013) addressed this

Figure 5.1 A comparison of Broadbent's theory (top), Treisman's theory
(middle), and Deutsch and Deutsch's theory (bottom).

182

Visual perception and attention

issue. Listeners heard separate speech messages presented to each ear
with instructions to attend to the left or right ear. There was greater
brain activation associated with the attended message (especially around
90 ms after stimulus presentation). This difference depended on
enhancement of the attended message combined with suppression of the
unattended message. Classic theories of selective auditory attention
(those of Broadbent, Treisman, and Deutsch and Deutsch) de-emphasised
the importance of suppression or inhibition of the unattended message
shown by Horton et al. (2013). For example, Schwartz and David (2018)
reported suppression of neuronal responses in the primary auditory
cortex to distractor sounds. More generally, all the classic theories
de-emphasise the flexibility of selective auditory attention and the
role of top-down processes in selection (see below).

Findings: cocktail party problem Humans are generally very good at
separating out and understanding one voice from several speaking at the
same time (i.e., solving the cocktail party problem). The extent of this
achievement is indicated by the finding that automatic speech
recognition systems are considerably inferior to human speech
recognition (Spille & Meyer, 2014). Mesgarani and Chang (2012) studied
listeners with implanted multielectrode arrays permitting the direct
recording of activity within the auditory cortex. They heard two
different messages (one in a male voice; one in a female voice)
presented to the same ear with instructions to attend to only one. The
responses within the auditory cortex revealed "The salient spectral
\[based on sound frequencies\] and temporal features of the attended
speaker, as if subjects were listening to that speaker alone" (Mesgarani
& Chang, 2012, p. 233). Listeners found it easy to distinguish between
the two messages in the study by Mesgarani and Chang (2012) because they
differed in physical characteristics (i.e., male vs female voice).
Olguin et al. (2018) presented native English speakers with two messages
in different female voices. The attended message was always in English
whereas the unattended message was in English or an unknown language.
Comprehension of the attended message was comparable in both conditions.
However, there was stronger neural encoding of both messages in the
former condition. As Olguin et al. concluded, "The results offer strong
support to flexible accounts of selective \[auditory\] attention"
(p. 1618). In everyday life, we are often confronted by several
different speech streams. Accordingly, Puvvada and Simon (2017)
presented three speech streams and assessed brain activity as listeners
attended to only one. Early in processing, "the auditory cortex
maintains an acoustic representation of the auditory scene with no
significant preference to attended over ignored sources" (p. 9195).
Later in processing, "Higher-order auditory cortical areas represent an
attended speech stream separately from, and with significantly higher
fidelity \[accuracy\] than, unattended speech streams" (p. 9189). This
latter finding results from top-down processes (e.g., attention). How do
we solve the cocktail party problem? The importance of top-down
processes is suggested by the existence of extensive descending

Attention and performance

pathways from the auditory cortex to brain areas involved in early
auditory processing (Robinson & McAlpine, 2009). Various top-down
factors based on listeners' knowledge and/or expectations are involved.
For example, listeners are more accurate at identifying what one speaker
is saying in the context of several other voices if they have previously
heard that speaker's voice in isolation (McDermott, 2009). Woods and
McDermott (2018) investigated top-down processes in selective auditory
attention in more detail. They argued, "Sounds produced by a given
source often exhibit consistencies in structure that might be useful in
separating sources" (p. E3313). They used the term "schemas" to refer to
such structural consistencies. Listeners showed clear evidence of schema
learning leading to rapid improvements in their listening performance.
An important aspect of such learning is temporal coherence -- a given
source's sound features are typically all present when it is active and
absent when it is silent. Shamma et al. (2011) discussed research
showing that if listeners can identify one distinctive feature of the
target voice, they can then distinguish its other sound features via
temporal coherence. Evans et al. (2016) compared patterns of brain
activity when attended speech was presented on its own or together with
competing unattended speech. Brain areas associated with attentional and
control processes (e.g., frontal and parietal regions) were more
activated in the latter condition. Thus, top-down processes relating to
attention and control are important in selective auditory processing.
Finally, Golumbic et al. (2013) suggested individuals at actual cocktail
parties can potentially use visual information to assist them in
understanding what a given speaker is saying. Listeners heard two
simultaneous messages (one in a male voice and the other in a female
voice). Processing of the attended message was enhanced when they saw a
video of the speaker talking. In sum, listeners generally achieve the
complex task of selecting one speech message from among several such
messages. There has been progress in identifying the top-down processes
involved. For example, if listeners can identify at least one
consistently distinctive feature of the target voice, this makes it
easier for them to attend only to that voice. Top-down processes often
produce a "winner-takes-all" situation where the processing of one
auditory input (the winner) suppresses the brain activity associated
with all other inputs (Kurt et al., 2008).

FOCUSED VISUAL ATTENTION There has been much more research on visual
attention than auditory attention. The main reason is that vision is our
most important sense modality with more of the cortex devoted to it than
any other sense. Here we consider four key issues. First, what is
focused visual attention like? Second, what is selected in focused
visual attention? Third, what happens to unattended visual stimuli?
Fourth, what are the major systems involved in visual attention? In the
next section (see pp. 196--200), we discuss what the study of visual
disorders has taught us about visual attention.

183

184

Visual perception and attention

KEY TERM

Spotlight, zoom lens or multiple spotlights?

Split attention Allocation of attention to two (or more) nonadjacent
regions of visual space.

Look around you and attend to any interesting objects. Was your visual
attention like a spotlight? A spotlight illuminates a fairly small area,
little can be seen outside its beam and it can be redirected to focus on
any given object. Posner (1980) argued the same is true of visual
attention. Other psychologists (e.g., Eriksen & St. James, 1986) claim
visual attention is more flexible than suggested by the spotlight
analogy and argue visual attention resembles a zoom lens. We can
increase or decrease the area of focal attention just as a zoom lens can
be adjusted to alter the visual area it covers. This makes sense. For
example, car drivers often need to narrow their attention after spotting
a potential hazard. A third theoretical approach is even more flexible.
According to the multiple spotlights theory (Awh & Pashler, 2000), we
sometimes exhibit split attention (attention directed to two or more
non-adjacent regions in space). The notion of split attention is
controversial. Jans et al. (2010) argued attention is often strongly
linked to motor action and so attending to two separate objects might
disrupt effective action. However, there is no strong evidence for such
disruption.

Findings Support for the zoom-lens model was reported by Müller et
al. (2003). On each trial, observers saw four squares in a semi-circle
and were cued to attend to one, two or all four. Four objects were then
presented (one in each square) and observers decided whether a target
(e.g., a white circle) was among them. Brain activation in early visual
areas was most widespread when the attended region was large (i.e.,
attend to all four squares) and was most limited when it was small
(i.e., attend to one square). As predicted by the zoom-lens theory,
performance (reaction times and errors) was best with the smallest
attended region and worst with the largest one. Chen and Cave (2016,
p. 1822) argued the optimal attentional zoom setting "includes all
possible target locations and excludes possible distractor locations".
Most findings indicated people's attentional zoom setting is close to
optimal. However, Collegio et al. (2019) obtained contrary findings.
Drawings of large objects (e.g., jukebox) and small objects (e.g.,
watch) were presented so their retinal size was the same. The observer's
area of focal attention was greater with large objects because they made
top-down inferences concerning their real-world sizes. As a result, the
area of focal attention was larger than optimal for large objects.
Goodhew et al. (2016) pointed out that nearly all research has focused
only on spatial perception (e.g., identification of a specific object).
They focused on temporal perception (was a disc presented continuously
or were there two presentations separated by a brief interval?).
Spotlight size had no effect on temporal acuity, which is inconsistent
with the theory. How can we explain these findings? Spatial resolution
is poor in peripheral vision but temporal resolution is good. As a
consequence, a small attentional spotlight is more beneficial for
spatial than temporal acuity. We turn now to split attention. Suppose
you had to identify two digits that would probably be presented to two
cued locations a little way apart

Attention and performance

185 Figure 5.2 (a) Shaded areas indicate the cued locations; the near
and far locations are not cued. (b) Probability of target detection at
valid (left or right) and invalid (near or far) locations. Based on
information in Awh and Pashler (2000).

(see Figure 5.2a). Suppose also that on some trials a digit was
presented between the two cued locations. According to zoom-lens theory,
the area of maximal attention should include the two cued locations and
the space in between. As a result, the detection of digits presented in
the middle should have been very good. In fact, Awh and Pashler (2000)
found it was poor (see Figure 5.2b). Thus, attention can resemble
multiple spotlights, as predicted by the split-attention approach.
Morawetz et al. (2007) presented letters and digits at five locations
simultaneously (one in each quadrant of the visual field and one in the
centre). In one condition, observers attended to the visual stimuli at
the upper left and bottom right locations and ignored the other stimuli.
There were two peaks of brain activation corresponding to the attended
areas but less activation corresponding to the region in between.
Overall, the pattern of activation strongly suggested split attention.
Niebergall et al. (2011) recorded the neuronal responses of monkeys
attending to two moving stimuli while ignoring a distractor. In the key
condition, there was a distractor between (and close to) the two
attended stimuli. In this condition, neuronal responses to the
distractor decreased compared to other conditions. Thus, split attention
involves a mechanism reducing attention to (and processing of)
distractors located between attended stimuli.

186

KEY TERM Hemifield One half of the visual field. Information from the
left hemifield of each eye proceeds to the right hemisphere and
information from the right hemifield proceeds to the left hemisphere.

Visual perception and attention

In most research demonstrating split attention, the two non-adjacent
stimuli being attended simultaneously were each presented to a different
hemifield (one half of the visual field). Note that the right hemisphere
receives visual signals from the left hemifield and the left hemisphere
receives signals from the right hemifield. Walter et al. (2016) found
performance was better when non-adjacent stimuli were presented to
different hemifields rather than the same hemifield. Of most importance,
the assessment of brain activity indicated effective filtering or
inhibition of stimuli presented between the two attended stimuli only
when presented to different hemifields. In sum, we can use visual
attention very flexibly. Visual selective attention can resemble a
spotlight, a zoom lens or multiple spotlights, depending on the current
situation and the observer's goals. However, split attention may require
that two stimuli are presented to different hemifields rather than the
same one. A limitation with all these theories is that metaphors (e.g.,
attention is a zoom lens) are used to describe experimental findings but
these metaphors fail to specify the underlying mechanisms (Di Lollo,
2018).

What is selected? Why might selective attention resemble a spotlight or
zoom lens? Perhaps we selectively attend to an area or region of space:
space-based attention. Alternatively, we may attend to a given object or
objects: object-based attention. Object-based attention is prevalent in
everyday life because visual attention is mainly concerned with objects
of interest to us (see Chapters 2 and 3). As expected, observers' eye
movements as they view natural scenes are directed almost exclusively to
objects (Henderson & Hollingworth, 1999). However, even though we
typically focus on objects of potential importance, our attentional
system is so flexible we can attend to an area of space or a given
object. There is also feature-based attention. For example, suppose you
are looking for a friend in a crowd. Since she nearly always wears red
clothes, you might attend to the feature of colour rather than specific
objects or locations. Leonard et al. (2015) asked observers to identify
a red letter within a series of rapidly presented letters. Performance
was impaired when a \# symbol also coloured red was presented very
shortly before the target. Thus, there was evidence for feature-based
attention (e.g., colour; motion).

Findings Visual attention is often object-based. For example, O'Craven
et al. (1999) presented observers with two stimuli (a face and a house),
transparently overlapping at the same location, with instructions to
attend to one of them. Brain areas associated with face processing were
more activated when the face was attended to than when the house was.
Similarly, brain areas associated with house processing were activated
when the house was the focus of attention. Egly et al. (1994) devised a
much-used method for comparing objectbased and space-based attention
(see Figure 5.3). The task was to select a target stimulus as rapidly as
possible. A cue presented before the target

Attention and performance

187

was valid (same location as the target) or invalid (different location
from the target). Of key importance, invalid cues were in the same
object as the target (within-object cues) or in a different object
(between-object cues). The key finding was that target detection was
faster on invalid trials when the cue was in the same object rather than
a different one. Thus, attention was at least partly object-based. Does
object-based attention in the Egly et al. (1994) task occur fairly
"automatically" or does it involve strategic processes? Object- Figure
5.3 based attention should always be found if it is Stimuli adapted from
Egly et al. (1994). Participants saw two rectangles and a cue indicated
the most likely location of a automatic. Drummond and Shomstein (2010)
subsequent target. The target appeared at the cued location found no
evidence for object-based attention (V), at the uncued end of the cued
rectangle (IS) or at the when the cue indicated with 100% certainty
uncued, equidistant end of the uncued rectangle (ID). where the target
would appear. Thus, any From Chen (2012). © Psychonomic Society,
Inc. Reprinted with preference for object-based attention can be
permission from Springer. overridden when appropriate. Hollingworth et
al. (2012) found evidence object-based and space-based attention can
occur at the same time using a task resembling that of Egly et
al. (1994). There were three types of within-object cues varying in the
distance between the cue and subsequent target (see Figure 5.4). There
was evidence for object-based attention: when the target was far from
the cue, performance was worse when the cue was in a different object
rather than the same one. There was also evidence for space-based
attention: when the target was in the same object as the cue,
performance declined the greater the distance between target and cue.
Thus, object-based and space-based attention are not mutually exclusive.
Similar findings were reported by Kimchi et al. (2016). Observers
responded faster to a target presented within rather than outside an
object. This indicates object-based attention. There was also evidence
for spacebased attention: when targets were presented outside the
object, observers responded faster when they were close to it. Kimchi et
al. concluded that "object-related and space-related attentional
processing can operate simultaneously" (p. 48). Pilz et al. (2012)
compared object-based and space-based attention using various tasks.
Overall, there was much more evidence of space-based than object-based
attention, with only a small fraction of participants showing clear-cut
evidence of object-based attention. Donovan et al. (2017) noted that
most studies indicating visual attention is object-based have used
spatial cues, which may bias the allocation of attention. Donovan et
al. avoided the use of spatial cues and found "Object-based
representations do not guide attentional selection in the absence of
spatial cues" (p. 762). This finding suggests previous research KEY TERM
has exaggerated the extent of object-based visual attention. Inhibition
of return When we search the visual environment, it would be inefficient
if we A reduced probability of repeatedly attended to any given
location. In fact, we exhibit inhibition of visual attention returning
to a recently attended return (a reduced probability of returning to a
region recently the focus of location or object. attention). Of
theoretical importance is whether inhibition of return applies

188

Visual perception and attention

Figure 5.4 (a) Possible target locations (same object far, same object
near, valid, different object far) for a given cue. (b) Performance
accuracy at the various target locations. From Hollingworth et
al. (2012). © 2011 American Psychological Association.

more to locations or objects. The evidence is mixed (see Chen, 2012).
List and Robertson (2007) used Egly et al.'s (1994) task shown in Figure
5.4 and found location- or space-based inhibition of return was much
stronger than object-based inhibition of return. Theeuwes et al. (2014)
found location- and object-based inhibition of return were both present
at the same time. According to Theeuwes et al. (p. 2254), "If you direct
your attention to a location in space, you will automatically direct
attention to any object . . . present at that location, and vice versa."
There is considerable evidence of feature-based attention (see Bartsch
et al., 2018, for a review). In their own research, Bartsch et
al. addressed

Attention and performance

the issue of whether feature-based attention to colour-defined targets
is confined to the spatially attended region or whether it occurs across
the entire visual field. They discovered the latter was the case.
Finally, Chen and Zelinsky (2019) argued it is important to study the
allocation of attention under more naturalistic conditions than those
typically used in research. In their study, observers engaged in free
(unconstrained) viewing of natural scenes. Eye-fixation data suggested
that attention initially selects regions of space. These regions may
provide "the perceptual fragments from which objects are built"
(p. 148).

Evaluation Research on whether visual attention is object- or
location-based have produced variable findings and so few definitive
conclusions are possible. However, the relative importance of
object-based and space- or location-based attention is flexible. For
example, individual differences are important (Pilz et al., 2012). Note
that visual attention can be both objectbased and space-based at the
same time. What are the limitations of research in this area? First,
most research apparently demonstrating that object-based attention is
more important than space- or location-based attention has involved the
use of spatial cues. Recent evidence (Donovan et al., 2017) suggests
such cues may bias visual attention and that visual attention is not
initially object-based in their absence. Second, space-, object- and
feature-based forms of attention often interact with each other to
enhance object processing (Kravitz & Behrmann, 2011). However, we have
as yet limited theoretical understanding of the mechanisms involved in
such interactions. Third, there is a need for more research assessing
patterns of attention under naturalistic conditions. In recent research
where observers view artificial stimuli while performing a specific
task, it is unclear whether attentional processes resemble those when
they engage in free viewing of natural scenes.

What happens to unattended or distracting stimuli? Unsurprisingly,
unattended visual stimuli receive less processing than attended ones.
Martinez et al. (1999) compared event-related potentials (ERPs) to
attended and unattended visual stimuli. The ERPs to unattended visual
stimuli were comparable to those to attended ones 50--55 ms after
stimulus onset. After that, however, the ERPs to attended stimuli were
greater than those to unattended stimuli. Thus, selective attention
influences all but the very early stages of processing. As we have all
discovered to our cost, it is often hard (or impossible) to ignore
task-irrelevant stimuli. Below we consider factors determining whether
task performance is adversely affected by distracting stimuli.

Load theory Lavie's (2005, 2010) load theory has been an influential
approach to understanding distraction effects. It distinguishes between
perceptual

189

190

Visual perception and attention

and cognitive load. Perceptual load refers to the perceptual demands of
a current task. Cognitive load refers to the burden placed on the
cognitive system by a current task (e.g., demands on working memory).
Tasks involving high perceptual load require nearly all our perceptual
capacity whereas low-load tasks do not. With low-load tasks there are
spare attentional resources, and so task-irrelevant stimuli are more
likely to be processed. In contrast, tasks involving high cognitive load
reduce our ability to use cognitive control to discriminate between
target and distractor stimuli. Thus, high perceptual load is associated
with low distractibility, whereas high cognitive load is associated with
high distractibility.

Findings There is much support for the hypothesis that high perceptual
load reduces distraction effects. Forster and Lavie (2008) presented six
letters in a circle and participants decided which target letter (X or
N) was present. The five non-target letters resembled the target letter
more closely in the high-load condition. On some trials a picture of a
cartoon character (e.g., Spongebob Squarepants) was presented as a
distractor outside the circle. Distractors interfered with task
performance only under low-load conditions. According to the theory,
brain activation associated with distractors should be less when
individuals are performing a task involving high perceptual load. This
finding has been obtained with visual tasks and distractors (e.g.,
Schwartz et al., 2005) and also with auditory tasks and distractors
(e.g., Sabri et al., 2013). Why is low perceptual load associated with
high distractibility? Biggs and Gibson (2018) argued this happens
because observers generally adopt a broad attentional focus when
perceptual load is low. They tested this hypothesis using three low-load
conditions in which participants decided whether a target X or N was
presented and a distractor letter was sometimes presented (see Figure
5.5). They argued that observers would adopt the smallest attentional
focus in the circle condition and the largest attentional focus in the
solo condition. As predicted, distractor interference was greatest in
the solo condition and least in the circle condition. Thus, distraction
effects depend strongly on size of attentional focus as well as
perceptual load. The hypothesis that distraction effects should be
greater when cognitive or working memory load is high rather than low
was tested by Burnham et al. (2014). As predicted, distraction effects
on a visual search task were

Figure 5.5 Sample displays for three low perceptual load conditions in
which the task required deciding whether a target X or N was presented.
See text for further details. From Biggs and Gibson (2018).

Standard condition

Solo condition

X

X

- 

Circle condition

X

- T

- 

- 

- 

- 

- 

- 

- 

T

T \*

Attention and performance

greater when participants performed another task placing high demands on
the cognitive system. Sörqvist et al. (2016) argued high cognitive load
can reduce rather than increase distraction. They pointed out that
cognitive load is typically associated with high levels of concentration
and our everyday experience indicates high concentration generally
reduces distractibility. As predicted, they found neural activation
associated with auditory distractors was reduced when cognitive load on
a visual task was high rather than low. The effects of cognitive load on
distraction are very variable. How can we explain this variability?
Sörqvist et al. (2016) argued that an important factor is how easily
distracting stimuli can be distinguished from task stimuli. When it is
easy (e.g., task and distracting stimuli are in different modalities as
in the Sörqvist et al., 2016, study), high cognitive load reduces
distraction. In contrast, when it is hard to distinguish between task
and distracting stimuli (e.g., they are similar and/or in the same
modality), then high cognitive load increases distraction. Load theory
assumes the effects of perceptual and cognitive load are independent.
However, Linnell and Caparos (2011) found perceptual and cognitive
processes interacted: perceptual load only influenced attention as
predicted when cognitive load was low. Thus, the effects of perceptual
load are not "automatic" as assumed theoretically but instead depend on
cognitive resources being available.

Evaluation The distinction between perceptual and cognitive load has
proved useful in predicting when distraction effects will be small or
large. More specifically, the prediction that high perceptual load is
associated with reduced distraction effects has received much empirical
support. In applied research, load theory successfully predicts several
aspects of drivers' attention and behaviour (Murphy & Greene, 2017). For
example, drivers exposed to high perceptual load responded more slowly
to hazards and drove less safely. What are the theory's limitations?
First, the terms "perceptual load" and "cognitive load" are vague,
making it hard to test the theory (Murphy et al., 2016). Second, the
assumption that perceptual and cognitive load have separate effects on
attention is incorrect (Linnell & Caparos, 2011). Third, perceptual load
and attentional breadth are often confounded. Fourth, the prediction
that high cognitive load is associated with high distractibility has
been disproved when task and distracting stimuli are easily
distinguishable. Fifth, the theory de-emphasises several relevant
factors including the salience or conspicuousness of distracting stimuli
and the spatial distance between distracting and task stimuli (Murphy et
al., 2016).

Major attention networks As we saw in Chapter 1, many cognitive
processes are associated with networks spread across relatively large
areas of cortex rather than small, specific regions. With respect to
attention, several theorists (e.g., Posner, 1980; Corbetta & Shulman,
2002) have argued there are two major networks.

191

192

Visual perception and attention

KEY TERM

One attention network is goal-directed or endogenous whereas the other
is stimulus-driven or exogenous.

Covert attention Attention to an object in the absence of an eye
movement towards it.

Posner's (1980) approach Posner (1980) studied covert attention in which
attention shifts to a given spatial location without an accompanying eye
movement. In his research, people responded rapidly to a light. The
light was preceded by a central cue (arrow pointing to the left or
right) or a peripheral cue (brief illumination of a box outline). Most
cues were valid (i.e., indicating where the target light would appear)
but some were invalid (i.e., providing inaccurate information about the
light's location). Responses to the light were fastest to valid cues,
intermediate to neutral cues (a central cross) and slowest to invalid
cues. The findings were comparable for central and peripheral cues. When
the cues were valid on only a small fraction of trials, they were
ignored when they were central cues. However, they influenced
performance when they were peripheral cues. The above findings led
Posner (1980) to distinguish between two attention systems: (1) (2)

An endogenous system: it is controlled by the individual's intentions
and is used when central cues are presented. An exogenous system: it
automatically shifts attention and is involved when uninformative
peripheral cues are presented. Stimuli that are salient or different
from other stimuli (e.g., in colour) are most likely to be attended to
using this system.

Corbetta and Shulman's (2002) approach Corbetta and Shulman (2002)
identified two attention systems that are involved in basic aspects of
visual processing. First, there is a goal-directed or top-down system
resembling Posner's endogenous system. This dorsal attention network
consists of a fronto-parietal network including the intraparietal
sulcus. It is influenced by expectations, knowledge and current goals.
It is used when a cue predicts the location or other feature of a
forthcoming visual stimulus. Second, Corbetta and Shulman (2002)
identified a stimulus-driven or bottom-up attention system resembling
Posner's exogenous system. This is the ventral attention network and
consists primarily of a right-hemisphere ventral fronto-parietal
network. This system is used when an unexpected and potentially
important stimulus (e.g., flames appearing under the door) occurs. Thus,
it has a "circuit-breaking" function, meaning visual attention is
redirected from its current focus. What stimuli trigger this
circuitbreaking? According to Corbetta et al. (2008), non-task stimuli
(i.e., distractors) closely resembling task stimuli are especially
likely to activate the ventral attention network although salient or
conspicuous stimuli also activate the same network. Corbetta and Shulman
(2011; see Figure 5.6) identified the brain areas associated with each
network. Key areas within the dorsal attention network are as follows:
superior parietal lobule (SPL), intraparietal sulcus

Attention and performance

193 Figure 5.6 The brain areas associated with the dorsal or
goaldirected attention network and the ventral or stimulusdriven
network. The full names of the areas involved are indicated in the text.
From Corbetta and Shulman (2011). © Annual Reviews. With permission of
Annual Reviews.

(IPS), inferior frontal junction (IFJ), frontal eye field (FEF), middle
temporal area (MT) and V3A (a visual area). Key areas within the ventral
attention network are as follows: inferior frontal junction (IFJ),
inferior frontal gyrus (IFG), supramarginal gyrus (SMG), superior
temporal gyrus (STG) and insula (Ins). The temporo-parietal junction
also forms part of the ventral attention network. The existence of two
attention networks makes much sense. The goal-directed system (dorsal
attention network) allows us to attend to stimuli directly relevant to
our current goals. If we only had this system, however, our attentional
processes would be dangerously inflexible. It is also important to have
a stimulus-driven attentional system (ventral attention network) leading
us to switch attention away from goal-relevant stimuli to unexpected
threatening stimuli (e.g., a ferocious animal). More generally, the two
attention networks typically interact effectively with each other.

Findings Corbetta and Shulman (2002) supported their two-network model
by carrying out meta-analyses of brain-imaging studies. In essence, they
argued, brain areas most often activated when participants expect a
stimulus that has not yet been presented form the dorsal attention
network. In contrast, brain areas most often activated when individuals
detect low-frequency targets form the ventral attention network. Hahn et
al. (2006) tested Corbetta and Shulman's (2002) theory by comparing
patterns of brain activation when top-down and bottom-up processes were
required. As predicted, there was little overlap between the brain areas
associated with top-down and bottom-up processing. In addition, the
brain areas involved in each type of processing corresponded reasonably
well to those identified by Corbetta and Shulman. Chica et al. (2013)
reviewed research on the two attention systems and identified 15
differences between them. For example, stimulus-driven attention is
faster than top-down attention and is more object-based. In addition, it
is more resistant to interference from other peripheral cues once
activated. The existence of so many differences strengthens the argument
the two attentional systems are separate. Considerable research evidence
(mostly involving neuroimaging) indicates the dorsal and ventral
attention systems are associated with distinct

194

Visual perception and attention

neural circuits even during the resting state (Vossel et al., 2014).
However, neuroimaging studies cannot establish that any given brain area
is necessarily involved in stimulus-driven or goal-directed attention
processes. Chica et al. (2011) provided relevant evidence by using
transcranial magnetic stimulation (TMS; see Glossary) to interfere with
processing in a given brain area. TMS applied to the right
temporo-parietal junction impaired the functioning of the
stimulus-driven system but not the top-down one. In the same study,
Chica et al. (2011) found TMS applied to the right intraparietal sulcus
impaired the functioning of both attention systems. This provides
evidence of the two attention systems working together. Evidence from
brain-damaged patients (discussed below, see pp. 196--200) is also
relevant to establishing the brain areas necessarily involved in
goaldirected or stimulus-driven attentional processes. Shomstein et
al. (2010) had brain-damaged patients complete two tasks, one requiring
stimulusdriven attentional processes whereas the other required top-down
processes. Patients having greater problems with top-down attentional
processing typically had brain damage to the superior parietal lobule
(part of the dorsal attention network). In contrast, patients having
greater problems with stimulus-driven attentional processing typically
had brain damage to the temporo-parietal junction (part of the ventral
attention network). Wen et al. (2012) investigated interactions between
the two visual attention systems. They assessed brain activation while
participants responded to target stimuli in one visual field while
ignoring all stimuli in the unattended visual field. There were two main
findings. First, stronger causal influences of the top-down system on
the stimulus-driven system led to superior performance on the task. This
finding suggests the appearance of an object at the attended location
caused the top-down attention system to suppress activity within the
stimulus-driven system. Second, stronger causal influences of the
stimulus-driven system on the top-down system were associated with
impaired task performance. This finding suggests activation within the
stimulus-driven system produced by stimuli not in attentional focus
disrupted the attentional set maintained by the top-down system.

Recent developments Corbetta and Shulman's (2002) theoretical approach
has been developed in recent years. Here we briefly consider three such
developments. First, we now have a greater understanding of interactions
between their two attention networks. Meyer et al. (2018) found
stimulus-driven and goal-directed attention both activated frontal and
parietal regions within the dorsal attention network, suggesting it has
a pivotal role in integrating bottom-up and top-down processing. Second,
previous research reviewed by Corbetta and Shulman (2002) indicated the
dorsal attention network is active immediately prior to the presentation
of an anticipated visual stimulus. However, this research did not
indicate how long this attention network remained active. Meehan et
al. (2017) addressed this issue and discovered that top-down influences
associated within the dorsal attention network persisted over a
relatively long time period.

Attention and performance

Third, brain networks relevant to attention additional to those within
Corbetta and Shulman's (2002) theory have been identified (Sylvester et
al., 2012). One such network is the cingulo-opercular network including
the anterior insula/operculum and dorsal anterior cingulate cortex
(dACC; see Figure 5.7). This network is associated with non-selective
attention or alertness (Coste & Kleinschmidt, 2016). Another additional
network is the default mode network including the posterior cingulate
cortex (PCC), the lateral parietal cortex (LP), the inferior temporal
cortex (IT), the medial prefrontal cortex (MPF) and the subgenual
anterior cingulate cortex (sgACC). The default mode network is activated
during internally focused cognitive processes (e.g., mindwandering;
imagining the future). What is the relevance of this network to
attention? In essence, performance on tasks requiring externally focused
attention is often enhanced if the default mode network is deactivated
(Amer et al., 2016a). Finally, there is the fronto-parietal network
(Dosenbach et al., 2008), which includes the anterior dorsolateral
prefrontal cortex (aDLPFC), the

(a) 

195

KEY TERM Default mode network A network of brain regions that is active
"by default" when an individual is not involved in a current task; it is
associated with internal processes including mindwandering, remembering
the past and imagining the future.

IPS

aDLPFC

TPJ LP

VLPFC anterior insula

IT

(b) 

MCC dACC PCC MPF

sgACC

Networks

Key:

Fronto-parietal

Default mode

Cingulo-opercular

Ventral attention

Figure 5.7 This is part of a theoretical approach based on several
functional networks of relevance to attention: the four networks shown
(fronto-parietal; default mode; cingulo-opercular; and ventral
attention) are all discussed fully in the text. Sylvester et al., 2012,
p. 528. Reprinted with permission of Elsevier.

196

Visual perception and attention

KEY TERMS

middle cingulate cortex (MCC) and the intraparietal sulcus (IPS). It is
associated with top-down attentional and cognitive control.

Neglect A disorder involving right-hemisphere damage (typically) in
which the left side of objects and/ or objects presented to the left
visual field are undetected; the condition resembles extinction but is
more severe. Pseudo-neglect A slight tendency in healthy individuals to
favour the left side of visual space.

Evaluation The theoretical approach proposed by Corbetta and Shulman
(2002) has several successes to its credit. First, there is convincing
evidence for somewhat separate stimulus-driven and top-down attention
systems, each with its own brain network. Second, research using
transcranial magnetic stimulation suggests major brain areas within each
attention system play a causal role in attentional processes. Third,
some interactions between the two networks have been identified. Fourth,
research on brain-damaged patients supports the theoretical approach
(see next section, pp. 196--200). What are the limitations of this
theoretical approach? First, the precise brain areas associated with
each attentional system have not been clearly identified. Second, there
is more commonality (especially within the parietal lobe) in the brain
areas associated with the two attention networks than assumed
theoretically by Corbetta and Shulman (2002). Third, there are
additional attention-related brain networks not included within the
original theory. Fourth, much remains to be discovered about how
different attention systems interact.

DISORDERS OF VISUAL ATTENTION Here we consider two important attentional
disorders in brain-damaged individuals: neglect and extinction. Neglect
(or spatial neglect) involves a lack of awareness of stimuli presented
to the side of space on the opposite side to the brain damage (the
contralesional side). This occurs because information from the left side
of the visual field proceeds to the right hemisphere. Most neglect
patients have damage in the right hemisphere and so lack awareness of
stimuli on the left side of the visual field: space-based or egocentric
neglect. For example, patients crossing out targets presented to their
left or right side (cancellation task) cross out more of those presented
to the right. When instructed to mark the centre of a horizontal line
(line bisection task), patients put it to the right of the centre. Note
that the right hemisphere is dominant in spatial attention in healthy
individuals -- they exhibit pseudo-neglect, in which the left side of
visual space is favoured (Friedrich et al., 2018). There is also
object-centred or allocentric neglect involving a lack of awareness of
the left side of objects (see Figure 5.8). Patients with
right-hemisphere damage typically draw the right side of all figures in
a multi-object scene but neglect their left side in the left and right
visual fields (Gainotti & Ciaraffa, 2013). Do allocentric and egocentric
neglect reflect a single disorder or separate disorders? Rorden et
al. (2012) obtained two findings supporting the single disorder
explanation. First, the correlation between the extent of each form of
neglect across 33 patients was +.80. Second, similar brain regions were
associated with each type of neglect. However, Pedrazzini et al. (2017)
found damage to the intraparietal sulcus was more associated

Attention and performance

197 Figure 5.8 On the left is a copying task in which a patient with
unilateral neglect distorted or ignored the left side of the figures to
be copied (shown on the left). On the right is a clock drawing task in
which the patient was given a clock face and told to insert the numbers
into it. Reprinted from Danckert and Ferber (2006). Reprinted with
permission from Elsevier.

with allocentric than egocentric neglect, whereas the opposite was the
case with damage to the temporo-parietal junction. Extinction is often
found in neglect patients. Extinction involves a failure to detect a
stimulus presented to the side opposite the brain damage when a second
stimulus is presented to the same side as the brain damage. Extinction
and neglect are closely related but separate deficits (de Haan et al.,
2012). We will focus mostly on neglect because it has attracted much
more research. Which brain areas are damaged in neglect patients?
Neglect is a heterogeneous condition and the brain areas damaged vary
considerably across patients. In a meta-analysis, Molenberghs et
al. (2012) found the main areas damaged in neglect patients are in the
right hemisphere and include the superior temporal gyrus, the inferior
frontal gyrus, the insula, the supramarginal gyrus and the angular gyrus
(gyrus means ridge). Nearly all these areas are within the
stimulus-driven or ventral attention network (see Figure 5.6) suggesting
brain networks are damaged rather than simply specific brain areas
(Corbetta & Shulman, 2011). We also need to consider functional
connectivity (correlated brain activity between brain regions).
Baldassarre et al. (2014, 2016) discovered widespread disruption of
functional connectivity between the hemispheres in neglect patients.
This disruption did not involve the bottom-up and topdown attention
networks. Of importance, recovery from attention deficits in neglect
patients was associated with improvements in functional connectivity in
bottom-up and top-down attention networks (Ramsey et al., 2016). The
right-hemisphere temporo-parietal junction and intraparietal sulcus are
typically damaged in extinction patients (de Haan et al., 2012). When
transcranial magnetic stimulation is applied to these areas to interfere
with processing, extinction-like behaviour results (de Haan et al.,
2012). Dugué et al. (2018) confirmed the importance of the
temporo-parietal junction

Interactive feature: Primal Pictures' 3D atlas of the brain

KEY TERM Extinction A disorder of visual attention in which a stimulus
presented to the side opposite the brain damage is not detected when
another stimulus is presented at the same time to the side of the brain
damage.

198

Visual perception and attention

(part of the ventral attention network) in control of spatial attention
in a neuroimaging study on healthy individuals. However, its subregions
varied in terms of their involvement in voluntary and involuntary
attention shifts.

Conscious awareness and processing Neglect patients generally report no
conscious awareness of stimuli presented to the left visual field.
However, that does not necessarily mean those stimuli are not processed.
Vuilleumier et al. (2002b) presented extinction patients with two
pictures at the same time, one to each visual field. The patients showed
very little memory for left-field stimuli. Then the patients identified
degraded pictures. There was a facilitation effect for left-field
pictures indicating they had been processed. Vuilleumier et al. (2002a)
presented GK, a male patient with neglect and extinction, with fearful
faces. He showed increased activation in the amygdala (associated with
emotional responses) whether or not these faces were consciously
perceived. This is explicable given there is a processing route from the
retina to the amygdala bypassing the cortex (Diano et al., 2017). Sarri
et al. (2010) found extinction patients had no awareness of leftfield
stimuli. However, these stimuli were associated with activation in early
visual processing areas, indicating they received some processing.
Processing in neglect and extinction has been investigated using
event-related potentials. Di Russo et al. (2008) focused on the
processing of left-field stimuli not consciously perceived by neglect
patients. Early processing of these stimuli was comparable to that of
healthy controls with only later processing being disrupted. Lasaponara
et al. (2018) obtained similar findings in neglect patients. In healthy
individuals, the presentation of left-field targets inhibits processing
of right-field space. This was less the case in neglect patients, which
helps to explain their lack of conscious perception of left-field
stimuli.

Theoretical considerations Corbetta and Shulman (2011) discussed neglect
in the context of their two-system theory (discussed earlier, see
pp. 192--196). In essence, the bottom-up ventral attention network is
damaged. Strong support for this assumption was reported by Toba et
al. (2018a) who found in 25 neglect patients that impaired performance
on tests of neglect was associated with damage to parts of the ventral
attention network (e.g., angular gyrus; supramarginal gyrus). Since the
right hemisphere is dominant in the ventral attention network, neglect
patients typically have damage in that hemisphere. Of importance,
Corbetta and Shulman (2011) also assumed that damage to the ventral
network impairs the functioning of the goal-directed dorsal attention
network (even though not itself damaged). How does the damaged ventral
attention network impair the dorsal attention network's functioning? The
two attention networks interact and so damage to the ventral network
inevitably affects the functioning of the dorsal network. More
specifically, damage to the ventral attention network "impairs
non-spatial \[across the entire visual field\] functions, hypoactivates

Attention and performance

\[reduces activation in\] the right hemisphere, and unbalances the
activity of the dorsal attention network" (Corbetta & Shulman, 2011,
p. 592). de Haan et al. (2012) proposed a theory of extinction based on
two major assumptions: (1) (2)

"Extinction is a consequence of biased competition for attention between
the ipsilesional \[right-field\] and contralesional \[left-field\]
target stimuli" (p. 1048); Extinction patients have much reduced
attentional capacity so often only one target \[the right-field one\]
can be detected.

Findings According to Corbetta and Shulman (2011), the dorsal attention
network in neglect patients functions poorly because of reduced
activation in the right hemisphere and associated reduced alertness and
attentional resources. Thus, increasing patients' general alertness
should enhance their detection of left-field visual targets. Robertson
et al. (1998) found the slower detection of left visual field stimuli
compared to those in the right visual field was no longer present when
warning sounds were used to increase alertness. Bonato and Cutini (2016)
compared neglect patients' ability to detect visual targets with (or
without) a second, attentionally demanding task. Detection rates were
high for targets presented to the right visual field in both conditions.
In contrast, patients detected only approximately 50% as many targets in
the left visual field as the right when performing another task. Thus,
neglect patients have limited attentional resources. Corbetta and
Shulman (2011) assumed neglect patients have an essentially intact
dorsal attention network. Accordingly, neglect patients might use that
network effectively if steps were taken to facilitate its use. Duncan et
al. (1999) presented arrays of letters and neglect patients recalled
only those in a pre-specified colour (the dorsal attention network could
be used to select the appropriate letters). Neglect patients resembled
healthy controls in showing equal recall of letters presented to each
side of visual space. The two attention networks typically work closely
together. Bays et al. (2010) studied neglect patients. They used eye
movements during a visual search to assess patients' problems with
top-down and stimulus-driven attentional processes. Both types of
attentional processes were equally impaired (as predicted by Corbetta
and Shulman, 2011). Of most importance, there was a remarkably high
correlation of +.98 between these two types of attentional deficit. Toba
et al. (2018b) identified two reasons for the failure of neglect
patients to detect left-field stimuli: (1) (2)

a "magnetic" attraction of attention (i.e., right-field stimuli
immediately capture attention). impaired spatial working memory making
it hard for patients to keep track of the locations of stimuli.

Both reasons were equally applicable to most patients. However, the
first reason was dominant in 12% of patients and the second reason in

199

200

KEY TERM Visual search A task involving the rapid detection of a
specified target stimulus within a visual display.

Visual perception and attention

24% of patients. Accordingly, Toba et al. argued we should develop
multi-component models of visual neglect to account for such individual
differences. We turn now to extinction patients. According to de Haan et
al. (2012), extinction occurs because of biased competition between
stimuli. If two stimuli could be integrated, that might minimise
competition and so reduce extinction. Riddoch et al. (2006) tested this
prediction by presenting objects used together often (e.g., wine bottle
and wine glass) or never used together (e.g., wine bottle and ball).
Extinction patients identified both objects more often in the former
condition than the latter (65% vs 40%, respectively). The biased
competition hypothesis has been tested in other ways. We can impair
attentional processes in the intact left hemisphere by applying
transcranial magnetic stimulation to it. This should reduce competition
from the left hemisphere in extinction patients and thus reduce
extinction. Some findings are consistent with this prediction (Oliveri &
Caltagirone, 2006). de Haan et al. (2012) also identified reduced
attentional capacity as a factor causing extinction. Bonato et
al. (2010) studied extinction with or without the addition of a second,
attentionally demanding task. As predicted, extinction patients showed a
substantial increase in the extinction rate (from 18% to over 80%) with
this additional task.

Overall evaluation Research has produced several important findings.
First, neglect and extinction patients can process unattended visual
stimuli in the absence of conscious awareness of those stimuli. Second,
most neglect patients have damage to the ventral attention network
leading to impaired functioning of the undamaged dorsal attention
network. Third, extinction occurs because of biased competition for
attention and reduced attentional capacity. What are the limitations of
research in this area? First, it is hard to produce theoretical accounts
applicable to all neglect or extinction patients because the precise
symptoms and regions of brain damage vary considerably across patients.
Second, neglect patients vary in their precise processing deficits
(e.g., Toba et al., 2018b), but this has been de-emphasised in most
theories. Third, the precise relationship between neglect and extinction
remains unclear. Fourth, the dorsal and ventral networks generally
interact but the extent of their interactions remains to be determined.

VISUAL SEARCH We spend much time searching for various objects (e.g., a
friend in a crowd). The processes involved have been studied in research
on visual search where a specified target is detected as rapidly as
possible. Initially, we consider an important real-world situation where
visual search can be literally a matter of life-or-death: airport
security checks. After that, we consider an early very influential
theory of visual search before discussing more recent theoretical and
empirical developments.

Attention and performance

201

IN THE REAL WORLD: AIRPORT SECURITY CHECKS Airport security checks have
become more thorough since 9/11. When your luggage is x-rayed, an
airport security screener searches for illegal and dangerous items (see
Figure 5.9). Screeners are well trained but mistakes sometimes occur.

Figure 5.9 Each bag contains one illegal item. From left to right: a
large bottle; a dynamite stick; and a gun part. From Mitroff & Biggs
(2014).

There are two major reasons it is often hard for airport security
screeners to detect dangerous items. First, illegal and dangerous items
are (thankfully!) present in only a minute fraction of passengers'
luggage. This rarity of targets makes it hard for airport security
screeners to detect them. Mitroff and Biggs (2014) asked observers to
detect illegal items in bags (see Figure 5.9). The detection rate was
only 27% when targets appeared under 0.15% of the time: they termed this
the "ultra rare item effect". In contrast, the detection rate was 92%
when targets appeared more than 1% of the time. Peltier and Becker
(2016) tested two explanations for the reduced detection rate with rare
targets: (1) a reduced probability that the target is fixated (selection
error); and (2) increased caution about reporting targets because they
are so unexpected (identification error). There was evidence for both
explanations. However, most detection failures were selection errors
(see Figure 5.10).

Accuracy

Accuracy 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0

Target present

10

50

Target absent

90

Prevalence

Figure 5.10 Frequency of selection and identification errors when
targets were present on 10%, 50% or 90% of trials. From Peltier and
Becker (2016).

202

Visual perception and attention

Second, security screeners search for numerous different objects. This
increases search difficulty. Menneer et al. (2009) found target
detection was worse when screeners searched for two categories of
objects (metal threats and improvised explosive devices) rather than
one. How can we increase the efficiency of security screening? First, we
can exploit individual differences in the ability to detect targets.
Rusconi et al. (2015) found individuals scoring high on a questionnaire
measure of attention to detail had superior target-detection performance
than low scorers. Second, airport security screeners can find it hard to
distinguish between targets (i.e., dangerous items) and similar-looking
non-targets. Geng et al. (2017) found that observers whose training
included non-targets resembling targets learned to develop increasingly
precise internal target representations. Such representations can
improve the speed and accuracy of security screening. Third, the low
detection rate when targets are very rare can be addressed. Threat image
projection (TIP) can be used to project fictional threat items into
x-ray images of luggage to increase the apparent frequency of targets.
When screeners are presented with TIPs plus feedback when they miss
them, screening performance improves considerably (Hofer & Schwaninger,
2005). In similar fashion, Schwark et al. (2012) found providing false
feedback to screeners to indicate they had missed rare targets reduced
their cautiousness about reporting targets and improved their
performance.

Feature integration theory Feature integration theory was proposed by
Treisman and Gelade (1980) and subsequently updated and modified (e.g.,
Treisman, 1998). According to the theory, we need to distinguish between
object features (e.g., colour; size; line orientation) and the objects
themselves. There are two processing stages: (1) (2)

KEY TERM Illusory conjunction Mistakenly combining features from two
different stimuli to perceive an object that is not present.

Basic visual features are processed rapidly and pre-attentively in
parallel across the visual scene. Stage (1) is followed by a slower
serial process with focused attention providing the "glue" to form
objects from the available features (e.g., an object that is round and
has an orange colour is perceived as an orange). In the absence of
focused attention, features from different objects may be combined
randomly producing an illusory conjunction.

It follows from the above assumptions that targets defined by a single
feature (e.g., a blue letter or an S) should be detected rapidly and in
parallel. In contrast, targets defined by a conjunction or combination
of features (e.g., a green letter T) should require focused attention
and so should be slower to detect. Treisman and Gelade (1980) tested
these predictions using both types of targets; the display size was
1--30 items and a target was present or absent. As predicted, response
was rapid and there was very little effect of display size when the
target was defined by a single feature: these findings suggest parallel
processing (see Figure 5.11). Response was slower and was strongly
influenced by display size when the target was defined by a conjunction
of features: these findings suggest there was serial processing.
According to the theory, lack of focused attention can produce illusory
conjunctions based on random combinations of features. Friedman-Hill

Attention and performance

203 Figure 5.11 Performance speed on a detection task as a function of
target deﬁnition (conjunctive vs single feature) and display size.
Adapted from Treisman and Gelade (1980).

et al. (1995) studied a brain-damaged patient (RM) having problems with
the accurate location of visual stimuli. This patient produced many
illusory conjunctions combining the shape of one stimulus with the
colour of another.

Limitations What are the theory's limitations? First, Duncan and
Humphreys (1989, 1992) identified two factors not included within
feature integration theory: (1) (2)

When distractors are very similar to each other, visual search is faster
because it is easier to identify them as distractors. The number of
distractors has a strong effect on search time to detect even targets
defined by a single feature when targets resemble distractors.

Second, Treisman and Gelade (1980) estimated the search time with
conjunctive targets was approximately 60 ms per item and argued this
represented the time taken for focal attention to process each item.
However, research with other paradigms indicates it takes approximately
250 ms for attention indexed by eye movements to move from one location
to another. Thus, it is improbable focal attention plays the key role
assumed within the theory. Third, the theory assumes visual search is
often item-by-item. However, the information contained within most
visual scenes cannot be divided up into "items" and so the theory is of
limited applicability. Such considerations led Hulleman and Olivers
(2017) to produce an article entitled "The impending demise of the item
in visual search". Fourth, visual search involves parallel processing
much more than implied by the theory. For example, Thornton and Gilden
(2007) used 29 different visual tasks and found 72% apparently involved
parallel

204

Visual perception and attention

processing. We can explain such findings by assuming that each eye
fixation permits considerable parallel processing using information
available in peripheral vision (discussed below, see pp. 206--208).
Fifth, the theory assumes that the early stages of visual search are
entirely feature-based. However, recent research using event-related
potentials indicates that object-based processing can occur much faster
than predicted by feature integration theory (e.g., Berggren & Eimer,
2018). Sixth, the theory assumes visual search is essentially random.
This assumption is wrong with respect to the real world -- we typically
use our knowledge of where a target object is likely to be located when
searching for it (see below).

Dual-path model In most of the research discussed so far, the target
appeared at a random location within the visual display. This is
radically different from the real world. Suppose you are outside looking
for your missing cat. Your visual search would be very selective -- you
would ignore the sky and focus mostly on the ground (and perhaps the
trees). Thus, your search would involve top-down processes based on your
knowledge of where cats are most likely to be found. Ehinger et
al. (2009) studied top-down processes in visual search by recording eye
fixations of observers searching for a person in 900 realworld outdoor
scenes. Observers typically fixated plausible locations (e.g.,
pavements) and ignored implausible ones (e.g., sky; trees; see Figure
5.12). Observers also fixated locations differing considerably from
neighbouring locations and areas containing visual features resembling
those of a human figure. How can we reconcile Ehinger et al.'s (2009)
findings with those discussed earlier? Wolfe et al. (2011) proposed a
dual-path model (see Figure 5.13). There is a selective pathway of
limited capacity (indicated by the bottleneck) with objects being
selected individually for recognition.

Figure 5.12 The first three eye fixations made by observers searching
for pedestrians. As can be seen, the great majority of their fixations
were on regions in which pedestrians would most likely be found.
Observers' fixations were much more like each other in the lefthand
photo than in the right-hand one, because there were fewer likely
regions in the left-hand one. From Ehinger et al. (2009). Reprinted with
permission from Taylor & Francis.

Attention and performance

ve

p

e

ns

No

Early vision

ti lec

y wa h t a

Features

thway ive pa Select

Color Orientation Size Depth Motion Etc.

205 Figure 5.13 A two-pathway model of visual search. The selective
pathway is capacity limited and can bind stimulus features and recognise
objects. The non-selective pathway processes the gist of scenes.
Selective and non-selective processing occur in parallel to produce
effective visual search. From Wolfe et al. (2011). Reprinted with
permission from Elsevier.

Binding and recognition

This pathway has been the focus of most research until recently. There
is also a non-selective pathway in which the "gist" of a scene is
processed. Such processing can then guide processing within the
selective pathway (represented by the arrow labelled "guidance"). This
pathway allows us to utilise our stored environmental knowledge and so
is of great value in the real world.

Findings Wolfe et al. (2011) compared visual searches for objects
presented within a scene setting or at random locations. As predicted,
search rate per item was much faster in the scene setting (10 ms vs 40
ms, respectively). Võ and Wolfe (2012) explained that finding in terms
of "functional set size" -- searching in scenes is efficient because
most regions can be ignored. As predicted, Võ and Wolfe found 80% of
each scene was rarely fixated. Kaiser and Cichy (2018) presented
observers with objects typically located in the upper (e.g., aeroplane;
hat) or lower (e.g., carpet; shoe) visual field. These objects were
presented in their typical or atypical location (e.g., hat in the lower
visual field). Observers had to indicate whether an object presented
very briefly was located in the upper or lower visual field. Observers'
performance was better when objects appeared in their typical location
because of their extensive knowledge of where objects are generally
located. Chukoskie et al. (2013) found observers can easily learn where
targets are located. An invisible target was presented at random
locations on a blank screen and observers were provided with feedback.
There was a strong learning effect -- fixations rapidly shifted from
being fairly

206

KEY TERM Fovea A small area within the retina in the centre in the field
of vision where visual acuity is greatest.

Visual perception and attention

random to being focused on the area within which the target might be
present. Ehinger et al.'s (2009) findings (discussed earlier, see
p. 204) suggested that scene gist or context can be used to enhance the
efficiency of visual search. Katti et al. (2017) presented scenes very
briefly (83 ms) followed by a mask. Observers were given the task of
detecting a person or a car and performed very accurately (over 90%) and
rapidly. Katti et al. confirmed that scene gist or context influenced
performance. However, performance was influenced more strongly by
features of the target object -- the more key features of an object were
visible, the faster it was detected. What is the take-home message from
the above study? The efficiency of visual search with real-world scenes
is more complex than implied by Ehinger et al. (2009). More
specifically, observers may rapidly fixate on the area close to a target
person because they are using scene gist or because they rapidly process
features of the person (e.g., wearing clothes).

Evaluation Our knowledge of likely (and unlikely) locations for any
given object in a scene influences visual search in the real world. This
is fully acknowledged in the dual-path model. There is also support for
the notion that scene knowledge facilitates visual search by reducing
functional set size. What are the model's limitations? First, how we use
gist knowledge of a scene very rapidly to reduce the search area remains
unclear. Second, there is insufficient focus on the learning processes
that can greatly facilitate visual search -- the effects of such
processes can be seen in the very rapid and accurate detection of target
information by experts in several domains (see Chapter 11). Third, it is
important not to exaggerate the importance of scene gist or context in
influencing the efficiency of visual search. Features of the target
object can influence visual search more than scene gist (Katti et al.,
2017). Fourth, the assumption that items are processed individually
within the selective pathway is typically mistaken. As we will see
shortly, visual search often depends on parallel processes within
peripheral vision and such processes are not considered within the
model.

Attention vs perception: texture tiling model Several theories (e.g.,
Treisman & Gelade, 1980) have assumed that individual items are the
crucial units in visual search. Such theories have also often assumed
that slow visual search depends mostly on the limitations of focused
attention. A plausible implication of these assumptions is that slow
visual search depends mostly on foveal vision (the fovea is a small area
of maximal visual acuity in the retina). Both the above assumptions have
been challenged recently. At the risk of oversimplification, full
understanding of visual search requires less emphasis on attention and
more on perception. According to Rosenholtz (2016), peripheral
(non-foveal) vision is of crucial importance. Acuity decreases as we
move away from the fovea to the periphery of vision, but much less than
often assumed. You can demonstrate this by holding out

Attention and performance

your thumb and fixating the nail. Foveal vision only covers the nail so
the great majority of what you can see is in peripheral vision. We can
also compare the value of foveal and peripheral vision by considering
individuals with impaired eyesight. Those with severely impaired
peripheral vision (e.g., due to glaucoma) had greater problems with
mobility (e.g., number of falls; ability to drive) than those who lack
foveal vision (due to macular degeneration) (Rosenholtz, 2016).
Individuals with severely impaired central or foveal vision performed
almost as well as healthy controls at detecting target objects in
coloured scenes (75% vs 79%, respectively) (Thibaut et al., 2018). If
visual search depends heavily on peripheral vision, what predictions can
we make? First, if each fixation provides observers with a considerable
amount of information about several objects, visual search will
typically involve parallel rather than serial processing. Second, we
need to consider limitations of peripheral vision (e.g., visual acuity
is less in peripheral than foveal vision). However, a more important
limitation concerns visual crowding -- a reduced ability to recognise
objects or other stimuli because of irrelevant neighbouring objects or
stimuli (clutter). Visual crowding impairs peripheral vision to a much
greater extent than foveal vision. Rosenholtz et al. (2012) proposed the
texture tiling model based on the assumption peripheral vision is of
crucial importance in visual search. More specifically, processing in
peripheral vision can cause adjacent stimuli to tile (join together) to
form an apparent target, thus increasing the difficulty of visual
search. Below we consider findings relevant to this model.

Findings As mentioned earlier (p. 203), Thornton and Gilden (2007) found
almost three-quarters of the visual tasks they studied involved parallel
processing. This is entirely consistent with the emphasis on parallel
processing in the model. Direct evidence for the importance of
peripheral vision to visual search was reported by Young and Hulleman
(2013). They manipulated the visible area around the fixation point
making it small, medium or large. As predicted by the model, visual
search performance was worst when the visible area was small (so only
one item could be processed per fixation). Overall, visual search was
almost parallel when the visible area was large but serial when it was
small. Chang and Rosenholtz (2016) used various search tasks. According
to feature integration theory, both tasks shown in Figure 5.14 should be
comparably hard because the target and distractors share features. In
contrast, the texture tiling model predicts the task on the right should
be harder because adjacent distractors seen in peripheral vision can
more easily tile (join together) to form an apparent T. The findings
from these tasks (and several others) supported the texture tiling model
but were inconsistent with feature integration theory. Finally, Hulleman
and Olivers (2017) produced a model of visual search consistent with the
texture tiling model. According to this model, each eye fixation lasts
250 ms, during which information from foveal and peripheral vision is
extracted in parallel. They also assumed that the area

207

KEY TERM Visual crowding The inability to recognise objects in
peripheral vision due to the presence of neighbouring objects.

208

Visual perception and attention

Figure 5.14 The target (T) is easier to find in the display on the left
than the one on the right. From Chang and Rosenholtz (2016).

(a) 

Easier search

(b) 

Harder search

Find the T

around the fixation point within which a target can generally be
detected is smaller when the visual search task is difficult (e.g.,
because target discriminability is low). A key prediction from Hulleman
and Olivers' (2017) model is that the main reason why search times are
longer with more difficult search tasks is because more eye fixations
are required than with easier tasks. A computer simulation based on
these assumptions produced search times very similar to those obtained
in experimental studies.

Evaluation What are the strengths of the texture tiling model? First,
the information available in peripheral vision is much more important in
visual search than assumed previously. The model explains how observers
make use of the information available in peripheral vision. Second, the
model explains why parallel processing is so prevalent in visual search
-- it reflects directly parallel processing within peripheral vision.
Third, there is accumulating evidence that search times are generally
directly related to the number of eye fixations. Fourth, an approach
based on eye fixations and peripheral vision can potentially explain
findings from all visual search paradigms, including complex visual
scenes and item displays. Such an approach thus has more general
applicability than feature integration theory. What are the model's
limitations? First, as Chang and Rosenholtz (2016) admitted, it needs
further development to account fully for visual search performance. For
example, it does not predict search times with precision. In addition,
it does not specify the criteria used by observers to decide no target
is present. Second, visual search is typically much faster for experts
than nonexperts in their domain of expertise (e.g., medical experts
examining mammograms) (see Chapter 11). The texture tiling model does
not identify clearly the processes allowing experts to make very
efficient use of peripheral information.

CROSS-MODAL EFFECTS Nearly all the research discussed so far is limited
in that the visual (or auditory) modality was studied on its own. We
might try to justify this approach by assuming attentional processes in
each sensory modality operate

Attention and performance

independently from those in other modalities. However, that assumption
is incorrect. In the real world, we often coordinate information from
two or more sense modalities at the same time (cross-modal attention).
An example is lip reading, where we use visual information about a
speaker's lip movements to facilitate our understanding of what they are
saying (see Chapter 9). Suppose we present participants with two streams
of lights (as was done by Eimer and Schröger, 1998), with one stream
being presented to the left and the other to the right. At the same
time, we present participants with two streams of sounds (one to each
side). In one condition, participants detect deviant visual events
(e.g., longer than usual stimuli) presented to one side only. In the
other condition, participants detect deviant auditory events in only one
stream. Event-related potentials were recorded to assess the allocation
of attention. Unsurprisingly, Eimer and Schröger (1998) found ERPs to
deviant stimuli in the relevant modality were greater to stimuli
presented on the to-be-attended side than the to-be-ignored side. Thus,
participants allocated attention as instructed. Of more interest is what
happened to the allocation of attention in the irrelevant modality.
Suppose participants detected visual targets on the left side. In that
case, ERPs to deviant auditory stimuli were greater on the left side
than the right. This is a cross-modal effect: the voluntary or
endogenous allocation of visual attention also affected the allocation
of auditory attention. Similarly, when participants detected auditory
targets on one side, ERPs to deviant visual stimuli on the same side
were greater than ERPs to those on the opposite side. Thus, the
allocation of auditory attention also influenced the allocation of
visual attention.

Ventriloquism effect What happens when there is a conflict between
simultaneous visual and auditory stimuli? We will focus on the
ventriloquism effect in which sounds are misperceived as coming from
their apparent visual source. Ventriloquists (at least good ones!) speak
without moving their lips while manipulating a dummy's mouth movements.
It seems as if the dummy is speaking. Something similar happens at the
movies. The actors' lips move on the screen but their voices come from
loudspeakers beside the screen. Nevertheless, we hear those voices
coming from their mouths. Certain conditions must be satisfied for the
ventriloquism effect to occur (Recanzone & Sutter, 2008). First, the
visual and auditory stimuli must occur close together in time. Second,
the sound must match expectations created by the visual stimulus (e.g.,
high-pitched sound coming from a small object). Third, the sources of
the visual and auditory stimuli should be close together spatially. More
generally, the ventriloquism effect reflects the unity assumption (the
assumption that two or more sensory cues come from the same object: Chen
& Spence, 2017). The ventriloquism effect exemplifies visual dominance
(visual information dominating perception). Further evidence comes from
the Colavita effect (Colavita, 1974): participants instructed to respond
to all stimuli respond more often to visual than simultaneous auditory
stimuli (Spence et al., 2011).

209

KEY TERMS Cross-modal attention The coordination of attention across two
or more modalities (e.g., vision and audition). Ventriloquism effect The
mistaken perception that sounds are coming from their apparent source
(as in ventriloquism).

210

KEY TERM Temporal ventriloquism effect Misperception of the timing of a
visual stimulus when an auditory stimulus is presented close to it in
time.

Visual perception and attention

When during processing is visual spatial information integrated with
auditory information? Shrem et al. (2017) found that misleading visual
information about the location of an auditory stimulus influenced the
processing of the auditory stimulus approximately 200 ms after stimulus
onset. The finding that this effect is still present even when
participants are aware of the spatial discrepancy between the visual and
auditory input suggests it occurs relatively "automatically". However,
the ventriloquism effect is smaller when participants had previously
heard syllables spoken in a fearful voice (Maiworm et al., 2012). This
suggests the effect is not entirely "automatic" but is reduced when the
relevance of the auditory channel is increased. Why does vision capture
sound in the ventriloquism effect? The visual modality typically
provides more precise information about spatial location. However, when
visual stimuli are severely blurred and poorly localised, sound captures
vision (Alais & Burr, 2004). Thus, we combine visual and auditory
information effectively by attaching more weight to the more informative
sense modality.

Temporal ventriloquism The above explanation for the ventriloquist
illusion is a development of the modality appropriateness and precision
hypothesis (Welch & Warren, 1980). According to this hypothesis, when
conflicting information is presented in two or more modalities, the
modality having the greatest acuity generally dominates. This hypothesis
predicts the existence of another illusion. The auditory modality is
typically more precise than the visual modality at discriminating
temporal relations. As a result, judgements about the temporal onset of
visual stimuli might be biased by auditory stimuli presented very
shortly beforehand or afterwards. This is the temporal ventriloquism
effect. Research on temporal ventriloquism was reviewed by Chen and
Spence (2017). A simple example is when the apparent onset of a flash is
shifted towards an abrupt sound presented slightly asynchronously (see
Figure 5.15). Other research has found that the apparent duration of
visual stimuli can be distorted by asynchronous auditory stimuli. We
need to consider the temporal ventriloquism effect in the context of the
unity assumption. This is the assumption that "two or more uni-sensory
cues belong together (i.e., that they come from the same object or
event)" (Chen & Spence, 2017, p. 1). Chen and Spence discussed findings
showing that Figure 5.15 the unity assumption generally (but not An
example of temporal ventriloquism in which the apparent always) enhances
the temporal ventriloquism time of onset of a flash is shifted towards
that of a sound effect. presented at a slightly different timing from
the flash. Orchard-Mills et al. (2016) extended From Chen and Vroomen
(2013). Reprinted with permission from Springer. research by using two
visual stimuli (one

Attention and performance

211

IN THE REAL WORLD: WARNING SIGNALS PROMOTE SAFE DRIVING
Front-to-rear-end collisions cause 25% of road accidents with driver
inattention the most common cause (Spence, 2012). Thus, it is important
to devise effective warning signals to enhance driver attention and
reduce collisions. Warning signals might be especially useful if they
were informative (i.e., indicating the nature of the danger). However,
informative warning signals requiring time-consuming cognitive
processing might be counterproductive. Ho and Spence (2005) considered
drivers' reaction times when braking to avoid a car in front or
accelerating to avoid a speeding car behind. An auditory warning signal
(car horn) came from the same direction as the critical visual event on
80% or 50% of trials. Braking times were faster when the sound and
critical visual event were from the same direction. The greater
beneficial effects of auditory signals when predictive rather than
non-predictive suggests the involvement of endogenous spatial attention
(controlled by the individual's intentions). Auditory stimuli also
influenced visual attention even when non-predictive: this probably
involved exogenous spatial attention ("automatic" allocation of
attention). Gray (2011) studied braking times to avoid a collision with
the car in front when drivers heard auditory warning signals increasing
in intensity as the time to collision reduced. These signals are known
as looming sounds. The most effective condition was the one where the
rate of increase in the intensity of the auditory signal was the fastest
because it implied the time to collision was the least. Lahmer et
al. (2018) found evidence that looming sounds are effective because they
are consistent with the visual experience of an approaching collision.
Vibrotactile signals produce the perception of vibration through touch.
Gray et al. (2014) studied the effects of such signals on speed of
braking to avoid a collision. Signals were presented at three sites on
the abdomen arranged vertically. In the most effective condition,
successive signals moved towards the driver's head at an increasing rate
reflecting the speed they were approaching the car in front. Braking
time was 250 ms faster in this condition than a no-warning control
condition, probably because it was highly informative. Ahtamad et
al. (2016) compared the effectiveness of three vibrotactile warning
signals delivered to the back on braking times to avoid a collision with
the car in front: (1) expanding (centre of back followed by areas to
left and right); (2) contracting (areas to left and right followed by
the centre of the back); (3) static (centre of the back + areas to left
and right at the same time). The dynamic vibrotactile conditions (1 and
2) produced comparable braking reaction times that were faster than
those in the static condition (3). In a second experiment, Ahtamad et
al. (2016) compared the expanding vibrotactile condition against a
linear motion condition (vibrotactile stimulation to the hands followed
by the shoulders). Emergency braking reaction times were faster in the
linear motion condition (approximately 585 ms vs 640 ms) because drivers
found it easier to interpret the warning signals in that condition. In
sum, the various auditory and vibrotactile warning signals discussed
above typically reduce braking reaction times by approximately 40 ms.
That sounds modest. However, it can easily be the difference between
colliding with the car in front or avoiding it and so could potentially
save many lives. At present, however, we lack a theoretical framework
within which to understand precisely why some warning signals are more
effective than others.

above and the other below fixation) and two auditory stimuli (low- and
high-pitch). When the visual and auditory stimuli were congruent (e.g.,
visual stimulus above fixation and auditory stimulus high-pitch), the
temporal ventriloquism effect was found. However, this effect was
eliminated when the visual and auditory stimuli were incongruent, which
prevented binding of information across the two senses.

212

Visual perception and attention

KEY TERMS

Overall evaluation

Endogenous spatial attention Attention to a stimulus controlled by
intentions or goal-directed mechanisms.

What are the limitations of research on cross-modal effects? First, as
just mentioned, our theoretical understanding lags behind the
accumulation of empirical findings. Second, much research has involved
complex artificial tasks far removed from naturalistic conditions.
Third, individual differences have generally been ignored. However,
individual differences (e.g., preference for auditory or visual stimuli)
influence cross-modal effects (van Atteveldt et al., 2014).

Exogenous spatial attention Attention to a given spatial location
determined by "automatic" processes. Multi-tasking Performing two or
more tasks at the same time by switching rapidly between them.

Case study: Multi-tasking efficiency

DIVIDED ATTENTION: DUAL-TASK PERFORMANCE In this section, we consider
factors influencing how well we can perform two tasks at the same time.
In our hectic 24/7 lives, we increasingly try to do two things at once
(multi-tasking) (e.g., sending text messages while walking down the
street). More specifically, multi-tasking "refers to the ability to
co-ordinate the completion of several tasks to achieve an overall goal"
(MacPherson, 2018, p. 314). It can involve performing two tasks at the
same time or switching between two tasks. There is controversy as to
whether massive amounts of multi-tasking have beneficial or detrimental
effects on attention and cognitive control (see Box). What determines
how well we can perform two tasks at once? Similarity (e.g., in terms of
modality) is one important factor. Treisman and Davies (1973) found two
monitoring tasks interfered with each other much more when the stimuli
on both tasks were in the same modality (visual or auditory). Two tasks
can also be similar in response modality. McLeod (1977) had participants
perform a continuous tracking task with manual responding together with
a tone-identification task. Some participants responded vocally to the
tones whereas others responded with the hand not involved in tracking.
Tracking performance was worse with high response similarity (manual
responses on both tasks) than with low response similarity. Practice is
the most important factor determining how well two tasks can be
performed together. The saying "Practice makes perfect" was apparently
supported by Spelke et al. (1976). Two students (Diane and John)
received 5 hours of training a week for 4 months on various tasks. Their
first task involved reading short stories for comprehension while
writing down words from dictation, which they initially found very hard.
After 6 weeks of training, however, they could read as rapidly and with
as much comprehension when writing to dictation as when only reading.
With further training, Diane and John learned to write down the names of
the categories to which the dictated words belonged while maintaining
normal reading speed and comprehension. Spelke et al.'s (1976) findings
are hard to interpret for various reasons. First, Spelke et al. focused
on accuracy measures, which are typically less sensitive to dual-task
interference than speed measures. Second, Diane and John's attentional
focus was relatively uncontrolled, and so they may have alternated
attention between tasks rather than attending to both at the same time.
More controlled research on the effects of practice on dual-task
performance is discussed later.

Attention and performance

213

IN THE REAL WORLD: MULTI-TASKING What are the effects of frequent
multi-tasking in our everyday lives? Two main answers have been
proposed. First, heavy multi-tasking may impair cognitive control
because it leads individuals to allocate their attentional resources too
widely. This is the scattered attention hypothesis (van der Schuur et
al., 2015). Second, heavy multi-tasking may enhance some control
processes (e.g., task switching) because of prolonged practice in
processing multiple streams of information. This is the trained
attention hypothesis (van der Schuur et al., 2015). The relevant
evidence is very inconsistent -- "positive, negative, and null effects
have all been reported" (Uncapher & Wagner, 2018, p. 9894). Ophir et
al. (2009) used a questionnaire (the Media Multitasking Index) to
identify levels of multi-tasking. Heavy multi-taskers were more
distractible. In a review, van der Schuur et al. (2015) found findings
supported the scattered attention hypothesis (e.g., heavy multi-taskers
had impaired sustained attention). Moisala et al. (2016) found heavy
multi-taskers were more adversely affected than light multi-taskers by
distracting stimuli while performing speech--listening and reading
tasks. During distraction, the heavy multi-taskers had greater activity
than the light multi-taskers in the right prefrontal cortex (associated
with attentional control). This suggests heavy multi-taskers have
greater problems than previously believed -- their performance is
impaired even though they try harder to exert top-down attentional
control. Uncapher and Wagner (2018) found in a review that most research
indicated negative effects of heavy multi-tasking on tasks involving
working memory, long-term memory, sustained attention and relational
reasoning. These negative effects are likely to be due to attentional
lapses. Of relevance, there are several studies where media
multi-tasking was positively associated with self-reported everyday
attentional failures. In addition, heavy multi-taskers often report high
impulsivity -- such individuals often make rapid decisions based on very
limited evidence. Most studies have only found an association between
media multi-tasking and measures of attention and performance. This
makes it hard to establish causality -- it is possible individuals with
certain patterns of attention choose to engage in extensive
multi-tasking. Evidence suggesting that media multi-tasking can cause
attention problems was reported by Baumgartner et al. (2018). They found
that high media multi-tasking at one point in time predicted attention
problems several months later.

Serial vs parallel processing When individuals perform two tasks
together, they might use serial or parallel processing. Serial
processing involves switching attention backwards and forwards between
two tasks with only one task being processed at any given moment. In
contrast, parallel processing involves processing both tasks at the same
time. There has been much theoretical controversy on the issue of serial
vs parallel processing in dual-task conditions (Koch et al., 2018). Of
importance, processing can be mostly parallel or mostly serial. Lehle et
al. (2009) trained participants to use serial or parallel processing
when performing two tasks together. Those using serial processing
performed better. However, they found the tasks more effortful because
they had to inhibit processing of one task while performing the other
one. Lehle and Hübner (2009) also instructed participants to perform two
tasks together in a serial or parallel fashion. Those using parallel
processing

214

Visual perception and attention

performed much worse. Fischer and Plessow (2015) reviewed dual-task
research and concluded: "While serial task processing appears to be the
most efficient \[dual-task\] processing strategy, participants are able
to adopt parallel processing. Moreover, parallel processing can even
outperform serial processing under certain conditions" (p. 8). Brüning
and Manzey (2018) confirmed serial processing is not always more
efficient than parallel processing. Participants performed many
alternate trials on two different tasks but could see the stimulus for
the next trial ahead of time. Participants engaging in parallel
processing (processing the stimulus for trial n+1 during trial n)
performed better than those using only serial processing (not processing
the trial n+1 stimulus ahead of time). Parallel processing reduced the
costs incurred when task switching. Individuals high in working memory
capacity (see Glossary) were more likely to use parallel processing,
perhaps because of their superior attentional control.

IN THE REAL WORLD: CAN WE THINK AND DRIVE? Car driving is the riskiest
activity engaged in by tens of millions of adults. Over 50 countries
have laws restricting the use of mobile or cell phones by drivers to
increase car safety. Are such restrictions necessary? The short answer
is "Yes" -- drivers using a mobile phone are several times more likely
to be involved in a car accident (Nurullah, 2015). This is so even
though drivers try to reduce the risks by driving slightly more slowly
(reducing speed by 5--6 mph) than usual shortly after initiating a
mobile-phone call (Farmer et al., 2015). Caird et al. (2008) in a review
of studies using simulated driving tasks reported that reaction times to
events (e.g., onset of brake lights on the car in front) increased by
250 ms with mobilephone use and were greater when drivers were talking
rather than listening. This 250 ms increase in reaction time translates
into travelling an extra 18 feet (5.5 metres) before stopping for a
motorist doing 50 mph (80 kph). This could be the difference between
stopping just short of a child or killing that child. Strayer and Drews
(2007) studied the above slowing effect using event-related potentials
while drivers responded rapidly to the onset of brake lights on the car
in front. The magnitude of the P300 (a positive wave associated with
attention) was reduced by 50% in mobile-phone users. Strayer et
al. (2011) considered a real-life driving situation. Drivers were
observed to see whether they obeyed a law requiring them to stop at a
road junction. Of drivers not using a mobile phone, 79% obeyed the law
compared to only 25% of mobile-phone users.

Theoretical considerations Why do so many drivers endanger people's
lives by using mobile phones? Most believe they can drive safely while
using a mobile phone whereas other drivers cannot (Sanbonmatsu et al.,
2016b). Their misplaced confidence depends on limited monitoring of
their driving performance: drivers using a mobile phone make more
driving errors but do not remember making more errors (Sanbonmatsu et
al., 2016a). Why does mobile-phone use impair driving performance?
Strayer and Fisher (2016) in their SPIDER model identified five
cognitive processes that are adversely affected when drivers' attention
is diverted from driving (e.g., by mobile-phone use):

Attention and performance

215

(1) There is less effective visual scanning of the environment for
    potential threats. Distracted drivers are more inclined to focus
    attention on the centre of the road and less inclined to scan
    objects in the periphery and their side mirrors (Strayer & Fisher,
    2016).
(2) The ability to predict where threats might occur is impaired.
    Distracted drivers are much less likely to make anticipatory glances
    towards the location of a potential hazard (e.g., obstructed view of
    a pedestrian crossing) (Taylor et al., 2015).
(3) There is reduced ability to identify visible threats, a phenomenon
    known as inattentional blindness (see Glossary; and Chapter 4). In a
    study by Strayer and Drews (2007), 30 objects (e.g., pedestrians;
    advertising hoardings) were clearly visible to drivers. However,
    those using a mobile phone subsequently recognised far fewer objects
    they had fixated than those not using a mobile phone (under 25% vs
    50%, respectively).
(4) It is harder to decide what action is necessary in a threatening
    situation. Cooper et al. (2009) found drivers were 11% more likely
    to make unsafe lane changes when using a mobile phone.
(5) It becomes harder to execute the appropriate action. Reaction times
    are slowed (Caird et al., 2008, discussed above, p. 214). The SPIDER
    model is oversimplified in several ways. First, various different
    activities are associated with mobile-phone use. Simmons et
    al. (2016) found in a meta-analytic review that the risk of
    safetycritical events was increased by activities requiring drivers
    to take their eyes off the road (e.g., locating a phone; dialling;
    texting). However, talking on a mobile phone did not increase risk.
    Second, driving-irrelevant cognitive activities do not always impair
    all aspects of driving performance. Engstrom et al. (2017, p. 734)
    proposed their cognitive control hypothesis: "Cognitive load
    selectively impairs driving sub-tasks that rely on cognitive control
    but leaves automatic performance unaffected." For example,
    driving-irrelevant activities involving cognitive load (e.g.,
    mobilephone use) typically have no adverse effect on well-practised
    driving skills, such as lane keeping and braking when getting close
    to the vehicle in front (Engstrom et al., 2017). Third, individuals
    using mobile phones while driving are unrepresentative of drivers in
    general (e.g., they tend to be relatively young and to engage in
    more risk-taking activities: Precht et al., 2017). Thus, we must
    consider individual differences in personality and risk taking when
    interpreting accidents associated with mobile-phone use. Fourth, the
    SPIDER model implies that performance cannot be improved by adding a
    secondary task. However, driving performance in monotonous
    conditions is sometimes better when drivers listen to the radio at
    the same time (see Engstrom et al., 2017). Listening to the radio
    can reduce the mind-wandering that occurs when someone drives in
    monotonous conditions. Drivers indicating their immediate thoughts
    during their daily commute reported mind-wandering 63% of the time
    and active focus on driving only 15%--20% of the time (Burdett et
    al., 2018).

Multiple resource theory Wickens (1984, 2008) argued in his multiple
resource model that the processing system consists of several
independent processing resources or mechanisms. The model includes four
major dimensions (see Figure 5.16): (1) (2)

Processing stages: there are successive stages of perception, cognition
(e.g., working memory) and responding. Processing codes: perception,
cognition and responding can use spatial and/or verbal codes; action can
involve speech (vocal verbal) or manual/spatial responses.

216

Visual perception and attention

Figure 5.16 Wickens's four-dimensional multiple resource model. The
details are described in the text. From Wickens (2008). © 2008.
Reprinted by permission of SAGE Publications.

(3) 
(4) 

Modalities: perception can involve visual and/or auditory resources.
Visual channels: visual processing can be focal (high acuity) or ambient
(peripheral).

Here is the model's crucial prediction: "To the extent that two tasks
use different levels along each of the three dimensions \[excluding (4)
above\], timesharing \[dual-task performance\] will be better" (Wickens,
2008, p. 450). Thus, tasks requiring different resources can be
performed together more successfully than those requiring the same
resources. Wickens's approach bears some resemblance to Baddeley's
(e.g., 2012) working memory model (see Chapter 6). According to that
model, two tasks can be performed together successfully provided they
use different components or processing resources.

Findings Research discussed earlier (Treisman & Davies, 1973; McLeod,
1977) showing the negative effects of stimulus and response similarity
on performance are entirely consistent with the theory. Lu et al. (2013)
reviewed research where an ongoing visual-motor task (e.g., car driving)
was performed together with an interrupting task in the visual, auditory
or tactile (touch) modality. As predicted, non-visual interrupting tasks
(especially those in the tactile modality) were processed more
effectively than visual ones and there were no adverse effects on the
visual-motor task. According to the model, there should be only limited
dual-task interference between two visual tasks if one requires focal or
foveal vision, whereas the other requires ambient or peripheral vision.
Tsang and Chan (2018) obtained support for this prediction in a study in
which participants tracked a moving target in focal vision while
responding to a spatial task in ambient or peripheral vision. Dual-task
performance is often more impaired than predicted by the theory. For
example, consider a study by Robbins et al. (1996; see

Attention and performance

Chapter 6). The main task was selecting chess moves and we will focus on
the condition where the task performed at the same time was generating
random letters. These two tasks involve different processing codes
(spatial vs verbal, respectively) and they also involve different
response types (manual vs vocal, respectively). Nevertheless, generating
random letters caused substantial interference on the chess task.

Evaluation The main assumptions of the theory have largely been
supported by the experimental evidence. In other words, dual-task
performance is generally less impaired when two tasks differ with
respect to modalities, processing codes or visual channels than when
they do not. What are the model's limitations? (1)

(2) 
(3) 

Successful dual-task performance often requires higher-level processes
of coordinating and organising the demands of the two tasks (see later
section on cognitive neuroscience, pp. 220--222). However, these
processes are de-emphasised within the theory. The theory's assumption
there is a sequence of processing stages (perception; cognition;
responding) is too rigid given the flexible nature of much dual-task
processing (Koch et al., 2018). The numerous forms of cognitive
processing intervening between perception and responding are not
discussed in detail. It is implied within the theory that negative or
interfering effects of performing two tasks together would be constantly
present. However, Steinborn and Huestegge (2017) found dual-task
conditions led only to occasional performance breakdown due to attention
failures.

Threaded cognition Salvucci and Taatgen (2008, 2011) proposed a model of
threaded cognition in which streams of thought are represented as
threads of processing. For example, processing two tasks might involve
two separate threads. The central theoretical assumptions are as
follows: Multiple threads or goals can be active at the same time, and
as long as there is no overlap in the cognitive resources needed by
these threads, there is no multi-tasking interference. When threads
require the same resource at the same time, one thread must wait and its
performance will be adversely affected. (Salvucci & Taatgen, 2011,
p. 228) This is because all resources have limited capacity. Taatgen
(2011) discussed the threaded cognition model (see Figure 5.17). Several
cognitive resources can be the source of competition between two tasks.
These include visual perception, declarative memory, task control and
focal working memory or problem state. Nijboer et al. (2016a) discussed
similarities between this model and Baddeley's working memory model (see
Chapter 6). Three components of the model relate to

217

218

Visual perception and attention

Figure 5.17 Threaded cognition theory. We possess several cognitive
resources (e.g., declarative memory, task control, visual perception).
These resources can be used in parallel but each resource can only work
on one task at a time. Our ability to perform two tasks at the same time
(e.g., driving and dialling, subtraction and typing) depends on the
precise ways in which cognitive resources need to be used. The theory
also identifies some of the brain areas associated with cognitive
resources.

working memory: (1) problem state (attentional focus); (2) declarative
memory (activated short-term memory); and (3) subvocal rehearsal
(resembling the phonological loop; see Chapter 6). Each thread or task
controls resources in a greedy, polite way -- threads claim resources
greedily when required but release them politely when no longer needed.
These aspects of the model lead to one of its most original assumptions
-- several goals (each associated with a given thread) can be active
simultaneously. The model resembles Wickens's multiple resource model:
both models assume there are several independent processing resources.
However, only the threaded cognition model led to a computational model
making specific predictions. In addition, the threaded cognition model
identifies the brain areas associated with each processing resource (see
Figure 5.17).

Findings

According to the model, any given cognitive resource (e.g., visual
perception; focal From Taatgen (2011). With permission of the author.
working memory) can be used by only one process at any given time.
Nijboer et al. (2013) tested this assumption using multi-column
subtraction as the primary task with participants responding using a
keypad. Easy and hard conditions differed in whether digits were carried
over ("borrowed") from one column to the next: (1: easy) 336789495
--224578381

(2: hard) 3649772514 --1852983463

The model predicts focal working memory is required only in the hard
condition. Subtraction was combined with a secondary task: a tracking
task involving visual and manual resources or a tone-counting task
involving working memory. Nijboer et al. (2013) predicted performance on
the easy subtraction task should be worse when combined with the
tracking task because both compete for visual and manual resources. In
contrast, performance on the hard subtraction task should be worse when
combined with the tonecounting task because there are large disruptive
effects when two tasks compete for working memory resources. The
findings were as predicted. Borst et al. (2013) found there was far less
impairment of hard subtraction performance by a secondary task requiring
working memory when

Attention and performance

participants saw a visual sign explicitly indicating that "borrowing"
was needed. This supports the model's assumption that dual-task
performance can be enhanced by appropriate environmental support.
According to the threaded cognition model, we often cope with the
demands of combining two tasks by switching flexibly between them to
maximise performance. Support was reported by Farmer et al. (2018).
Participants performed a typing task and a tracking task at the same
time. The relative value of the two tasks was varied by manipulating the
number of points lost for poor tracking performance. Participants
rapidly learned to adjust their strategies over time to increase the
overall number of points they gained. Katidioti and Taatgen (2014) found
task switching is not always optimal. Participants performed two tasks
together: (1) an email task in which information needed to be looked up;
(2) chat messages containing questions to be answered. When there was a
delay on the email task, most participants switched to the chat task.
This happened even when this was suboptimal because it caused
participants to forget information in the email task. How can we explain
the above findings? According to Katidioti and Taatgen (2014, p. 734),
"The results . . . agree with threaded cognition's 'greedy' theory . . .
which states that people will switch to a task that is waiting as soon
as the resources for it are available." Huijser et al. (2018) obtained
further evidence of "greediness". When there were brief blank periods
during the performance of a cognitively demanding task, participants
often had task-irrelevant thoughts (e.g., mind-wandering) even though
these thoughts impaired task performance. Katidioti and Taatgen (2014)
also discovered substantial individual differences in task switching --
some participants never switched to the chat task when delays occurred
on the email task. Such individual differences cannot be explained by
the theory. As mentioned earlier, a recent version of threaded cognition
theory discussed by Nijboer et al. (2016a) identifies three components
of working (i.e., problem state or focus of attention; declarative
memory or activated short-term memory; and subvocal rehearsal). Nijboer
et al. had participants perform two working memory tasks at the same
time; these tasks varied in the extent to which they required the same
working memory components. They obtained measures of performance and
also used neuroimaging under dual-task and single-task conditions. What
did Nijboer et al. (2016a) find? First, dual-task interference could be
predicted from the extent to which the two tasks involved the same
working memory components. Second, dual-task interference could also be
predicted from the extent of overlap in brain activation of the two
tasks in single-task conditions. In sum, dual-task interference depended
on competition for specific resources (i.e., working memory components)
rather than general resources (e.g., central executive).

Evaluation The model has proved successful in various ways. First,
several important cognitive resources have been identified. Second, the
model identifies brain

219

220

Visual perception and attention

areas associated with various cognitive resources. This has led to
computational modelling testing the model's predictions using
neuroimaging and behavioural findings. Thus, the model accounts for
dual-task performance without assuming the existence of a central
executive or other executive process (often vaguely defined in other
theories). Fourth, the theory predicts factors determining switching
between two tasks being performed together. Fifth, individuals often
have fewer problems performing two simultaneous tasks than generally
assumed. What are the model's limitations? First, it predicts that
"Practising two tasks concurrently \[together\] results in the same
performance as performing the two tasks independently" (Salvucci &
Taatgen, 2008, p. 127). This de-emphasises the importance of processes
coordinating and managing two tasks performed together (see next
section). Second, excluding processes resembling Baddeley's central
executive is controversial and may well prove inadvisable. Third, most
tests of the model have involved the simultaneous performance of two
relatively simple tasks and its applicability to more complex tasks
remains unclear. Fourth, the theory does not provide a full explanation
for individual differences in the extent of task switching (e.g.,
Katidioti & Taatgen, 2014).

Cognitive neuroscience The cognitive neuroscience approach is
increasingly used to test theoretical models and enhance our
understanding of processes underlying dual-task performance. Its value
is that neuroimaging provides "an additional data source for contrasting
between alternative models" (Palmeri et al., 2017, p. 61). More
generally, behavioural findings indicate the extent to which dual-task
conditions impair task performance but are often relatively
uninformative about the precise reasons for such impairment. Suppose we
compare patterns of brain activation while participants perform tasks x
and y singly or together. Three basic patterns are shown in Figure 5.18:
(1)

Figure 5.18 (a) Underadditive activation; (b) additive activation; (c)
overadditive activation. White indicates task 1 activation; grey
indicates task 2 activation; and black indicates activation only present
in dual-task conditions. From Nijboer et al., 2014. Reprinted with
permission of Elsevier.

Underadditive activation: reduced activation in one or more brain areas
in the dual-task condition occurs because of resource competition
between the tasks.

(a) Underadditive activation

(b) Additive activation

(c) Overadditive activation

Component task 1

Component task 1

Component task 1

Component task 2

Time

Component task 2

Time Dual-task

Time

Time Dual-task

Time

Component task 2

Time

Time Dual-task

Time

Time

Attention and performance

(2) 
(3) 

Additive activation: brain activation in the dual-task condition is
simply the sum of the two single-task activations because access to
resources is integrated efficiently between the two tasks. Overadditive
activation: brain activation in one or more brain areas is present in
the dual-task condition but not the single-task conditions. This occurs
when dual-task conditions require executive processes that are absent
(or less important) with single tasks. These executive processes include
the coordination of task demands, attentional control and dual-task
management generally. We would expect such executive processes to be
associated mostly with activation in prefrontal cortex.

221

KEY TERM Underadditivity The finding that brain activation when tasks A
and B are performed at the same time is less than the sum of the brain
activation when tasks A and B are performed separately.

Findings We start with an example of underadditive activation. Just et
al. (2001) used two very different tasks (auditory sentence
comprehension and mental rotation of 3-D figures) performed together or
singly. Performance on both tasks was impaired under dual-task
conditions compared to single-task conditions. Under dual-task
conditions, brain activation in language processing areas decreased by
53% and reduced by 29% in areas associated with mental rotation. These
findings suggest fewer task-relevant processing resources were available
when both tasks were performed together. Schweizer et al. (2013) also
reported underadditivity. Participants performed a driving task on its
own or with a distracting secondary task (answering spoken questions).
Driving performance was unaffected by the secondary task. However,
driving with distraction reduced activation in posterior brain areas
associated with spatial and visual processing (underadditivity). It also
produced increased activation in the prefrontal cortex (overadditivity;
see Figure 5.19) probably because driving with distraction requires
increased attentional or cognitive control within the prefrontal cortex.
Dual-task performance is often associated with overadditivity due to
increased activity within the prefrontal cortex (especially the lateral
prefrontal cortex) during dual-task performance (see Strobach et al.,
2018, for a review). However, most such findings do not show that this
increased prefrontal activation is actually required for dual-task
performance. More direct evidence that prefrontal areas associated with
attentional or cognitive control are causally involved in enhancing
dual-task performance was reported by Filmer et al. (2017) and Strobach
et al. (2018). Filmer et al. (2017) studied the effects of transcranial
direct current stimulation (tDCS; see Glossary) applied to areas of the
prefrontal cortex associated with cognitive control. Anodal tDCS during
training enhanced cognitive control and subsequent dual-task
performance.

Figure 5.19 Effects of an audio distraction task on brain activity
associated with a straight driving task. There were significant
increases in activation within the ventrolateral prefrontal cortex and
the auditory cortex (in orange). There was decreased activation in
occipital-visual areas (in blue). From Schweizer et al. (2013).

222

Visual perception and attention

Strobach et al. (2018) reported similar findings. Anodal tDCS applied to
the lateral prefrontal cortex led to enhanced dual-task performance. In
another condition, cathodal tDCS to the same area of the prefrontal
cortex impaired dual-task performance. These findings were as predicted
given that anodal and cathodal tDCS often have opposite effects on
performance. These findings indicate that the lateral prefrontal cortex
causally influences dual-task performance. Additional evidence of the
importance of the lateral prefrontal cortex was reported by Wen et
al. (2018). Individuals with high connectivity (connectedness) within
that brain area showed superior dual-task performance to those with low
connectivity. Finally, patterns of brain activation can help to explain
practice effects on dual-task performance. Garner and Dux (2015) found
much frontoparietal activation (associated with cognitive control) when
two tasks were performed singly or together. Extensive training greatly
reduced dual-task interference and also produced increasing
differentiation in the pattern of fronto-parietal activation associated
with the two tasks. Participants showing the greatest reduction in
dual-task interference tended to have the greatest increase in
differentiation. Thus, using practice to increase differences in
processing and associated brain processing between tasks can be very
effective.

Evaluation Brain activity in dual-task conditions often differs from the
sum of brain activity of the same two tasks performed singly. Dual-task
activity can exhibit underadditivity or overadditivity. The findings are
theoretically important because they indicate performance of dual tasks
can involve much more cognitive control and other processes than single
tasks. Garner and Dux's (2015) findings demonstrate that enhanced
dual-task performance with practice can depend on increased
differentiation between the two tasks with respect to processing and
brain activation. What are the limitations of the cognitive neuroscience
approach? First, increased (or decreased) activity in a given brain area
in dual-task conditions is not necessarily very informative. For
example, Dux et al. (2009) found dual-task performance improved over
time because practice increased the speed of information processing in
the prefrontal cortex rather than because it changed activation within
that region. Second, it is often unclear whether patterns of brain
activation are directly relevant to task processing rather than
reflecting non-task processing. Third, findings in this area are rather
inconsistent (Strobach et al., 2018) and we lack a comprehensive theory
to account for these inconsistencies. Plausible reasons for these
apparent inconsistencies are the great variety of task combinations used
in dual-task studies and individual differences in task proficiency
among participants (Watanabe & Funahashi, 2018).

Psychological refractory period: cognitive bottleneck? Much of the
research discussed so far was limited because the task combinations used
made it hard to assess in detail the processes used by participants. For
example, the data collected were often insufficient to indicate

Attention and performance

the frequency with which participants switched their attentional focus
from one task to the other. This led researchers to use much simpler
tasks so that they had "better experimental control over the timing of
the component task processes" (Koch et al., 2018, p. 575). The dominant
paradigm in recent research is as follows. There are two stimuli (e.g.,
two lights) and two responses (e.g., button presses), one associated
with each stimulus. Participants respond to each stimulus as rapidly as
possible. When the two stimuli are presented at the same time (dual-task
condition), performance is typically worse on both tasks than when each
task is presented separately (single-task conditions). When the second
stimulus is presented shortly after the first, there is typically a
marked slowing of the response to the second stimulus: the psychological
refractory period (PRP) effect. This effect is robust -- Ruthruff et
al. (2009) obtained a large PRP effect even when participants were given
strong incentives to eliminate it. The PRP effect has direct real-world
relevance. Hibberd et al. (2013) studied the effects of a simple
in-vehicle task on braking performance when the vehicle in front braked
and slowed down. There was a classic PRP effect -- braking time was
slowest when the in-vehicle task was presented immediately before the
vehicle in front braked. How can we explain the PRP effect? It is often
argued task performance involves three successive stages: (1)
perceptual; (2) central response selection; and (3) response execution.
According to the bottleneck model (e.g., Pashler, 1994), The response
selection stage of the second task cannot begin until the response
selection stage of the first task has finished, although the other
stages . . . can proceed in parallel . . . according to this model, the
PRP effect is a consequence of the waiting time of the second task
because of a bottleneck at the response selection stage. (Mittelstädt &
Miller, 2017, p. 89) The bottleneck model explains several findings. For
example, consider the effects of varying the time between the start of
the first and second stimuli (stimulus onset asynchrony (SOA)).
According to the model, processing on the first task should slow down
second-task processing much more when the SOA is small than when it is
larger. The predicted finding is generally obtained (Mittelstädt &
Miller, 2017). The bottleneck model remains the most influential
explanation of the PRP effect (and other dual-task costs). However,
resource models (e.g., Navon & Miller, 2002) are also influential.
According to these models, limited processing capacity can be shared
between two tasks so both are processed simultaneously. Of crucial
importance, sharing is possible even during the response selection
process. A consequence of sharing processing capacity across task is
that each task is processed more slowly than if performed on its own.
Many findings can be explained by both models. However, resource models
are more flexible than bottleneck models. Why is this? Resource models
assume the division of processing resources between two tasks varies
freely to promote efficient performance.

223

KEY TERMS Psychological refractory period (PRP) effect The slowing of
the response to the second of two stimuli when presented close together
in time. Stimulus onset asynchrony (SOA) Time interval between the start
of two stimuli.

224

KEY TERM Crosstalk In dual-task conditions, the direct interference
between the tasks that is sometimes found.

Visual perception and attention

Another factor influencing the PRP effect is crosstalk (the two tasks
interfere directly with each other). This mostly occurs when the stimuli
and/or responses on the two tasks are similar. A classic example of
crosstalk is when you try to rub your stomach in circles with one hand
while patting your head with the other hand (try it!). Finally, note
that participants in most studies receive only modest amounts of
practice in performing two tasks at the same time. As a consequence, the
PRP effect may occur at least in part because participants receive
insufficient practice to eliminate it.

Findings According to the bottleneck model, we would expect to find a
PRP effect even when easy tasks are used and/or participants receive
prolonged practice. Contrary evidence was reported by Schumacher et
al. (2001). They used two tasks: (1) say "one", "two" or "three" to
low-, medium- and high-pitched tones, respectively; (2) press response
keys corresponding to the position of a disc on a computer screen. These
tasks were performed together for over 2,000 trials, by which time some
participants performed them as well together as singly. Strobach et
al. (2013) conducted a study very similar to that of Schumacher et
al. (2001). Participants took part in over 5,000 trials involving
single-task or dual-task conditions. However, dual-task costs were not
eliminated after extensive practice: dual-task costs on the auditory
task reduced from 185 to 60 ms and those on the visual task from 83 to
20 ms (see Figure 5.20). How did dual-task practice benefit performance?
Practice speeded up the central response selection stage in both tasks.
Why did the findings differ in the two studies discussed above? In both
studies, participants were rewarded for fast responding on single-task
and dual-task trials. However, the way the reward system was set up in
the Schumacher et al. study may have led participants to exert more
effort in dual-task than single-task trials. This potential bias was
absent from the

Figure 5.20 Reaction times for correct responses only over eight
experimental sessions under dual-task (auditory and visual tasks) and
singletask (auditory or visual task) conditions. From Strobach et
al. (2013). Reprinted with permission of Springer.

Attention and performance

Strobach et al. study. This difference in reward structure could explain
the greater dual-task costs in the Strobach et al. study. Hesselmann et
al. (2011) studied the PRP effect using event-related potentials. The
slowing of responses on the second task was closely matched by slowing
in the onset of the P300 (an ERP component reflecting response
selection). However, there was no slowing of earlier ERP components
reflecting perceptual processing. Thus, as predicted by the bottleneck
model, the PRP effect depended on response selection rather than
perceptual processes. According to the resource model approach,
individuals choose whether to use serial or parallel processing on PRP
tasks. Miller et al. (2009) argued that serial processing generally
leads to superior performance compared with parallel processing.
However, parallel processing should theoretically be superior when the
stimuli associated with the two tasks are mostly presented close in
time. As predicted, there was a shift from predominantly serial
processing towards parallel processing when that was the case. Miller et
al. (2009) used very simple tasks and it is likely parallel processing
is most likely to be used with such tasks. Han and Marois (2013) used
two tasks, one of which was relatively difficult. Participants used
serial processing even when parallel processing was encouraged by
financial rewards. Finally, we consider the theoretically important
backward crosstalk effect: "characteristics of Task 2 of 2 subsequently
performed tasks influence Task 1 performance" (Janczyk et al., 2018,
p. 261). Hommel (1998) obtained this effect. Participants responded to
Task 1 by making a left or right key-press and to Task 2 by saying
"left" or "right". Task 1 responses were faster when the two responses
were compatible (e.g., press right key + say "right") than when they
were incompatible (e.g., press right key + say "left"). Evidence for the
backward crosstalk effect was also reported by Janczyk et al. (2018).
Why is the backward crosstalk effect theoretically important? It
indicates that aspects of response selection processing on Task 2 occur
before response selection processing on Task 1 has finished. This effect
is incompatible with the bottleneck model, which assumes response
selection on Task 1 is completed prior to any response selection on Task
2. In other words, this model assumes there is serial processing at the
response selection stage. In contrast, the backward crosstalk effect is
compatible with the resource model approach.

Summary and conclusions The findings from most research on the
psychological refractory period effect are consistent with the
bottleneck model. As predicted, this effect is typically larger when the
second task follows very soon after the first task. In addition, even
prolonged practice rarely eliminates the psychological refractory period
effect suggesting that central response selection processes typically
occur serially. The bottleneck model assumes processing is less flexible
than is often the case. For example, the existence of the backward
crosstalk effect is inconsistent with the bottleneck model but
consistent with the resource

225

KEY TERM Backward crosstalk effect Aspects of Task 2 influence response
selection and performance speed on Task 1 in studies on the
psychological refractory period (PRP) effect.

226

Visual perception and attention

model approach. Fischer et al. (2018) also found evidence for much
flexibility. There was less interference between the two tasks when
financial rewards were offered because participants devoted more
processing resources to protecting the first task from interference.
However, the resource model approach has the disadvantage compared to
the bottleneck model that its predictions are less precise, making it
harder to submit to detailed empirical testing. Finally, as Koch et
al. (2017, p. 575) pointed out, the bottleneck model "can be applied
(with huge success) mainly for conditions in which two tasks are
performed strictly sequentially". This is often the case with research
on the psychological refractory period effect but is much less
applicable to more complex dual-task situations.

"AUTOMATIC" PROCESSING We have seen in studies of divided attention that
practice often causes a dramatic improvement in performance. This
improvement has been explained by assuming some processes become
automatic through prolonged practice. For example, the huge amount of
practice we have had with reading words has led to the assumption that
familiar words are read "automatically". Below we consider various
definitions of "automaticity". We also consider different approaches to
explaining the development of automatic processing.

Traditional approach: Shiffrin and Schneider (1977) Shiffrin and
Schneider (1977) and Schneider and Shiffrin (1977) distinguished between
controlled and automatic processes: ●

●

Controlled processes are of limited capacity, require attention and can
be used flexibly in changing circumstances. Automatic processes suffer
no capacity limitations, do not require attention and are very hard to
modify once learned.

In Schneider and Shiffrin's (1977) research, participants memorised
letters (the memory set) followed by a visual display containing
letters. They then decided rapidly whether any item in the visual
display was the same as any item in the memory set. The crucial
manipulation was the type of mapping. With consistent mapping, only
consonants were used as members of the memory set and only numbers were
used as distractors in the visual display (or vice versa). Thus, a
participant given only consonants to memorise would know any consonant
detected in the visual display was in the memory set. With varied
mapping, numbers and consonants were both used to form the memory set
and to provide distractors in the visual display. The mapping
manipulation had dramatic effects (see Figure 5.21). The numbers of
items in the memory set and visual display greatly affected decision
speed only with varied mapping. According to Schneider and Shiffrin
(1977), varied mapping involved serial comparisons between each item in
the memory set and each item in the visual display until a match was
achieved or every comparison had been made. In contrast, consistent

Attention and performance

227 Figure 5.21 Response times on a decision task as a function of
memory-set size, displayset size and consistent vs varied mapping.
Response times on a decision task as a function of memory-set size,
displayset size and consistent vs varied mapping. Data from Shiffrin and
Schneider (1977). American Psychological Association.

mapping involved automatic processes operating independently and in
parallel. These automatic processes have evolved through prolonged
practice in distinguishing between letters and numbers. In a second
experiment, Shiffrin and Schneider (1977) used consistent mapping with
the consonants B to L forming one set and Q to Z the other set. As
before, items from only one set always formed the memory set with all
the distractors in the visual display being selected from the other set.
Performance improved greatly over 2,100 trials, reflecting increased
automaticity. After that, there were 2,100 trials with the reverse
consistent mapping (swapping over the memory and visual display sets).
With this reversal, it took nearly 1,000 trials before performance
recovered to its level at the start of the experiment! Evidence that
there may be limited (or no conscious awareness in the consistent
mapping condition was reported by Jansma et al. (2001)). Increasing
automaticity (indexed by increased performance speed) was accompanied by
reduced activation in areas associated with conscious awareness (e.g.,
dorsolateral prefrontal cortex). In sum, automatic processes function
rapidly and in parallel but are inflexible (second part of the second
experiment). Controlled processes are flexible and versatile but operate
relatively slowly and in a serial fashion.

Limitations What are the limitations with this approach? First, the
distinction between automatic and controlled processes is oversimplified
(discussed below). Second, Shiffrin and Schneider (1977) argued
automatic processes operate in parallel and place no demands on
attentional capacity and so decision speed should be unrelated to the
number of items. However, decision

228

Visual perception and attention

speed was slower when the memory set and visual display both contained
several items (see Figure 5.21). Third, the theory is descriptive rather
than explanatory -- it does not explain how serial controlled processing
turns into parallel automatic processing.

Definitions of automaticity Shiffrin and Schneider (1977) assumed there
is a clear-cut distinction between automatic and controlled processes.
More specifically, automatic processes possess several features (e.g.,
inflexibility; very efficient because they have no capacity limitations;
occurring in the absence of attention). In essence, it is assumed there
is perfect coherence or consistency among the features (i.e., they are
all found together). Moors and De Houwer (2006) and Moors (2016)
identified four key features associated with automaticity: (1) (2) (3)
(4)

unconscious: lack of conscious awareness of at least one of the
following: "the input, the output, and the transition from one to the
other" (Moors, 2016, p. 265); efficient: using very little attentional
capacity; fast; goal-unrelated or goal-uncontrolled: at least one of the
following is missing: "the goal is absent, the desired state does not
occur, or the causal relation \[between the goal and the occurrence of
the desired state\] is absent" (Moors, 2016, p. 265).

Why might these four features (or the similar ones identified by
Shiffrin and Schneider (1977)) often be found together? Instance theory
(Logan, 1988; Logan et al., 1999) provides an influential answer. It is
assumed task practice leads to storage of information in long-term
memory which facilitates subsequent performance on that task. In
essence, "Automaticity is memory retrieval: performance is automatic
when it is based on a single-step direct-access retrieval of past
solutions from memory" (Logan, 1988, p. 493). For example, if you were
given the problem "24 × 7 = ???" numerous times, you would retrieve the
answer (168) "automatically" without performing any mathematical
calculations. Instance theory makes coherent sense of several
characteristics of automaticity. Automatic processes are fast because
they require only the retrieval of past solutions from long-term memory.
They make few demands on attentional resources because the retrieval of
heavily over-learned information is relatively effortless. Finally,
there is no conscious awareness of automatic processes because no
significant processes intervene between stimulus presentation and
retrieval of the correct response. In spite of its strengths, instance
theory is limited (see Moors, 2016). First, the theory implies the key
features of automaticity will typically all be found together. However,
this is not the case (see below). Second, it is assumed practice leads
to automatic retrieval of solutions with learners having no control over
such retrieval. However, Wilkins and Rawson (2011) found evidence
learners can exercise top-down control over retrieval: when the
instructions emphasised accuracy, there was less evidence of retrieval

Attention and performance

229

than when they emphasised speed. Thus, the use of retrieval after
practice is not fully automatic. Melnikoff and Bargh (2018) argued that
the central problem with the traditional approach is that no research
has shown the four features associated with "automaticity" occurring
together. As they pointed out, "No attempt has been made to estimate the
probability of a process being intentional given that is conscious
versus unconscious, or the probability of a process being controllable
given that it is efficient versus inefficient, and so forth" (p. 282).

Decompositional approach: Moors (2016) Moors and De Houwer (2006) and
Moors (2016) argued that previous theoretical approaches are greatly
oversimplified. Instead, they favoured a decompositional approach.
According to this approach, the features of automaticity are clearly
separable and are by no means always found together: "It is dangerous to
draw inferences about the presence or absence of one feature on the
basis of the presence or absence of another" (Moors & de Houwer, 2006,
p. 320). Moors and De Houwer (2006) also argued there is no firm
dividing line between automaticity and non-automaticity. The features
are continuous rather than all-or-none (e.g., a process can be fairly
fast or slow; it can be partially conscious). As a result, most
processes involve a blend of automaticity and non-automaticity. This
approach is rather imprecise because few processes are 100% automatic or
non-automatic. However, we can make relative statements (e.g., process X
is more/less automatic than process Y). Moors (2016) claimed the
relationships between factors such as goals, attention and consciousness
are much more complex than claimed within traditional approaches to
"automaticity". This led her to develop a new theoretical account (see
Figure 5.22). A key assumption is that all information

Prior stimulus factors • Frequency • Recency • Stimulus quality:
duration, intensity

Prior stimulus representation factors • Existence of stimulus
representation in LTM • Strength of trace to stimulus representation in
LTM \~ Availability of stimulus representation in LTM • Quality of
stimulus representation in WM

Prior stimulus × person factors • Selection history • Reward history

Conscious processing

Attention

2nd threshold Current stimulus factors • Stimulus quality: duration,
intensity • Un/expectedness • Goal in/congruence • Novelty/familiarity

Attention

Current stimulus representation factors • Quality of stimulus
representation: duration, intensity, distinctiveness \~ Accessibility of
stimulus representation for processing

Unconscious processing 1st threshold

Figure 5.22 Factors that are hypothesised to influence representational
quality within Moors' (2016) theoretical approach. From Moors (2016).

230

Visual perception and attention

processes require an input of sufficient representational quality
(defined by the "intensity, duration, and distinctiveness of a
representation", Moors, 2016, p. 273). What factors determine
representational quality? (1) (2) (3) (4)

current stimulus factors, including the extent to which a stimulus is
expected or unexpected, familiar or novel, and goal congruent or
incongruent; prior stimulus factors (e.g., the frequency and recency
with which the current stimulus has been encountered); prior stimulus
representation factors based on relevant information stored within
long-term memory; attention, which enhances or amplifies the impact of
current stimulus factors and prior stimulus representation factors on
the current stimulus representation.

According to this theoretical account, the above factors influence
representational quality additively so that a high level of one factor
can compensate for a low level of another factor. For example, selective
attention or relevant information in long-term memory can compensate for
brief stimulus presentations. The main impact of consciousness occurs
later than for other factors (e.g., attention and goal congruence). More
specifically, representational quality must reach the first threshold to
permit unconscious processing but a more stringent second threshold to
permit conscious processing.

Findings According to Moors' (2016) theoretical framework, there is a
flexible relationship between controlled and conscious processing. This
contrasts with Schneider and Shiffrin's (1977) assumption that executive
control is always associated with conscious processing. Diao et
al. (2016) reported findings consistent with Moors' prediction. They
used a Go/No-Go task where participants made a simple response (Go
trials) or withheld it (No-Go trials). High-value or low-value financial
rewards were available for successful performance. Task stimuli were
presented above or below the level of conscious awareness. What did Diao
et al. (2016) find? Performance was better on highreward than low-reward
trials even when task processing was unconscious. In addition,
participants showed superior unconscious inhibitory control (assessed by
event-related potentials) on high-reward trials. Thus, one feature of
automaticity (unconscious processing) was present whereas another
feature (goal-uncontrolled) was not. Huber-Huber and Ansorge (2018) also
reported problems for the traditional approach. Participants received
target words indicating an upward or downward direction (e.g., above;
below). Prior to the target word, a prime word also indicating an upward
or downward direction was presented below the level of conscious
awareness. Response times to the target words were slower when there was
a conflict between the meanings of the prime and target words than when
they were congruent in meaning. As in

Attention and performance

231

the study by Diao et al. (2016), unconscious processing was combined
with control, a combination that is inconsistent with the traditional
approach.

Evaluation The theoretical approach to automaticity proposed by Moors
(2016) has several strengths. First, the assumption that various
features associated with automaticity often correlate poorly with each
other is clearly superior to the earlier notion that these features
exhibit perfect coherence. Second, her assumption that processes vary in
the extent to which they are "automatic" is much more realistic than the
simplistic division of processes into automatic and non-automatic.
Third, the approach is more comprehensive than previous ones because it
considers more factors relevant to "automaticity". What are the
limitations with Moors' (2016) approach? First, numerous factors are
assumed to influence representational quality (and thus the extent to
which processes are automatic) (see Figure 5.22). It would thus require
large-scale experimental research to assess the ways all these factors
interact. Second, the approach provides only a partial explanation of
the underlying mechanisms causing the various factors to influence
representational quality.

CHAPTER SUMMARY •

Focused auditory attention. When two auditory messages are presented at
the same time, there is less processing of the unattended than the
attended message. Nevertheless, unattended messages often receive some
semantic processing. The restricted processing of unattended messages
may reflect a bottleneck at various stages of processing. However,
theories assuming the existence of a bottleneck de-emphasise the
flexibility of selective auditory attention. Attending to one voice
among several (the cocktail party problem) is a challenging task. Human
listeners use top-down and bottom-up processes to select one voice.
Topdown processes include the use of various control processes (e.g.,
focused attention; inhibitory processes) and learning about structural
consistencies present in the to-be-attended voice.

•

Focused visual attention. Visual attention can resemble a spotlight or
zoom lens. In addition, the phenomenon of split attention suggests
visual attention can also resemble multiple spotlights. However,
accounts based on spotlights or a zoom lens typically fail to specify
the underlying mechanisms. Visual attention can be object-based,
space-based or feature-based, and it is often object-based and
space-based at the same time. Visual attention is flexible and is
influenced by factors such as individual differences. According to
Lavie's load theory, we are more susceptible to distraction when our
current task involves low perceptual load and/or high cognitive load.
There is much support for this theory.

Interactive exercise: Definitions of attention

232

Visual perception and attention

However, the effects of perceptual and cognitive load are often not
independent as predicted. In addition, it is hard to test the theory
because the terms "perceptual load" and "cognitive load" are vague.
There are stimulus-driven ventral attention and goaldirected dorsal
attention networks involving different (but partially overlapping) brain
networks. More research is required to establish how these two
attentional systems interact. Additional brain networks (e.g.,
cingulo-opercular network; default mode network) relevant to attention
have also been identified. •

Disorders of visual attention. Neglect occurs when damage to the ventral
attention network in the right hemisphere impairs the functioning of the
undamaged dorsal attention network. This impaired functioning of the
dorsal attention network involves reduced activation and alertness
within the left hemisphere. Extinction is due to biased competition for
attention between the two hemispheres combined with reduced attentional
capacity. More research is required to clarify differences among neglect
patients in their specific processing deficits (e.g., the extent to
which failures to detect left-field stimuli are due to impaired spatial
working memory).

•

Visual search. One problem with airport security checks is that there
are numerous possible target objects. Another problem is the rarity of
targets, which leads to excessive caution in reporting targets.
According to feature integration theory, object features are processed
in parallel and then combined by focused attention in visual search.
This theory ignores our use of general scene knowledge in everyday life
to focus visual search on areas of the scene most likely to contain the
target object. It also exaggerates the prevalence of serial processing.
Contemporary approaches emphasise the role of perception in visual
search. Parallel processing is very common because much information is
typically extracted from the peripheral visual field as well as from
central or foveal vision. Problems in visual search occur when there is
visual crowding in peripheral vision.

•

Cross-modal effects. In the real world, we often coordinate information
across sense modalities. In the ventriloquist effect, vision dominates
sound because an object's location is typically indicated more precisely
by vision. In the temporal ventriloquism effect, sound dominates vision
because the auditory modality is typically more precise at
discriminating temporal relations. Both effects depend on the assumption
that visual and auditory stimuli come from the same object. Auditory or
vibrotactile warning signals that are informative about the direction of
danger and/or imminence of collision speed up drivers' braking times. We
lack a theoretical framework within which to understand why some warning
signals are more effective than others.

Attention and performance

•

Divided attention: dual-task performance. Individuals engaging in heavy
multi-tasking show evidence of increased distractibility and impaired
attentional control. A demanding secondary task (e.g., mobile-phone use)
impairs aspects of driving performance requiring cognitive control but
not well-practised driving skills (e.g., lane keeping). Multiple
resource theory and threaded cognition theory both assume dual-task
performance depends on several limited-capacity processing resources.
This permits two tasks to be performed together successfully provided
they use different processing resources. This general approach
de-emphasises highlevel executive processes (e.g., monitoring and
coordinating two tasks). Some neuroimaging studies have found
underadditivity in dual-task conditions (less activation than for the
two tasks performed separately). This may indicate people have limited
general processing resources. Other neuroimaging studies have found
dual-task conditions can introduce new processing demands of task
coordination associated with activation within the dorsolateral
prefrontal cortex and cerebellum. It is often unclear whether patterns
of brain activation are directly relevant to task processing. The
psychological refractory period (PRP) effect can be explained by a
processing bottleneck during response selection. This remains the most
influential explanation. However, some evidence supports resource models
claiming parallel processing of two tasks is often possible. Such models
are more flexible than bottleneck models and they provide an explanation
for interference effects from the second of two tasks on the first one.

•

"Automatic" processing. Shiffrin and Schneider distinguished between
slow, flexible controlled processes and fast, automatic ones. This
distinction is greatly oversimplified. Other theorists have claimed
automatic processes are unconscious, efficient, fast and goal-unrelated.
However, these four processing features are not all-or-none and they
often correlate poorly with each other. Thus, there is no sharp
distinction between automatic and non-automatic processes. Moors' (2016)
decompositional approach plausibly assumes that there is considerable
flexibility in terms of the extent to which any given process is
"automatic".

FURTHER READING Chen, Y.-C. & Spence, C. (2017). Assessing the role of
the "unity assumption" on multi-sensory integration: A review. Frontiers
in Psychology, 8 (Article 445). Factors determining the extent to which
stimuli from different sensory modalities are integrated are discussed.
Engstrom, J., Markkula, G., Victor, T. & Merat, N. (2017). Effects of
cognitive load on driving performance: The cognitive control hypothesis.
Human Factors,

233

234

Visual perception and attention 59, 734--764. Johan Engstrom and his
colleagues review research on factors influencing driving performance
and provide a new theoretical approach. Hulleman, J. & Olivers, C.N.L.
(2017). The impending demise of the item in visual search. Behavioral
and Brain Sciences, 40, 1--20. This review article indicates very
clearly why theoretical accounts of visual search increasingly emphasise
the role of fixations and visual perception. Several problems with
previous attention-based theories of visual search are also discussed.
Karnath, H.-O. (2015). Spatial attention systems in spatial neglect.
Neuropsychologia, 75, 61--73. Hans-Otto Karnath discusses theoretical
accounts of neglect emphasising the role of attentional systems. Koch,
I., Poljac, E., Müller, H. & Kiesel, A. (2018). Cognitive structure,
flexibility, and plasticity in human multitasking -- An integrative
review of dual-task and task-switching research. Psychological Bulletin,
144, 557--583. Iring Koch and colleagues review dual-task and
task-switching research with an emphasis on major theoretical
perspectives. McDermott, J.H. (2018). Audition. In J.T. Serences (ed.),
Stevens' Handbook of Experimental Psychology and Cognitive Neuroscience,
Vol. 2: Sensation, Perception, and Attention (4th edn; pp. 63--120). New
York: Wiley. Josh McDermott discusses theory and research focused on
selective auditory attention in this comprehensive chapter. Melnikoff,
D.E. & Bargh, J.A. (2018). The mythical number two. Trends in Cognitive
Sciences, 22, 280--293. Research revealing limitations with traditional
theoretical approaches to "automaticity" is discussed. Moors, A. (2016).
Automaticity: Componential, causal, and mechanistic explanations. Annual
Review of Psychology, 67, 263--287. Agnes Moors provides an excellent
critique of traditional views on "automaticity" and develops her own
comprehensive theoretical account. Nobre, A.C. (2018). Attention. In
J.T. Serences (ed.), Stevens' Handbook of Experimental Psychology and
Cognitive Neuroscience, Vol. 2: Sensation, Perception, and Attention
(4th edn; pp. 241--316). New York: Wiley. Anna (Kia) Nobre discusses the
key role played by attention in numerous aspects of cognitive
processing.

How important is memory? Imagine if we were without it. We would not
recognise anyone or anything as familiar. We would be unable to talk,
read or write because we would remember nothing about language. We would
have extremely limited personalities because we would have no
recollection of the events of our own lives and therefore no sense of
self. In sum, we would have the same lack of knowledge as a newborn
baby. Nairne et al. (2007) argued there were close links between memory
and survival in our evolutionary history. Our ancestors prioritised
information relevant to their survival (e.g., remembering the location
of food or water; ways of securing a mate). Nairne et al. found memory
for word lists was especially high when participants rated the words for
their relevance to survival in a dangerous environment: the
survival-processing effect. This effect has been replicated several
times (Kazanas & Altarriba, 2015) and is stronger when participants
imagine themselves alone in a dangerous environment rather than with a
group of friends (Leding & Toglia, 2018). In sum, human memory may have
evolved in part to promote survival. We use memory for numerous purposes
throughout every day of our lives. It allows us to keep track of
conversations, to remember how to use a mobile phone, to write essays in
examinations, to recognise other people's faces, to take part in
conversations, to ride a bicycle, to carry out intentions and, perhaps,
to play various sports. More generally, our interactions with others and
with the environment depend crucially on having an effective memory
system. The wonders of human memory are discussed at length in Chapters
6--8. Chapter 6 deals mainly with key issues regarded as important from
the early days of memory research. For example, we consider the
distinction between short-term and long-term memory. The notion of
short-term memory has been largely superseded by that of a
working-memory system combining the functions of processing and
short-term information storage. There is extensive coverage of working
memory in Chapter 6. Another topic discussed at length in Chapter 6 is
learning. Long-term memory is generally enhanced when meaning is
processed at the time of learning. Long-term memory is also better if
much of the learning period

PART II

Memory

238

Memory

is spent practising retrieval. Evidence suggesting some learning is
implicit (i.e., does not depend on conscious processes) is also
discussed. Finally, we discuss forgetting. Why do we tend to forget
information over time? Chapter 7 is devoted to long-term memory. Our
long-term memories include personal information, knowledge about
language, much knowledge about psychology (hopefully!), knowledge about
thousands of objects in the world around us, and information about how
to perform various skills (e.g., riding a bicycle; playing the piano).
The central issue addressed in Chapter 7 is how to account for this
incredible richness. Several theorists have claimed there are several
long-term memory systems. Others argue that there are numerous processes
that are combined and recombined depending on the specific demands of
any given memory task. Memory is important in everyday life in ways
de-emphasised historically. For example, autobiographical memory
(discussed in Chapter 8) is of great significance to us. It gives us a
coherent sense of ourselves and our personalities. The other topics
considered in Chapter 8 are eyewitness testimony and prospective memory
(memory for future intentions). Research into eyewitness testimony has
revealed that eyewitness testimony is often much less accurate than
generally assumed. This has implications for the legal system because
hundreds of innocent individuals have been imprisoned solely on the
basis of eyewitness testimony. When we think about memory, we naturally
focus on memory of the past. However, we also need to remember numerous
future commitments (e.g., meeting a friend as arranged), and such
remembering involves prospective memory. We will consider how we try to
ensure we carry out our future intentions. The study of human memory is
fascinating, and substantial progress has been made. However, it is
complex and depends on several factors. Four kinds of factors are
especially important: events, participants, encoding and retrieval
(Roediger, 2008). Events range from words and pictures to texts and life
events. Participants vary in age, expertise, memory-specific disorders
and so on. What happens at encoding varies as a function of task
instructions, the immediate context and participants' strategies.
Finally, memory performance at retrieval often varies considerably
depending on the nature of the memory task (e.g., free recall; cued
recall; recognition). The take-home message is that memory findings are
context-sensitive -- they depend on interactions between the four
factors. Thus, the effects of manipulating, say, what happens at
encoding depend on the participants used, the events to be remembered
and the conditions of retrieval. That explains why Roediger (2008)
entitled his article, "Why the laws of memory vanished". How, then, do
we make progress? As Baddeley (1978, p. 150) argued, "The most fruitful
way to extend our understanding of human memory is not to search for
broader generalisations and 'principles', but is rather to develop ways
of separating out and analysing more deeply the complex underlying
processes."

Chapter

Learning, memory and forgetting

6

INTRODUCTION This chapter (and the next two) focus on human memory. All
three chapters deal with intact human memory, but Chapter 7 also
considers amnesic patients in detail. Traditional laboratory-based
research is the focus of this chapter and Chapter 7, with more
naturalistic research being discussed in Chapter 8. There are important
links among these different types of research. For example, many
theoretical issues relevant to brain-damaged and healthy individuals can
be tested in the laboratory or in the field. Learning and memory involve
several stages of processing. Encoding occurs during learning: it
involves transforming presented information into a representation that
can subsequently be stored. This is the first stage. As a result of
encoding, information is stored within the memory system. Thus, storage
is the second stage. The third stage is retrieval, which involves
recovering information from the memory system. Forgetting (discussed
later, see pp. 278--293) occurs when our attempts at retrieval are
unsuccessful. Several topics are discussed in this chapter. The basic
structure of the chapter consists of three sections: (1)

(2) 

The first section focuses mostly on short-term memory (a form of memory
in which information is held for a brief period of time). This section
has three topics (short-term vs long-term memory; working memory; and
working memory: executive functions and individual differences). The
emphasis here is on the early stages of processing (especially
encoding). The second section focuses on learning and the processes
occurring during the acquisition of information (i.e., encoding
processes) leading to long-term memory. Learning can be explicit
(occurring with conscious awareness of what has been learned) or
implicit (occurring without conscious awareness of what has been
learned). The first two topics in this section (levels of processing;
learning through retrieval) focus on explicit learning whereas the third
topic focuses on implicit learning.

KEY TERM Encoding The process by which information contained in external
stimuli is transformed into a representation that can be stored within
the memory system.

240

Memory

KEY TERM

(3) 

Iconic memory A sensory store that holds visual information for between
250--1,000 milliseconds following the offset of a visual stimulus.

The third section consists of a single topic: forgetting from long-term
memory. The emphasis differs from the other two sections in that the
emphasis is on retrieval processes rather than encoding processes. More
specifically, the focus is on the reasons responsible for the failures
of retrieval.

SHORT-TERM VS LONG-TERM MEMORY Many theorists distinguish between
short-term and long-term memory. For example, there are enormous
differences in capacity: only a few items can be held in short-term
memory compared with essentially unlimited capacity in long-term memory.
There are also massive differences in duration: a few seconds for
short-term memory compared with up to several decades for long-term
memory. The distinction between short-term and long-term memory stores
was central to multi-store models. More recently, however, some
theorists have proposed unitary-store models in which this distinction
is much less clear-cut. Both types of models are discussed below.

Multi-store model Atkinson and Shiffrin (1968) proposed an extremely
influential multi-store model (see Figure 6.1): ●

● ●

sensory stores, each modality-specific (i.e., limited to one sensory
modality) and holding information very briefly; short-term store of very
limited capacity; long-term store of essentially unlimited capacity
holding information over very long periods of time.

According to the multi-store model, environmental stimulation is
initially processed by the sensory stores. These stores are
modality-specific (e.g., vision; hearing). Information is held very
briefly in the sensory stores, with some being attended to and processed
further within the short-term store.

Sensory stores The visual store (iconic memory) holds visual information
briefly. According to a recent estimate (Clarke & Mack, 2015), iconic
memory for a natural scene lasts for at least 1,000 ms after stimulus
offset. If you twirl

Figure 6.1 The multi-store model of memory as proposed by Atkinson and
Shiffrin (1968).

Learning, memory and forgetting

a lighted object in a circle in the dark, you will see a circle of light
because of the persistence of visual information in iconic memory. More
generally, iconic memory increases the time for which visual information
is accessible (e.g., when reading). Atkinson and Shiffrin (1968) and
many other theorists have assumed iconic memory is pre-attentive (not
dependent on attention). However, Mack et al. (2016) obtained findings
strongly suggesting that iconic memory does depend on attention.
Participants had to report the letters in the centre of a visual array
(iconic memory) or whether four circles presented close to the fixation
point were the same colour. Performance on the iconic memory task was
much worse when the probability of having to perform the iconic memory
task was only 10% rather than 90%. This happened because there was much
less attention to the letters in the former condition. Echoic memory,
the auditory equivalent of iconic memory, holds auditory information for
a few seconds. Suppose someone asked you a question while your mind was
elsewhere. Perhaps you replied "What did you say?", just before
realising you did know what had been said. This "playback" facility
depends on echoic memory. Ioannides et al. (2003) found the duration of
echoic memory was longer in the left hemisphere than the right, probably
because of the dominance of the left hemisphere in language processing.
There are sensory stores associated with all other senses (e.g., touch;
taste). However, they are less important than iconic and echoic memory
and have attracted much less research.

241

KEY TERMS Echoic memory A sensory store that holds auditory information
for approximately 2--3 seconds. Chunks Stored units formed from
integrating smaller pieces of information.

Short-term memory Short-term memory has very limited capacity. Consider
digit span: participants listen to a random digit series and then repeat
back the digits immediately in the correct order. There are also letter
and word spans. The maximum number of items recalled without error is
typically about seven. There are two reasons for rejecting seven items
as the capacity of short-term memory. First, we must distinguish between
items and chunks -- "groups of items . . . collected together and
treated as a single unit" (Mathy & Feldman, 2012, p. 346). For example,
most individuals presented with the letter string IBMCIAFBI would treat
it as three chunks rather than nine letters. Here is another example:
you might find it hard to recall the following five words: is thing
many-splendoured a love but easier to recall the same words presented as
follows: love is a many-splendoured thing. Simon (1974) showed the
importance of chunking. Immediate serial recall was 22 words with 8-word
sentences but only 7 with unrelated words. In contrast, the number of
chunks recalled varied less: it was 3 with the sentences compared to 7
with the unrelated words. Second, estimates of short-term memory
capacity are often inflated because participants' performance is
influenced by rehearsal and long-term memory. What influences chunking?
As we have seen, it is strongly determined by information stored in
long-term memory (e.g., IBM stands for International Business Machines).
However, chunking also depends on people's abilities to identify
patterns or regularities in the material presented for learning.

Interactive exercise: Capacity of short-term memory

Interactive exercise: Duration of short-term memory

242

Memory

KEY TERM

For example, compare the digit sequences 2 3 4 5 6 and 2 4 6 3 5. It is
much easier to chunk the former sequence as "all digits between 2 and
6". Chekaf et al. (2016) found participants' short-term memory was
greatly enhanced by spontaneous detection of such patterns. When there
were no patterns in the learning material, short-term memory was only
three items. A similar capacity limit was reported by Chen and Cowan
(2009). When rehearsal was prevented by articulatory suppression (saying
"the" repeatedly), only three chunks were recalled. Within the
multi-store model, it is assumed all items within short-term memory have
equal importance. However, this is an oversimplification. Vergauwe and
Langerock (2017) assessed speed of performance when participants were
presented with four letters followed by a probe letter and decided
whether the probe was the same as any of the original letters. Response
to the probe was fastest when it corresponded to the letter currently
being attended to (cues were used to manipulate which letter was the
focus of attention at any given moment). How is information lost from
short-term memory? Several answers have been provided (Endress & Szabó,
2017). Atkinson and Shiffrin (1968) emphasised the importance of
displacement -- the capacity of short-term memory is very limited, and
so new items often displace items currently in short-term memory.
Another possibility is that information in short-term memory decays over
time in the absence of rehearsal. A further possibility is interference
which could come from items on previous trials and/or from information
presented during the retention interval. The experimental findings are
variable. Berman et al. (2009) claimed interference is more important
than decay. Short-term memory performance on any given trial was
disrupted by words presented on the previous trial. Suppose this
disruption effect occurred because words from the previous trial had not
decayed sufficiently. If so, disruption would have been greatly reduced
by increasing the inter-trial interval. In fact, increasing that
interval had no effect. However, the disruption effect was largely
eliminated when interference from previous trials was reduced. Campoy
(2012) pointed out Berman et al.'s (2009) research was limited because
their experimental design did not allow them to observe any decay
occurring within 3.3 seconds of item presentation. Campoy obtained
strong decay effects at time intervals shorter than 3.3 seconds.
Overall, the findings suggest decay occurs mostly at short retention
intervals and interference at longer ones. Strong evidence interference
is important was reported by Endress and Potter (2014). They rapidly
presented 5, 11 or 21 pictures of familiar objects. In their unique
condition, no pictures were repeated over trials, whereas in their
repeated condition, the same pictures were seen frequently over trials.
Short-term memory was greater in the unique condition in which there was
much less interference than in the repeated condition (see Figure 6.2).
In sum, most of the evidence indicates that interference is the most
important factor causing forgetting from short-term memory, although
decay may also play a part. There is little direct evidence that
displacement (emphasised by Atkinson & Shiffrin, 1968) is the main
factor causing forgetting. However, it is possible that interference
causes items to be displaced from short-term memory (Endress & Szabó,
2017).

Articulatory suppression Rapid repetition of a simple sound (e.g., "the
the the"), which uses the articulatory control process of the
phonological loop.

Learning, memory and forgetting

10

Unique condition Repeated condition

9.1

Capacity estimate

8 6

4.9

3.7

4.8

2.3

0 5

Figure 6.2 Short-term memory performance in conditions designed to
create interference (repeated condition) or minimise interference
(unique condition) for set sizes 5, 11 and 21 pictures. From Endress and
Potter, 2014.

4 3.2 2

243

11

21

Set size

Short-term vs long-term memory Is short-term memory distinct from
long-term memory, as assumed by Atkinson and Shiffrin (1968)? If they
are separate, we would expect some patients to have impaired long-term
memory but intact short-term memory with others showing the opposite
pattern. This would produce a double dissociation (see Glossary). The
findings are generally supportive. Patients with amnesia (discussed in
Chapter 7) have severe long-term memory impairments but nearly all have
intact short-term memory (Spiers et al., 2001). A few brain-damaged
patients have severely impaired short-term memory but intact long-term
memory. For example, KF had no problems with long-term learning and
recall but had a very small digit span (Shallice & Warrington, 1970).
Subsequent research indicated his shortterm memory problems focused
mainly on recall of verbal material (letters; words; digits) rather than
meaningful sounds or visual stimuli (Shallice & Warrington, 1974).

Evaluation The multi-store model has been enormously influential. It is
widely accepted (but see below) that there are three separate kinds of
memory stores. Several sources of experimental evidence support the
crucial distinction between short-term and long-term memory. However,
the strongest evidence probably comes from brain-damaged patients having
impairments only to shortterm or long-term memory. What are the model's
limitations? First, it is very oversimplified (e.g., the assumptions
that the short-term and long-term stores are both unitary: operating in
a single, uniform way). Below we discuss an approach where the single
short-term store is replaced by a working memory system having four
components. In similar fashion, there are several long-term memory
systems (see Chapter 7).

244

Memory

Second, the assumption that the short-term store is a gateway between
the sensory stores and long-term memory (see Figure 6.1) is incorrect.
The information processed in short-term memory has typically already
made contact with information in long-term memory (Logie, 1999). For
example, you can only process IBM as a single chunk in short-term memory
after you have accessed long-term memory to obtain the meaning of IBM.
Third, Atkinson and Shiffrin (1968) assumed information in shortterm
memory represents the "contents of consciousness". This implies only
information processed consciously is stored in long-term memory.
However, there is much evidence for implicit learning (learning without
conscious awareness of what has been learned) (discussed later, see
pp. 269--278). Fourth, the assumption all items within short-term memory
have equal status is incorrect. The item currently being attended to is
accessed more rapidly than other items within short-term memory
(Vergauwe & Langerock, 2017). Fifth, the notion that most information is
transferred to long-term memory via rehearsal greatly exaggerates its
role in learning. In fact, only a small fraction of the information
stored in long-term memory was rehearsed during learning. Sixth, the
notion that forgetting from short-term memory is caused by displacement
minimises the role of interference.

Unitary-store model Several theorists have argued the multi-store
approach should be replaced by a unitary-store model. According to such
a model, "STM \[short-term memory\] consists of temporary activations of
LTM \[long-term memory\] representations or of representations of items
that were recently perceived" (Jonides et al., 2008, p. 198). In
essence, Atkinson and Shiffrin (1968) emphasised the differences between
short-term and long-term memory whereas advocates of the unitary-store
approach focus on the similarities. How can unitary-store models explain
amnesic patients having essentially intact short-term memory but
severely impaired long-term memory? Jonides et al. (2008) argued they
have special problems in forming novel relations (e.g., between items
and their context) in both short-term and long-term memory. Amnesic
patients perform well on short-term memory tasks because such tasks
typically do not require storing relational information. Thus, amnesic
patients should have impaired short-term memory performance on tasks
requiring relational memory. According to Jonides et al. (2008), the
hippocampus and surrounding medial temporal lobes (damaged in amnesic
patients) are crucial for forming novel relations. Multi-store theorists
assume these structures are much more involved in long-term than
short-term memory. However, unitary-store models predict the hippocampus
and medial temporal lobes would be involved if a short-term memory task
required forming novel relations.

Learning, memory and forgetting

Findings Several studies have assessed the performance of amnesic
patients on short-term memory tasks. In some studies (e.g., Hannula et
al., 2006) the performance of amnesic patients was impaired. However,
Jeneson and Squire (2012) in a review found these allegedly short-term
memory studies also involved long-term memory. More specifically, the
information to be learned exceeded the capacity of short-term memory and
so necessarily involved long-term memory as well as short-term memory
(Norris, 2017). As a result, such studies do not demonstrate deficient
short-term memory in amnesic patients. Several neuroimaging studies have
reported hippocampal involvement (thought to be crucial for long-term
memory) during short-term memory tasks. However, it has generally been
unclear whether hippocampal activation was due in part to encoding for
long-term memory. An exception was a study by Bergmann et al. (2012).
They assessed short-term memory for face--house pairs followed by an
unexpected test of long-term memory for the pairs. What did Bergmann et
al. (2012) find? Encoding of pairs remembered in both short- and
long-term memory involved the hippocampus. However, there was no
hippocampal activation at encoding when short-term memory for word pairs
was successful but subsequent long-term memory was not. Thus, the
hippocampus was only involved on a short-term memory task when long-term
memories were being formed.

Evaluation As predicted by the unitary-store approach, activation of
part of long-term memory often plays an important role in short-term
memory. More specifically, relevant information from long-term memory
frequently influences the contents of short-term memory. What are the
limitations of the unitary-store approach? First, the claim that
short-term memory consists only of activated long-term memory is
oversimplified. As Norris (2017, p. 992) pointed out, "The central
problem . . . is that STM has to be able to store arbitrary
configurations of novel information. For example, we can remember novel
sequences of words or dots in random positions on a screen. These cannot
possibly have pre-existing representations in LTM that could be
activated." Short-term memory is also more flexible than expected on the
unitary-store approach (e.g., backward digit recall: recalling digits in
the opposite order to the one presented). Second, we must distinguish
between the assumption that short-term memory is only activated
long-term memory and the assumption that short-term and long-term memory
are separate but often interact. Most evidence supports the latter
assumption rather than the former. Third, the theory fails to provide a
precise definition of the crucial explanatory concept of "activation".
It is thus unclear how activation might maintain representations in
short-term memory (Norris, 2017). Fourth, the medial temporal lobes
(including the hippocampus) are of crucial importance for many forms of
long-term memory (especially

245

246

Memory

declarative memory -- see Glossary). Amnesic patients with damage to
these brain areas have severely impaired declarative memory. In
contrast, amnesic patients typically have intact short-term memory
(Spiers et al., 2001).

WORKING MEMORY: BADDELEY AND HITCH

Photos courtesy of Alan Baddeley and Graham Hitch.

Research activity: Phonemic similarity

Is short-term memory useful in everyday life? Textbook writers used to
argue it allows us to remember a telephone number for the few seconds
required to dial it. Of course, that is now irrelevant -- our mobile
phones store all the phone numbers we need regularly. Baddeley and Hitch
(1974) provided a convincing answer to the above question. They argued
we typically use short-term memory when performing complex tasks. Such
tasks involve storing information about the outcome of early processes
in short-term memory while moving on to later processes. Baddeley and
Hitch's key insight was that short-term memory is essential to the
performance of numerous tasks that are not explicitly memory tasks. The
above line of thinking led Baddeley and Hitch (1974) to replace the
concept of short-term memory with that of working memory. Working memory
"refers to a system, or a set of processes, holding mental
representations temporarily available for use in thought and action"
(Oberauer et al., 2018, p. 886). Since 1974, there have been several
developments of the working memory system (Baddeley, 2012, 2017; see
Figure 6.3):

Central executive

Shape

Object

Kinaesthetic Tactile Smell

Visual

Spatial

Taste Speech

Haptic

Lip-reading

Music and sound

Episodic buﬀer Visuo-spatial sketch pad

Visual semantics

Artic

Alan Baddeley and Graham Hitch.

Episodic long-term memory

Phonological loop

Language

Figure 6.3 The working memory model showing the connections between its
four components and their relationship to long-term memory. Artic =
articulatory rehearsal. From Darling et al., 2017.

Learning, memory and forgetting

●

●

●

●

a modality-free central executive, which "is an attentional system"
(Baddeley, 2012, p. 22); a phonological loop processing and storing
information briefly in a phonological (speech-based) form; a
visuo-spatial sketchpad specialised for spatial and visual processing
and temporary storage; an episodic buffer providing temporary storage
for integrated information coming from the visuo-spatial sketchpad and
phonological loop; this component (added by Baddeley, 2000) is discussed
later (see pp. 252--253).

The most important component is the central executive. The phonological
loop and the visuo-spatial sketchpad are slave systems used by the
central executive for specific purposes. The phonological loop preserves
word order, whereas the visuo-spatial sketchpad stores and manipulates
spatial and visual information. All three components discussed above
have limited capacity and can function fairly independently of the
others. Two key assumptions follow: (1) (2)

If two tasks use the same component, they cannot be performed
successfully together. If two tasks use different components, they can
be performed as well together as separately.

Robbins et al. (1996) investigated these assumptions in a study on the
selection of chess moves. Chess players selected continuation moves from
various chess positions while also performing one of the following
tasks: ● ● ●

●

repetitive tapping: the control condition; random letter generation:
this involves the central executive; pressing keys on a keypad in a
clockwise fashion: this uses the visuo-spatial sketchpad; rapid
repetition of the word "see-saw": this is articulatory suppression and
uses the phonological loop.

The quality of chess moves was impaired when the additional task
involved the central executive or visuo-spatial sketchpad but not when
it involved the articulatory loop. Thus, calculating successful chess
moves requires use of the central executive and the visuo-spatial
sketchpad but not the articulatory loop.

Phonological loop According to the working memory model, the
phonological loop has two components (see Figure 6.4): ● ●

a passive phonological store directly concerned with speech perception;
an articulatory process linked to speech production (i.e., rehearsal)
giving access to the phonological store.

247

KEY TERMS Working memory A limited-capacity system used in the
processing and brief holding of information. Central executive A
modality-free, limitedcapacity, component of working memory.
Phonological loop A component of working memory in which speechbased
information is processed and stored briefly and subvocal articulation
occurs. Visuo-spatial sketchpad A component of working memory used to
process visual and spatial information and to store this information
briefly. Episodic buffer A component of working memory; it is
essentially passive and stores integrated information briefly.

248

Memory

Figure 6.4 Phonological loop system as envisaged by Baddeley (1990).

Interactive exercise: Encoding in STM

KEY TERMS Phonological similarity effect The finding that immediate
serial recall of verbal material is reduced when the items sound
similar. Word-length effect The finding that verbal memory span
decreases when longer words are presented. Orthographic neighbours With
reference to a target word, the number of words that can be formed by
changing one of its letters.

Suppose we test individuals' memory span by presenting a word list
visually and requiring immediate recall in the correct order. Would they
use the phonological loop to engage in verbal rehearsal (i.e., saying
the words repeatedly to themselves)? Two kinds of evidence (discussed
below) indicate the answer is "Yes". First, there is the phonological
similarity effect -- reduced immediate serial recall when words are
phonologically similar (i.e., have similar sounds). For example,
Baddeley et al. (2018) found that short-term memory was much worse with
phonologically similar words (e.g., pan, cat, bat, ban, pad, man) than
phonologically dissimilar words (e.g., man, pen, rim, cod, bud, peel).
The working memory model does not make it clear whether the phonological
similarity effect depends more on acoustic similarity (similar sounds)
or articulatory similarity (similar articulatory movements). Schweppe et
al. (2011) found the effect depends more on acoustic than articulatory
similarity. However, there was an influence of articulatory similarity
when recall was spoken. Second, there is the word-length effect: word
span (words recalled immediately in the correct order) is greater for
short than long words. Baddeley et al. (1975) obtained this effect with
visually presented words. As predicted, the effect disappeared when
participants engaged in articulatory suppression (repeating the digits 1
to 8) to prevent rehearsal within the phonological loop during list
presentation. In similar fashion, Jacquemot et al. (2011) found a
brain-damaged patient with greatly impaired ability to engage in verbal
rehearsal had no word-length effect. Jalbert et al. (2011) pointed out a
short word generally has more orthographic neighbours (words of the same
length differing from it in only one letter) than a long word. When
short (one-syllable) and long (three-syllable) words were equated for
neighbourhood size, the wordlength effect disappeared. Thus, the
word-length effect may be misnamed. Which brain areas are associated
with the phonological loop? Areas in the parietal lobe, especially the
supramarginal gyrus (BA40) and angular gyrus (BA39), are associated with
the phonological store, whereas Broca's area (approximately BA44 and
BA45) within the frontal lobe is associated with the articulatory
control process. Evidence indicating these areas differ in their
functioning was reported by Papagno et al. (2017). Patients undergoing
brain surgery received direct

Learning, memory and forgetting

249

electrical stimulation while performing a digit-span task. Stimulation
within the parietal lobe increased item errors in the task because it
disrupted the storage of information. In contrast, stimulation within
Broca's area increased order errors because it disrupted rehearsal of
items in the correct order (see Figure 6.5). How is the phonological
loop useful in everyday life? The answer is not immediately obvious.
Baddeley et al. (1988) found a female patient, PV, with a very small
digit span (only two items) coped very well (e.g., running a shop and
raising a family). In subsequent research, however, Baddeley et
al. (1998) argued the phonological loop is useful when learning a
language. PV (a native Italian speaker) had generally good learning
ability but was totally unable to associate Russian words with Figure
6.5 their Italian translations. Indeed, she showed no Sites where direct
electrical stimulation disrupted digitspan performance. Item-error sites
are in blue, orderlearning at all over ten trials! error sites are in
yellow and sites where both types of The phonological loop ("inner
voice") is also errors occurred are in green. used to resist temptation.
Tullett and Inzlicht (2010) found articulatory suppression (saying
computer repeatedly) reduced participants' ability to control their
actions (they were more likely to respond on trials where they should
have inhibited a response).

Visuo-spatial sketchpad The visuo-spatial sketchpad is used for the
temporary storage and manipulation of visual patterns and spatial
movement. In essence, visual processing involves remembering what and
spatial processing involves remembering where. In everyday life, we use
the sketchpad to find the route when moving from one place to another or
when watching television. The distinction between visual and spatial
processing is very clear with respect to blind individuals. Schmidt et
al. (2013) found blind individuals could construct spatial
representations of the environment almost as accurately as those of
sighted individuals despite their lack of visual processing. Is there a
single system containing combining visual and spatial processing or are
there partially separate systems? Logie (1995) identified two separate
components:

KEY TERMS

involved in the rehearsal of information in the visual cache and
transfers information from the visual cache to the central executive.

Visual cache According to Logie, the part of the visuo-spatial sketchpad
that stores information about visual form and colour.

Smith and Jonides (1997) obtained findings supporting the notion of
separate visual and spatial systems. Two visual stimuli presented
together were followed by a probe stimulus. Participants decided whether
the probe was in the same location as one of the initial stimuli
(spatial task) or had the same form (visual task). Even though the
stimuli presented were identical in

Inner scribe According to Logie, the part of the visuo-spatial sketchpad
dealing with spatial and movement information.

(1) 
(2) 

visual cache: this stores information about visual form and colour;
inner scribe: this processes spatial and movement information; it is

250

Figure 6.6 Amount of interference on a spatial task (dots) and a visual
task (ideographs) as a function of a secondary task (spatial: movement
vs visual: colour discrimination). From Klauer and Zhao (2004). © 2000
American Psychological Association. Reproduced with permission.

Memory

the two tasks, there was more activity in the right hemisphere during
the spatial task than the visual task, but the opposite was the case for
activity in the left hemisphere. Zimmer (2008) found in a research
review that areas within the occipital and temporal lobes were activated
during visual processing. In contrast, areas within the parietal cortex
(especially the intraparietal sulcus) were activated during spatial
processing. Klauer and Zhao (2004) used two main tasks: (1) a spatial
task (memory for dot locations); (2) a visual task (memory for Chinese
characters). The main task was performed at the same time as a visual
(colour discrimination) or spatial (movement discrimination)
interference task. If the visuo-spatial sketchpad has separate spatial
and visual components, the spatial interference task should disrupt
performance more on the spatial main task. Second, the visual
interference task should disrupt performance more on the visual main
task. Both predictions were supported (see Figure 6.6). Vergauwe et
al. (2009) argued that visual and spatial tasks often require the
central executive's attentional resources. They used more demanding
versions of Klauer and Zhao's (2004) main tasks and obtained different
findings: each type of interference (visual and spatial) had comparable
effects on the spatial and visual main tasks. Thus, there are general,
attentionally demanding interference effects when tasks are demanding
but also interference effects specific to the type of interference when
tasks are relatively undemanding. Morey (2018) discussed the theoretical
assumption that the visuospatial sketchpad is a specialised system
separate from other cognitive systems and components of working memory.
She identified two predictions following from that assumption: (1)

(2) 

Some brain-damaged patients should have selective impairments of visual
and/or spatial short-term memory with other cognitive processes and
systems essentially intact. Short-term visual or spatial memory in
healthy individuals should be largely or wholly unaffected by the
requirement to perform a secondary task at the same time (especially
when that task does not require visual or spatial processing).

Morey (2018) reviewed evidence inconsistent with both the above
predictions. First, the great majority of brain-damaged patients with
impaired visual and/or spatial short-term memory also have various more
general cognitive impairments. Second, Morey carried out a meta-analytic
review and found that short-term visual and spatial memory was strongly
impaired by cognitively demanding secondary tasks. This was the case
even when the secondary task did not require visual or spatial
processing.

Learning, memory and forgetting

In sum, there is some support for the notion that the visuo-spatial
sketchpad has somewhat separate visual and spatial components. However,
the visuo-spatial sketchpad seems to interact extensively with other
cognitive and memory systems, which casts doubt on the theoretical
assumption that it often operates independently from other systems.

Central executive The central executive (which resembles an attentional
system) is the most important and versatile component of the working
memory system. It is heavily involved in almost all complex cognitive
activities (e.g., solving a problem; carrying out two tasks at the same
time) but does not store information. There is much controversy
concerning the brain regions most associated with the central executive
and its various functions (see below, pp. 257--262). However, it is
generally assumed the prefrontal cortex is heavily involved. Mottaghy
(2006) reviewed studies using repetitive transcranial magnetic
stimulation (rTMS; see Glossary) to disrupt the dorsolateral prefrontal
cortex (BA9/46). Performance on many complex cognitive tasks was
impaired by this manipulation. However, executive processes do not
depend solely on the prefrontal cortex. Many brain-damaged patients
(e.g., those with diffuse trauma) have poor executive functioning
despite having little or no frontal damage (Stuss, 2011). Baddeley has
always recognised that the central executive is associated with several
executive functions (see Glossary). For example, Baddeley (1996)
speculatively identified four such processes: (1) focusing attention or
concentration; (2) dividing attention between two stimulus streams; (3)
switching attention between tasks; and (4) interfacing with longterm
memory. It has proved difficult to obtain consensus on the number and
nature of executive processes. However, two influential theoretical
approaches are discussed below. Brain-damaged individuals whose central
executive functioning is impaired suffer from dysexecutive syndrome.
Symptoms include impaired response inhibition, rule deduction and
generation, maintenance and shifting of sets, and information generation
(Godefroy et al., 2010). Unsurprisingly, patients with this syndrome
have great problems in holding a job and functioning adequately in
everyday life (Chamberlain, 2003).

Evaluation The notion of a unitary central executive is greatly
oversimplified (see below). As Logie (2016, p. 2093) argued, "Executive
control \[may\] arise from the interaction among multiple differing
functions in cognition that use different, but overlapping, brain
networks . . . the central executive might now be offered a dignified
retirement." Similar criticisms can be directed against the notion of a
dysexecutive syndrome. Patients with widespread damage to the frontal
lobes may have a global dysexecutive syndrome. However, as discussed
below, patients with limited frontal damage display various patterns of
impairment to executive processes (Stuss & Alexander, 2007).

251

KEY TERMS Executive processes Processes that organise and coordinate the
functioning of the cognitive system to achieve current goals.
Dysexecutive syndrome A condition in which damage to the frontal lobes
causes impairments to the central executive component of working memory.

252

Memory

Episodic buffer

Case study: The episodic buffer

Why was the episodic buffer added to the model? There are various
reasons. First, the original version of the model was limited because
its components were too separate in their functioning. For example, it
was unclear how verbal information from the phonological loop and visual
and spatial information from the visuo-spatial sketchpad was integrated
to form multidimensional representations. Second, it was hard to explain
within the original model the finding that people can provide immediate
recall of up to 16 words presented in sentences (Baddeley et al., 1987).
This high level of immediate sentence recall is substantially beyond the
capacity of the phonological loop. The function of the episodic buffer
is suggested by its name. It is episodic because it holds integrated
information (or chunks) about episodes or event in a multidimensional
code combining visual, auditory and other information sources. It acts
as a buffer between the other working memory components and also links
to perception and long-term memory. Baddeley (2012) suggested the
capacity of the episodic buffer is approximately four chunks (integrated
units of information). This potentially explains why people can recall
up to 16 words in immediate recall from sentences. Baddeley (2000)
argued the episodic buffer could be accessed only via the central
executive. However, it is now assumed the episodic buffer can be
accessed by the visuo-spatial sketchpad and the phonological loop as
well as by the central executive (see Figure 6.3). In sum, the episodic
buffer differed from the existing subsystems representations \[i.e.,
phonological loop and visuo-spatial sketchpad\] in being able to hold a
limited number of multi-dimensional representations or episodes, and it
differed from the central executive in having storage capacity . . . The
episodic buffer is a passive storage system, the screen on which bound
information from other sources could be made available to conscious
awareness and used for planning future action. (Baddeley, 2017,
pp. 305--306)

Findings Why did Baddeley abandon his original assumption that the
central executive controls access to and from the episodic buffer?
Consider a study by Allen et al. (2012). Participants were presented
with visual stimuli and had to remember briefly a single feature
(colour; shape) or colour--shape combinations. It was assumed combining
visual features would require the central executive prior to storage in
the episodic buffer. On that assumption, the requirement to perform a
task requiring the central executive (counting backwards) at the same
time should have reduced memory to a greater extent for colour--shape
combinations than single features. Allen et al. (2012) found that
counting backwards had comparable effects on memory performance
regardless of whether or not feature combinations needed to be
remembered. These findings suggest combining

Learning, memory and forgetting

6

1

2

3

4

5

6

7

8

9

Figure 6.7 Screen displays for the digit 6. Clockwise from top left: (1)
single item display; (2) keypad display; and (3) linear display. From
Darling and Havelka (2010).

0

0

1

2

3

4

5

6

7

8

253

9

visual features does not require the central executive but instead
occurs "automatically" prior to information entering the episodic
buffer. Grot et al. (2018) clarified the relationship between the
central executive and the episodic buffer. Participants learned to link
or bind together words and spatial locations within the episodic buffer
for a memory test. It was either relatively easy to bind words and
spatial locations together (passive binding) or relatively difficult
(active binding). The central executive was involved only in the more
difficult active binding condition. Darling et al. (2017) discussed
several studies showing how memory can be enhanced by the episodic
buffer. Much of this research focused on visuo-spatial bootstrapping
(verbal memory being bootstrapped (supported) by visuo-spatial memory).
Consider a study by Darling and Havelka (2010). Immediate serial recall
of random digits was best when they were presented on a keypad display
rather on a single item or linear display (see Figure 6.7). Why was
memory performance best with the keypad display? This was the only
condition which allowed visual information, spatial information and
knowledge about keyboard displays accessed from long-term memory to be
integrated within the episodic buffer using bootstrapping.

Evaluation The episodic buffer provides a brief storage facility for
information from the phonological loop, the visuo-spatial sketchpad and
long-term memory. Bootstrapping data (e.g., Darling & Havelka, 2010)
suggest that processing in the episodic buffer "interacts with long-term
knowledge to enable integration across multiple independent stimulus
modalities" (Darling et al., 2017, p. 7). The central executive is most
involved when it is hard to bind together different kinds of information
within the episodic buffer. What are the limitations of research on the
episodic buffer? First, it remains unclear precisely how information
from the phonological loop and the visuo-spatial sketchpad is combined
to form unified representations within the episodic buffer. Second, as
shown in Figure 6.3, it is assumed information from sensory modalities
other than vision and hearing can be stored in the episodic buffer.
However, relevant research on smell and taste is lacking.

254

Memory

KEY TERM

Overall evaluation

Working memory capacity An assessment of how much information can be
processed and stored at the same time; individuals with high capacity
have higher intelligence and more attentional control.

Interactive exercise: Working memory

The working memory model remains highly influential over 45 years since
it was first proposed. There is convincing empirical evidence for all
components of the model. As Logie (2015, p. 100) noted, it explains
findings "from a very wide range of research topics, for example,
aspects of children's language development, aspects of counting and
mental arithmetic, reasoning and problem solving, dividing and switching
attention, navigating unfamiliar environments". What are the model's
limitations? First, it is oversimplified. Several kinds of information
are not considered within the model (e.g., those relating to smell,
touch and taste). In addition, we can subdivide spatial working memory
into somewhat separate eye-centred, hand-centred and foot-centred
spatial working memory (Postle, 2006). This could lead to an unwieldy
model with numerous components each responsible for a different kind of
information. Second, the notion of a central executive should be
replaced with a theoretical approach identifying the major executive
processes (see below, pp. 257--262). Third, the notion that the
visuo-spatial sketchpad is a specialised and relatively independent
processing system is doubtful. There is much evidence (Morey, 2018) that
it typically interacts with other working memory components (especially
the central executive). Fourth, we need more research on the
interactions among the four components of working memory (e.g., how the
episodic buffer integrates information from the other components and
from long-term memory). Fifth, the common assumption that conscious
awareness is necessarily associated with processing in all working
memory components requires further consideration. For example, executive
processes associated with the functioning of the central executive can
perhaps occur outside conscious awareness (Soto & Silvanto, 2014). As
discussed in Chapter 16, many complex processes can apparently occur in
the absence of conscious awareness.

WORKING MEMORY: INDIVIDUAL DIFFERENCES AND EXECUTIVE FUNCTIONS There
have been numerous recent attempts to enhance our understanding of
working memory. Here we will focus on two major theoretical approaches.
First, some theorists (e.g., Engle & Kane, 2004) have focused on working
memory capacity. In essence, they claim performance across numerous
tasks (including memory ones) is strongly influenced by individual
differences in working memory capacity. Second, many theorists have
replaced a unitary central executive with several more specific
executive functions.

Working memory capacity Several theorists (e.g., Engle & Kane, 2004)
have considered working memory from the perspective of individual
differences in working memory capacity, "the ability to hold and
manipulate information in a temporary

Learning, memory and forgetting

active state" (DeCaro et al., 2016, p. 39). Daneman and Carpenter (1980)
used reading span to assess this capacity. Individuals read sentences
for comprehension (processing task) and then recalled the final word of
each sentence (storage task). The reading span was defined as the
largest number of sentences from which individuals could recall the
final words over 50% of the time. Operation span is another measure of
working memory capacity. Items (e.g., IS (4 × 2) -- 3 = 5? TABLE) are
presented. Individuals answer each arithmetical question and try to
remember all the last words. Operation span is the maximum number of
items for which individuals can remember all the last words over half
the time. It correlates highly with reading span. Working memory
capacity correlates positively with intelligence. We can clarify this
relationship by distinguishing between crystallised intelligence (which
depends on knowledge, skills and experience) and fluid intelligence
(which involves a rapid understanding of novel relationships; see
Glossary). Working memory capacity correlates more strongly with fluid
intelligence (sometimes as high as +.7 or +.8; Kovacs & Conway, 2016).
The correlation with crystallised intelligence is relatively low because
it involves acquired knowledge whereas working memory capacity depends
on cognitive processes and temporary information storage. Engle and Kane
(2004) argued individuals who are high and low in working memory
capacity differ in attentional control. In their influential two-factor
theory, they emphasised two key aspects of attentional control: (1) the
maintenance of task goals; (2) the resolution of response competition or
conflict. Thus, high-capacity individuals are better at maintaining task
goals and resolving conflict. How does working memory capacity relate to
Baddeley's working memory model? The two approaches differ in emphasis.
Researchers investigating working memory capacity focus on individual
differences in processing and storage capacity whereas Baddeley focuses
on the underlying structure of working memory. However, there has been
some convergence between the two theoretical approaches. For example,
Kovacs and Conway (2016, p. 157) concluded that working memory capacity
"reflects individual differences in the executive component of working
memory, particularly executive attention and cognitive control". In view
of the association between working memory capacity and intelligence, we
would expect high-capacity individuals to outperform low-capacity ones
on complex tasks. That is, indeed, the case (see Chapter 10). However,
Engle and Kane's (2004) theory also predicts high-capacity individuals
might perform better than low-capacity ones even on relatively simple
tasks if it were hard to maintain task goals.

Findings There are close links between working memory capacity and the
executive functions of the central executive. For example, McCabe et
al. (2010) found measures of working memory capacity correlated highly
with measures of executive functioning. Both types of measures reflect
executive attention (which maintains task goals).

255

KEY TERMS Reading span The largest number of sentences read for
comprehension from which an individual can recall all the final words
over 50% of the time. Operation span The maximum number of items
(arithmetical questions + words) for which an individual can recall all
the words more than 50% of the time. Crystallised intelligence A form of
intelligence that involves the ability to use one's knowledge and
experience effectively.

256

Memory

The hypothesis that high-capacity individuals have greater attentional
control than low-capacity ones has received experimental support.
Sörqvist (2010) studied distraction effects caused by the sounds of
planes flying past. Recall of a prose passage was adversely affected by
distraction only in low-capacity individuals. Yurgil and Golob (2013),
using event-related potentials (ERPs; see Glossary), found that
high-capacity individuals attended less than low-capacity ones to
distracting auditory stimuli. We have seen goal maintenance or
attentional control in low-capacity individuals is disrupted by external
distraction. It is also disrupted by internal task-unrelated thoughts
(mind-wandering). McVay and Kane (2012) used a sustained-attention task
in which participants responded to frequent target words but withheld
responses to rare non-targets. Low-capacity individuals performed worse
than high-capacity ones on this task because they engaged in more
mind-wandering. Robison and Unsworth (2018) identified two main reasons
why this might be the case. First, low-capacity individuals' inferior
attentional control may lead to increased amounts of spontaneous or
unplanned mind-wandering. Second, low-capacity individuals may be less
motivated to perform cognitive tasks well and so engage in increased
deliberate mind-wandering. Robison and Unsworth's findings provided
support only for the first reason. Individuals having low working memory
capacity may have worse task performance than high-capacity ones because
they consistently have poorer attentional control and ability to
maintain the current task goal. Alternatively, their failures of
attentional control may only occur relatively infrequently. Unsworth et
al. (2012) compared these two explanations. They used the anti-saccade
task: a flashing cue is presented to the left (or right) of fixation
followed by a target presented in the opposite location. Reaction times
to identify the target were recorded. Unsworth et al. (2012) divided
each participant's reaction times into quintiles (five bins representing
the fastest 20%, the next fastest 20% and so on). Low-capacity
individuals were significantly slower than the highcapacity ones only in
the slowest quintile (see Figure 6.8). Thus, they experienced failures
of goal maintenance or attentional goal on only a small fraction of
trials.

Figure 6.8 Mean reaction times (RTs) quintile-by-quintile on the
anti-saccade task by groups high and low in working memory capacity.
From Unsworth et al. (2012).

Learning, memory and forgetting

Evaluation Theory and research on working memory capacity indicate the
value of focusing on individual differences. There is convincing
evidence high- and low-capacity individuals differ in attentional
control. More specifically, high-capacity individuals are better at
controlling external and internal distracting information. In addition,
they are less likely than low-capacity individuals to experience
failures of goal maintenance. Of importance, individual differences in
working memory capacity are relevant to performance on numerous
different tasks (see Chapter 10). What are the limitations of research
in this area? First, the finding that working memory capacity correlates
highly with fluid intelligence means many findings ascribed to
individual differences in working memory capacity may actually reflect
fluid intelligence. However, it can be argued that general executive
functions relevant to working memory capacity partially explain
individual differences in fluid intelligence (Kovacs & Conway, 2016).
Second, research on working memory capacity is somewhat narrowly based
on behavioural research with healthy participants. In contrast, the
unity/diversity framework (discussed next) has been strongly influenced
by neuroimaging and genetic research and by research on brain-damaged
patients. Third, there is a lack of conceptual clarity. For example,
theorists differ as to whether the most important factor differentiating
individuals with high- or low-capacity is "maintenance of task goals",
"resolution of conflict", "executive attention" or "cognitive control".
We do not know how closely related these terms are. Fourth, the inferior
attentional or cognitive control of low-capacity individuals might
manifest itself consistently throughout task performance or only
sporadically. Relatively little research (e.g., Unsworth et al., 2012)
has investigated this issue. Fifth, the emphasis in theory and research
has been on the benefits for task performance associated with having
high working memory capacity. However, some costs are associated with
high capacity. These costs are manifest when the current task requires a
broad focus of attention but high-capacity individuals adopt a narrow
and inflexible focus (e.g., DeCaro et al., 2016, 2017; see Chapter 12).

Executive functions: unity/diversity framework Executive functions are
"high-level processes that, through their influence on lower-level
processes, enable individuals to regulate their thoughts and actions
during goal-directed behaviour" (Friedman & Miyake, 2017, p. 186). The
crucial issue is to identify the number and nature of these executive
functions or processes. Various approaches can address this issue:

(1) 

Psychometric approach: several tasks requiring the use of executive
functions are administered and the pattern of inter-correlations among
the tasks is assessed. Consider the following hypothetical example.
There are four executive tasks (A, B, C and D). There is a moderate
positive correlation between tasks A and B and between C

257

KEY TERMS Executive functions Processes that organise and coordinate the
workings of the cognitive system to achieve current goals; key executive
functions include inhibiting dominant responses, shifting attention and
updating information in working memory.

258

Memory

KEY TERMS Stroop task A task in which participants have to name the ink
colours in which colour words are printed; performance is slowed when
the to-be-named colour (e.g., green) conflicts with the colour word
(e.g., red).

(2) 
(3) 
(4) 

and D but the remaining correlations are small. Such a pattern suggests
tasks A and B involve the same executive function whereas tasks C and D
involve a different executive function. Neuropsychological approach: the
focus is on individuals with brain damage causing impaired executive
functioning. Patterns of impaired functioning are related to the areas
of brain damage to identify executive functions and their locations
within the brain. Shallice and Cipiolotti (2018) provide a thorough
discussion of the applicability of this approach to understanding
executive functioning. Neuroimaging approach: the focus is on assessing
similarities and differences in the patterns of brain activation
associated with various executive tasks. For example, the existence of
two executive functions (A and B) would be supported if they were
associated with different patterns of brain activation. Genetic
approach: twin studies are conducted with an emphasis on showing
different sets of genes are associated with each executive function
(assessed by using appropriate cognitive tasks).

Several theories have been proposed on the basis of evidence using the
above approaches (see Friedman and Miyake, 2017, for a review). Here we
will focus on the very influential theory originally proposed by Miyake
et al. (2000) and developed subsequently (e.g., Friedman & Miyake,
2017).

Unity/diversity framework

Interactive exercise: Stroop

In their initial study, Miyake et al. (2000) used the psychometric
approach: they administered several executive tasks and then focused on
the pattern of inter-correlations among the tasks. They identified three
related (but separable) executive functions: (1)

Case study: Automatic processes, attention and the emotional Stroop
effect

(2) 
(3) 

Inhibition function: used to deliberately override dominant responses
and to resist distraction. For example, it is used on the Stroop task
(see Figure 1.3 on p. 5), which involves naming the colours in which
words are printed. When the words are conflicting colour words (e.g.,
the word BLUE printed in red), it is necessary to inhibit saying the
word. Shifting function: used to switch flexibly between tasks or mental
sets. Suppose you are presented with two numbers on each trial. Your
task is to switch between multiplying the two numbers and dividing one
by the other on alternate trials. Such task switching requires the
shifting function. Updating function: used to monitor and engage in
rapid addition or deletion of working memory contents. For example, this
function is used if you must keep track of the most recent member of
each of several categories.

Subsequent research (e.g., Friedman et al., 2008; Miyake & Friedman,
2012) led to the development of the unity/diversity framework. The basic
idea is that each executive function consists of what is common to all
three executive functions (unity) plus what is unique to that function
(diversity) (see Figure 6.9). After accounting for what was common to
all executive

Learning, memory and forgetting

Figure 6.9 Schematic representation of the unity and diversity of three
executive functions (EFs). Each executive function is a combination of
what is common to all three and what is specific to that executive
function. The inhibition-specific component is absent because the
inhibition function correlates very highly with the common executive
function. From Miyake and Friedman (2012). Reprinted with permission of
SAGE Publications.

functions, Friedman et al. found there was no unique variance left for
the inhibition function. Of importance, separable shifting and updating
factors have consistently been identified in subsequent research
(Friedman & Miyake, 2017). What is the nature of the common factor?
According to Friedman and Miyake (2017, p. 194), "It reflects individual
differences in the ability to maintain and manage goals, and use those
goals to bias ongoing processing." Goal maintenance (resembling
concentration) may be especially important on inhibition tasks where it
is essential to focus on task requirements to avoid distraction or
incorrect competing responses. This could explain why such tasks load
only on the common factor. Support for the notion that the common factor
reflects goal maintenance was reported by Gustavson et al. (2015).
Everyday goal-management failures (assessed by questionnaire) correlated
negatively with the common factor.

Findings So far we have focused on the psychometric approach. The
unity/diversity framework is also supported by research using the
genetic approach. Friedman et al. (2008) had monozygotic (identical) and
dizygotic (fraternal) twins perform several executive function tasks.
One key finding was that individual differences in all three executive
functions (common; updating; shifting) were strongly influenced by
genetic factors. Another key finding was that different sets of genes
were associated with each function. We turn now to neuroimaging
research. Such research partly supports the unity/diversity framework.
Collette et al. (2005) found all three of Miyake et al.'s (2000)
functions (i.e., inhibition; shifting; updating) were

259

260

Memory

Figure 6.10 Activated brain regions across all executive functions in a
meta-analysis of 193 studies (shown in red). From Niendam et al. (2012).

associated with activation in different prefrontal areas. However, all
tasks produced activation in other areas (e.g., the left lateral
prefrontal cortex, which is consistent with Miyake and Friedman's (2012)
unity notion). Niendam et al. (2012) carried out a meta-analysis (see
Glossary) of findings from 193 studies where participants performed many
tasks involving executive functions. Of most importance, several brain
areas were activated across all executive functions (see Figure 6.10).
These areas included the dorsolateral prefrontal cortex (BA9/46),
fronto-polar cortex (BA10), orbitofrontal cortex (BA11) and anterior
cingulate (BA32). This brain network corresponds closely to the common
factor identified by Miyake and Friedman (2012). In addition, Niendam et
al. found some differences in activated brain areas between shifting and
inhibition function tasks. Stuss and Alexander (2007) argued the notion
of a dysexecutive syndrome (see Glossary; discussed earlier, p. 251)
erroneously implies brain damage to the frontal lobes damages all
central executive functions. While there may be a global dysexecutive
syndrome in patients having widespread damage to the frontal lobes, this
is not so in patients having limited prefrontal damage. Among such
patients, Stuss and Alexander identified three executive processes, each
associated with a different region within the frontal cortex
(approximate brain locations are in brackets): (1)

Task setting (left lateral): this involves planning; it is "the ability
to set a stimulus-response relationship . . . necessary in the early
stages of learning to drive a car or planning a wedding" (p. 906).

Learning, memory and forgetting

(2) 
(3) 

Monitoring (right lateral): this involves checking the adequacy of one's
task performance; deficient monitoring leads to increased variability of
performance and increased errors. Energisation (superior medial): this
involves sustained attention or concentration; deficient energisation
leads to slow performance on all tasks requiring fast responding.

The above three executive processes are often used in combination when
someone performs a complex task. Note that these three processes differ
from those identified by Miyake et al. (2000). However, there is some
overlap: task setting and monitoring both involve aspects of cognitive
control as do the processes of inhibition and shifting. Stuss (2011)
confirmed the importance of the above three executive functions. In
addition, he identified a fourth executive process he called
metacognition/integration (located in BA10: fronto-polar prefrontal
cortex). According to Stuss (p. 761), "This function is integrative and
coordinating-orchestrating . . . \[it includes\] recognising the
differences between what one knows from what one believes." Evidence for
this process has come from research on patients with damage to BA10
(Burgess et al., 2007).

Evaluation The unity/diversity framework provides a coherent account of
the major executive functions and is deservedly highly influential. One
of its greatest strengths is that it is supported by research using
several different approaches (e.g., psychometric; genetic; neuroimaging;
neuropsychological). The notion of a hierarchical system with one very
general function (common executive function) plus more specific
functions (e.g., shifting; updating) is consistent with most findings.
What are the limitations of the unity/diversity framework? First, as
Friedman and Miyake (2017, p. 199) admitted, "The results of lesion
studies are in partial agreement with the unity/diversity framework . .
. the processes \[identified\] in these studies are not clearly the same
as those \[identified\] in studies of normal individual differences."
For example, Stuss (2011) obtained evidence for task setting,
monitoring, energisation and metacognition/integration functions in
research on brain-damaged patients. Second, many neuroimaging findings
appear inconsistent with the framework. For example, Nee et al. (2013)
carried out a meta-analysis of 36 neuroimaging studies on executive
processes. There was little evidence that functions such as shifting,
updating and inhibition differed in their patterns of brain activation.
Instead, one frontal region was mostly involved in processing spatial
content (where-based processing) and a second frontal region was
involved in processing non-spatial content (what-based processing).
Third, Waris et al. (2017) also found evidence for content-based factors
differing from the executive factors emphasised within the
unity/diversity framework. They factor-analysed performance on ten
working memory tasks and identified two specific content-based factors:
(1) a visuo-spatial factor; and (2) a numerical-verbal factor. There is
some overlap between these factors and those identified by Nee et
al. (2013).

261

262

Memory

Fourth, an important assumption within the unity/diversity framework is
that all individuals have the same executive processes (Friedman &
Miyake, 2017). The complexities and inconsistencies of the research
evidence suggest this assumption may be only partially correct.

LEVELS OF PROCESSING (AND BEYOND)

Interactive exercise: Levels of processing

What determines long-term memory? According to Craik and Lockhart
(1972), how information is processed during learning is crucial. In
their levels-of-processing approach, they argued that attentional and
perceptual processes of learning determine what information is stored in
long-term memory. Levels of processing range from shallow or physical
analysis of a stimulus (e.g., detecting specific letters in words) to
deep or semantic analysis. The greater the extent to which meaning is
processed, the deeper the level of processing. Here are Craik and
Lockhart's (1972) main theoretical assumptions: ●

●

The level or depth of stimulus processing has a large effect on its
memorability: the levels-of-processing effect. Deeper levels of analysis
produce more elaborate, longer-lasting and stronger memory traces than
shallow levels.

Craik (2002) subsequently moved away from the notion that there is a
series of processing levels going from perceptual to semantic. Instead,
he argued that the richness or elaboration of encoding is crucial for
long-term memory. Hundreds of studies support the levels-of-processing
approach. For example, Craik and Tulving (1975) compared deep processing
(decide whether each word fits the blank in a sentence) and shallow
processing (decide whether each word is in uppercase or lowercase
letters). Recognition memory was more than three times higher with deep
than with shallow processing. Elaboration of processing (amount of
processing of a given kind) was also important. Cued recall following
the deep task was twice as high for words accompanying complex sentences
(e.g., "The great bird swooped down and carried off the struggling
\_\_\_\_") as those accompanying simple sentences (e.g., "She cooked the
\_\_\_\_"). Rose et al. (2015) reported a levels-of-processing effect
even with an apparently easy memory task: only a single word had to be
recalled and the retention interval was only 10 seconds. More
specifically, words associated with deep processing were better recalled
than those associated with shallow processing when the retention
interval was filled with a task involving adding or subtracting).
Baddeley and Hitch (2017) pointed out the great majority of studies had
used verbal materials (e.g., words). Accordingly, they decided to see
whether a levels-of-processing effect would be obtained with different
learning materials. In one study, they found the effect with recognition
memory was much smaller with doors and clocks than with food names (see
Figure 6.11). The most plausible explanation is that it is harder to
produce an elaborate semantic encoding with doors or clocks than with
most words.

Learning, memory and forgetting

263

p (correct)

Morris et al. (1977) disproved the 1 levels-of-processing theory.
Participants Shallow 0.9 answered semantic or shallow (rhyme) Deep 0.8
questions for words. Memory was tested 0.7 by a standard recognition
test (select list 0.6 words and reject non-list words) or a 0.5 0.4
rhyming recognition test (select words 0.3 rhyming with list words --
the list words 0.2 themselves were not presented). There 0.1 was the
usual superiority of deep pro0 cessing on the standard recognition test.
Clocks Menus Doors However, the opposite was the case on the rhyme test,
a finding inconsistent with Figure 6.11 the theory. According to Morris
et al.'s Recognition memory performance as a function of processing
transfer-appropriate processing theory, depth (shallow vs deep) for
three types of stimuli: doors, clocks retrieval requires that the
processing and menus. during learning is relevant to the demands From
Baddeley and Hitch (2017). Reprinted with permission of Elsevier. of the
memory test. With the rhyming test, rhyme information is relevant but
sematic information is not. Challis et al. (1996) compared the
levels-of-processing effect on explicit memory tests (e.g., recall;
recognition) involving conscious recollection and on implicit memory
tests not involving conscious recollection (see Chapter 7). The effect
was generally greater in explicit than implicit memory. Parks (2013)
explained this difference in terms of transfer-appropriate processing.
Shallow processing involves more perceptual but less conceptual
processing than deep processing. Accordingly, the levels-of-processing
effect should generally be smaller when the memory task requires
demanding perceptual processing (as is the case with most implicit
memory tasks).

Distinctiveness Another important factor influencing long-term memory is
distinctiveness. Distinctiveness means a memory trace differs from other
memory traces because it was processed differently during learning.
According to Hunt and Smith (2014, p. 45), distinctive processing is
"the processing of difference in the context of similarity". Eysenck and
Eysenck (1980) studied distinctiveness using nouns having irregular
pronunciations (e.g., comb has a silent "b"). In one condition,
participants said these nouns in a distinctive way (e.g., pronouncing
the "b" in comb). Thus, the processing was shallow (i.e., phonemic) but
the memory traces were distinctive. Recognition memory was much higher
than in a phonemic condition involving non-distinctive processing (i.e.,
pronouncing nouns as normal). Indeed, memory was as good with
distinctive phonemic processing as with deep or semantic processing. How
can we explain the beneficial effects of distinctiveness on longterm
memory? Chee and Goh (2018) identified two potential explanations.
First, distinctive items may attract additional attention and processing
at the time of study. Second, distinctive items may be well remembered
because of effects occurring at the time of retrieval, an explanation

KEY TERMS Explicit memory Memory that involves conscious recollection of
information. Implicit memory Memory that does not depend on conscious
recollection. Distinctiveness This characterises memory traces that are
distinct or different from other memory traces stored in long-term
memory.

Figure 6.12 Percentage recall of the critical item (e.g., kiwi) in
encoding, retrieval and control conditions; also shown is the percentage
recall of preceding and following items in the three conditions. From
Chee and Goh (2018). Reprinted with permission of Elsevier.

Memory

1 0.9 0.8 Proportion of recall

264

0.7 0.6

Instruction type

0.5

Control

0.4

Encoding

0.3

Retrieval

0.2 0.1 0

Preceding

Critical item type

Following

originally proposed by Eysenck (1979). For example, suppose the
distinctive item is printed in red whereas all the other items are
printed in black. The retrieval cue (recall the red item) uniquely
specifies one item and so facilitates retrieval. Chee and Goh (2018)
contrasted the two above explanations. They presented a list of words
referring to species of birds including the word kiwi. Of importance,
kiwi is a homograph (two words having the same spelling but two
different meanings): it can mean a species of bird or a type of fruit.
Participants were instructed before study (encoding condition) or after
study (retrieval condition) that one of the words would be a type of
fruit. The findings are shown in Figure 6.12. A distinctiveness effect
was found in the retrieval condition in the absence of distinctive
processing at study. These findings strongly support a retrieval-based
explanation of the distinctiveness effect.

Evaluation There is compelling evidence that processes at learning have
a major impact on subsequent long-term memory (Roediger, 2008). Another
strength of the theory is the central assumption that learning and
remembering are byproducts of perception, attention and comprehension.
The levels-of-processing approach led to the identification of
elaboration and distinctiveness of processing as important factors in
learning and memory. Finally, "The levels-of-processing approach has
been fruitful and generative, providing a powerful set of experimental
techniques for exploring the phenomena of memory" (Roediger & Gallo,
2001, p. 44). The levels-of-processing approach has several limitations.
First, Craik and Lockhart (1972) underestimated the importance of the
retrieval environment in determining memory performance (e.g., Morris et
al., 1977). Second, the relative importance of processing depth,
elaboration of processing and distinctiveness of processing to long-term
memory remains unclear. Third, the terms "depth", "elaboration" and
"distinctiveness" are vague and hard to measure (Roediger & Gallo,
2001). Fourth, we do not know

Learning, memory and forgetting

precisely why deep processing is so effective or why the
levels-of-processing effect is small in implicit memory. Fifth, the
levels-of-processing effect is typically smaller with non-verbal stimuli
than with words (Baddeley & Hitch, 2017).

LEARNING THROUGH RETRIEVAL How can we maximise our learning (e.g., of
some topic in cognitive psychology)? Many people (including you?) think
what is required is to study and re-study the to-be-learned material
with testing serving only to establish what has been learned. In fact,
this is not the case. As we will see, there is typically a testing
effect: "the finding that intermediate retrieval practice between study
and a final memory test can dramatically enhance final-test performance
when compared with restudy trials" (Kliegl & Bäuml, 2016). The testing
effect is generally surprisingly strong. Dunlosky et al. (2013)
discussed ten learning techniques including writing summaries, forming
images of texts and generating explanations for stated facts, and found
repeated testing was the most effective technique. Rowland (2014)
carried out a meta-analysis: 81% of the findings were positive. Most of
these studies were laboratory-based. Reassuringly, Schwieren et
al. (2017) found the magnitude of the testing effect was comparable in
real-life contexts (teaching psychology) and laboratory conditions.

Explanations of the testing effect We start by identifying two important
theoretical approaches to explaining the testing effect. First, several
theorists have emphasised the importance of retrieval effort (Rowland,
2014). The core notion here is that the testing effect will be greater
when the difficulty or effort involved in retrieval during the learning
period is high rather than low. Why does increased retrieval effort have
this beneficial effect? Several answers have been suggested. For
example, there is the elaborative retrieval hypothesis, which is
applicable to paired-associate learning (e.g., learning to associate the
cue Chalk with the target Crayon). According to this hypothesis, "the
act of retrieving a target from a cue activates cue-relevant information
that becomes incorporated with the successfully retrieved target,
providing a more elaborate representation" (Carpenter & Yeung, 2017,
p. 129). According to a more specific version of this hypothesis (the
mediator effectiveness hypothesis), retrieval practice promotes the use
of more effective mediators. In the above example, Board might be a
mediator triggered by the cue Chalk. Rickard and Pan (2018) proposed a
related (but more general) dual-memory theory. In essence, restudy
causes the memory trace formed at initial study to be strengthened.
Testing with feedback (which involves effort) also strengthens the
memory trace formed at initial study. More importantly, it leads to the
formation of a second memory trace (see Figure 6.13). The strength of
this second memory trace probably depends on the amount of retrieval
effort during testing. Thus, testing generally promotes superior memory
to restudy because it promotes the acquisition of two memory traces for
each item rather than one.

265

KEY TERM Testing effect The finding that longterm memory is enhanced
when some of the learning period is devoted to retrieving to-be-learned
information rather than simply studying it.

266

Memory

Figure 6.13 (a) Restudy causes strengthening of the memory trace formed
after initial study; (b) testing with feedback causes strengthening of
the original memory trace; and (c) the formation of a second memory
trace. t = the response threshold that must be exceeded for any given
item to be retrieved on the final test.

(a) Study memory After initial study Restudy After training t

Strength

(b) Study memory After initial study

From Rickard & Pan (2018).

Testing with feedback

After training t

Strength

(c) Test memory

Testing with feedback

After training t

Strength

Second, there is the bifurcation model (bifurcation means division into
two) proposed by Kornell et al. (2011). According to this model, items
successfully retrieved during testing practice are strengthened more
than restudied items. However, the crucial assumption is that items not
retrieved during testing practice are strengthened less than restudied
items; indeed, their memory strength does not change. Thus, there should
be circumstances in which the testing effect is reversed.

Findings Several findings indicate that the size of the testing effect
depends on retrieval effort (probably because it leads to the formation
of a strong second memory trace). Endres and Renkl (2015) asked
participants to rate the mental effort they used during retrieval
practice and restudying. They obtained a testing effect that disappeared
when mental effort was controlled for statistically. As predicted, more
effortful or difficult retrieval tests (e.g., free recall) typically led
to a greater testing effect than easy retrieval tests (e.g., recognition
memory) (Rowland, 2014). All these findings provide indirect support for
the dual-memory theory. It seems reasonable to assume retrieval practice
is more effortful and demanding when initial memory performance is low
rather than high. As

Learning, memory and forgetting

267

predicted, the testing effect is greater when initial memory performance
was low in studies providing feedback (re-presentation of the learning
materials) (Rowland, 2014). Suppose you are trying to learn the word
pair wingu--cloud. You might try to link the words by using the mediator
plane. When subsequently given the cue (wingu) and told to recall the
target word (cloud), you might generate the sequence wingu--wing--cloud
according to the mediator effectiveness hypothesis. Pyc and Rawson
(2010) instructed participants to learn Swahili-English pairs (e.g.,
wingu--cloud). In one condition, each trial after the initial study
trial involved only restudy. In the other condition (test-restudy), each
trial after the initial study trial involved a cued recall test followed
by restudy. Participants generated and reported mediators on the study
and restudy trials. There were three recall conditions on the final
memory test 1 week later: (1) cue only; (2) cue + the mediator generated
during learning; (3) cue + prompt to try to generate the mediator. The
findings were straightforward (see Figure 6.14(a)): (1)

(2) 
(3) 

Memory performance in the cue only condition replicated the basic
testing effect. Performance in the cue + mediator condition shows
test-restudy participants generated more effective mediators than
restudy-only participants. Test-restudy participants performed much
better than restudy-only ones in the cue + prompt condition. Testrestudy
participants remembered the mediators much better. Retrieving mediators
was important for the testrestudy participants -- their performance was
poor when they failed to recall mediators.

Pyc and Rawson (2012) developed the mediator effectiveness hypothesis.
Participants were more likely to change their mediators during
test-restudy practice than restudy-only practice. Of most importance,
participants engaged in test-restudy practice were more likely to change
their mediators following retrieval failure than retrieval success.
Thus, retrieval practice allows people to evaluate the effectiveness of
their mediators and to replace ineffective ones with effective ones. We
turn now to the bifurcation model, the main theoretical approach
predicting reversals of the testing effect. Support was

Figure 6.14 (a) Final recall for restudy-only and test-restudy group
participants provided at test with cues (C), cues + the mediators
generated during learning (CM) or cues plus prompts to recall their
mediators (CMR). (b) Recall performance in the CMR group as a function
of whether the mediators were or were not retrieved. From Pyc and Rawson
(2010). © American Association for Advancement of Science. Reprinted
with permission of AAAS.

268

Memory

reported by Pastötter and Bäuml (2016). Participants had
retrieval/testing or restudy practice for paired 100 associates during
Session 1. In Session 2 (48 hours 90 **later), Test 1 was immediately
followed by feedback 80 70 (re-presentation of the word pairs) and 10
minutes 60 later by Test 2.** \* 50 There was a testing effect on Test 1
but a reversed 40 testing effect on Test 2 (see Figure 6.15). According
30 to the bifurcation model, non-recalled items on Test Test 1 Test 2 1
should be weaker if previously subject to retrieval practice rather than
restudy. Thus, they should benefit Retrieval practice Restudy practice
less from feedback. That is precisely what happened (see Figure 6.15).
Figure 6.15 Most research on the testing effect has involved Mean recall
percentage in Session 2 on Test 1 the use of identical materials during
both initial and (followed by feedback) and Test 2 10 minutes later
final retrieval tests. For many purposes, however, we as function of
retrieval practice (in blue) or restudy want retrieval to produce more
general and flexible practice (in green) in Session 1. learning that
transfers to related (but non-tested) From Pastötter & Bäuml (2016).
information. Pan and Rickard (2018) found in a meta-analysis that
retrieval practice on average has a moderately beneficial effect on
transfer of learning. This was especially the case when retrieval
practice involved elaborative feedback (e.g., extended and detailed
feedback) than when only basic feedback (i.e., the correct answer) was
provided. % Recall

Session 2

Evaluation The testing effect is strong and has been obtained with many
different types of learning materials. Testing during learning has the
advantage it can be used almost regardless of the nature of the
to-be-learned material. Of importance, retrieval practice often produces
learning that generalises or transfers to related (but non-tested)
information. Testing has beneficial effects because it produces a more
elaborate memory trace (elaborative retrieval hypothesis) or a second
memory trace (dual-memory theory). However, testing can be ineffective
if the studied material is not retrieved and there is no feedback (the
bifurcation model). What are the limitations of theory and research in
this area? (1)

(2) 
(3) 

There are several ways retrieval practice might produce more elaborate
memory traces (e.g., additional processing of external context; the
production of more effective internal mediators). The precise form of
such elaborate memory traces is hard to predict. The dual-memory theory
provides a powerful explanation of the testing effect. However, more
research is required to demonstrate the conditions in which testing
leads to the formation of a second memory trace differing from the
memory trace formed during initial study. The bifurcation model has
received empirical support. However, it does not specify the underlying
processes or mechanisms responsible for the reversed testing effect.

Learning, memory and forgetting

(4) 

The fact that the testing effect has been found with numerous types of
learning material and testing conditions suggests that many different
processes can produce that effect. Thus, currently prominent theories
are probably applicable to only some findings.

IMPLICIT LEARNING Earlier in the chapter we discussed learning through
retrieval and learning from the levels-of-processing perspective. In
both cases, the emphasis was on explicit learning: it generally makes
substantial demands on attention and working memory and learners are
aware of what they are learning. Can we learn something without an
awareness of what we have learned? It sounds improbable. Even if we
learned something without realising, it seems unlikely we would make
much use of it. In fact, there is much evidence for implicit learning:
"learning that occurs without full conscious awareness of the
regularities contained in the learning material itself and/ or that
learning has occurred" (Sævland & Norman, 2016, p. 1). As we will see,
it is often assumed implicit learning differs from explicit learning in
being less reliant on attention and working memory. We can also
distinguish between implicit learning and implicit memory (memory not
involving conscious recollection; discussed in Chapter 7). There can be
implicit memory for information acquired through explicit learning if
learners lose awareness of that information over time. There can also be
explicit memory for information acquired through implicit learning if
learners are provided with informative contextual cues when trying to
remember that information. However, implicit learning is typically
followed by implicit memory whereas explicit learning is followed by
explicit memory. There is an important difference between research on
implicit learning and implicit memory. Research on implicit learning
mostly involves focusing on performance changes occurring over a lengthy
sequence of learning trials. In contrast, research on implicit memory
mostly involves one or a few learning trials and the emphasis is on the
effects of various factors (e.g., retention interval; retrieval cues) on
memory performance. In addition, research on implicit learning often
uses fairly complex, novel tasks whereas much research on implicit
memory uses simple, familiar stimulus materials. Reber (1993) made five
assumptions concerning major differences between implicit and explicit
learning (none established definitively): (1) (2) (3) (4) (5)

Age independence: implicit learning is little influenced by age or
developmental level. IQ independence: performance on implicit tasks is
relatively unaffected by IQ. Robustness: implicit systems are relatively
unaffected by disorders (e.g., amnesia) affecting explicit systems. Low
variability: there are smaller individual differences in implicit
learning than explicit learning. Commonality of process: implicit
systems are common to most species.

269

KEY TERM Implicit learning Learning complex information without
conscious awareness of what has been learned.

270

Memory

Here we will briefly consider the first two assumptions (the third
assumption is discussed later, p. 277). With respect to the first
assumption, some studies have reported comparable implicit learning in
older and young adults. However, implicit learning is mostly
significantly impaired in older adults. How can we explain this deficit?
Older adults generally have reduced volume of frontal cortex and the
striatum, an area strongly associated with implicit learning (King et
al., 2013a). With respect to the second assumption, Christou et
al. (2016) found on a visuo-motor task that the positive effects of high
working memory capacity on task performance were due to explicit but not
implicit learning. When the visuo-motor task was changed to reduce the
possibility of explicit learning, high working memory capacity was
unrelated to performance. Overall, intelligence is associated more
strongly with explicit learning. However, the association between
intelligence and implicit learning appears greater than predicted by
Reber (1993).

IN THE REAL WORLD: SKILLED TYPISTS AND IMPLICIT LEARNING Millions of
individuals have highly developed typing skills (e.g., the typical
American student who touch types produces 70 words a minute) (Logan &
Crump, 2009). Nevertheless, many expert typists find it hard to think
exactly where the letters are on the keyboard. For example, the first
author of this book has typed 8 million words for publication but has
limited conscious awareness of the locations of most letters! This
suggests expert typing relies heavily on implicit learning and memory.
However, typing initially involves mostly explicit learning as typists
learn to associate finger movements with specific letter keys. Snyder et
al. (2014) studied college students averaging 11.4 years of typing
practice. In the first experiment, typists saw a blank keyboard and were
instructed to write the letters in their correct locations (see Figure
6.16). They located only 14.9 (57.3%) of the letters accurately. If you
are a skilled typist, try this task before checking your answers (shown
in Figure 6.22). Accurate identification of letters' keyboard locations
could occur because typists engage in simulated typing. In their second
experiment, Snyder et al. (2014) found the ability to identify the
keyboard locations of letters was reduced when simulated typing was
prevented. Thus, explicit memory for letter locations is lower than 57%.

Figure 6.16 Schematic representation of a traditional keyboard. From
Snyder et al. (2014). © 2011 Psychonomic Society. Reprinted with
permission from Springer.

Learning, memory and forgetting

271

In a final experiment, Snyder et al. (2014) gave typists two hours'
training on the Dvorak keyboard, on which the letter locations differ
from the traditional QWERTY keyboard. The ability to locate letters on
the Dvorak and QWERTY keyboards was comparable. Thus, typists have no
more explicit knowledge of letter locations on a keyboard after 11 years
than after 2 hours! What is the nature of experienced typists' implicit
learning? Logan (2018) addressed this issue. Much of this learning
involves forming associations between individual letters and finger
movements. In addition, however, typists learn to treat each word as a
single chunk or unit. As a result, they type words much faster than
non-words containing the same number of letters. Thus, implicit learning
occurs at both the word and letter levels (Logan, 2018). If experts rely
on implicit learning and memory, we might predict performance
impairments if they focused consciously on their actions. There is much
support for this prediction. For example, Flegal and Anderson (2008)
gave skilled golfers a putting task before and after they described
their actions in detail. Their putting performance was markedly worse
after describing their actions because conscious processes disrupted
implicit ones.

Assessing implicit learning You might think it is easy to decide whether
implicit learning has occurred -- we simply ask participants after
performing a task to indicate their conscious awareness of their
learning. Implicit learning is shown if there is no such conscious
awareness. Alas, individuals sometimes fail to report fully their
conscious awareness of their learning (Shanks, 2010). For example, there
is the "retrospective problem" (Shanks & St. John, 1994) -- participants
may be consciously aware of what they are learning at the time but have
forgotten it when questioned subsequently. Shanks and St. John (1994)
proposed two criteria (incompletely implemented in most research) for
implicit learning to be demonstrated: (1)

(2) 

Information criterion: The information participants are asked to provide
on the awareness test must be the information responsible for the
improved performance. Sensitivity criterion: "We must . . . show our
test of awareness is sensitive to all of the relevant knowledge" (Shanks
& St. John, 1994, p. 374). We may underestimate participants'
consciously accessible knowledge if we use an insensitive awareness
test.

When implicit learning studies fail to obtain significant evidence of
explicit learning, researchers often (mistakenly) conclude there was no
explicit learning. Consider research on contextual cueing: participants
search for targets in visual displays and targets are detected
increasingly rapidly (especially with repeated rather than random
displays). Subsequently, participants see the repeating patterns and new
random ones and indicate whether they have previously seen each one.
Typically, participants fail to identify the repeating patterns
significantly more often than the random ones. Such non-significant
findings imply all task learning is implicit. Vadillo et al. (2016)
argued many of the above non-significant findings occurred because
insufficiently large samples were used. In their review of 73 studies,
78.5% of awareness tests produced non-significant findings.

272

Memory

KEY TERMS

Nevertheless, participants in 67% of the studies performed above chance
(a highly significant finding). Thus, some explicit learning is involved
in contextual cueing even though the opposite is often claimed. Finally,
we consider the process-dissociation procedure. Suppose participants
perform a task involving a repeating sequence of stimuli. They either
guess the next stimulus (inclusion condition) or try to avoid guessing
the next stimulus accurately (exclusion condition). If learning is
wholly implicit, performance should be comparable in both conditions
because participants would have no conscious access to relevant
information. If it is partly or wholly explicit, performance should be
better in the inclusion condition. The process-dissociation procedure is
based on the assumption that the influence of implicit and explicit
processes is unaffected by instructions (inclusion vs exclusion).
However, Barth et al. (2019) found explicit knowledge was less likely to
influence performance in the exclusion than the inclusion condition.
Such findings make it hard to interpret findings obtained using the
process-dissociation procedure.

Process-dissociation procedure On learning tasks, participants try to
guess the next stimulus (inclusion condition) or avoid guessing the next
stimulus accurately (exclusion condition); the difference between the
two conditions indicates the amount of explicit learning. Serial
reaction time task Participants on this task respond as rapidly as
possible to stimuli typically presented in a repeating sequence; it is
used to assess implicit learning.

Findings The serial reaction time task has often been used to study
implicit learning. On each trial, a stimulus appears at one of several
locations on a computer screen and participants respond using the
response key corresponding to its location. There is typically a
complex, repeating sequence over trials but participants are not told
this. Towards the end of the experiment, there is often a block of
trials conforming to a novel sequence but the participants are not
informed. Participants speed up over trials on the serial reaction time
task but respond much more slowly during the novel sequence (Shanks,
2010). When questioned at the end of the experiment, participants
usually claim no conscious awareness of a repeating sequence or pattern.
However, participants sometimes have partial awareness of what they have
learned. Wilkinson and Shanks (2004) gave participants 1,500 trials (15
blocks) or 4,500 trials (45 blocks) on the task and obtained strong
sequence learning. This was followed by a test of explicit learning
based on the processdissociation procedure. Participants' predictions
were significantly better in the inclusion than exclusion condition (see
Figure 6.17) indicating some conscious or explicit knowledge was
acquired. In a similar study, Gaillard et al. (2009) obtained comparable
findings and discovered conscious knowledge increased with practice.
Haider et al. (2011) argued the best way to assess whether learning is
explicit or implicit is to use several measures of conscious awareness.
They used a version of the serial reaction time task in which a colour
word (the target) was written in ink of the same colour (congruent
trials) or a different colour (incongruent trials). Participants
responded to the colour word rather than the ink. There were six
different coloured squares below the target word and participants
pressed the coloured square corresponding to the colour word. The
correct coloured square followed a regular sequence (1-6-4-2-3-5) but
participants were not told this.

Learning, memory and forgetting

Haider et al. (2011) found 34% of participants showed a sudden drop in
reaction times at some point. They hypothesised these RT-drop
participants were consciously aware of the regular sequence (explicit
learning). The remaining 66% failed to show a sudden drop (the
no-RT-drop participants) and were hypothesised to have engaged only in
implicit learning (see Figure 6.18). Haider et al. (2011) used the
processdissociation procedure to test the above hypotheses. The RT-drop
participants performed well: 80% correct on inclusion trials vs 18%
correct on exclusion trials, suggesting considerable explicit learning.
In contrast, the no-RT-drop participants had comparably low performance
on inclusion and exclusion trials indicating an absence of explicit
learning. Finally, all participants described the training sequence
(explicit task). Almost all (91%) of the RT-drop participants did this
perfectly compared to 0% of the no-RT-drop participants. Thus, all the
various findings supported Haider et al.'s hypotheses.

273

Figure 6.17 Mean number of completions (guessed locations) corresponding
to the trained sequence (own) or the untrained sequence (other) in
inclusion and exclusion conditions as a function of number of trials (15
vs 45 blocks). From Wilkinson and Shanks (2004). © 2004 American
Psychological Association. Reproduced with permission.

Figure 6.18 Response times for participants showing a sudden drop in RTs
(right-hand side) or not showing such a drop (left-hand side). The
former group showed much greater learning than the latter group
(especially on incongruent trials on which the colour word was in a
different coloured ink). From Haider et al. (2011). Reprinted with
permission from Elsevier.

274

Memory

If implicit learning does not require cognitively demanding processes
(e.g., attention), people should be able to perform two implicit
learning tasks simultaneously without interference. As predicted,
Jiménez and Vázquez (2011) reported no interference when participants
performed the serial reaction time task and a second implicit learning
task. Many tasks involve a combination of implicit and explicit
learning. Taylor et al. (2014) used a visuo-motor adaptation task on
which participants learned to point at a target that rotated 45 degrees
counterclockwise. Participants initially indicated their aiming
direction and then made a rapid reaching movement. The former provided a
measure of explicit learning whereas the latter provided a measure of
implicit learning. Thus, an advantage of this experimental approach is
that it provides separate measures of explicit and implicit learning.
Huberdeau et al. (2015) reviewed findings using the above visuo-motor
adaptation task and drew two main conclusions. First, improved
performance over trials depended on both implicit and explicit learning.
Second, there was a progressive increase in implicit learning with
practice, whereas most explicit learning occurred early in practice.

Cognitive neuroscience If implicit and explicit learning are genuinely
different, they should be associated with different brain areas.
Implicit learning has been linked to the striatum, which is part of the
basal ganglia (see Figure 6.19). For example, Reiss et al. (2005) found
on the serial reaction time task that participants showing implicit
learning had greater activation in the striatum than those not
exhibiting implicit learning. In contrast, explicit learning and memory
are typically associated with activation in the medial temporal lobes
including the hippocampus (see Chapter 7). Since conscious awareness is
most consistently associated with activation of the dorsolateral
prefrontal cortex and the anterior cingulate (see Chapter 16), these
areas should be more active during explicit than implicit learning.
Relevant evidence was reported by Wessel et al. (2012) using the serial
reaction time task. Some participants showed clear evidence of explicit
learning during training. A brain area centred on the right prefrontal
cortex became much more active around the onset of explicit learning. In
similar fashion, Lawson et al. (2017) compared participants showing (or
not showing) conscious awareness of a repeating pattern on the serial
reaction time task. The fronto-parietal network was Figure 6.19 more
activated for those showing conscious The striatum (which includes the
caudate nucleus and the putamen) is of central importance in implicit
learning. awareness.

Learning, memory and forgetting

It is often hard to establish the brain regions associated with implicit
and explicit learning because learners often use both kinds of learning.
Destrebecqz et al. (2005) used the process-dissociation procedure (see
Glossary) with the serial reaction time task to distinguish more clearly
between the explicit and implicit components of learning. Striatum
activation was associated with the implicit component whereas the
prefrontal cortex and anterior cingulate were associated with the
explicit component. Penhune and Steele (2012) proposed a model of motor
sequence learning (see Figure 6.20). The striatum is involved in
learning stimulus-- response associations and motor chunking or
organisation. The cerebellum is involved in producing an internal model
to aid sequence performance and error correction. Finally, the motor
cortex is involved in storing the learned motor sequence. Of importance,
the involvement of each brain area varies across stages of learning.
Evidence for the importance of the cerebellum in motor sequence learning
was reported by Shimizu et al. (2017) using transcranial direct current
stimulation (tDCS; see Glossary) applied to the cerebellum. This

Figure 6.20 A model of motor sequence learning. The top panel shows the
brain areas (PMC or M1 = primary motor cortex) and associated mechanisms
involved in motor sequence learning. The bottom panel shows the changing
involvement of different processing components (chunking,
synchronisation, sequence ordering, error correction) in overall
performance. Each component is colour-coded to its associated brain
region. From Penhune and Steele (2012). Reprinted with permission of
Elsevier.

275

KEY TERM Striatum It forms part of the basal ganglia and is located in
the upper part of the brainstem and the inferior part of the cerebral
hemispheres.

Interactive feature: Primal Pictures' 3D atlas of the brain

276

Memory

stimulation influenced implicit learning (enhancing or impairing
performance) as predicted theoretically. In spite of the above findings,
there are many inconsistencies and complexities in the research
literature (Reber, 2013). For example, Gheysen et al. (2011) found the
striatum contributed to explicit learning of motor sequences as well as
implicit learning and the hippocampus is sometimes involved in implicit
learning (Henke, 2010). Why are the findings inconsistent? First, there
are numerous forms of implicit learning. As Reber (2013, p. 2029)
argued, "We should expect to find implicit learning . . . whenever
perception and/or actions are repeated so that processing comes to
reflect the statistical structure of experience." As a consequence, it
is probable that implicit learning can involve several different brain
networks. Second, we can regard, "the cerebellum, basal ganglia, and
cortex as an integrated system" (Caligiore et al., 2017, p. 204). This
system plays an important role in implicit and explicit learning. Third,
as we have seen, there are large individual differences in learning
strategies and the balance between implicit and explicit learning. These
individual differences introduce complexity into the overall findings.
Fourth, there are often changes in the involvement of implicit and
explicit processes during learning. For example, Beukema and Verstynen
(2018) focused on changes in the involvement of different brain regions
during the acquisition of sequential motor skills (e.g., the skills
acquired by typists). Explicit processes dependent on the medial
temporal lobe (shown in magenta) were especially important early in
learning whereas implicit processes dependent on the basal ganglia
(shown in blue) became increasingly important later in learning (see
Figure 6.21).

Figure 6.21 Sequential motor skill learning initially depends on the
medial temporal lobe (MTL) including the hippocampus (shown in magenta)
but subsequently depends more on the basal ganglia (BG) including the
striatum (shown in blue). From Beukema and Verstynen, 2018).

Learning, memory and forgetting

Brain-damaged patients Amnesic patients with damage to the medial
temporal lobes often have intact performance on implicit-memory tests
but are severely impaired on explicit-memory tests (see Chapter 7). If
separate learning systems underlie implicit and explicit learning, we
might expect amnesic patients to have intact implicit learning but
impaired explicit learning. That pattern of findings has been reported
several times. However, amnesic patients are often slower than healthy
controls on implicit-learning tasks (Oudman et al., 2015). Earlier we
discussed the hypothesis that the basal ganglia (especially the
striatum) are of major importance in implicit learning. Patients with
Parkinson's disease (a progressive neurological disorder) have damage to
this region. As predicted, Clark et al. (2014) found in a meta-analytic
review that patients with Parkinson's disease typically exhibit impaired
implicit learning on the serial reaction time task (see Chapter 7).
However, Wilkinson et al. (2009) found Parkinson's patients also showed
impaired explicit learning on that task. In a review, Marinelli et
al. (2017) found that Parkinson's patients showed the greatest
impairment in motor learning when the task required conscious processing
resources (e.g., attention; cognitive strategies). Much additional
research indicates Parkinson's patients have impaired conscious
processing (see Chapter 7). Siegert et al. (2008) found in a
metaanalytic review that such patients exhibited consistently poorer
performance than healthy controls on working memory tasks. Roussel et
al. (2017) found 80% of Parkinson's patients have dysexecutive syndrome
which involves general impairments in cognitive processing. In sum,
findings from Parkinson's patients provide only limited information
concerning the distinction between implicit and explicit learning.

Evaluation Research on implicit learning has several strengths (see also
Chapter 7). First, the distinction between implicit and explicit
learning has received

Figure 6.22 Percentages of experienced typists given an unfilled
schematic keyboard (see Figure 6.16) who correctly located (top number),
omitted (middle number) or misplaced (bottom number) each letter with
respect to the standard keyboard. From Snyder et al. (2014). © 2011
Psychonomic Society. Reprinted with permission from Springer.

277

KEY TERM Parkinson's disease A progressive disorder involving damage to
the basal ganglia (including the striatum); the symptoms include muscle
rigidity, limb tremor and mask-like facial expression.

278

Memory

KEY TERM

considerable support from behavioural and neuroimaging studies on
healthy individuals and from research on brain-damaged patients. Second,
the basal ganglia (including the striatum) tend to be associated with
implicit learning whereas the prefrontal cortex, anterior cingulate and
medial temporal lobes are associated with explicit learning. There is
accumulating evidence that complex brain networks are involved in
implicit learning (e.g., Penhune & Steele, 2012). Third, given the
deficiencies in assessing conscious awareness with any single measure,
researchers are increasingly using several measures. Thankfully,
different measures often provide comparable estimates of the extent of
conscious awareness (e.g., Haider et al., 2011). Fourth, researchers
increasingly reject the erroneous assumption that finding some evidence
of explicit learning implies no implicit learning occurred. In fact,
learning typically involves implicit and explicit aspects and the extent
to which learners are consciously aware of what they are learning
depends on individual differences and the stage of learning (e.g.,
Wessel et al., 2012). What are the limitations of research on implicit
learning?

Savings method A measure of forgetting introduced by Ebbinghaus in which
the number of trials for relearning is compared against the number for
original learning.

(1) 
(2) 
(3) 
(4) 

There is often a complex mixture of implicit and explicit learning,
making it hard to determine the extent of implicit learning. The
processes underlying implicit and explicit learning interact in ways
that remain unclear. In order to show the existence of implicit learning
we need to demonstrate that learning has occurred in the absence of
conscious awareness. This is hard to do -- we may fail to assess fully
participants' conscious awareness (Shanks, 2017). The definition of
implicit learning as learning occurring without conscious awareness is
vague and underspecified, and so is applicable to numerous forms of
learning having little in common with each other. It is probable that no
current theory can account for the diverse forms of implicit learning.

FORGETTING FROM LONG-TERM MEMORY Hermann Ebbinghaus (1885/1913) studied
forgetting from long-term memory in detail, using himself as the only
participant (not recommended!). He initially learned lists of nonsense
syllables lacking meaning and then relearned each list between 21
minutes and 31 days later. His basic measure of forgetting was the
savings method -- the reduction in the number of trials during
relearning compared to original learning. Ebbinghaus found forgetting
was very rapid over the first hour after learning but then slowed
considerably (see Figure 6.23). Rubin and Wenzel (1996) found the same
pattern when analysing numerous forgetting functions and argued a
logarithmic function describes forgetting over time. In contrast,
Averell and Heathcote (2011) argued for a power function. It is often
assumed (mistakenly) that forgetting should always be avoided. Nørby
(2015) identified three major functions served by forgetting:

Learning, memory and forgetting

279 Figure 6.23 Forgetting over time as indexed by reduced savings. Data
from Ebbinghaus (1885/1913).

(1) 
(2) 
(3) 

It can enhance psychological well-being by reducing access to painful
memories. It is useful to forget outdated information (e.g., where your
friends used to live) so it does not interfere with current information
(e.g., where your friends live now). Richards and Frankland (2017)
developed this argument. They argued a major purpose of memory is to
enhance decision-making and this purpose is facilitated when we forget
outdated information. When trying to remember what we have read or
heard, it is typically most useful to forget specific details and focus
on the overall gist or message (see Box and Chapter 10).

IN THE REAL WORLD: IS PERFECT MEMORY USEFUL? What would it be like to
have a perfect memory? Jorge Luis Borges (1964) answered this question
in a story called "Funes the memorious". After falling from a horse,
Funes remembers everything that happens to him in full detail. This had
several negative consequences. When he recalled the events of any given
day, it took him an entire day to do so! He found it very hard to think
because his mind was full of incredibly detailed information. Here is an
example: Not only was it difficult for him to comprehend that the
generic symbol dog embraces so many unlike individuals of diverse size
and form; it bothered him that the dog at three fourteen (seen from the
side) should have the same name as the dog at three fifteen (seen from
the front). (p. 153)

280

Memory

KEY TERM

The closest real-life equivalent of Funes was a Russian called Solomon
Shereshevskii. When he worked as a journalist, his editor noticed he
could repeat everything said to him verbatim. The editor sent
Shereshevskii (S) to see the psychologist Luria. He found S rapidly
learned complex material (e.g., lists of over 100 digits) which he
remembered perfectly (even in reverse order) several years later.
According to Luria (1968), "There was no limit either to the capacity of
S's memory or to the durability of the traces he retained." What was S's
secret? He had exceptional imagery and an amazing capacity for
synaesthesia (the tendency for processing in one modality to evoke other
sense modalities). For example, when hearing a tone, he said: "It looks
like fireworks tinged with a pink-red hue." Do you envy S's memory
powers? Ironically, his memory was so good it disrupted his everyday
life. For example, this was his experience when hearing a prose passage:
"Each word calls up images, they collide with one another, and the
result is chaos." His mind came to resemble "a junk heap of
impressions". His acute awareness of details meant he sometimes failed
to recognise someone he knew if, for example, their facial colouring had
altered because they had been on holiday. These memory limitations made
it hard for him to live a normal life and he eventually ended up in an
asylum.

Synaesthesia The tendency for one sense modality to evoke another.

Most forgetting studies focus on declarative or explicit memory
involving conscious recollection (see Chapter 7). Forgetting is often
slower in implicit than explicit memory. For example, Mitchell (2006)
asked participants to identify pictures from fragments having seen some
of them in an experiment 17 years previously. Performance was better
with the previously seen pictures, providing evidence for very-long-term
implicit memory. However, there was little explicit memory for the
previous experiment. A 36-year-old male participant confessed, "I'm
sorry -- I don't really remember this experiment at all." Below we
discuss major theories of forgetting. These theories are not mutually
exclusive -- they all identify factors jointly responsible for
forgetting.

Decay Perhaps the simplest explanation for forgetting of long-term
memories is decay, which involves "forgetting due to a gradual loss of
the substrate of memory" (Hardt et al., 2013, p. 111). More
specifically, forgetting often occurs because of decay processes
occurring within memory traces. In spite of its plausibility, decay has
largely been ignored as an explanation of forgetting. Hardt et
al. argued a decay process (operating mostly during sleep) removes
numerous trivial memories we form every day. This decay process is
especially active in the hippocampus (part of the medial temporal lobe
involved in acquiring new memories; see Chapter 7). Forgetting can be
due to decay or interference (discussed shortly). Sadeh et al. (2016)
assumed detailed memories (i.e., containing contextual information) are
sufficiently complex to be relatively immune to interference

Learning, memory and forgetting

from other memories. As a result, most forgetting of such memories
should be due to decay. In contrast, weak memories (i.e., lacking
contextual information) are very susceptible to interference and so
forgetting of such memories should be primarily due to interference
rather than decay. Sadeh et al.'s findings supported these assumptions.
Thus, the role played by decay in forgetting depends on the nature of
the underlying memory traces.

Interference theory Interference theory was the dominant approach to
forgetting during much of the twentieth century. According to this
theory, long-term memory is impaired by two forms of interference: (1)
proactive interference -- disruption of memory by previous learning; (2)
retroactive interference -- disruption of memory for previous by other
learning or processing during the retention interval. Research using
methods such as those shown in Figure 6.22 indicates proactive and
retroactive interference are both maximal when two different responses
are associated with the same stimulus.

281

KEY TERMS Proactive interference Disruption of memory by previous
learning (often of similar material). Retroactive interference
Disruption of memory for previously learned information by other
learning or processing occurring during the retention interval.

Proactive interference Proactive interference typically involves
competition between the correct response and an incorrect one. There is
greater competition (and thus more interference) when the incorrect
response is associated with the same stimulus as the correct response.
Jacoby et al. (2001) found proactive interference was due much more to
the strength of the incorrect response than the weakness of the correct
response. Thus, it is hard to exclude incorrect responses from the
retrieval process. More evidence for the importance of retrieval
processes was reported by Bäuml and Kliegl (2013). They tested the
hypothesis that proactive interference is often found because
rememberers' memory search is too

Figure 6.24 Methods of testing for proactive and retroactive
interference.

282

Memory

broad, including material previously learned but currently irrelevant.
In the remember (proactive interference) condition, three word lists
were presented followed by free recall of the last one. In the forget
condition, the same lists were presented but participants were told
after the first two lists to forget them. Finally, there was a control
(no proactive interference) condition where only one list was learned
and tested. Participants in the control condition recalled 68% of the
words compared to only 41% in the proactive interference condition.
Crucially, participants in the forget condition recalled 68% of the
words despite having learned two previous lists. The instruction to
Figure 6.25 forget the first two lists allowed participants to
Percentage of items recalled over time for the conditions: no limit
their retrieval efforts to the third list. This proactive interference
(PI), remember (proactive interference) interpretation was strengthened
by the finding and forget (forget previous lists). that retrieval speed
was comparable in the From Bäuml & Kliegl (2013). Reprinted with
permission of Elsevier. forget and control conditions (see Figure 6.25).
Kliegl et al. (2015) found in a similar study that impaired encoding
(see Glossary) contributes to proactive interference. Encoding was
assessed using electroencephalography (EEG; see Glossary). The EEG
indicated there was reduced attention during encoding of a word list
preceded by other word lists (proactive interference condition). As in
the study by Bäuml and Kliegl (2013), there was also evidence that
proactive interference impaired retrieval. Suppose participants learn
word pairs on the first list (e.g., Cat--Dirt) and more word pairs on
the second list (e.g., Cat--Tree). They are then given the first words
(e.g., Cat) and must recall the paired word from the second list (see
Figure 6.24). Jacoby et al. (2015) argued proactive interference (e.g.,
recalling Dirt instead of Tree) often occurs when participants often
fail to recognise changes in the word pairings between lists. As
predicted, when they instructed some participants to detect changed
pairs, there was proactive facilitation rather than interference. Thus,
proactive interference can be reduced (or even reversed) if we recollect
the changes between information learned originally and subsequently.

Retroactive interference Anecdotal evidence that retroactive
interference can be important in everyday life comes from travellers
claiming exposure to a foreign language reduces their ability to recall
words in their own language. Misra et al. (2012) studied bilinguals
whose native language was Chinese and second language was English. They
named pictures in Chinese more slowly after previously naming the same
pictures in English. The evidence from eventrelated potentials suggested
participants were inhibiting second-language names when naming pictures
in Chinese.

Learning, memory and forgetting

As discussed earlier, Jacoby et al. (2015) found evidence for proactive
facilitation rather than interference when participants explicitly
focused on changes between the first and second lists (e.g., Cat--Dirt
and Cat--Tree). Jacoby et al. also found that instructing participants
to focus on changes between lists produced retroactive facilitation
rather than interference. Focusing on changes made it easier for
participants to discriminate accurately between list 1 responses (e.g.,
Dirt) and list 2 responses (e.g., Tree). Retroactive interference is
generally greatest when the new learning resembles previous learning.
However, Dewar et al. (2007) obtained evidence of retroactive
interference for a word list when participants performed an unrelated
task (e.g., detecting tones) between learning and memory test. Fatania
and Mercer (2017) found children were more susceptible than adults to
non-specific retroactive interference, perhaps because they used fewer
effective strategies (e.g., rehearsal) to minimise such interference. In
sum, retroactive interference can occur in two ways: (1) (2)

learning material similar to the original learning material; distraction
involving expenditure of mental effort during the retention interval
(non-specific retroactive interference); this cause of retroactive
interference is probably most common in everyday life.

Retrieval problems play a major role in producing retroactive
interference. Lustig et al. (2004) found that much retroactive
interference occurs because people find it hard to avoid retrieving
information from the wrong list. How can we reduce retrieval problems?
Unsworth et al. (2013) obtained substantial retroactive interference
when two word lists were presented prior to recall of the first list.
When focused retrieval was made easier (the words in each list belonged
to two separate categories such as animals and trees), there was no
retroactive interference. Ecker et al. (2015) also tested recall of the
first list following presentation of two word lists. When the time
interval between lists was long rather than short, recall performance
was better. Focusing retrieval on first-list words was easier when the
two lists were more separated in time and thus more discriminable.

Evaluation There is convincing evidence for both proactive and
retroactive interference, and progress has been made in identifying the
underlying processes. Proactive and retroactive interference depend in
part on problems with focusing retrieval exclusively on to-be-remembered
information. Proactive interference also depends on impaired encoding of
information. Both types of interference can be reduced by active
strategies (e.g., focusing on changes between the two lists). What are
the limitations of theory and research in this area? First, interference
theory explains why forgetting occurs but does not explain why
forgetting rate decreases over time. Second, we need clarification of
the roles of impaired encoding and impaired retrieval in producing
interference effects. For example, there may be interaction effects with
impaired

283

284

Memory

KEY TERMS

encoding reducing the efficiency of retrieval. Third, the precise
mechanisms responsible for the reduced interference effects with various
strategies have not been identified.

Repression Motivated forgetting of traumatic or other threatening events
(especially from childhood). Recovered memories Childhood traumatic
memories forgotten for several years and then remembered in adult life.

Motivated forgetting Interest in motivated forgetting was triggered by
the bearded Austrian psychologist Sigmund Freud (1856--1939). His
approach was narrowly focused on repressed traumatic and other
distressing memories. More recently, a broader approach to motivated
forgetting has been adopted. Much information in long-term memory is
outdated and useless for present purposes (e.g., where you have
previously parked your car). Thus, motivated or intentional forgetting
can be adaptive.

Repression Freud claimed threatening or traumatic memories often cannot
gain access to conscious awareness: this serves to reduce anxiety. He
used the term repression to refer to this phenomenon. He claimed
childhood traumatic memories forgotten for many years are sometimes
remembered in adult life. Freud found these recovered memories were
often recalled during therapy. However, many experts (e.g., Loftus &
Davis, 2006) argue most recovered memories are false memories referring
to imaginary events. Relevant evidence concerning the truth of recovered
memories was reported by Lief and Fetkewicz (1995). Of adult patients
who admitted reporting false recovered memories, 80% had therapists who
had made direct suggestions they had been subject to childhood sexual
abuse. These findings suggest recovered memories recalled inside therapy
are more likely to be false than those recalled outside. Geraerts et
al. (2007) obtained support for the above suggestion in a study on three
adult groups who had suffered childhood sexual abuse: (1) (2) (3)

Suggestive therapy group: their recovered memories were recalled
initially inside therapy. Spontaneous recovery group: their recovered
memories were recalled initially outside therapy. Continuous memory
group: they had continuous memories of abuse from childhood onwards.

Geraerts et al. (2007) argued the genuineness of the memories produced
could be assessed approximately by using corroborating evidence (e.g.,
the abuser had confessed). Such evidence was available for 45% of the
continuous memory group and 37% of the outside therapy group but for 0%
of the inside therapy group. These findings suggest recovered memories
recalled outside therapy are much more likely to be genuine than those
recalled inside therapy. Geraerts (2012) reviewed research comparing
women whose recovered memories were recalled spontaneously or in
therapy. Of importance, those with spontaneous recovered memories showed
more ability to suppress unwanted memories and were more likely to
forget they remembered

Learning, memory and forgetting

something previously. Spontaneous recovery memories are often triggered
by relevant retrieval cues (e.g., returning to the scene of the abuse).
It seems surprising that women recovering memories outside therapy
failed for many years to remember childhood sexual abuse. However, it is
so only if the memories are traumatic (as Freud assumed). In fact, only
8% of women with recovered memories regarded the relevant events as
traumatic or sexual when they occurred (Clancy & McNally, 2005/2006).
The great majority described their memories as confusing or
uncomfortable -- it seems reasonable that confusing or uncomfortable
memories could be suppressed or simply ignored or forgotten. In sum,
many assumptions about recovered memories are false. As McNally and
Geraerts (2009, p. 132) concluded, "A genuine recovered CSA \[childhood
sexual abuse\] memory does not require repression, trauma, or even
complete forgetting."

Directed forgetting Directed forgetting is a phenomenon involving
impaired long-term memory triggered by instructions to forget
information previously presented for learning. It is often studied using
the item method: several words are presented, each followed immediately
by an instruction to remember or forget it. After the words have been
presented, participants are tested for recall or recognition memory of
all the words. Memory performance is worse for the to-be-forgotten words
than the to-be-remembered ones. What causes directed forgetting? The
instructions cause learners to direct their rehearsal processes to
to-be-remembered items at the expense of to-be-forgotten ones.
Inhibitory processes are also involved. Successful forgetting is
associated with activation in areas within the right frontal cortex
involved in inhibition (Rizio & Dennis, 2013). Directed forgetting is
often unsuccessful. Rizio and Dennis (2017) found 60% of items
associated with forget instructions (Forget items) were successfully
recognised compared to 73% for items associated with remember
instructions (Remember items). They then considered brain activation for
successfully recognised items associated with a feeling of remembering.
There was greater activation in prefrontal areas associated with
effortful processing for recognised Forget items than recognised
Remember items. This enhanced effort was required because participants
engaged in inhibitory processing of Forget items at encoding even if
they were subsequently recognised.

Think/No-Think paradigm: suppression Anderson and Green (2001) developed
the Think/No-Think paradigm to assess whether individuals can actively
suppress memories. Participants learn a list of cue--target word pairs
(e.g., Ordeal--Roach; Steam--Train). Then they receive the cues studied
earlier (e.g., Ordeal; Steam) and try to recall the associated words
(e.g., Roach; Train) (respond condition) or prevent them coming to mind
(suppress condition). Some cues are not presented at this stage
(baseline condition).

285

KEY TERM Directed forgetting Reduced long-term memory caused by
instructions to forget information that had been presented for learning.

286

Memory

Finally, there are two testing conditions. In the same-probe test
condition, the original cues are presented (e.g., Ordeal) and
participants recall the corresponding target words (e.g., Roach). In the
independent-probe test condition, participants are presented with a
novel category cue (e.g., Roach might be cued with Insect--r). If people
can suppress unwanted memories, recall should be lower in the suppress
than the respond condition. Recall should also be lower in the suppress
condition than the baseline condition. Anderson and Huddleston (2012)
carried out a meta-analysis of 47 Figure 6.26 experiments and found
strong support for Percentage of words correctly recalled across 32
articles in both predictions (see Figure 6.26). However, the respond,
baseline and suppress conditions (in that order, suppression attempts
were often unsuccessful: reading from left to right) with same probe and
independent in the suppress condition (same-probe test), probe testing
conditions. 82% of items were recalled. From Anderson and Huddleston
(2012). Reproduced with permission of Springer Science+Business Media.
What strategies do individuals use to produce successful suppression of
unwanted memories? Direct suppression (focusing on the cue word and
blocking out the associated target word) is an important strategy.
Thought substitution (associating a different non-target word with each
cue word) is also very common. Bergström et al. (2009) found these
strategies were comparably effective in reducing recall in the suppress
condition. Anderson et al. (2016b) pointed out the Think/No-Think
paradigm is unrealistic in that we rarely make deliberate efforts to
retrieve suppressed memories in everyday life. They argued it would be
more realistic to assess the involuntary or spontaneous retrieval of
suppressed memories. They found suppression was even more effective than
voluntary retrieval at reducing involuntary retrieval of such memories.
How do suppress instructions cause forgetting? Anderson (e.g., Anderson
& Huddleston, 2012) argues inhibitory control is important -- the
learned response to the cue word is inhibited. More specifically, he
assumes inhibitory control involves the dorsolateral prefrontal cortex
and other frontal areas. Prefrontal activation leads to reduced
activation in the hippocampus (of central importance in learning and
memory). There is much support for the above hypothesis. First, there is
typically greater dorsolateral prefrontal activation during suppression
attempts than retrieval but reduced hippocampal activation (Anderson et
al., 2016b). Second, studies focusing on connectivity between the
dorsolateral prefrontal cortex and hippocampus indicated the former
influences the latter (Anderson et al., 2016b). Third, individuals whose
left and right hemisphere frontal areas involved in inhibitory control
are most closely coordinated exhibit superior memory suppression (Smith
et al., 2018).

Learning, memory and forgetting

Evaluation Most individuals can actively suppress unwanted memories
making them less likely to be recalled on purpose or involuntarily.
Progress has been made in identifying the underlying mechanisms. Of most
importance, inhibitory control mechanisms associated with the prefrontal
cortex (especially the dorsolateral prefrontal cortex) often reduce
hippocampal activation (Anderson et al., 2016b). What are the
limitations of theory and research in this area? First, more research is
required to clarify the reasons why suppression attempts are often
unsuccessful. Second, the reduced recall typically obtained in the
suppress condition is not always due exclusively to inhibitory
processes. Some individuals use thought substitution, a strategy which
reduces recall by producing interference or competition with the correct
words (Bergström et al., 2009). However, del Prete et al. (2015) argued
(with supporting evidence) that inhibitory processes play a part in
explaining the successful use of thought substitution.

Cue-dependent forgetting We often attribute forgetting to the weakness
of relevant memory traces. However, forgetting often occurs because we
lack the appropriate retrieval cues (cue-dependent forgetting). For
example, suppose you have forgotten the name of an acquaintance. If
presented with four names, however, you might well recognise the correct
one. Tulving (1979) argued that forgetting typically occurs when there
is a poor match or fit between memory-trace information and information
available at retrieval. This notion was expressed in his encoding
specificity principle: "The probability of successful retrieval of the
target item is a monotonically increasing function of informational
overlap between the information present at retrieval and the information
stored in memory" (p. 478). (If you are bewildered, note that a
"monotonically increasing function" is one that generally rises and does
not decrease at any point.) The encoding specificity principle resembles
the notion of transfer-appropriate processing (Morris et al., 1977;
discussed earlier, see p. 263). The main difference is that the latter
focuses more directly on the processes involved in memory. Tulving
(1979) assumed that when we store information about an event, we also
store information about its context. According to the encoding
specificity principle, memory is better when the retrieval context is
the same as that at learning. Note that context can be external (the
environment in which learning and retrieval occur) or internal (e.g.,
mood state). Eysenck (1979) argued that long-term memory does not depend
only on the match between information available at retrieval and stored
information. The Endel Tulving. extent to which the retrieval
information allows us Courtesy of Anders Gade.

287

KEY TERM Encoding speciﬁcity principle The notion that retrieval depends
on the overlap between the information available at retrieval and the
information in the memory trace.

288

Memory

to discriminate between the correct memory trace and incorrect ones also
matters (discussed further below, see p. 298).

Findings Recognition memory is typically much better than recall (e.g.,
we can recognise names we cannot recall). However, it follows from the
encoding specificity principle that recall will be better than
recognition memory when information in the recall cue overlaps more than
that in the recognition cue with memory-trace information. This
surprising finding has been reported many times. For example, Muter
(1978) found people were better at recalling famous names (e.g., author
of the Sherlock Holmes stories: Sir Arthur Conan \_\_\_) than selecting
the same names on a recognition test (e.g., DOYLE). Much research
indicates the importance of context in determining forgetting. On the
assumption that information about mood state (internal context) is often
stored in the memory trace, there should be less forgetting when the
mood state at learning and retrieval is the same rather than different.
This phenomenon (mood-state-dependent memory) has often been reported
(see Chapter 15). Godden and Baddeley (1975) manipulated external
context. Divers learned words on a beach or 10 feet underwater and then
recalled the words in the same or the other environment. Recall was much
better in the same environment. However, Godden and Baddeley (1980)
found no effect of context in a very similar experiment testing
recognition memory rather than recall. This probably happened because
the presence of the learned items on the recognition test provided
powerful cues outweighing any impact of context. Bramão and Johansson
(2017) found that having the same picture context at learning and
retrieval enhanced memory for word pairs provided that each word pair
was associated with a different picture context. However, having the
same picture context at learning and retrieval impaired memory when each
word pair was associated with the same picture context. In this
condition, the picture context did not provide useful information
specific to each of the word pairs being tested. The encoding
specificity principle can be expressed in terms of brain activity:
"Memory success varies as a function of neural encoding patterns being
reinstated at retrieval" (Staudigl et al., 2015, p. 5373). Several
studies have supported the notion that neural reinstatement is important
for memory success. For example, Wing et al. (2015) presented scenes
paired with matching verbal labels at encoding and asked participants to
recall the scenes in detail when presented with the labels at retrieval.
Recall performance was better when brain activity at encoding and
retrieval was similar in the occipito-temporal cortex, which is involved
in visual processing. Limitations on the predictive power of neural
reinstatement were shown by Mallow et al. (2015) in a study on trained
memory experts learning the locations of 40 digits presented in a
matrix. They turned the numbers into concrete objects, which were then
mentally inserted into a memorised route. On average, they recalled 86%
of the digits in the correct order. However, none of the main brain
areas active during encoding was activated during recall: thus, there
was remarkably little neural reinstatement.

Learning, memory and forgetting

289

This happened because the processes occurring during encoding were very
different from (and much more complex than) those occurring at
retrieval. Suppose you learn paired associates including park--grove and
are later given the cue word park and asked to supply the target or
response word (i.e., grove). The response words to the other paired
associates are either associated with park (e.g., tree; bench;
playground) or not associated. In the latter case, the cue is uniquely
associated with the target word and so your task should be easier. There
is high overload when a cue is associated with several response words
and low overload when it is only associated with one response word. The
target word is more distinctive when there is low overload
(distinctiveness was discussed earlier in the chapter). Goh and Lu
(2012) tested the above predictions. Encoding-retrieval overlap was
manipulated by using three item types. There was maximal overlap when
the same cue was presented at retrieval and learning (e.g., park--grove
followed by park--???); this was an intra-list cue. There was moderate
overlap when the cue was a strong associate of the target word (e.g.,
airplane--bird followed by feather--???). Finally, there was little
overlap when the cue was a weak associate of the target word e.g.,
roof--tin followed by armour--???). As predicted from the encoding
specificity principle, encoding-retrieval overlap was important (see
Figure 6.27). However, cue overload was also important -- memory
performance was much better when each cue was uniquely associated with a
single response word. According to the encoding specificity principle,
memory performance should be best when encoding-retrieval overlap is
highest (i.e., with intra-list cues). However, that was not the case
with high overload.

Evaluation Tulving's approach based on the encoding specificity
principle has several strengths. The overlap between memory-trace
information and that available in retrieval cues often determines
retrieval success. The principle has also received some support from
neuroimaging studies and research on mood-statedependent memory (see
Chapter 15). The notion that contextual information (external and
internal) strongly influences memory performance has proved correct.
What are the limitations with Tulving's approach? First, he exaggerated
the importance of encoding-retrieval overlap as the major factor
determining remembering and forgetting. Remembering typically involves
rejecting incorrect items as well as selecting correct ones. For this
purpose, a cue's ability to discriminate among memory traces is
important (Bramão & Johansson, 2017; Eysenck, 1979; Goh & Lu, 2012).

Figure 6.27 Proportion of words recalled in high- and low-overload
conditions with intra-list cues, strong extra-list cues and weak
extra-list cues. From Goh and Lu (2012). © 2011 Psychonomic Society,
Inc. Reprinted with the permission of Springer.

290

Memory

KEY TERMS

Second, neural reinstatement of encoding brain activity at retrieval is
sometimes far less important than implied by the encoding specificity
principle. This is especially the case when the processes at retrieval
are very different from those used at encoding (e.g., Mallow et al.,
2015). Third, Tulving's assumption that retrieval-cue information is
compared directly with memory-trace information is oversimplified. For
example, you would probably use complex problem-solving strategies to
answer the question, "What did you do six days ago?". Remembering is a
more dynamic, reconstructive process than implied by Tulving (Nairne,
2015a). Fourth, as Nairne (2015a, p. 128) pointed out, "Each of us
regularly encounters events that 'match' prior episodes in our lives . .
. but few of these events yield instances of conscious recollection."
Thus, we experience less conscious recollection than implied by the
encoding specificity principle. Fifth, it is not very clear from the
encoding specificity principle why context effects are often greater on
recall than recognition memory (e.g., Godden & Baddeley, 1975, 1980).
Sixth, memory allegedly depends on "informational overlap" between
memory trace and retrieval environment, but this is rarely assessed.
Inferring the amount of informational overlap from memory performance is
circular reasoning.

Consolidation A basic process within the brain involved in establishing
long-term memories; this process lasts several hours or more and newly
formed memories are fragile. Retrograde amnesia Impaired ability of
amnesic patients to remember information and events from the time period
prior to the onset of amnesia.

Consolidation and reconsolidation The theories discussed so far identify
factors that cause forgetting, but do not indicate clearly why the rate
of forgetting decreases over time. The answer may lie in consolidation.
According to this theory, consolidation "refers to the process by which
a temporary, labile memory is transformed into a more stable,
long-lasting form" (Squire et al., 2015, p. 1). According to the
standard theory, episodic memories are initially dependent on the
hippocampus. However, during the process of consolidation, these
memories are stored within cortical networks. This theory is
oversimplified: the process of consolidation involves bidirectional
interactions between the hippocampus and the cortex (Albo & Gräff,
2018). The key assumption of consolidation theory is that recently
formed memories are still being consolidated and so are especially
vulnerable to interference and forgetting. Thus, "New memories are clear
but fragile and old ones are faded but robust" (Wixted, 2004, p. 265).

Findings Much research supports consolidation theory. First, the
decreased rate of forgetting typically found over time can be explained
by assuming recent memories are more vulnerable than older ones due to
an ongoing consolidation process. Second, there is research on
retrograde amnesia, which involves impaired memory for events occurring
before amnesia onset. As predicted by consolidation theory, patients
with damage to the hippocampus often show greatest forgetting for
memories formed shortly before amnesia onset and least for more remote
memories (e.g., Manns et al., 2003). However, the findings are somewhat
mixed (see Chapter 7).

Learning, memory and forgetting

Squire et al. (1975) assessed recognition memory before and after
patients were given electroconvulsive therapy. Electroconvulsive therapy
reduced their memory for programmes up to 3 years beforehand from 65% to
42% but had no effect on memories acquired 4 to 17 years earlier. Third,
individuals who drink excessively sometimes experience "blackouts" (an
almost total loss of memory for events occurring while drunk). These
blackouts probably indicate a failure to consolidate memories formed
while intoxicated. As predicted, Moulton et al. (2005) found long-term
memory was impaired in individuals who drank alcohol shortly before
learning. However, alcohol consumption shortly after learning led to
improved memory. Alcohol may inhibit the subsequent formation of new
memories that would interfere with the consolidation process of memories
formed just before alcohol consumption. Fourth, consolidation theory
predicts newly formed memories are more susceptible to retroactive
interference than older ones. There is some support for this prediction
when the interfering material is dissimilar to that in the first
learning task (Wixted, 2004). Fifth, consolidation processes during
sleep can enhance long-term memory (Paller, 2017). Consider a technique
known as target memory reactivation: sleeping participants are exposed
to auditory or olfactory cues (the latter relate to the sense of smell)
present in the context where learning took place. This enhances memory
consolidation by reactivating brain networks (including the hippocampus)
involved in encoding new information and increases long-term memory
(Schouten et al., 2017).

Reconsolidation Consolidation theory assumes memory traces are "fixated"
because of a consolidation process. However, accumulating evidence
indicates that is oversimplified. The current view is that consolidation
involves progressive transformation of memory traces rather than simply
fixation (Elsey et al., 2018). Of most importance, reactivation of
previously consolidated memory traces puts them back into a fragile
state that can lead to those memory traces being modified (Elsey et al.,
2018). Reactivation can lead to reconsolidation (a new consolidation
process).

Findings Reconsolidation is very useful for updating our knowledge
because previous learning is now irrelevant. However, it can impair
memory for the information learned originally. This is how it happens.
We learn some information at Time 1. At Time 2, we learn additional
information. If the memory traces based on the information learned at
Time 1 are activated at Time 2, they immediately become fragile. As a
result, some information learned at Time 2 will mistakenly become
incorporated into the memory traces of Time 1 information and thus cause
misremembering. Here is a concrete example. Chan and LaPaglia (2013) had
participants watch a movie about a fictional terrorist attack (original
learning). Subsequently, some recalled 24 specific details from the move
(e.g., a terrorist using a hypodermic syringe) to produce
reconsolidation (reactivation)

291

KEY TERM Reconsolidation This is a new process of consolidation
occurring when a previously formed memory trace is reactivated; it
allows that memory trace to be updated.

292

Memory

whereas others performed an irrelevant distractor task (no
reactivation). After that, the participants encountered misinformation
(e.g., the terrorist used a stun gun) or neutral information
(relearning). Finally, there was a recognition-memory test for the
information in the movie. What did Chan and LaPaglia (2013) find?
Misinformation during the relearning phase led to substantial forgetting
of information from the movie in the reactivation/reconsolidation
condition but not the no-reactivation condition. Reactivating memory
traces from the movie triggered reconsolidation making those memory
traces vulnerable to disruption from misinformation. In contrast, memory
traces not subjected to reconsolidation were not disrupted. Scully et
al. (2017) reported a meta-analytic review based on 34 experiments. As
predicted, memory reactivation made memories susceptible to behavioural
interference leading to impaired memory performance for the original
learning event. These findings presumably reflect a reconsolidation
process. However, the mean effect size was small and some studies (e.g.,
Hardwicke et al., 2016) failed to obtain significant effects.

Evaluation Consolidation theory explains why the rate of forgetting
decreases over time. It also successfully predicts that retrograde
amnesia is greater for recently formed memories and that retroactive
interference effects are greatest when the interfering information is
presented shortly after learning. Consolidation processes during sleep
are important in promoting long-term memory and progress has been made
in understanding the underlying processes (e.g., Vahdat et al., 2017).
Reconsolidation theory helps to explain how memories are updated and no
other theory can explain the range of phenomena associated with
reconsolidation (Elsey et al., 2018). It is a useful corrective to the
excessive emphasis of consolidation theory on the permanent storage of
memory traces. Reconsolidation may prove very useful in clinical
contexts. For example, patients with post-traumatic stress disorder
(PTSD) typically experience flashbacks (vivid re-experiencing of
trauma-related events). There is preliminary evidence that
reconsolidation can be used successfully in the treatment of PTSD (Elsey
et al., 2018). What are the limitations of this theoretical approach?
(1)

(2) 
(3) 
(4) 

Forgetting does not depend solely on consolidation but also depends on
factors (e.g., encoding-retrieval overlap) not considered within the
theory. Consolidation theory does not explain why proactive and
retroactive interference are greatest when two different responses are
associated with the same stimulus. Much remains to be done to bridge the
gap between consolidation theory (with its focus on physical processes
within the brain) and approaches to forgetting that emphasise cognitive
processes. Consolidation processes are very complex and only partially
understood. For example, it has often been assumed that cortical
networks become increasingly important during consolidation. In
addition,

Learning, memory and forgetting

(5) 
(6) 
(7) 

however, consolidation is associated with a reorganisation within the
hippocampus (Dandolo & Schwabe, 2018). How memory retrieval makes
consolidated memories vulnerable and susceptible to reconsolidation
remains unclear (Bermúdez-Rattoni & McGaugh, 2017). It has not always
been possible to replicate reconsolidation effects. For example,
Hardwicke et al. (2016) conducted seven studies but found no evidence of
reconsolidation. Impaired memory performance for reactivated memory
traces is typically explained as indicating that reconsolidation has
disrupted storage of the original memory traces. However, it may also
reflect problems with memory retrieval (Hardwicke et al., 2016).

CHAPTER SUMMARY •

Short-term vs long-term memory. The multi-store model assumes there are
separate sensory, short-term and long-term stores. Much evidence (e.g.,
from amnesic patients) provides general support for the model, but it is
greatly oversimplified. According to the unitary-store model, short-term
memory is the temporarily activated part of long-term memory. That is
partially correct. However, the crucial term "activation" is not
precisely defined. In addition, research on amnesic patients and
neuroimaging studies suggest the differences between short-term and
long-term memory are greater than assumed by the unitary-store model.

•

Working memory. Baddeley's original working memory model consisted of
three components: an attention-like central executive, a phonological
loop holding speech-based information, and a visuo-spatial sketchpad
specialised for visual and spatial processing. However, there are doubts
as to whether the visuospatial sketchpad is as separate from other
cognitive processes and system as assumed theoretically. The importance
of the central executive can be seen in brain-damaged patients whose
central executive functioning is impaired (dysexecutive syndrome). The
notions of a central executive and dysexecutive syndrome are
oversimplified because they do not distinguish different executive
functions. More recently, Baddeley added an episodic buffer that stores
integrated information in multidimensional representations.

•

Working memory: executive functions and individual differences.
Individuals high in working memory capacity have greater attentional
control than low-capacity individuals, and so are more resistant to
external and internal distracting information. There is a lack of
conceptual clarity concerning the crucial differences between high- and
low-capacity individuals, and potential costs associated with high
capacity have rarely been investigated. According to the unity/diversity
framework, research on executive functions indicates the existence of a
common factor

293

294

Memory

resembling concentration and two specific factors (shifting and
updating). Support for this framework has been obtained from the
psychometric, neuroimaging and genetic approaches. However, research on
brain-damaged patients provides only partial support for the theoretical
framework. •

Levels of processing. Craik and Lockhart (1972) focused on learning
processes in their levels-of-processing theory. They identified depth of
processing, elaboration of processing and distinctiveness of processing
as key determinants of long-term memory. Insufficient attention was paid
to the relationship between learning processes and those at retrieval
and to the role of distinctive processing in enhancing long-term memory.
The theory is not explanatory, and the reasons why depth of processing
influences explicit memory much more than implicit memory remain
unclear.

•

Learning through retrieval. Long-term memory is typically much better
when much of the learning period is devoted to retrieval practice rather
than study and the beneficial effects of retrieval practice extend to
relevant but non-tested information. The testing effect is greater when
it is hard to retrieve the to-beremembered information. Difficult
retrieval probably enhances the generation and retrieval of effective
mediators. There is a reversal of the testing effect when numerous items
are not retrieved during testing practice; this reversal is explained by
the bifurcation model.

•

Implicit learning. Behavioural findings support the distinction between
implicit and explicit learning even though most measures of implicit
learning are relatively insensitive. The brain areas activated during
implicit learning (e.g., striatum) often differ from those activated
during explicit learning (e.g., prefrontal cortex). However,
complexities arise because there are numerous forms of implicit
learning, and learning is often a mixture of implicit and explicit.
Amnesic patients provide some support for the notion of implicit
learning because they generally have less impairment of implicit than
explicit learning. Parkinson's patients with damage to the basal ganglia
show the predicted impairment of implicit learning. However, they
generally also show impaired explicit learning and so provide only
limited information concerning the distinction between implicit and
explicit learning.

•

Forgetting from long-term memory. Some forgetting from longterm memory
is due to a decay process operating mostly during sleep. Strong
proactive and retroactive interference effects have been found inside
and outside the laboratory. People use active control processes to
minimise proactive interference. Recovered

Learning, memory and forgetting

memories of childhood abuse are more likely to be genuine when recalled
outside (rather than inside) therapy. Memories can be deliberately
suppressed with inhibitory control processes within the prefrontal
cortex producing reduced hippocampal activation. Forgetting depends in
part on encoding-retrieval overlap (encoding specificity principle).
However, retrieval is often a more complex and dynamic process than
implied by this principle. Consolidation theory explains the form of the
forgetting curve but de-emphasises the role of cognitive processes.
Reconsolidation theory explains how memories are updated and provides a
useful corrective to consolidation theory's excessive emphasis on
permanent storage. However, the complex processes involved in
consolidation and reconsolidation are poorly understood.

FURTHER READING Baddeley, A.D., Eysenck, M.W. & Anderson, M.C. (2020).
Memory (3rd edn). Abingdon, Oxon.: Psychology Press. The main topics
covered in this chapter are discussed in this textbook (for example,
Chapters 8--10 are on theories of forgetting). Eysenck, M.W. & Groome,
D. (eds) (2020). Forgetting: Explaining Memory Failure. London: Sage.
This edited book focuses on causes of forgetting in numerous laboratory
and real-life situations. Chapter 1 by David Groome and Michael Eysenck
provides an overview of factors causing forgetting and a discussion of
the potential benefits of forgetting. Friedman, N.P. & Miyake, A.
(2017). Unity and diversity of executive functions: Individual
differences as a window on cognitive structure. Cortex, 86, 186--204.
Naomi Friedman and Akira Miyake provide an excellent review of our
current understanding of the major executive functions. Karpicke, J.D.
(2017). Retrieval-based learning: A decade of progress. In J. Wixted
(ed.), Learning and Memory: A Comprehensive Reference (2nd edn;
pp. 487--514). Amsterdam: Elsevier. Jeffrey Karpicke provides an
up-to-date account of the testing effect and other forms of
retrieval-based learning. Morey, C.C. (2018). The case against
specialised visual-spatial short-term memory. Psychological Bulletin,
144, 849--883. Candice Morey discusses a considerable range of evidence
apparently inconsistent with Baddeley's working memory model (especially
the visuo-spatial sketchpad). Norris, D. (2017). Short-term memory and
long-term memory are still different. Psychological Bulletin, 143,
992--1009. Dennis Norris discusses much evidence supporting a clear-cut
separation between short-term and long-term memory. Oberauer, K.,
Lewandowsky, S., Awh, E., Brown, G.D.A., Conway, A., Cowan, N., (2018).
Benchmarks for models of short-term and working memory. Psychological
Bulletin, 144, 885--958. This article provides an excellent account of
the key findings relating to short-term and working memory that would
need to be explained by any comprehensive theory. Shanks, D.R. (2017).
Regressive research: The pitfalls of post hoc data selection in the
study of unconscious mental processes. Psychonomic Bulletin & Review,
24, 752--775. David Shanks discusses problems involved in attempting to
demonstrate the existence of implicit learning.

295

Chapter

7

Long-term memory systems INTRODUCTION We have an amazing variety of
information stored in long-term memory (e.g., details of our last summer
holiday; Paris is the capital of France; how to ride a bicycle). Much of
this information is stored in schemas or organised packets of knowledge
used extensively during language comprehension (see Chapter 10). This
remarkable variety is inconsistent with Atkinson and Shiffrin's (1968)
notion of a single long-term memory store (see Chapter 6). More
recently, there has been an emphasis on memory systems (note the
plural!). Each memory system is distinct, having its own specialised
brain areas and being involved in certain forms of learning and memory.
Schacter and Tulving (1994) identified four memory systems: episodic
memory; semantic memory; the perceptual representation system; and
procedural memory. Since then, there has been a lively debate concerning
the number and nature of long-term memory systems.

Amnesia Case study: Amnesia and long-term memory

KEY TERMS Amnesia A condition caused by brain damage in which there is
severe impairment of long-term memory (mostly declarative memory).
Korsakoff's syndrome Amnesia (impaired longterm memory) caused by
chronic alcoholism.

Suggestive evidence for several long-term memory systems comes from
brain-damaged patients with amnesia. If you are a movie fan you may have
mistaken ideas about the nature of amnesia (Baxendale, 2004). In the
movies, serious head injuries typically cause characters to forget the
past while still being fully able to engage in new learning. In the real
world, however, new learning is typically greatly impaired as well.
Bizarrely, many movies suggest the best cure for amnesia caused by
severe head injury is to suffer another blow to the head! Approximately
40% of Americans believe a second blow to the head can restore memory in
patients whose amnesia was caused by a previous blow (Spiers, 2016).
Patients become amnesic for various reasons. Closed head injury is the
most common cause. However, patients with closed head injury often have
several other cognitive impairments making it hard to interpret their
memory deficits. As a result, much research has focused on patients
whose amnesia is due to chronic alcohol abuse (Korsakoff's syndrome).

Long-term memory systems

297

IN THE REAL WORLD: THE FAMOUS CASE OF HM HM (Henry Gustav Molaison) was
the most-studied amnesic patient of all time. When he was 27, his
epileptic condition was treated by surgery involving removal of his
medial temporal lobes including the hippocampus. This affected his
memory more dramatically than his general cognitive functioning (e.g.,
IQ). Corkin (1984, p. 255) reported many years later that HM "does not
know where he lives, who cares for him, or where he ate his last meal .
. . in 1982 he did not recognise a picture of himself". Research on HM
(starting with Scoville and Milner, 1957) transformed our understanding
of long-term memory in several ways (see Eichenbaum, 2015): (1)

(2) 
(3) 
(4) 

Scoville and Milner's article was "the origin of modern neuroscience
research on memory" Henry Molaison, the most famous amnesic (Eichenbaum,
2015, p. 71). patient of all time. Research on him transformed our
knowledge of the workings HM showed reasonable learning and long-term of
long-term memory. retention on a mirror-tracing task (drawing objects
seen only in reflection) (Corkin, 1968). He also showed learning on the
pursuit rotor (manual tracking of a moving target) suggesting there is
more than one long-term memory system. HM had essentially intact
short-term memory supporting the important distinction between
short-term and long-term memory (see Chapter 6). HM had generally good
memory for events occurring a long time before his operation. This
suggests memories are not stored permanently in the hippocampus.

Research on HM led to an exaggerated emphasis on the role of the
hippocampus in memory (Aggleton, 2013). His memory problems were greater
than those experienced by the great majority of amnesic patients with
hippocampal damage. This probably occurred mainly because surgery
removed other areas (e.g., the parahippocampal region) and possibly
because the anti-epileptic drugs used by HM damaged brain cells relevant
to memory (Aggleton, 2013). The notion that HM's brain damage
exclusively affected his long-term memory for memories formed after his
operation is oversimplified (Eichenbaum, 2015). Evidence suggests HM had
various deficits in his perceptual and cognitive capacities. It also
indicates he had impaired memory for public and personal events
occurring prior to his operation. Thus, HM's impairments were more
widespread than generally assumed. In sum, we need to beware of "the
myth of HM" (Aly & Ranganath, 2018, p. 1), which consists of two
mistaken assumptions. First, while the hippocampus and medial temporal
lobe are important in episodic memory (memory for personal events),
episodic memory depends on a network that includes several other brain
regions. For example, Vidal-Piñeiro et al. (2018) found that
long-lasting episodic memories were associated with greater activation
at encoding in inferior lateral parietal regions as well as the
hippocampus. Second, the role of the hippocampus is not limited to
memory. It also includes "other functions, such as perception, working
memory, and implicit memory \[memory not involving conscious
recollection\]" (Aly & Ranganath, 2018, p. 1). This issue is discussed
later (see pp. 332--336).

298

Memory

Korsakoff patients are said to suffer from the "amnesic syndrome":

KEY TERM Anterograde amnesia Reduced capacity for new learning (and
subsequent remembering) after the onset of amnesia.

●

●

●

●

anterograde amnesia: a marked impairment in the ability to learn and
remember information encountered after the onset of amnesia; retrograde
amnesia: problems in remembering events prior to amnesia onset (see
Chapter 6); only slightly impaired short-term memory on measures such as
digit span (repeating back a random string of digits); some remaining
learning ability (e.g., motor skills).

The relationship between anterograde and retrograde amnesia is typically
strong. Smith et al. (2013) obtained a correlation of +.81 between the
two forms of amnesia in patients with damage to the medial temporal
lobes. However, new learning is more easily disrupted by limited brain
damage within the medial temporal lobes than is memory for previously
acquired information. This probably occurs because there has typically
been consolidation (see Glossary) of previously acquired information
prior to amnesia onset. Further evidence the brain areas (and processes)
underlying the two forms of amnesia differ was provided by Buckley and
Mitchell (2016). Damage to the retrosplenial cortex (connected to the
hippocampus) caused retrograde amnesia but not anterograde amnesia.
There are problems with using Korsakoff patients. First, amnesia
typically has a gradual onset caused by an increasing deficiency of the
vitamin thiamine. Thus, it is often unclear whether certain past events
occurred before or after amnesia onset. Second, brain damage in
Korsakoff patients typically involves the medial temporal lobes
(especially the hippocampus; see Figure 7.1). However, there is often
damage to the frontal lobes as well producing various cognitive deficits
(e.g., impaired cognitive control). This complicates interpreting
findings from these patients. Third, the precise area of brain damage
(and thus the pattern of memory impairment) varies across patients. For
example, some Korsakoff patients exhibit confusion, lethargy and
inattention.

Figure 7.1 Damage to brain areas within and close to the medial temporal
lobes (indicated by asterisks) producing amnesia. Republished with
permission of Routledge Publishing Inc.

Long-term memory systems

Fourth, research on Korsakoff patients does not provide direct evidence
concerning the impact of brain damage on long-term memory. Brain
plasticity and learning of compensatory strategies mean patients can
gradually alleviate some memory problems (Fama et al., 2012). In sum,
the study of amnesic patients has triggered several theoretical
developments. For example, the distinction between declarative and
non-declarative memory (see below) was originally proposed in part
because of findings from amnesic patients.

Declarative vs non-declarative memory Historically, the most important
distinction between different types of long-term memory was between
declarative memory and non-declarative memory (Squire & Dede, 2015).
Declarative memory involves conscious recollection of events and facts
-- it often refers to memories that can be "declared" or described but
also includes memories that cannot be described verbally. Declarative
memory is sometimes referred to as explicit memory and involves knowing
that something is the case. The two main forms of declarative memory are
episodic and semantic memory. Episodic memory is concerned with personal
experiences of events that occurred in a given place at a specific time.
Semantic memory consists of general knowledge about the world, concepts,
language and so on. In contrast, non-declarative memory does not involve
conscious recollection. We typically obtain evidence of non-declarative
memory by observing changes in behaviour. For example, consider someone
learning to ride a bicycle. Their cycling ability improves over time
even though they cannot consciously recollect what they have learned.
Non-declarative memory is sometimes known as implicit memory. There are
various forms of non-declarative or implicit memory. One is memory for
skills (e.g., piano playing; bicycle riding). Such memory involves
knowing how to perform certain actions and is known as procedural
memory. Another form of non-declarative memory is priming (also known as
repetition priming): it involves facilitated processing of a stimulus
presented recently (Squire & Dede, 2015, p. 7). For example, it is
easier to identify a picture as a cat if a similar picture of a cat has
been presented previously. The earlier picture is a prime facilitating
processing when the second cat picture is presented. Amnesic patients
find it much harder to form and remember declarative than
non-declarative memories. For example, HM (discussed above) had
extremely poor declarative memory for personal events occurring after
his operation and for faces of those who became famous in recent
decades. In stark contrast, he had reasonable learning ability and
memory for non-declarative tasks (e.g., mirror tracing; the pursuit
rotor; perceptual identification aided by priming). This chapter
contains detailed discussion of declarative and nondeclarative memory.
Figure 7.2 presents the hugely influential traditional theoretical
account, which strongly influenced most of the research discussed in
this chapter. However, it is oversimplified. At the end of this chapter,
we discuss its limitations and possible new theoretical developments

299

KEY TERMS Declarative memory A form of long-term memory that involves
knowing something is the case; it involves conscious recollection and
includes memory for facts (semantic memory) and events (episodic
memory); sometimes known as explicit memory. Non-declarative memory
Forms of long-term memory that influence behaviour but do not involve
conscious recollection (e.g., priming; procedural memory); also known as
implicit memory. Procedural memory This is memory concerned with knowing
how and it includes the knowledge required to perform skilled actions.
Priming Facilitating the processing of (and response) to a target
stimulus by presenting a stimulus related to it shortly beforehand.
Repetition priming The finding that processing of a stimulus is
facilitated if it has been processed previously.

300

Memory

Figure 7.2 The traditional theoretical account based on dividing
long-term memory into two broad classes: declarative and nondeclarative.
Declarative memory is divided into episodic and semantic memory, whereas
non-declarative memory is divided into procedural memory, priming,
simple classical conditioning, and habituation and sensitisation. The
assumption that there are several forms of long-term memory is
accompanied by the further assumption that different brain regions are
associated with each one. From Henke (2010). Reprinted with permission
from Nature Publishing Group.

in the section entitled "Beyond memory systems and declarative vs
nondeclarative memory" (pp. 332--340).

DECLARATIVE MEMORY

KEY TERMS Episodic memory A form of long-term memory concerned with
personal experiences or episodes occurring in a given place at a
specific time. Semantic memory A form of long-term memory consisting of
general knowledge about the world, concepts, language and so on.

Declarative or explicit memory encompasses numerous different kinds of
memories. For example, we remember what we had for breakfast this
morning and that "le petit déjeuner" is French for "breakfast". Tulving
(1972) argued the crucial distinction within declarative memory was
between what he termed "episodic memory" and "semantic memory" (see
Eysenck & Groome, 2015b). What is episodic memory? According to Tulving
(2002, p. 5), "It makes possible mental time travel through subjective
time from the present to the past, thus allowing one to re-experience .
. . one's own previous experiences." Nairne (2015b) identified the three
"Ws" of episodic memory: remembering a specific event (what) at a given
time (when) in a particular place (where). What is semantic memory? It
is "an individual's store of knowledge about the world. The content of
semantic memory is abstracted from actual experience and is therefore
said to be conceptual, that is, generalised and without reference to any
specific experience" (Binder & Desai, 2011, p. 527). What is the
relationship between episodic memory and autobiographical memory
(discussed in Chapter 8)? Both are concerned with personal past
experiences. However, much information in episodic memory is trivial

Long-term memory systems

and is remembered only briefly. In contrast, autobiographical memory
typically stores information for long periods of time about personally
significant events and experiences. What is the relationship between
episodic and semantic memory? According to Tulving (2002), episodic
memory developed out of semantic memory during the course of evolution.
It also develops later in childhood than semantic memory.

Episodic vs semantic memory If episodic and semantic memory form
separate memory systems, they should differ in several ways. Consider
the ability of amnesic patients to acquire new episodic and semantic
memories. Spiers et al. (2001) reviewed 147 cases of amnesia involving
damage to the hippocampus or fornix. Episodic memory was impaired in all
cases, whereas many patients had relatively small impairment of semantic
memory. The above difference in the impact of hippocampal brain damage
suggests episodic and semantic memory are distinctly different. However,
the greater vulnerability of episodic memories than semantic ones may
occur mainly because episodic memories are formed from a single
experience whereas semantic memories often combine several learning
opportunities. We would have stronger evidence if we discovered
brain-damaged patients with very poor episodic memory but essentially
intact semantic memory. Elward and Vargha-Khadem (2018) reviewed
research on patients with developmental amnesia (amnesia due to
hippocampal damage at a young age). These patients, "typically show
relatively preserved semantic memory and factual knowledge about the
natural world despite severe impairments in episodic memory" (p. 23).
Vargha-Khadem et al. (1997) studied two patients (Beth and Jon) with
developmental amnesia. Both had very poor episodic memory for the day's
activities and television programmes, but their semantic memory
(language development; literacy; and factual knowledge) were within the
normal range. However, Jon had various problems with semantic memory
(Gardiner et al., 2008). His rate of learning was slower than that of
healthy controls when provided with facts concerning geographical,
historical and other kinds of knowledge. Similarly slow learning in
semantic memory has been found in most patients with developmental
amnesia (Elward & Vargha-Khadem, 2018). The findings from patients with
developmental amnesia are surprising given the typical finding that
individuals with an intact hippocampus depend on it for semantic memory
acquisition (Baddeley et al., 2020). Why, then, is their semantic memory
reasonably intact? Two answers have been proposed. First, developmental
amnesics typically devote more time than healthy individuals to repeated
study of factual information. This may produce durable long-term
semantic memories via a process of consolidation (see Glossary and
Chapter 6). Second, episodic memory may depend on the hippocampus
whereas semantic memory depends on the underlying entorhinal, perirhinal
and parahippocampal cortices. Note the brain damage suffered by Jon and
Beth centred on the hippocampus. Bindschaedler et al. (2011) studied a
boy (VI)

301

302

Memory

with severe hippocampal damage but relatively preserved perirhinal and
entorhinal cortex. His performance on semantic memory tasks (e.g.,
vocabulary) improved at the normal rate even though his performance was
very poor on episodic memory tasks. Many amnesics may have severe
problems with episodic and semantic memory because the hippocampus and
underlying cortices are both damaged. This is very likely given the two
areas are adjacent. Curot et al. (2017) applied electrical brain
stimulation to memoryrelated brain areas to elicit reminiscences.
Semantic memories were mostly elicited by stimulation of the rhinal
cortex (including the entorhinal and perirhinal cortices). In contrast,
episodic memories were only elicited by stimulation of the hippocampal
region. Blumenthal et al. (2017) studied a female amnesic (HC) with
severe hippocampal damage but intact perirhinal and entorhinal cortices.
She was given the semantic memory task of generating intrinsic features
of objects (e.g., shape; colour) and extrinsic features (e.g., how the
object is used). HC performed comparably to controls with intrinsic
features but significantly worse than controls with extrinsic features.
Thus, the hippocampus is important for learning some aspects of semantic
memory. How can we explain Blumenthal et al.'s (2017) findings? The
hippocampus is involved in learning associations between objects and
contexts in episodic memory (see final section of the chapter,
pp. 332--340). In a similar fashion, generating extrinsic features of
objects requires learning associations between objects and their uses.

Retrograde amnesia We turn now to amnesic patients' problems with
remembering information learned prior to the onset of amnesia:
retrograde amnesia (see Glossary and Chapter 6). Many amnesic patients
have much greater retrograde amnesia for episodic than semantic
memories. Consider the amnesic patient KC. According to Tulving (2002,
p. 13), "He cannot recollect any personally experienced events . . .,
whereas his semantic knowledge \[e.g. general world knowledge\] acquired
before the critical accident is still reasonably intact." There is much
support for the notion that remote semantic memories formed prior to the
onset of amnesia are essentially intact (see Chapter 6). For example,
amnesic patients often perform comparably to healthy controls on
semantic memory tasks (e.g., vocabulary knowledge; object naming).
However, Klooster and Duff (2015) argued such findings may reflect the
use of insensitive measures. In their study, Klooster and Duff gave
amnesic patients the semantic memory task of listing features of common
objects. On average, amnesic patients listed only 50% as many features
as healthy controls. Retrograde amnesia for episodic memories in amnesic
patients often spans several years and has a temporal gradient, i.e.,
older memories showing less impairment (Bayley et al., 2006). In
contrast, retrograde amnesia for semantic memories is generally small
except for knowledge acquired shortly before amnesia onset (Manns et
al., 2003). In sum, retrograde amnesia is typically greater for episodic
than semantic memories. However, semantic memories can be subject to
retrograde amnesia when assessed using sensitive measures.

Long-term memory systems

303

Semantic dementia

KEY TERMS

Patients with semantic dementia have severe loss of concept knowledge
from semantic memory. However, their episodic memory and most cognitive
functions (e.g., attention; non-verbal problem solving) are reasonably
intact initially. Semantic dementia always involves degeneration of the
anterior temporal lobes. Areas such as the perirhinal and entorhinal
cortex are probably involved in the formation of semantic memories. In
contrast, the anterior temporal lobes are where such memories are stored
semipermanently. However, episodic memory and executive functioning are
reasonably intact in the early stages. Patients with semantic dementia
have great problems accessing information about concepts stored in
semantic memory (Lambon Ralph et al., 2017). However, their performance
on many episodic memory tasks is good (e.g., they have intact ability to
reproduce complex visual designs: Irish et al., 2016). They also have
comparable performance to healthy controls in remembering what tasks
they performed 24 hours earlier and where those tasks were performed
(Adlam et al., 2009). Landin-Romero et al. (2016) reviewed relevant
research. The good episodic memory of semantic dementia patients
probably occurs because they make effective use of the frontal and
parietal regions within the brain. In sum, we have an apparent double
dissociation (see Glossary). Amnesic patients have very poor episodic
memory but often reasonably intact semantic memory. In contrast,
patients with semantic dementia have very poor semantic memory but
reasonably intact episodic memory. However, the double dissociation is
only approximate and it is hard to interpret the somewhat complex
findings.

Semantic dementia A condition involving damage to the anterior temporal
lobes involving widespread loss of information about the meanings of
words and concepts; however, episodic memory and executive functioning
are reasonably intact initially.

Interdependence of episodic and semantic memory We have seen the
assumption that there are separate episodic and semantic memory systems
is oversimplified. Here we focus on the interdependence of episodic and
semantic memory. In a study by Renoult et al. (2016), participants
answered questions belonging to four categories: (1) unique events
(e.g., "Did you drink coffee this morning?"); (2) general factual
knowledge (e.g., "Do many people drink coffee?"); (3) autobiographical
facts (e.g., "Do you drink coffee every day?"); and (4) repeated
personal events (e.g., "Have you drunk coffee while shopping?").
Category 1 involves episodic memory and category 2 involves semantic
memory. Categories 3 and 4 involve personal semantic memory (a
combination of episodic and semantic memory). Renoult et al. (2016) used
event-related potentials (ERPs; see Glossary) during retrieval for all
four question categories. There were clear-cut ERP differences between
categories 1 and 2. Of most importance, ERP patterns for category 3 and
4 questions were intermediate between those for categories 1 and 2
suggesting they required retrieval from both episodic and semantic
memory. Tanguay et al. (2018) reported similar findings. They
interpreted the various findings with reference to personal semantics:
aspects of autobiographical memory resembling semantic memory in being
factual but also resembling episodic memory in being "idiosyncratically
personal" (p. 65).

Personal semantics Aspects of one's personal or autobiographical memory
that combine elements of episodic memory and semantic memory.

304

Memory

KEY TERM

Greenberg et al. (2009) showed episodic and semantic memory can be
interdependent. Amnesic patients and healthy controls generated as many
members as possible from various categories. Some categories (e.g.,
kitchen utensils) were selected so that performance would benefit from
using episodic memory, whereas other categories (e.g., things typically
red) seemed less likely to involve episodic memory. Amnesic patients
performed worse than controls especially with categories potentially
benefitting from episodic memory. With those categories, controls were
much more likely than patients to use episodic memory as an efficient
organisational strategy to generate category members.

Semanticisation The phenomenon of episodic memories changing into
semantic memories over time.

Semanticisation of episodic memory Robin and Moscovitch (2017) argued
initially episodic memories are transformed into semantic memories over
time. For example, the first time you went to a seaside resort, you
formed episodic memories of your experiences there. As an adult, while
you still remember visiting that seaside resort as a child, you have
probably forgotten the personal and contextual information originally
associated with your childhood memories. Thus, what was an episodic
memory has become a semantic memory. This change involves
semanticisation of episodic memory and suggests episodic and semantic
memories are related. Robin and Moscovitch (2017) argued the process of
semanticisation often involves a memory transformation from an initially
detail-rich episodic representation to a gist-like or schematic
representation involving semantic memory. They provided a theoretical
framework within which to understand these processes (see Figure 7.3).
There is much support for this theoretical approach (discussed later).
For example, Gilboa and Marlatte (2017) found in a meta-analytic review
that the ventromedial prefrontal cortex is typically involved in schema
processing within semantic memory. Sekeres et al. (2016) tested memory
for movie clips. There was much more forgetting of peripheral detail
over time (episodic memory) than of the gist (semantic memory).
St-Laurent et al. (2016) found amnesic patients with hippocampal damage
had reduced processing of episodic perceptual details. Robin and
Moscovitch (2017) discussed research focusing on changes in brain
activation during recall as time since learning increased. As predicted,
there was reduced anterior hippocampal activation but increased
activation in the ventromedial prefrontal cortex. These findings
reflected increased use of gist or schematic information compensating
for reduced availability of details.

Overall evaluation There is some support for separate episodic and
semantic memory systems in the double dissociation involving amnesia and
semantic dementia: the former is associated with greater impairment of
episodic than semantic memory whereas the latter is associated with the
opposite pattern. However, there are complications in interpreting these
findings and the

Long-term memory systems

305

Particular, detailed cues: Cake at 10th birthday party

Generic cues:

Posterior neocortex

Particular, coarse cues: House

Party Mom's house

Perceptual representations

10th birthday party

pHPC vmPFC Schema / monitoring

EL

O AB

TIO RA

N

Details CO N

STR

UC

aHPC TIO

N

Gist

A EL

BO

TIO RA

N

WEAK ELABORATION

Figure 7.3 Episodic memories (involving perceptual representations and
specific details) depend on the posterior hippocampus (pHPC); semantic
memories (involving schemas) depend on the ventromedial prefrontal
cortex (vmPFC); and gist memories (combining episodic and semantic
memory) depend on the anterior hippocampus (aHPC). There are
interactions between these forms of memory caused by processes such as
construction and elaboration. From Robin and Moscovitch (2017).
Reprinted with permission of Elsevier.

double dissociation is only approximate. In addition, episodic and
semantic memory are often interdependent at learning and during
retrieval, making it hard to disentangle their respective contributions.

EPISODIC MEMORY How can we assess someone's episodic memory following
learning (e.g., a list of to-be-remembered items)? Recognition and
recall are the two main types of episodic memory test.
Recognition-memory tests generally involve presenting various items with
participants deciding whether each one was presented previously (often
50% were presented previously and 50% were not). As we will see, more
complex forms of recognition-memory test have also been used. There are
three types of recall test: free recall, serial recall and cued recall.
Free recall involves producing previously presented items in any order
in the absence of specific cues. Serial recall involves producing
previously presented items in the order they were presented. Cued recall
involves producing previously presented items to relevant cues. For
example, "cat--table" might be presented at learning and the cue,
"cat--???" at test.

KEY TERMS Free recall A test of episodic memory in which previously
presented to-be-remembered items are recalled in any order. Serial
recall A test of episodic memory in which previously presented
to-beremembered items must be recalled in the order of presentation.
Cued recall A test of episodic memory in which previously presented
to-be-remembered items are recalled in response to relevant cues.

306

Memory

Recognition memory: familiarity and recollection Recognition memory can
involve recollection or familiarity. Recollection involves recognition
based on conscious retrieval of contextual information whereas such
conscious retrieval is lacking in familiarity-based recognition (Brandt
et al., 2016). Here is a concrete example. Several years ago, the first
author walked past a man in Wimbledon, and was immediately confident he
recognised him. However, he simply could not think where he had
previously seen the man. After some thought (this is the kind of thing
academic psychologists think about!), he realised the man was a
ticket-office clerk at Wimbledon railway station. Initial recognition
based on familiarity was replaced by recognition based on recollection.
The remember/know procedure (Migo et al., 2012) has often been used to
assess familiarity and recollection. List learning is followed by a test
where participants indicate whether each item is "Old" or "New". Items
identified as "Old" are followed by a know or remember judgement.
Typical instructions require participants to respond know if they
recognise the list words, "but these words fail to evoke any specific
conscious recollection from the study list" (Rajaram, 1993, p. 102).
They should respond remember if "the 'remembered' word brings back to
mind a particular association, image, or something more personal from
the time of study" (Rajaram, 1993, p. 102). Dunn (2008) proposed a
single-process account: strong memory traces give rise to recollection
judgements whereas weak memory traces give rise to familiarity
judgements. As we will see, however, most evidence supports a dual- or
two-process account, namely, that recollection and familiarity involve
different processes.

Brain mechanisms Diana et al. (2007) provided an influential theoretical
account of the key brain areas involved in recognition memory in their
binding-of-item-andcontext model (see Figure 7.4): (1) (2) (3)

The perirhinal cortex receives information about specific items (what
information needed for familiarity judgements). The parahippocampal
cortex receives information about context (where information useful for
recollection judgements). The hippocampus receives what and where
information (both of great importance to episodic memory) and binds them
to form item--context associations permitting recollection.

Findings Functional neuroimaging studies support the above model. In a
metaanalytic review, Diana et al. (2007) found recollection was
associated with more activation in parahippocampal cortex and the
hippocampus than perirhinal cortex. In contrast, familiarity was
associated with more activation in perirhinal cortex than the
parahippocampal cortex or hippocampus.

Long-term memory systems

307

Figure 7.4 (a) Locations of the hippocampus (red), the perirhinal cortex
(blue) and the parahippocampal cortex (green); (b) the
binding-ofitem-and-context model. From Diana et al. (2007). Reprinted
with permission of Oxford University Press.

Neuroimaging evidence is correlational and so cannot show the
hippocampus is more essential to recollection than familiarity. In
principle, more direct evidence could be obtained from brain-damaged
patients. Bowles et al. (2010) studied amnesic patients with severe
hippocampal damage. As predicted, these patients had significantly
impaired recollection but not familiarity. However, other research has
typically found amnesic patients with medial temporal lobe damage have a
minor impairment in familiarity but a much larger one in recollection
(Skinner & Femandes, 2007). According to the model, patients with damage
to the perirhinal cortex should have largely intact recollection but
impaired familiarity. Bowles et al. (2011) tested this prediction with a
female patient, NB. As predicted, her recollection performance was
consistently intact. However, she had impaired familiarity for verbal
materials. Brandt et al. (2016) studied a female patient, MR, with
selective damage to entorhinal cortex (adjacent to perirhinal cortex and
previously linked to familiarity). As predicted, MR had impaired
familiarity for words but intact recollection.

308

Memory

According to the original model, the parahippocampal cortex is limited
to processing spatial context (i.e., where information). This is too
limited. Diana (2017) used a non-spatial context -- words were
accompanied by contextual questions (e.g., "Is this word common or
uncommon?"). There was greater parahippocampal activation for words
associated with correct (rather than incorrect) context memory. Since
the context (i.e., contextual questions) was non-spatial, the role of
the parahippocampal cortex in episodic memory extends beyond spatial
information. Dual-process models assume the hippocampus is required to
process relationships between items and to bind items to contexts but is
not required to process items in isolation. There are two potential
problems with these assumptions (Bird, 2017). First, the term "item" is
often imprecisely defined. Second, these models often de-emphasise the
importance of the learning material (e.g., faces; names; pictures).
Smith et al. (2014) compared immediate memory performance in healthy
controls and amnesic patients with hippocampal damage. Fifty famous
faces were presented followed by a recognition-memory test. The amnesic
patients performed comparably to controls for famous faces not
identified as famous but were significantly impaired for famous faces
identified as famous. A plausible interpretation is that unfamiliar
faces (i.e., unknown famous faces) are processed as isolated items and
so do not require hippocampal processing. In contrast, known famous
faces benefit from additional contextual processing dependent on the
hippocampus. Bird (2017, p. 161) concluded his research review as
follows: "There are no clear-cut examples of materials other than
\[unfamiliar\] faces that can be recognised using extrahippocampal
\[outside the hippocampus\] familiarity processes." This is because most
"items" are not processed in isolation but require the integrative
processing provided by the hippocampus. Scalici et al. (2017) reviewed
research on the involvement of the prefrontal cortex in familiarity and
recollection. There was greater familiarity-based than
recollection-based activity in the ventromedial and dorsomedial
prefrontal cortex and lateral BA10 (at the front of the prefrontal
cortex) whereas the opposite was the case in medial BA10 (see Figure
7.5). These findings suggest familiarity and recollection involve
different processes.

Evaluation Recognition memory depends on rather separate processes of
familiarity and recollection, as indicated by neuroimaging studies.
However, the most convincing findings come from studying brain-damaged
patients. A double dissociation has been obtained -- some patients have
reasonably intact familiarity but impaired recollection whereas a few
patients exhibit the opposite pattern. What are the limitations of
theory and research in this area? (1)

The typical emphasis on recollection based on conscious awareness of
contextual details is oversimplified because we can also have

Long-term memory systems

309

Figure 7.5 Left lateral (A), medial (B) and anterior (C) views of
prefrontal areas having greater activation to familiarity-based than
recollection-based processes (in red) and areas showing the opposite
pattern (in blue). From Scalici et al. (2017). Reprinted with permission
of Elsevier.

Figure 7.6 Sample pictures on the recognition-memory test. The one on
the left is high-contrast and easy to process whereas the one on the
right is low-contrast and hard to process. From Geurten & Willems
(2017). Reprinted with permission of Elsevier.

(2) 

conscious awareness of having previously seen the target items
themselves. Brainerd et al. (2014) found a model assuming two types of
recollection predicted behavioural data better than models assuming only
one type of recollection. Diana et al.'s (2007) model does not identify
the processes underlying familiarity judgements. However, it is often
assumed that items on a recognition-memory test that are easy to process
are judged to be familiar. Geurten and Willems (2017) tested this
assumption using unfamiliar pictures. On the recognition-memory test,
some pictures were presented with reduced contrast to reduce processing
fluency (see Figure 7.6). As predicted, recognition-memory performance
was better with high-contrast than with low-contrast test pictures (70%
vs 59%, respectively).

310

Memory

(3) 
(4) 

More brain mechanisms are involved in recognition memory than assumed by
Diana et al. (2007). The notion of an "item" requires more precise
definition (Bird, 2017).

Recall memory Here we will consider briefly similarities and differences
between recall (especially free recall: see Glossary) and recognition
memory. Mickes et al. (2013) reported important similarities using the
remember/know procedure with free recall. Participants received a word
list and for each word answered one question (e.g., "Is this item
animate?"; "Is this item bigger than a shoebox?"). They then recalled
the words, made a remember or know judgement for each recalled word and
indicated which question had been associated with each word (contextual
information). Participants were more accurate at remembering which
question was associated with recalled words when the words received
remember (rather than know) judgements. This is very similar to
recognition memory where participants access more contextual information
for remember words than know ones. Kragel and Polyn (2016) compared
patterns of brain activation during recognition-memory and free-recall
tasks. Brain areas activated during familiarity processes in recognition
memory were also activated during free recall. There was also weaker
evidence that brain areas activated during recollective processes in
recognition were activated in free recall. As we have seen, amnesic
patients exhibit very poor recognition memory (especially recognition
associated with recollection). Amnesic patients also typically have very
poor free recall (e.g., Brooks & Baddeley, 1976). Some aspects of
recognition memory depend on structures other than the hippocampus
itself (Diana et al., 2007). In contrast, it has typically been assumed
the hippocampus is crucial for recall memory. Patal et al. (2015)
supported these assumptions in patients with relatively selective
hippocampal damage. The extent of hippocampal damage in these patients
was negatively correlated with their recall performance but uncorrelated
with their recognition-memory performance. There are several
similarities between the processes involved in recall and recognition.
However, the to-be-remembered information is physically present on
recognition tests but not recall tests. As a result, processing demands
should generally be less with recognition. Chan et al. (2017) obtained
findings consistent with this analysis in patients with damage to the
frontal lobes impairing higher-level cognitive processes. Individual
differences in intelligence were strongly related to performance on
recall tests but not recognition-memory tests. Thus, recall performance
depends much more on higher-level cognitive processes.

Is episodic memory constructive? We use episodic memory to remember
experienced past events. Most people believe the episodic memory system
resembles a video recorder providing us with accurate and detailed
information about past events (Simons & Chabris, 2011). In fact,
"Episodic memory is . . . a fundamentally

Long-term memory systems

constructive, rather than reproductive process that is prone to various
kinds of errors and illusions" (Schacter & Addis, 2007, p. 773). For
example, the constructive nature of episodic memory leads to distorted
remembering of stories (Chapter 10) and to eyewitnesses producing
inaccurate memories of crimes (Chapter 8). Why is episodic memory so
error-prone? First, it would require massive processing to produce a
semi-permanent record of all our experiences. Second, we typically want
to access the gist or essence of our past experiences, omitting trivial
details. Third, we often enrich our episodic memories when discussing
our experiences with friends even when this produces memory errors
(Dudai & Edelson, 2016; see Chapter 8). What are the functions of
episodic memory (other than to remember past events)? First, we use
episodic memory to imagine possible future scenarios and to plan the
future (Madore et al., 2016). Imagining the future (episodic simulation)
is greatly facilitated by episodic memory's flexible and constructive
nature. According to Addis (2018), remembered and imagined events are
both very similar, "simulations of experience from the same pool of
experiential details" (p. 69). However, Schacter and Addis (2007)
assumed in their constructive episodic simulation hypothesis that
episodic simulation is more demanding than episodic memory retrieval
because control processes are required to combine details from multiple
episodes. Second, Madore et al. (2019) found episodic memory influences
divergent creative thinking (thinking of unusual and creative uses for
common objects). Creative thinking was associated with enhanced
connectivity between brain areas linked to episodic processing and brain
areas associated with cognitive control.

Findings The tendency to recall the gist of our previous experiences
increases throughout childhood (Brainerd et al., 2008). More
surprisingly, children's greater focus on remembering gist as they
become older often increases memory errors. Brainerd and Mojardin (1998)
asked children to listen to sentences such as "The tea is hotter than
the cocoa". Subsequently, they decided whether test sentences had been
presented previously in precisely that form. Sentences having the same
meaning as an original sentence but different wording (e.g., "The cocoa
is cooler than the tea") were more likely to be falsely recognised by
older children. We turn now to the hypothesis (Schacter & Addis, 2007;
Addis, 2018) that imagining future events involves very similar
processes to those involved in remembering past episodic events. On that
hypothesis, brain areas important for episodic memory (e.g., the
hippocampus) should also be activated when imagining future events.
Benoit and Schacter (2015) reported supportive evidence. There were two
key findings: (1)

Several brain regions were activated both while imagining future events
(episodic simulation) and during episodic-memory recollection (see
Figure 7.7A). The overlapping areas included "the hippocampus and
parahippocampal cortex within the medial temporal lobes" (Benoit &
Schacter, 2015, p. 450).

311

312

Memory

(2) As predicted, several brain areas were more strongly activated
    during episodic simulation than episodic memory retrieval (see
    Figure 7.7B). These included clusters in the dorsolateral prefrontal
    cortex and posterior inferior parietal lobes and clusters in the
    right medial temporal lobe (including the hippocampus) (Benoit &
    Schacter, 2015, p. 453). Some of these areas are involved in
    cognitive control -- the borders of the fronto-parietal control
    network (see Chapter 6) are indicated by white dashed lines.
    Imagining future events is generally associated with hippocampal
    activation. We would have more direct evidence the hippocampus is
    necessarily involved if amnesic patients with hippocampal damage had
    impaired ability to imagine future events. Hassabis et al. (2007)
    found amnesics' imaginary experiences consisted of isolated
    fragments lacking the richness and spatial coherence of healthy
    controls' experiences. The amnesic patient KC with extensive brain
    damage (including to the hippocampus) could not recall a single
    episodic memory from the past or imagine a possible future event
    (Schacter & Madore, 2016). Robin (2018) argued that spatial context
    is of major importance for both episodic memory and imagining future
    events. For example, Robin et al. (2016) asked participants to read
    brief narratives and imagine them in detail. Even when Figure 7.7 no
    spatial context was specified in the narrative,

<!-- -->

(A) Areas activated for both episodic simulation and participants
    nevertheless generated an appropriepisodic memory; (B) areas
    activated more for episodic ate spatial context while imagining on
    78% of simulation than episodic memory. trials. From Benoit and
    Schacter (2015). Reprinted with permission of Elsevier. The
    similarities between recall of past personal events and imagining
    future personal events have typically been attributed to episodic
    processes common to both tasks. However, some similarities may also
    reflect non-episodic processes. For example, amnesics' impaired past
    recall and future imagining may reflect an impaired ability to
    construct detailed narrative. Schacter and Madore (2016) provided
    convincing evidence that episodic processes are involved in
    recalling past events and imagining future ones. Participants
    received training in recollecting details of a recent experience. If
    recall of past events and imaging of future events both rely on
    episodic memory, this induction should benefit performance by
    increasing participants' production of episodic details in recall
    and imagination. That is what was found.

Long-term memory systems

Evaluation It is assumed episodic memory relies heavily on constructive
processes. This assumption is supported by research on eyewitness memory
(Chapter 8) and language comprehension (Chapter 10). The additional
assumption that constructive processes used in episodic memory retrieval
of past events are also involved in imagining future events is an
exciting development supported by much relevant evidence. Episodic
memory is also involved in divergent creative thinking. What are the
main limitations of research in this area? First, several brain areas
associated with recalling past personal events and imagining future
events have been identified, but their specific contributions remain
somewhat unclear. Second, finding a given area is involved in recalling
the past and imagining the future does not necessarily mean it is
associated with the same cognitive processes in both cases. Third, there
is greater uncertainty about future events than past ones. This may
explain why imagined future events are less vivid than recalled past
events but more abstract and dependent on semantic memory (MacLeod,
2016).

SEMANTIC MEMORY Our organised general knowledge about the world is
stored in semantic memory. Such knowledge is extremely varied (e.g.,
information about the French language; the rules of hockey; the names of
capital cities). Much of this information consists of concepts: mental
representations relating to objects, people, facts and words (Lambon
Ralph et al., 2017). These representations are multimodal (i.e., they
incorporate information from several sense modalities). How is
conceptual information in semantic memory organised? We start this
section by addressing this issue. First, we consider the notion that
concepts are organised into hierarchies. Second, we discuss an
alternative view, according to which semantic memory is organised on the
basis of the semantic distance or semantic relatedness between concepts.
After that, we focus on the nature of concepts and on how concepts are
used. Finally, we consider larger information structures known as
schemas.

Organisation: hierarchies of concepts Suppose you are shown a photograph
of a chair and asked what it is. You might say it is an item of
furniture, a chair or an easy chair. This suggests concepts are
organised into hierarchies. Rosch et al. (1976) identified three levels
within such hierarchies: superordinate categories (e.g., items of
furniture) at the top, basic level categories (e.g., chair) in the
middle and subordinate categories (e.g., easy chair) at the bottom.
Which level do we use most often? Sometimes we talk about superordinate
categories (e.g., "That furniture is expensive") or subordinate
categories (e.g., "I love my iPhone"). However, we typically deal with
objects at the intermediate or basic level. Rosch et al. (1976) asked
people to list concept attributes at each level in the hierarchy. Very
few attributes were listed for superordinate

313

KEY TERM Concepts Mental representations of categories of objects or
items.

314

Memory

categories because they are relatively abstract. Many attributes were
listed for categories at the other two levels. However, very similar
attributes were listed for different categories at the lowest level.
Thus, basic level categories generally have the best balance between
informativeness and distinctiveness: informativeness is low at the
highest level of the hierarchy and distinctiveness is low at the lowest
level. In similar fashion, Rigoli et al. (2017) argued (with supporting
evidence) that categorising objects at the basic level generally allows
us to select the most appropriate action with respect to that object
while minimising processing costs. Bauer and Just (2017) found the
processing of basic level concepts involved many more brain regions than
the processing of subordinate concepts. More specifically, brain areas
associated with sensorimotor and language processing were activated with
basic level concepts, whereas processing was focused on perceptual areas
with subordinate concepts. Basic level categories have other special
properties. First, they represent the most general level at which
individuals use similar motor movements when interacting with category
members (e.g., we sit on most chairs in similar ways). Second, basic
level categories were used 99% of the time when people named pictures of
objects (Rosch et al., 1976). However, we do not always prefer basic
level categories. For example, we expect experts to use subordinate
categories. We would be surprised if a botanist simply described all the
different kinds of plants in a garden as plants! We also often use
subordinate categories with atypical category members. For example,
people categorise penguins faster as penguins than as birds (Jolicoeur
et al., 1984).

Findings Tanaka and Taylor (1991) studied category naming in
bird-watchers and dog experts who were shown pictures of birds and dogs.
Both groups used subordinate names much more often in their expert
domain than their novice domain. Even though people generally prefer
basic level categories, this does not necessarily mean they categorise
fastest at that level. Prass et al. (2013) presented photographs of
objects very briefly and asked participants to categorise them at the
superordinate level (animal or vehicle), the basic level (e.g., cat or
dog) or the subordinate level (e.g., Siamese cat vs Persian cat).
Performance was most accurate and fastest at the superordinate level
(see Figure 7.8). In similar fashion, Besson et al. (2017) found
categorisation of faces was fastest at the superordinate level. Why does
categorisation often occur faster at the superordinate level than the
basic level? Close and Pothos (2012) argued that categorisation at the
basic level is generally more informative and so requires more detailed
processing. Rogers and Patterson (2007) supported this viewpoint. They
studied patients with semantic dementia, a condition involving
impairment of semantic memory (discussed earlier in this chapter,
p. 303; see Glossary). Patients with severe semantic dementia performed
better at the superordinate level than the basic level because less
processing was required.

Long-term memory systems

315

Figure 7.8 Accuracy of (a) object categorisation and (b) speed of
categorisation at the superordinate, basic and subordinate levels. From
Prass et al. (2013). Reprinted with permission.

Organisation: semantic distance The assumption that concepts in semantic
memory are organised hierarchically is too inflexible and exaggerates
how neatly information in semantic memory is organised. Collins and
Loftus (1975) proposed an approach based on the more flexible assumption
that semantic memory is organised in terms of the semantic distance
between concepts. Semantic distance between concepts has been measured
in many ways (Kenett et al., 2017). Kenett et al. used data from 60
individuals instructed to produce as many associations as possible in 60
seconds to 800 Hebrew cue words in order to assess semantic distance in
terms of path length: "the shortest number of steps connecting any two
cue words" (p. 1473). Kenett et al. (2017) asked participants to judge
whether word pairs were semantically related. These judgements were well
predicted by path distance: 91% of directly linked words (one-step) were
judged to be semantically related, compared to 69% of two-step word
pairs and 64% of threestep word pairs. Of importance, Kenett et
al. (2017) found semantic distance predicted performance on various
episodic memory tasks (e.g., free recall). In an experiment on cued
recall, participants were presented with word pairs. This was followed
by presenting the first word of each pair and instructing them to recall
the associated word. Performance was much higher on directly linked word
pairs (1-step) than three-step word pairs: 30% vs 11%, respectively.
Semantic distance also predicts aspects of language production. For
example, Rose et al. (2019) had participants name target pictures (e.g.,
eagle) in the presence of distractor pictures that were semantically
close (e.g., owl) or semantically distant (e.g., gorilla). There was an
interference effect: naming times were longer when distractors were
semantically close. What is the underlying mechanism responsible for the
above findings? According to Collins and Loftus's (1975) influential
spreading-activation theory, the appropriate node in semantic memory is
activated when we see, hear or think about a concept. Activation then
spreads rapidly to other concepts, with greater activation for concepts
closely related semantically than those weakly related. Such an account
can readily explain Rose et al.'s (2019) findings.

316

Memory

Spreading-activation theory is also applicable to semantic priming (see
Glossary and Chapter 9). For example, dog is recognised as a word faster
when the preceding prime is cat than when it is car (Heyman et al.,
2018). This can be explained by assuming that presentation of cat
activates the dog concept and so facilitates recognising it as a word.
In sum, the semantic distance of concepts within semantic memory is
important in explaining findings in episodic memory research (e.g., free
recall; cued recall) as well as findings relating to language
processing. However, this approach is based on the incorrect assumption
that each concept has a single fixed representation in semantic memory.
Our processing of any given concept is influenced by context (see next
section). For example, think about the meaning of piano. You probably
did not focus on the fact that pianos are heavy. However, you would do
so if you read the sentence "Fred struggled to lift the piano". Thus,
the meaning of any concept (and its relation to other concepts) varies
as a function of the circumstances in which it is encountered.

Using concepts: Barsalou's approach What do the mental representations
of concepts look like? The "traditional" view involved the following
assumptions about concept representations: ●

●

●

They are abstract and so detached from input (sensory) and output
(motor) processes. They are stable: the same concept representation is
used on different occasions. Different individuals have similar
representations of any given concept.

In sum, it was assumed concept representations "have the flavour of
detached encyclopaedia descriptions in a database of categorical
knowledge about the world" (Barsalou, 2012, p. 247). This approach forms
part of the sandwich model (Barsalou, 2016b): cognition (including
concept processing) is "sandwiched" between perception and action and
can be studied without considering them. How, then, could we use such
concept representations to perceive the visual world or decide how to
behave in a given situation (Barsalou, 2016a)? Barsalou (2012) argued
all the above theoretical assumptions are incorrect. We process concepts
in numerous different settings and that processing is influenced by the
current setting or context. More generally, any concept's representation
varies flexibly across situations depending on the individual's current
goals and the precise situation. Consider the concept of a bicycle. A
traditional abstract representation would resemble the Chambers
Dictionary definition, a "vehicle with two wheels one directly in front
of the other, driven by pedals". According to Barsalou (2009), the
individual's current goals determine which features are activated. For
example, the saddle's height is important if you want to ride a bicycle,
whereas information about the tyres is activated if you have a puncture.
According to Barsalou's theoretical approach (e.g., 2012, 2016a,b),
conceptual processing is anchored in a given context or situation and

Long-term memory systems

involves the perceptual and motor or action systems. His approach is
described as grounded cognition: cognition (including concept
processing) is largely grounded (or based) on the perceptual and motor
systems.

Findings Evidence that conceptual processing can involve the perceptual
system was reported by Wu and Barsalou (2009). Participants wrote down
properties for nouns or noun phrases. Those given the word lawn focused
on external properties (e.g., plant; blades) whereas those given
rolled-up lawn focused more on internal properties (e.g., dirt; soil).
Thus, object qualities not visible if you were actually looking at the
object itself are harder to think of than visible ones. We might expect
Barsalou's grounded cognition approach to be less applicable to abstract
concepts (e.g., truth; freedom) than concrete ones (objects we can see
or hear). However, Barsalou et al. (2018) argued that abstract concepts
are typically processed within a relatively concrete context. In fact,
abstract-concept processing sometimes involves perceptual information
but much less often than concrete-concept processing (Borghi et al.,
2018). Hauk et al. (2004) reported suggestive evidence that the motor
system is often involved when we access concept information. When
participants read words such as "lick", "pick" and "kick", these verbs
activated parts of the motor strip overlapping with areas activated when
people make the relevant tongue, finger and foot movements. These
findings do not show the motor system is necessary for concept
processing -- perhaps activation in areas within the motor strip occurs
only after concept activation. Miller et al. (2018) asked participants
to make hand or foot responses after reading hand-associated words
(e.g., knead; wipe) or foot-associated words (e.g., kick; sprint).
Responses were faster when the word was compatible with the limb making
the response (e.g., hand response to a hand-associated word) than when
word and limb were incompatible. These findings apparently support
Barsalou's approach, according to which "The understanding of action
verbs requires activation of the motor areas used to carry out the named
action" (Miller et al., 2018, p. 335). Miller et al. (2018) tested the
above prediction using event-related potentials (see Glossary) to assess
limb-relevant brain activity. However, presentation of hand- and
foot-associated words was not followed rapidly by limb-relevant brain
activity. Thus, the reaction time findings discussed above were based on
processing verb meanings and did not directly involve motor processing.
How can we explain the differences in the findings obtained by Hauk et
al. (2004) and by Miller et al. (2018)? Miller et al. used a speeded
task that allowed insufficient time for motor imagery (and activation of
relevant motor areas) to occur, whereas this was not the case with the
study by Hauk et al. According to Barsalou, patients with severe motor
system damage should have difficulty in processing action-related words
(e.g., names of

317

318

Memory

tools). Dreyer et al. (2015) studied HS, a patient with damage to
sensorimotor brain systems close to the hand area. He had specific
problems in recognising nouns relating to tools rather than those
referring to food or animals. In a review, Vannuscorps et al. (2016)
found some studies reported findings consistent with Dreyer et al.'s
(2015) research. In other studies, however, patients with damage to
sensorimotor systems had no deficit in conceptual processing of actions
or manipulable objects. Vannuscorps et al. concluded many patients with
deficits in processing concepts relating to actions and tool have
extensive damage to brain areas additional to sensorimotor areas. The
findings from such patients have limited relevance to Barsalou's (2016b)
theory. Vannuscorps et al. (2016) studied a patient, JR, with brain
damage primarily affecting the action production system. JR's
picture-naming ability was assessed repeatedly over a 3-year period.
Even though JR's disease was progressive, his naming performance with
action-related concepts (e.g., hammer; shovel) remained intact. Thus,
processing of actionrelated concepts does not necessarily require the
involvement of the motor system.

Evaluation Barsalou's general theoretical approach has several
strengths. First, our everyday use of concept knowledge often involves
the perceptual and motor systems. Second, concept processing is
generally flexible: it is influenced by the present context and the
individual's goals. Third, it is easier to see how concept
representations facilitate perception and action within Barsalou's
approach than the "traditional" approach. What are the limitations of
Barsalou's approach? First, Barsalou argues it is generally necessary to
use perceptual and/or motor processes to understand concept meanings
fully. However, motor processes may often not be necessary (Miller et
al., 2018; Vannuscorps et al., 2016). Second, Barsalou exaggerates
variations in concept processing across time and contexts. The
traditional view that concepts possess a stable, abstract core has not
been disproved (Borghesani & Piazza, 2017). In fact, concepts have a
stable core and concept processing is often contextdependent (discussed
below). Third, much concept knowledge does not consist simply of
perceptual and motor features. Borghesani and Piazza (2017, p. 8)
provide the following example: "Tomatoes are native to South and Central
America." Fourth, we recognise the similarities between concepts not
sharing perceptual or motor features. For example, we categorise
watermelon and blackberry as fruit even though they are very different
visually and we eat them using different motor actions.

Using concepts: hub-and-spoke model We have seen concept processing
often involves the perceptual and motor systems. However, it is
improbable nothing else is involved. First, we would not have coherent
concepts if concept processing varied considerably across

Long-term memory systems

Figure 7.9 The hub-and-spoke model. (a) the hub within the anterior
temporal lobe (ATL) has bidirectional connections to the spokes (praxis
refers to object manipulability; it is action-related); (b) the
locations of the hub and spokes are shown, same colour coding as in (a).
From Lambon Ralph et al. (2017).

situations. Second, as mentioned above, we can detect similarities in
concepts differing greatly in perceptual terms. Such considerations led
Patterson et al. (2007) to propose their huband-spoke model (see Figure
7.9). The "spokes" consist of several modalityspecific regions involving
sensory and motor processing. Each concept also has a "hub" -- a
modality-independent unified representation efficiently integrating our
conceptual knowledge. It is assumed hubs are located within the anterior
temporal lobes. As discussed earlier, patients with semantic dementia
invariably have damage to the anterior temporal lobes and extensive loss
of conceptual knowledge is their main problem. In the original model, it
was assumed the two anterior temporal lobes (left and right hemisphere)
formed a unified system. This is approximately correct -- there is
substantial activation in both anterior temporal lobes whether concepts
are presented visually or verbally. However, the left anterior temporal
lobe was more involved than the right in processing verbal information
whereas the opposite was the case in processing visual information (Rice
et al., 2015). Lambon Ralph et al. (2017) discussed research where
patients with damage to the left anterior temporal lobe had particular
problems with anomia (object naming). In contrast, patients with damage
to the right anterior temporal lobe had particular problems in face
recognition.

Findings We start with research on the "hub". Mayberry et al. (2011)
argued semantic dementia involves a progressive loss of "hub"
information producing

319

320

Memory

KEY TERM

a blurring of the boundary between category members and non-members.
Accordingly, they predicted semantic dementia patients would have
particular problems making accurate category-membership decisions with
(1) atypical category members (e.g., emu is an atypical bird); and (2)
pseudotypical items: non-category members resembling category members
(e.g., butterfly is like a bird). Both predictions were supported with
pictures and words, suggesting processing within the anterior temporal
lobes is general and "hub-like" rather than modality-specific (e.g.,
confined to the visual modality). Findings from patients with semantic
dementia suggest the anterior temporal lobes are the main brain areas
associated with "hubs". Binder et al. (2009) reviewed 120 neuroimaging
studies involving semantic memory in healthy individuals and found the
anterior temporal lobes were consistently activated. Pobric et
al. (2010a) applied transcranial magnetic stimulation (TMS; see
Glossary) to interfere with processing in the left or right anterior
temporal lobe while participants processed concepts presented by verbal
or pictorial stimuli. TMS disrupted concept processing comparably in
both anterior temporal lobes. However, Murphy et al. (2017) discovered
important differences between ventral (bottom) and anterior (front)
regions of the anterior temporal lobe. Ventral regions responded to
meaning and acted as a hub. However, anterior regions were responsive to
differences in input modality (visual vs auditory) and thus are not
"hub-like". We turn now to research on the "spokes". Pobric et
al. (2010b) applied transcranial magnetic stimulation (TMS) to interfere
briefly with processing within the inferior parietal lobule (involved in
processing actions we can make towards objects; the praxis spoke in
Figure 7.9). TMS slowed naming times for manipulable objects but not
non-manipulable ones indicating this brain area (unlike the anterior
temporal lobes) is involved in relatively specific processing. Findings
consistent with those of Pobric et al. (2010b) were reported by
Ishibashi et al. (2018). They applied transcranial direct current
stimulation (tDCS; see Glossary) to the inferior parietal lobule and the
anterior temporal lobe. Since they used anodal tDCS, it was expected
this stimulation would enhance performance on tasks requiring rapid
access to semantic information concerning tool function (e.g., scissors
are used for cutting) or tool manipulation (e.g., pliers are gripped by
the handles). As predicted, anodal tDCS applied to the anterior temporal
lobe facilitated performance on both tasks because this brain area
contains much general object knowledge (see Figure 7.10). The effects of
anodal tDCS applied to the inferior parietal lobule were limited to the
manipulation task as predicted because this area processes
action-related information. Suppose we studied patients whose brain
damage primarily affected one or more of the "spokes". According to the
model, we should find category-specific deficits (problems with specific
categories of objects). There is convincing evidence for the existence
of various category-specific deficits and these deficits are mostly
associated with the model's spokes (Chen et al., 2017). However, it is
often hard to interpret the findings from patients with
category-specific deficits. For example, many patients find it much
harder

Category-speciﬁc deﬁcits Disorders caused by brain damage in which
semantic memory is disrupted for certain semantic categories.

Long-term memory systems

0.7

Accuracy

0.65

Sham ATL-A

0.6

IPL-A 0.55 0.5

Manipulation

Function Task

Figure 7.10 Performance accuracy on tool function and tool manipulation
tasks with anodal transcranial direct current stimulation to the
anterior temporal lobe (ATL-A) or to the inferior parietal lobule
(IPL-A) and in a control condition (Sham). From Ishibashi et al. (2018).

to identify pictures of living than non-living things. Several factors
are involved: living things have greater contour overlap than non-living
things, they are more complex structurally and they activate less motor
information (Marques et al., 2013). It is difficult to disentangle the
relative importance of these factors. Finally, we consider a study by
Borghesani et al. (2019). Participants read words (e.g., elephant)
having conceptual features (e.g., mammal) and perceptual features (e.g.,
big; trumpeting). There were two main findings. First, conceptual and
perceptual features were processed in different brain areas. Second,
initial processing of both types of features occurred approximately 200
ms after word onset. These findings support the model's assumptions that
there is somewhat independent processing of "hub" information (i.e.,
conceptual features) and "spoke" information (i.e., perceptual
features). However, the findings are inconsistent with Barsalou's
approach, according to which perceptual processing should precede (and
influence) conceptual processing.

Evaluation The hub-and-spoke model provides a comprehensive approach
combining aspects of the traditional view of concept processing and
Barsalou's approach. The notion within the model that concepts are
represented by abstract core information and modality-specific
information has strong support. Brain areas associated with different
aspects of concept processing have been identified. What are the model's
limitations? First, it emphasises mostly the storage and processing of
single concepts. However, we also need to consider relations between
concepts. For example, we can distinguish between taxonomic relations
based on similarity (e.g., dog--bear) and thematic relations based on
proximity (e.g., dog--leash). The anterior temporal lobes are important
for taxonomic semantic processing whereas the temporo-parietal

321

322

Memory

KEY TERMS

cortex is important for thematic semantic processing (Mirman et al.,
2017). The model has problems with the latter finding given its focus on
the anterior temporal lobes. Second, the role of the anterior temporal
lobes in semantic memory is more complex than assumed theoretically. For
example, Mesulam et al. (2013) found semantic dementia patients with
damage primarily to the left anterior temporal lobe had much greater
problems with verbal concepts than visually triggered object concepts.
Thus, regions of the left anterior temporal lobe form part of a language
network rather than a very general modality-independent hub. Third, we
have only a limited understanding of the division of labour between the
hub and the spokes during concept processing (Lambon Ralph, 2014). For
example, we do not know how the relative importance of hub-and-spoke
processing depends on task demands. It is also unclear how information
from hubs and spokes is integrated during concept processing.

Schema An organised packet of information about the world, events or
people stored in long-term memory. Script A form of schema containing
information about a sequence of events (e.g., events during a typical
restaurant meal).

Schemas vs concepts We may have implied semantic memory consists
exclusively of concepts. In fact, there are also larger information
structures called schemas. Schemas are "superordinate knowledge
structures that reflect abstracted commonalities across multiple
experiences" (Gilboa & Marlatte, 2017, p. 618). Scripts are schemas
containing information about sequences of events. For example, your
restaurant script probably includes the following: being given a menu,
ordering food and drink, eating and drinking and paying the bill (Bower
et al., 1979). Scripts (and schemas more generally) are discussed in
Chapter 10 (in relation to language comprehension and memory) and
Chapter 8 (relating to failures of eyewitness memory). Here we first
consider brain areas associated with schema-related information. We then
explore implications of the theoretical assumption that semantic memory
contains abstract concepts corresponding to words and broader
organisational structures based on schemas. On that assumption, we might
expect some brain-damaged patients would have greater problems accessing
concept-based information than schema-based information, whereas others
would exhibit the opposite pattern. This is a double dissociation (see
Glossary).

Brain networks Schema information and processing involves several brain
areas. However, the ventromedial prefrontal cortex (vmPFC) is especially
important. It includes several Brodmann Areas including BA10, BA11,
BA12, BA14 and BA25 (see Figure 1.5). Gilboa and Marlatte (2017)
reviewed 12 fMRI experiments where participants engaged in schema
processing. Much of the ventromedial prefrontal cortex was consistently
activated, plus other areas including the hippocampus. Research on
brain-damaged patients also indicates the important role of the
ventromedial prefrontal cortex in schema processing. Ghosh et al. (2014)
gave participants a schema ("going to bed at night") and asked

Long-term memory systems

them to decide rapidly whether each of a series of words was closely
related to it. Patients with damage to the ventromedial prefrontal
cortex performed worse than healthy controls on this task, indicating
impaired schema-related processing. Warren et al. (2014) presented
participants with words belonging to a single schema (e.g., winter;
blizzard; cold) followed by recall. Healthy individuals often falsely
recall a schema-relevant non-presented word (e.g., snow) because their
processing and recall involve extensive schema processing. If patients
with damage to the ventromedial prefrontal cortex engage in minimal
schema processing, they should show reduced false recall. That is what
Warren et al. found.

Double dissociation As discussed earlier, brain-damaged patients with
early-stage semantic dementia (see Glossary) have severe problems
accessing word and object meanings. Bier et al. (2013) assessed the
ability of three semantic dementia patients to use schema-relevant
information by asking them what they would do if they had unknowingly
invited two guests to lunch. The required script actions included
dressing to go outdoors, going to the grocery store, shopping for food,
preparing the meal and clearing up afterwards. One patient successfully
described all the above script actions accurately despite severe
problems with accessing concept information from semantic memory. The
other patients had particular problems with planning and preparing the
meal. However, they remembered script actions relating to dressing and
shopping. Note we might expect semantic dementia patients to experience
problems with using script knowledge because they would need access to
relevant concept knowledge (e.g., knowledge about food ingredients) when
using script knowledge (e.g., preparing a meal). Other patients have
greater problems with accessing script information than concept
meanings. Scripts typically have a goal-directed quality (e.g., using a
script to achieve the goal of enjoying a restaurant meal). Since the
prefrontal cortex is of major importance in goal-directed activity, we
might expect patients with prefrontal damage (e.g., ventromedial
prefrontal cortex) to have particular problems with script memory.
Cosentino et al. (2006) studied patients having semantic dementia or
fronto-temporal dementia (involving extensive damage to the prefrontal
cortex and the temporal lobes) with scripts containing sequencing or
script errors (e.g., dropping fish in a bucket before casting the
fishing line). Patients with extensive prefrontal damage failed to
detect far more sequencing or script errors than those with semantic
dementia. Farag et al. (2010) confirmed that patients with
fronto-temporal dementia are generally less sensitive than those with
semantic dementia to the appropriate order of script events. They
identified the areas of brain damage in their participants (see Figure
7.11). Patients (including fronto-temporal ones) insensitive to script
sequencing had damage in inferior and dorsolateral prefrontal cortex. In
contrast, patients (including those with semantic dementia) sensitive to
script sequencing showed little evidence of prefrontal damage.

323

324

Memory

Figure 7.11 (a) Brain areas damaged in patients with fronto-temporal
degeneration or progressive non-fluent aphasia. (b) Brain areas damaged
in patients with semantic dementia or mild Alzheimer's disease. From
Farag et al. (2010). By permission of Oxford University Press.

Zahn et al. (2017) also studied patients with fronto-temporal dementia
with damage to the fronto-polar cortex (BA10, part of the ventromedial
prefrontal cortex) and the anterior temporal lobe. They assessed
patients' knowledge of social concepts (e.g., adventurous) and script
knowledge (e.g., the likely long-term consequences of ignoring their
employer's requests). Patients with greater damage to the fronto-polar
cortex than the anterior temporal lobe showed relatively poorer script
knowledge than knowledge of social concepts. In contrast, patients with
the opposite pattern of brain damage had relatively poorer knowledge of
social concepts. In sum, semantic memory for concepts centres on the
anterior temporal lobe. Patients with semantic dementia have damage to
this area causing severely impaired concept memory. In contrast,
semantic memory for scripts or schemas involves the prefrontal cortex
(especially ventromedial prefrontal cortex). However, when we use our
script knowledge (e.g., preparing a

Long-term memory systems

meal), it is important to access relevant concept knowledge (e.g.,
knowledge about food ingredients). As a consequence, semantic dementia
patients whose primary impairment is to concept knowledge also have
great difficulties in accessing and using script knowledge.

NON-DECLARATIVE MEMORY Non-declarative memory does not involve conscious
recollection but instead reveals itself through behaviour. As mentioned
earlier, priming (the facilitated processing of repeated stimuli) and
procedural memory (mainly skill learning) are two major forms of
non-declarative memory. Note that procedural memory is typically
involved in implicit learning (discussed in Chapter 6). There are two
major differences between priming (also known as repetition priming) and
procedural memory: (1) (2)

Priming often occurs rapidly whereas procedural memory or skill learning
is typically slow and gradual (Knowlton & Foerde, 2008). Priming is tied
fairly closely to specific stimuli whereas skill learning typically
generalises to numerous stimuli. For example, it would be useless if you
could hit a good backhand at tennis only when the ball approached you
from a given direction at a given speed!

The strongest evidence for distinguishing between declarative and
nondeclarative memory comes from amnesic patients. Such patients mostly
have severely impaired declarative memory but almost intact
non-declarative memory (but see next section for a more complex
account). Oudman et al. (2015) reviewed research on priming and
procedural memory or skill learning in amnesic patients with Korsakoff's
syndrome (see Glossary). Their performance was nearly intact on tasks
such as the pursuit rotor (a stylus must be kept in contact with a
target on a rotating turntable) and the serial reaction time task (see
Glossary). Amnesic patients performed poorly on some non-declarative
tasks reviewed by Oudman et al. (2015) for various reasons. First, some
tasks require declarative as well as non-declarative memory. Second,
some Korsakoff's patients have widespread brain damage (including areas
involved in non-declarative memory). Third, the distinction between
declarative and non-declarative memory is less clear-cut and important
than traditionally assumed (see later discussion).

Repetition priming We can distinguish between perceptual and conceptual
priming. Perceptual priming occurs when repeated presentation of a
stimulus

leads to facilitated processing of its perceptual features. For example,
it is easier to identify a degraded stimulus if it was presented shortly
beforehand. Conceptual priming occurs when repeated presentation of a
stimulus leads to facilitated processing of its meaning. For example, we
can decide faster whether an object is living or non-living if we saw it
recently.

325

KEY TERMS Perceptual priming A form of priming in which repeated
presentations of a stimulus facilitates its perceptual processing.
Conceptual priming A form of priming in which there is facilitated
processing of stimulus meaning.

326

Memory

There are important differences between perceptual priming and
conceptual priming. Gong et al. (2016) found patients with frontal lobe
damage performed poorly on conceptual priming but had intact perceptual
priming. In contrast, patients with occipital lobe damage (an area
associated with visual processing) had intact conceptual priming but
impaired perceptual priming. If repetition priming involves
non-declarative memory, amnesic patients should show intact repetition
priming. This prediction has much support. For example, Cermak et
al. (1985) found amnesic patients had comparable perceptual priming to
controls. However, patients sometimes exhibit a modest priming
impairment. Levy et al. (2004) studied conceptual priming: deciding
whether words previously studied (vs not studied) belonged to given
categories. Two male amnesic patients (EP and GP) with large lesions in
the medial temporal lobes had intact conceptual priming to healthy
controls, but they performed much worse than controls on recognition
memory (involving declarative memory). Much additional research was
carried out on EP, who had extensive damage to the perirhinal cortex
(BA35 and BA36) plus other regions within the medial temporal lobe
(Insausti et al., 2013). His long-term declarative memory was massively
impaired. For example, he had very poor ability to identify names, words
and faces that became familiar only after amnesia onset. However, EP's
performance was intact on non-declarative tasks (e.g., perceptual
priming; visuo-motor skill learning; see Figure 7.12). His performance
was at chance level on recognition memory but as good as that of healthy
controls on perceptual priming. Schacter and Church (1995) reported
further evidence amnesic patients have intact perceptual priming.
Participants initially heard words all spoken in the same voice and then
identified the same words passed through an auditory filter. There was
priming because identification performance was better when the words
were spoken in the same voice as initially. The notion that priming
depends on memory systems different from those involved in declarative
memory would be strengthened if we found patients having intact
declarative memory but impaired priming. This would provide a double
dissociation when considered together with amnesics having intact
priming but impaired declarative memory. Gabrieli et al. (1995) studied
a patient, MS with damage to the right occipital lobe. MS had intact
performance on recognition and cued recall (declarFigure 7.12 ative
memory) but impaired performance on Percentages of priming effect
(left-hand side) and recognitionperceptual priming. This latter finding
is conmemory performance of healthy controls (CON) and sistent with
findings reported by Gong et al. patients (EP). (2016) in patients with
occipital lobe damage From Insausti et al. (2013). © National Academy of
Sciences. Reproduced with permission. (discussed earlier).

Long-term memory systems

The above picture is too neat-and-tidy. Like Schacter and Church (1995),
Schacter et al. (1995) studied perceptual priming based on auditory word
identification. However, the words were initially presented in six
different voices. On the word-identification test, half were presented
in the same voice as initially and the other half were spoken by one of
the other voices (re-paired condition). Healthy controls (but not
amnesic patients) had more priming for words presented in the same
voice. How can we explain these findings? In both conditions,
participants were exposed to words and voices previously heard. The only
advantage in the same voice condition was that the pairing of word and
voice was the same as before. However, only those participants who had
linked or associated words and voices at the original presentation would
have benefited from the repeated pairings. Thus, amnesics are poor at
binding together different kinds of information even on priming tasks
apparently involving non-declarative memory (see later discussion
pp. 333--336). Related findings were obtained by Race et al. (2019).
Amnesic patients had intact repetition priming when the task involved
relatively simple associative learning. However, their repetition
priming was impaired when the task involved more complex and abstract
associative learning. Race et al. concluded "These results highlight the
multiple, distinct cognitive and neural mechanisms that support
repletion priming" (p. 102).

Priming processes What processes are involved in priming? A popular view
is based on perceptual fluency: repeated presentation of a stimulus
means it can be processed more efficiently using fewer resources. This
view is supported by the frequent finding that brain activity decreases
with stimulus repetition: this is repetition suppression. However, this
finding on its own does not demonstrate a causal link between repetition
suppression and priming. Wig et al. (2005) reported more direct evidence
using transcranial magnetic stimulation to disrupt processing. TMS
abolished repetition suppression and conceptual priming suggesting that
repetition suppression was necessary for conceptual priming. Stimulus
repetition is sometimes associated with repetition enhancement involving
increased brain activity with stimulus repetition. de Gardelle et
al. (2013) presented repeated faces and found evidence of both stimulus
suppression and stimulus enhancement. What determines whether there is
repetition suppression or enhancement? Ferrari et al. (2017b) presented
participants with repeated neutral and emotional scenes. Repetition
suppression was found when scenes were repeated many times in rapid
succession, probably reflecting increased perceptual fluency. In
contrast, repetition enhancement was found when repetitions were spaced
out in time. This was probably due to spontaneous retrieval of
previously presented stimuli. Kim (2017a) reported a meta-analysis of
studies on repetition suppression and enhancement in repetition priming
(see Figure 7.13). There were two main findings. First, repetition
suppression was associated with reduced activation in the ventromedial
prefrontal cortex and related areas, suggesting it reflected reduced
encoding of repeated stimuli.

327

KEY TERMS Repetition suppression The finding that stimulus repetition
often leads to reduced brain activity (typically with enhanced
performance via priming). Repetition enhancement The finding that
stimulus repetition sometimes leads to increased brain activity.

328

Memory

Figure 7.13 Brain regions showing repetition suppression (RS; orange
colour) or response enhancement (RE; blue colour) in a meta-analysis.
From Kim (2017a).

Second, repetition enhancement was associated with increased activation
in dorsolateral prefrontal cortex and related areas. According to Kim
(2017a, p. 1894), "The mechanism for repetition enhancement is . . .
explicit retrieval during an implicit memory task." Thus, explicit or
declarative memory is sometimes involved in allegedly non-declarative
priming tasks. In sum, progress has been made in understanding the
processes underlying priming. Of importance is suggestive evidence that
priming sometimes involves declarative as well as non-declarative memory
(Kim, 2017). The mechanisms involved in repetition suppression and
priming are still not fully understood. However, these effects depend on
complex interactions among the time interval between successive stimuli,
the task and the allocation of attention (Kovacs & Schweinberger, 2016).

Procedural memory or skill learning Motor skills are important in
everyday life -- examples include word processing, writing, playing
netball and playing a musical instrument. Skill learning or procedural
memory includes sequence learning, mirror tracing (tracing a figure seen
in a mirror), perceptual skill learning, mirror reading (reading a text
seen in a mirror) and artificial grammar learning (Foerde & Poldrack,
2009; see Chapter 6). However, although these tasks are all categorised
as skill learning, they differ in terms of the precise cognitive
processes involved. Here we consider whether the above tasks involve
non-declarative or procedural memory and thus involve different memory
systems from those underlying episodic and semantic memory. We will
consider skill learning in amnesic patients. If they have essentially
intact skill learning but severely impaired declarative memory, that
would provide evidence that different memory systems are involved.
Before considering the relevant evidence, we address an important
general issue. It is sometimes incorrectly assumed any given task is
always

Long-term memory systems

performed using non-declarative or declarative memory. Consider the
weather-prediction task where participants use various cues to predict
whether the weather will be sunny or rainy. Reber et al. (1996) found
amnesics learned this task as rapidly as healthy controls, suggesting it
involves procedural (non-declarative) memory. However, Rustemeier et al.
(2013) found 61% of participants used a non-declarative strategy
throughout learning but 12% used a declarative strategy throughout. In
addition, 27% shifted from an early declarative to a later declarative
strategy.

Findings Amnesics often have essentially intact skill learning on
numerous skill-learning tasks. For example, using the pursuit rotor
(manual tracking of a moving target), Tranel et al. (1994) found that 28
amnesic patients had intact learning. Even a patient (Boswell) with
unusually extensive brain damage to brain areas strongly associated with
declarative memory had intact learning. Much research has used the
serial reaction time task (see Glossary). As discussed in Chapter 6,
amnesics' performance on this task is typically reasonably intact. It is
somewhat hard to interpret the findings because performance on this task
by healthy controls often involves some consciously accessible knowledge
(Gaillard et al., 2009). Spiers et al. (2001) considered the
non-declarative memory performance of 147 amnesic patients. All showed
intact performance on tasks involving priming and learning skills or
habits. However, as mentioned earlier, some studies have shown modest
impairment in amnesic patients (Oudman et al., 2015). In addition,
amnesics' procedural memory has important limitations: "\[Amnesic
patients\] typically do not remember how or where information was
obtained, nor can they flexibly use the acquired information. The
knowledge therefore lacks a . . . context" (Clark & Maguire, 2016,
p. 68). Most tasks assessing skill learning in amnesics require learning
far removed from everyday life. However, Cavaco et al. (2004) used five
skill-learning tasks (e.g., a weaving task) involving real-world skills.
Amnesic patients showed comparable learning to healthy controls despite
significantly impaired declarative memory for the same tasks. Anderson
et al. (2007) studied the motor skill of car driving in two severely
amnesic patients. Their steering, speed control, safety errors and
driving with distraction were intact. Finally, we discuss patients with
Parkinson's disease (see Glossary). These patients have damage to the
striatum (see Glossary), which is of greater importance to
non-declarative learning than declarative learning. As predicted,
Parkinson's patients typically have severely impaired nondeclarative
learning and memory (see Chapter 6). For example, Kemeny et al. (2018)
found on the serial reaction time task that Parkinson's patients showed
practically no evidence of learning (see Figure 7.14). However,
Parkinson's patients sometimes have relatively intact episodic memory.
For example, Pirogovsky-Turk et al. (2015) found normal performance by
Parkinson's patients on measures of free recall, cued recall and
recognition memory. These findings strengthen the case for a distinction
between declarative and non-declarative memory.

329

Memory

Figure 7.14 Mean reaction times on the serial reaction time task by
Parkinson's disease patients (PD) and healthy controls (HC).

1,150 1,100 1,050 Mean RTs (ms)

1,000 950 900 850 800 750 2R

1

k1

0

k1

oc

oc

k1

Bl

k9

k8

oc

oc Bl

Bl

HC

Bl

oc

k7

Bl

oc

k6

PD

Bl

oc

k5

Bl

k4

oc Bl

oc

k3

Bl

oc

k2

Bl

oc

oc

k1

700 Bl

From Kemeny et al. (2018).

1,200

Bl

330

Other research complicates the picture. First, Parkinson's patients
(especially as the disease progresses) often have damage to brain areas
associated with episodic memory. Das et al. (2019) found impairments in
recognition memory (a form of episodic memory) among Parkinson's
patients were related to damage within the hippocampus (of central
importance in episodic memory). Many Parkinson's patients also have
problems with attention and executive functions (Roussel et al., 2017).
Bezdicek et al. (2019) found impaired episodic memory in Parkinson's
patients was related to reduced functioning of brain areas associated
with attention and executive functions as well as reduced hippocampal
functioning. Second, there are individual differences in the strategies
used on many tasks (e.g., weather-prediction task discussed earlier).
Kemeny et al. (2018) found Parkinson's patients and healthy controls had
comparable performance on the weather-prediction task. However, most
Parkinson's patients used a much simpler strategy than healthy controls.
Thus, the patients' processing was affected by the disease although this
was not apparent from their overall performance.

Interacting systems A central theme of this chapter is that traditional
theoretical views are oversimplified (see next section pp. 332--340).
For example, skill learning often involves brain circuitry including the
hippocampus (traditionally associated exclusively with episodic memory).
Döhring et al. (2017) studied patients with transient global amnesia who
had dysfunction of the hippocampus lasting for several hours. This
caused profound deficits in declarative memory but also reduced learning
on a motor learning task involving finger sequence tapping. Thus,
optimal motor learning can require interactions of the procedural and
declarative memory systems. Albouy et al. (2013) discussed research on
motor sequence learning (skill learning). The hippocampus (centrally
involved in the formation of

Long-term memory systems

declarative memories) played a major role in the acquisition and storage
of procedural memories and there were numerous interactions between
hippocampal-cortical and striato-cortical systems. Doyon et al. (2018)
reviewed changes during motor sequence learning. Early learning mainly
involved striatal regions in conjunction with prefrontal and premotor
cortical regions. The contribution of the striatum and motor cortical
regions increases progressively during later learning. These findings
suggest procedural learning is dominant later in learning but that
declarative memory plays a part early in learning. Similar findings are
discussed by Beukema and Verstynen (2018) (see p. 276).

How different are priming and skill learning? Priming and skill learning
are both forms of non-declarative memory. However, as Squire and Dede
(2015, p. 2) pointed out, "Non-declarative memory is an umbrella term
referring to multiple forms of memory." Thus, we might expect to find
differences between priming and skill learning. As mentioned earlier,
priming generally occurs more rapidly and the learning associated with
priming is typically less flexible. If priming and skill learning
involve different processes, we would not necessarily expect individuals
good at skill learning to also be good at priming. Schwartz and
Hashtroudi (1991) found no correlation between performance on a priming
task (word identification) and a skill-learning task (inverted text
reading). Findings based on neuroimaging or on brain-damaged patients
might clarify the relationship between priming and skill learning.
Squire and Dede (2015) argued the striatum is especially important in
skill learning whereas the neocortex (including the prefrontal cortex)
is of major importance in priming. Some evidence (including research
discussed above) is supportive of Squire and Dede's (2015) viewpoint.
However, other research is less supportive. Osman et al. (2008) found
Parkinson's patients had intact procedural learning when learning about
and controlling a complex system (e.g., water-tank system). This
suggests the striatum is not needed for all forms of skill learning.
Gong et al. (2016; discussed earlier, p. 326) found patients with
frontal damage nevertheless had intact perceptual priming. The wide
range of tasks used to assess priming and skill learning means numerous
brain regions are sometimes activated on both kinds of tasks. We start
with skill learning. Penhune and Steele (2012; see Chapter 6) proposed a
theory assuming skill learning involves several brain areas including
the primary motor cortex, cerebellum and striatum. So far as priming is
concerned, Segaert et al. (2013) reviewed 29 neuroimaging studies and
concluded that "Repetition enhancement effects have been found all over
the brain" (p. 60).

Evaluation Much evidence suggests priming and skill learning are forms
of nondeclarative memory involving different processes and brain areas
from those involved in declarative memory. There is limited evidence of
a double

331

332

Memory

dissociation: amnesic patients often exhibit reasonably intact priming
and skill learning but severely impaired declarative memory. In
contrast, Parkinson's patients (especially in the early stages of the
disease) sometimes have intact declarative memory but impaired
procedural memory. What are the main limitations of research in this
area? (1)

(2) 
(3) 
(4) 

There is considerable flexibility in the processes used on many memory
tasks. As a result, it is often an oversimplification to describe a task
as involving only "non-declarative memory". Numerous tasks have been
used to assess priming and skill learning. More attention needs to be
paid to differences among tasks in the precise cognitive processes
involved. There should be more emphasis on brain networks rather than
specific brain areas. For example, motor sequence learning involves a
striato-cortical system rather than simply the striatum. In addition,
this system interacts with a hippocampal-cortical system (Albouy et al.,
2013). The findings from Parkinson's patients are mixed and
inconsistent. Why is this? As the disease progresses, brain damage in
such patients typically moves beyond brain areas involved in
non-declarative memory (e.g., the striatum) to areas involved in
declarative memory (e.g., the hippocampus and prefrontal areas).

BEYOND MEMORY SYSTEMS AND DECLARATIVE VS NON-DECLARATIVE MEMORY Until
relatively recently, most memory researchers argued the distinction
between declarative/explicit and non-declarative/implicit memory was of
major theoretical importance. According to this traditional approach, a
crucial difference between memory systems is whether they support
conscious access to stored information (see Figure 7.2). It was also
often assumed that only memory systems involving conscious access depend
heavily on the medial temporal lobe (especially the hippocampus). The
traditional approach has proved extremely successful -- consider all the
accurate predictions it made with respect to the research discussed
earlier. However, its major assumptions are oversimplified and more
complex theories are required.

Explicit vs implicit memory If the major dividing line in long-term
memory is between declarative (explicit) and non-declarative (implicit)
memory, it is important to devise tasks involving only one type of
memory. This sounds easy: declarative memory is involved when
participants are instructed to remember previously presented information
but not otherwise. Reality is more complex. Consider the word-completion
task. Participants are presented with a word list. Subsequently, they
perform an apparently unrelated task: word fragments (e.g., STR
\_\_\_\_\_ ) are presented and they produce a word starting with those
letters. Implicit memory is revealed by the extent to which their word
completions match list words. Since the instructions make no reference
to recall, this task is apparently

Long-term memory systems

an implicit/non-declarative task. However, participants who become aware
of the connection between the word list and the word-completion task
perform better than those who do not (Mace, 2003). Hippocampal
activation is generally associated with declarative memory whereas
activity of the striatum is associated with non-declarative memory.
However, Sadeh et al. (2011) obtained more complex findings. Effective
learning on an episodic memory task was associated with interactive
activity between the hippocampus and striatum. Following a familiar
route also often involves complex interactions between the hippocampus
and striatum with declarative memory assisting in the guidance of
ongoing actions retrieved from non-declarative memory (Goodroe et al.,
2018). The involvement of declarative/explicit memory and
non-declarative/ implicit memory on any given task sometimes changes
during the course of learning and/or there are individual differences in
use of the two forms of memory. Consider the acquisition of sequential
motor skills. There is often a shift from an early reliance on explicit
processes to a later reliance on implicit processes (Beukema &
Verstynen, 2018; see Chapter 6). Lawson et al. (2017) reported
individual differences during learning on the serial reaction time task
(see Chapter 6). Some learners appeared to rely solely on implicit
processes whereas others also used explicit processes.

Henke's processing-based theoretical account Several theories differing
substantially from the traditional theoretical approach have been
proposed. For example, compare Henke's (2010) processing-based model
(see Figure 7.15) against the traditional model (see Figure 7.2).
Henke's model differs crucially in that "Consciousness of encoding and
retrieval does not select for memory systems and hence does not feature
in this model" (p. 528). Another striking difference relates to
declarative memory. In the traditional model, all declarative memory
(episodic plus semantic memory) depends on the medial temporal lobes
(especially the hippocampus) and the diencephalon. In Henke's model, in
contrast, episodic memory depends on the hippocampus and neocortex,
semantic memory can involve brain areas outside the hippocampus, and
familiarity in recognition memory depends on the parahippocampal gyrus
and neocortex (and also the perirhinal cortex). Figure 7.15 is
oversimplified. Henke (2010) argued semantic knowledge can be learned in
two different ways: one way is indicated in the figure but the other way
"uses the hippocampus and involves episodic memory formation" (p. 528).
The assumption that semantic memory need not depend on the hippocampus
helps to explain why amnesic patients' semantic memory is generally less
impaired than their episodic memory (Spiers et al., 2001). There are
three basic processing modes in Henke's (2010) model: (1)

Rapid encoding of flexible associations: this involves episodic memory
and depends on the hippocampus. It is also assumed semantic memory often
involves the hippocampus.

333

Research activity: Word-stem completion task

334

Memory

Figure 7.15 A processing-based memory model. There are three basic
processing modes: (1) rapid encoding of flexible associations; (2) slow
encoding of rigid associations; and (3) rapid encoding of single or
unitised items formed into a single unit. The brain areas associated
with each of these processing modes are indicated towards the bottom of
the figure. From Henke (2010). Reproduced with permission from Nature
Publishing Group.

(2) 
(3) 

Slow encoding of rigid associations: this involves procedural memory,
semantic memory and classical conditioning, and depends on the basal
ganglia (e.g., the striatum) and cerebellum. Rapid encoding of single or
unitised items (formed into a single unit): this involves priming and
familiarity in recognition memory and depends on the parahippocampal
gyrus.

Many predictions are common to Henke's (2010) model and the traditional
model. For example, amnesic patients with hippocampal damage should have
generally poor episodic memory but intact procedural memory and priming.
However, the two models make different predictions: (1)

(2) 

Henke's (2010) model predicts that amnesic patients with hippocampal
damage should have severe impairments of episodic memory (and semantic
memory) for flexible relational associations but not for single or
unitised items. In contrast, according to the traditional model, amnesic
patients should have impaired episodic and semantic memory for single or
unitised items as well as for flexible relational associations. Henke's
(2010) model predicts the hippocampus is involved in the encoding of
flexible associations with unconscious and conscious

Long-term memory systems

(3) 

learning. In contrast, the traditional model assumes the hippocampus is
involved only in conscious learning. Henke's model predicts the
hippocampus is not directly involved in familiarity judgements in
recognition memory. In contrast, the traditional model assumes all forms
of episodic memory depend on the hippocampus.

Findings We start with the first prediction above as it applies to
episodic memory. Quamme et al. (2007) studied recognition memory for
word pairs (e.g., CLOUD--LAWN). In the key condition, each word pair was
unitised (e.g., CLOUD-LAWN was interpreted as a lawn used for viewing
clouds). Amnesic patients with hippocampal damage had a much smaller
recognition-memory deficit when the word pairs were unitised than when
they were not. Olson et al. (2015) presented faces with a fixed or
variable viewpoint followed by a recognition-memory test. It was assumed
flexible associations would be formed only in the variable-viewpoint
condition. As predicted, a female amnesic (HC) had intact performance
only in the fixed-viewpoint condition (see Figure 7.16). Research by
Blumenthal et al. (2017; discussed earlier, p. 302) on semantic memory
is also relevant to the first prediction. An amnesic patient with
hippocampal damage had impaired semantic memory performance when it
depended on having formed relational associations. However, her semantic
memory performance was intact when relational associations were not
required. Support for the second prediction was reported by Duss et
al. (2014). Unrelated word pairs (e.g., violin--lemon) were presented
subliminally to amnesic patients and healthy controls. The amnesic
patients had significantly poorer relational or associative encoding and
retrieval than the controls. However, their encoding (and retrieval) of
information about single

Corrected recognition

0.7 0.6 0.5 0.4

Controls ﬁxed HC ﬁxed Controls variable HC variable

0.3 0.2 0.1 0.0 Repeated

Novel

Tested viewpoint

Figure 7.16 Recognition memory for faces presented in a fixed or
variable viewpoint and tested in a fixed or variable viewpoint; HC is a
female amnesic patient. From Olson et al. (2015).

335

336

Memory

words (e.g., angler) was comparable to controls. Only the relational
task involved hippocampal activation. Hannula and Greene (2012)
discussed several studies showing associative or relational learning can
occur without conscious awareness. Of most relevance here, however, is
whether the hippocampus is activated during non-conscious encoding and
retrieval. Henke et al. (2003) presented participants with
task--occupation pairs below the level of conscious awareness. There was
hippocampal activation during nonconscious encoding of the
face--occupation pairs. There was also hippocampal activation during
non-conscious retrieval of occupations associated with faces. Finally,
we turn to Henke's third prediction, namely, that the hippocampus is not
required for familiarity judgements in recognition memory. If so, we
might predict amnesic patients should have intact familiarity
judgements. As predicted, amnesics have intact recognition memory
(including familiarity judgements) for unfamiliar faces (Bird, 2017;
discussed earlier, p. 308). However, the findings with unfamiliar faces
are unusual because patients generally have only reasonably (but not
totally) intact familiarity judgements for other types of material
(Bird, 2017; Bowles et al., 2010; Skinner & Femandes, 2007) (discussed
earlier, pp. 307--308). However, these findings may not be inconsistent
with Henke's (2010) model because amnesics' brain damage often extends
beyond the hippocampus to areas associated with familiarity (perirhinal
cortex). A male amnesic patient (KN) with hippocampal damage but no
perirhinal damage had intact familiarity performance (Aggleton et al.,
2005). As shown in Figure 7.15, Henke (2010) assumed that familiarity
judgements depend on activation in brain areas also involved in priming.
As predicted, Thakral et al. (2016) found similar brain areas were
associated with familiarity and priming, suggesting they both involve
similar processes.

Evaluation Henke's (2010) model with its emphasis on memory processes
rather than memory systems is an advance. We have considered several
examples where predictions from her model have proved superior to
predictions from the traditional approach. What are the model's
limitations? First, more research and theorising are needed to clarify
the role of consciousness in memory. Conscious awareness is associated
with integrated processing across several brain areas (Chapter 16) and
so is likely to enhance learning and memory. However, how this happens
is not specified. Second, the model resembles a framework rather than a
model. For example, it is assumed the acquisition of semantic memories
is sometimes closely related to episodic memory. However, we cannot make
precise predictions unless we know the precise conditions determining
when this is the case and how processes associated with semantic and
episodic memory interact. Third, the model does not consider the brain
networks associated with different types of memory (see below).

Long-term memory systems

337

Does each memory system depend on a few brain areas? According to the
traditional theoretical approach (see Figure 7.2), each memory system
depends on only a few key brain areas (a similar assumption was made by
Henke, 2010). Nowadays, however, it is generally assumed each type of
memory involves several brain areas forming one or more networks. How
can we explain the above theoretical shift? Early memory research relied
heavily on findings from brain-damaged patients. Such findings (while
valuable) are limited. They can indicate a given brain area is of major
importance. However, neuroimaging research allows us to identify all
brain areas associated with a given type of memory. Examples of the
traditional approach's limitations are discussed below. First, it was
assumed that episodic memory depends primarily on the medial temporal
lobe (especially the hippocampus). Neuroimaging research indicates that
several other brain areas interconnected with the medial temporal lobe
are also involved. In a review, Bastin et al. (2019) concluded there is
a general recollection network specific to episodic memory including the
inferior parietal cortex, the medial prefrontal cortex and the posterior
cingulate cortex. Kim and Voss (2019) assessed brain activity during the
formation of episodic memories. They discovered that activation within
large brain networks predicted subsequent recognition-memory performance
(see Figure 7.17). Why did activation in certain areas predict lower
recognition-memory performance? The most important reason is that such
activation often reflects various kinds of task-irrelevant processing.
Task-positive Second, in the traditional approach (and Henke's, 2010,
model), autobiographical memories were regarded simply as Task-negative
a form of episodic memory. However, the retrieval of autobiographical
memories often involves more brain networks than the retrieval of simple
episodic memories. As is shown Figure 7.17 in Figure 8.7, retrieval of
autobiographical memories involves Brain areas whose activity during the
fronto-parietal network, the cingulo-operculum network, the episodic
learning predicted increased medial prefrontal cortex network and the
medial temporal lobe recognition-memory performance network. Only the
last of these networks is emphasised within the (task-positive; in red)
or decreased performance (task-negative; in blue). traditional approach
(and Henke's model). Third, more brain areas are associated with
semantic From Kim & Voss (2019). memory than the medial temporal lobes
emphasised in the traditional model. In a meta-analysis, Binder et
al. (2009) identified a lefthemisphere network consisting of seven
regions including the middle temporal gyrus, dorsomedial prefrontal
cortex and ventromedial prefrontal cortex. Fourth, it was assumed within
the traditional approach that priming involves the neocortex. In fact,
what is involved is more complex. Kim (2017a; discussed earlier,
pp. 327--328) found in a meta-analysis that priming is associated with
reduced activation in the fronto-parietal control

338

Memory

network and the dorsal attention network but increased activation in the
dorsolateral prefrontal cortex and related areas.

Are memory systems independent? A key feature of the traditional
theoretical approach (see Figure 7.2) was the assumption that each
memory system operates independently. As a consequence, any given memory
task should typically involve only a single memory system. This
assumption is an oversimplification. As Ferbinteanu (2019, p. 74)
pointed out, "The lab conditions, where experiments are carefully
designed to target specific types of memories, most likely do not
universally apply in natural settings where different types of memories
combine in fluid and complex manners to guide behaviour." First,
consider episodic and semantic memory. Earlier we considered cases where
episodic and semantic memory were both involved. For example, people
answering questions about repeated personal events (e.g., "Have you
drunk coffee while shopping?") rely on both episodic and semantic memory
(Renoult et al., 2016). Second, consider skill learning and memory.
Traditionally, it was assumed that skill learning depends primarily on
implicit processes. However, as we saw earlier, explicit processes are
often involved early in learning processes (Beukema & Verstynen, 2018;
see Chapter 6).

Component-process models The traditional theoretical model is too neat
and tidy: it assumes the nature of any given memory task rigidly
determines the processes used. We need a theoretical approach assuming
that memory processes are much more flexible than assumed within the
traditional model (or Henke's model). Dew and Cabeza (2011) proposed
such an approach (see Figure 7.18). Five brain areas were identified
varying along three dimensions: (1) (2) (3)

cognitive process: perceptually or conceptually driven; stimulus
representation: item or relational; level of intention: controlled
vs. automatic.

This approach is based on two major assumptions, which differ from those
of previous approaches. First, there is considerable flexibility in the
combination of processes (and associated brain areas) involved in the
performance of any memory task. Second, "The brain regions operative
during explicit or implicit memory do not divide on consciousness per
se" (Dew & Cabeza, 2011, p. 185). Cabeza et al. (2018) proposed a
component-process model resembling that of Dew and Cabeza (2011). This
model assumes that processing is very flexible and depends heavily on
process-specific alliances (PSAs) or mininetworks. According to Cabeza
et al., "A PSA is a small team of brain regions that rapidly assemble to
mediate a cognitive process in response to task demands but quickly
disassemble when the process is no longer needed . . . PSAs are
flexible, temporary, and opportunistic" (p. 996).

Long-term memory systems

Ferbinteanu (2019) proposed a dynamic network model based on very
similar assumptions. A major motivation for this theoretical approach
was neuroimaging evidence. Here is an example involving the left angular
gyrus in the parietal lobe. This region is involved in both the
recollection of episodic memories and numerous tasks requiring semantic
processing (see Figure 7.19). Moscovitch et al. (2016) pointed out that
the hippocampus's connections to several other brain areas (e.g., those
involved in visual perception) suggests it is not only involved in
episodic memory. Consider research on boundary extension: "the . . .
tendency to reconstruct a scene with a larger background than actually
was presented" (Moscovitch et al., 2016, p. 121). Boundary extension is
accompanied by hippocampal activation and is greatly reduced in amnesic
patients with hippocampal damage. McCormick et al. (2018) reviewed
research on patients with damage to the hippocampus. Such patients
mostly showed decreased future thinking and impaired scene construction,
navigation and moral decision-making as well as impaired episodic
memory. McCormick et al. also reviewed research on patients with damage
to the ventromedial prefrontal cortex (centrally involved in schema
processing in semantic memory), which is also connected to several other
brain areas. Such patients had decreased future thinking and impaired
scene construction, navigation and emotion regulation.

Evaluation

339

Figure 7.18 A three-dimensional model of memory: (1) conceptually or
perceptually driven; (2) relational or item stimulus representation; (3)
controlled or automatic/involuntary intention. The brain areas are the
visual cortex (Vis Ctx), parahippocampal cortex (PHC), hippocampus
(Hipp), rhinal cortex (RhC) and left ventrolateral prefrontal cortex (L
VL PFC). From Dew and Cabeza (2011). © 2011 New York Academy of
Sciences. Reprinted with permission of Wiley & Sons.

Example PSAs including L-AG Episodic recollection

Semantic processing

AG AG

vATL HC

Figure 7.19 Process-specific alliances including the left angular gyrus
(L-AG) are involved in recollection of episodic memories (left-hand
side) and semantic processing (right-hand side).

The component-process approach has several strengths. First, there is
compelling evidence that processes associated with From Cabeza et
al. (2018). different memory systems combine very flexibly on numerous
memory tasks. This flexibility depends on the precise task demands
(e.g., processes necessary early in learning may be less so
subsequently) and on individual differences in learning/memory skills
and previous knowledge. In other words, we use whatever processes (and
associated brain areas) are most useful for the current learning or
memory task.

340

Memory

KEY TERM

Second, this approach is more consistent with the neuroimaging evidence
than previous approaches. It can account for the fact that many more
brain areas are typically active during most memory tasks than expected
from the traditional approach. Third, the component-process approach has
encouraged researchers to abandon the traditional approach of studying
memory as an isolated mental function. For example, processes associated
with episodic memory are also involved in scene construction, aspects of
decision-making, navigation, imagining the future and empathy (McCormick
et al., 2018; Moscovitch et al., 2016). More generally, "The border
between memory and perception/action has become more blurred"
(Ferbinteanu, 2019, p. 74). What are the limitations of the
component-process approach? First, it does not provide a detailed model.
This makes it hard to make specific predictions concerning the precise
combination of processes individuals will use on any given memory task.
Second, our ability to create process-specific alliances rapidly and
efficiently undoubtedly depends on our previous experiences and various
forms of learning (Ferbinteanu, 2019). However, the nature of such
learning remains unclear. Third, as Moscovitch et al. (2016, p. 125)
pointed out, "Given that PSAs are rapidly assembled and disassembled,
they require a mechanism that can quickly control communication between
distant brain regions." Moscovitch et al. argued the prefrontal cortex
is centrally involved, but we have very limited evidence concerning its
functioning. Fourth, process-specific alliances are typically
mini-networks involving two or three brain regions. However, as we have
seen, some research has suggested the involvement of larger brain
networks consisting of numerous brain regions (e.g., Kim & Voss, 2019).
The optimal network size for explaining learning and memory remains
unclear.

Boundary extension Misremembering a scene as having a larger surround
area than was actually the case.

CHAPTER SUMMARY •

Introduction. The notion there are several memory systems is very
influential. Within that approach, the crucial distinction is between
declarative memory (involving conscious recollection) and nondeclarative
memory (not involving conscious recollection). This distinction has
received strong support from amnesic patients with severely impaired
declarative memory but almost intact nondeclarative memory. Declarative
memory is divided into semantic and episodic/autobiographical memory,
whereas non-declarative memory is divided into priming and skill
learning or procedural memory.

•

Declarative memory. Evidence from patients supports the distinction
between episodic and semantic memory. Amnesic patients with damage to
the medial temporal lobes including the hippocampus typically have more
extensive impairment of episodic than semantic memory. In contrast,
patients with semantic dementia (involving damage to the anterior
temporal lobes) have

Long-term memory systems

more extensive impairment of semantic than episodic memory. However, a
complicating factor is that many memory tasks involve combining episodic
and semantic memory processes. Another complicating factor is
semanticisation (transformation of episodic memories into semantic ones
over time): perceptual details within episodic memory are lost over time
and there is increased reliance on gist and schematic information within
semantic memory. •

Episodic memory. Episodic memory is often assessed by recognition tests.
Recognition memory can involve familiarity or recollection. Evidence
supports the binding-of-item-and-context model: familiarity judgements
depend on perirhinal cortex whereas recollection judgements depend on
binding what and where information in the hippocampus. In similar
fashion, free recall can involve familiarity or recollection with the
latter being associated with better recall of contextual information.
Episodic memory is basically constructive rather than reproductive, and
so we remember mostly the gist of our past experiences. Constructive
processes associated with episodic memory are used to imagine future
events. However, imaging future events relies more heavily on semantic
memory than does recalling past events. Episodic memory is also used in
divergent creative thinking.

•

Semantic memory. Most objects can be described at the superordinate,
basic and subordinate levels. Basic level categories are typically used
in everyday life. However, categorisation is often faster at the
superordinate level than the basic level because less information
processing is required. According to Barsalou's situated simulation
theory, concept processing involves perceptual and motor information.
However, it is unclear whether perceptual and motor information are both
necessary and sufficient for concept understanding (e.g., patients with
damage to the motor system can understand action-related words).
Concepts have an abstract central core of meaning de-emphasised by
Barsalou. According to the hub-and-spoke model, concepts consist of hubs
(unified abstract representations) and spokes (modalityspecific
information). The existence of patients with categoryspecific deficits
supports the notion of spokes. Evidence from patients with semantic
dementia indicates hubs are stored in the anterior temporal lobes. It is
unclear how information from hubs and spokes is combined and integrated.
Schemas are stored in semantic memory with the ventromedial prefrontal
cortex being especially involved in schema processing. Patients with
damage to that brain area often have greater impairments in schema
knowledge than concept knowledge. In contrast, patients with semantic
dementia (damage to the anterior temporal lobes) have greater
impairments in concept knowledge than schema knowledge. Thus, there is
some evidence for a double dissociation.

341

342

Memory

•

Non-declarative memory. Priming is tied to specific stimuli and occurs
rapidly. Priming often depends on enhanced neural efficiency shown by
repetition suppression of brain activity. Skill learning occurs slowly
and generalises to stimuli not presented during learning. Amnesic
patients (with hippocampal damage) typically have fairly intact
performance on priming and skill learning but severely impaired
declarative memory. In contrast, Parkinson's patients (with striatal
damage) exhibit the opposite pattern. Amnesic and Parkinson's patients
provide only an approximate double dissociation. Complications arise
because some tasks can be performed using either declarative or
non-declarative memory, because different memory systems sometimes
interact during learning, and because non-declarative learning often
involves networks consisting of several brain areas.

•

Beyond memory systems and declarative vs non-declarative memory. The
traditional emphasis on the distinction between declarative and
non-declarative memory is oversimplified. It does not fully explain
amnesics' memory deficits and exaggerates the relevance of whether
processing is conscious or not. Henke's model (with its emphasis on
processes rather than memory systems) provides an account that is
superior to the traditional approach. According to the component-process
model, memory involves numerous brain areas and processes used in
flexible combinations rather than a much smaller number of rigid memory
systems. This model has great potential. However, it is hard to make
specific predictions about the combinations of processes individuals
will use on any given memory task.

FURTHER READING Baddeley, A.D., Eysenck, M.W. & Anderson, M.C. (2020).
Memory (3rd edn). Abingdon, Oxon.: Psychology Press. Several chapters
are of direct relevance to the topics covered in this chapter. Bastin,
C., Besson, G., Simon, J., Delhaye, E., Geurten, M., Willems, S.,
(2019). An integrative memory model of recollection and familiarity to
understand memory deficits. Behavioral and Brain Sciences, 1--66 (epub:
5 February 2019). Christine Bastin and colleagues provide a
comprehensive theoretical account of episodic memory. Cabeza, R.,
Stanley, M.L. & Moscovitch, M. (2018). Process-specific alliances (PSAs)
in cognitive neuroscience. Trends in Cognitive Sciences, 22, 996--1010.
Roberto Cabeza and colleagues how cognitive processes (including memory)
depend on flexible interactions among brain regions. Ferbinteanu, J.
(2019). Memory systems 2018 -- Towards a new paradigm. Neurobiology of
Learning and Memory, 157, 61--78. Janina Ferbinteanu discusses recent
theoretical developments in our understanding of memory systems. Kim, H.
(2017). Brain regions that show repetition suppression and enhancement:
A meta-analysis of 137 neuroimaging experiments. Human Brain Mapping,
38, 1894--1913. Hongkeun Kim discusses the processes underlying
repetition priming with reference to a meta-analysis of the relevant
brain areas.

Long-term memory systems Lambon Ralph, M.A., Jefferies, E., Patterson,
K. & Rogers, T.T. (2017). The neural and computational bases of semantic
cognition. Nature Reviews Neuroscience, 18, 42--55. Our current
knowledge and understanding of semantic memory are discussed in the
context of the hub-and-spoke model. Verfaillie, M. & Keane, M.M. (2017).
Neuropsychological investigations of human amnesia: Insights into the
role of the medial temporal lobes in cognition. Journal of the
International Neuropsychological Society, 23, 732--740. Research on
amnesia and memory is discussed in detail in this article. Yee, E.,
Jones, M.N. & McRae, K. (2018). Semantic memory. In S.L. ThompsonSchill
& J.T. Wixted (eds), Stevens' Handbook of Experimental Psychology and
Cognitive Neuroscience, Vol. 3: Language and Thought: Developmental and
social psychology (4th edn; pp. 319--356). New York: Wiley. This chapter
provides a comprehensive account of theory and research on semantic
memory.

343

Chapter

8

Everyday memory

INTRODUCTION Most memory research discussed in Chapters 6 and 7 was
laboratory-based but nevertheless of reasonably direct relevance to how
we use memory in our everyday lives. In this chapter, we focus on topics
rarely researched until approximately 50 years ago but arguably even
more directly relevant to our everyday lives. Two such topics are
autobiographical memory and prospective memory, which are both strongly
influenced by our everyday goals and motives. This is very clear with
prospective memory (remembering to carry out intended actions). Our
intended actions assist us to achieve our current goals. For example, if
you have agreed to meet a friend at 10 am, you need to remember to set
off at the appropriate time to achieve that goal. The other main topic
discussed in this chapter is eyewitness testimony. Such research has
obvious applied value with respect to the judicial system. However, most
research on eyewitness testimony has been conducted in laboratory
settings. Thus, it would be wrong to distinguish sharply between
laboratory research and everyday memory or applied research. In spite of
what has been said so far, everyday memory sometimes differs from more
traditional memory research in various ways. First, social factors are
often important in everyday memory (e.g., a group of friends discuss
some event or holiday they have shared together). In contrast,
participants in traditional memory research typically learn and remember
information on their own. Second, participants in traditional memory
experiments are generally motivated to be as accurate as possible. In
contrast, everyday memory research is typically based on the notion that
"Remembering is a form of purposeful action" (Neisser, 1996, p. 204).
This approach involves three assumptions about everyday memory: (1) (2)

It is purposeful (i.e., motivated). It has a personal quality about it,
meaning it is influenced by the individual's personality and other
characteristics.

Everyday memory

(3) 

It is influenced by situational demands (e.g., the wish to impress one's
audience).

The essence of Neisser's (1996) argument is this: what we remember in
everyday life is determined by our personal goals, whereas what we
remember in traditional memory research is mostly determined by the
experimenter's demands for accuracy. Sometimes we strive for maximal
memory accuracy in our everyday life (e.g., during an examination), but
that is typically not our main goal.

Findings Evidence that the memories we report in everyday life are
sometimes deliberately distorted was reported by Brown et al. (2015).
They found 58% of students admitted to having "borrowed" other people's
personal memories when describing experiences that had allegedly
happened to them. This was often done to entertain or impress an
audience. If what you say about an event is deliberately distorted, does
this change the memory itself? It often does. Dudokovic et al. (2004)
asked people to recall a story accurately (as in traditional memory
research) or entertainingly (as in the real world). Unsurprisingly,
entertaining retellings were more emotional but contained fewer details.
The participants were then instructed to recall the story accurately.
Those who had previously recalled it entertainingly recalled fewer
details and were less accurate than those who previously recalled it
accurately. This exemplifies the saying-is-believing effect -- tailoring
what one says about an event to suit a given audience causes
inaccuracies in memory for that event. Further evidence of the
saying-is-believing effect was reported by Hellmann et al. (2011).
Participants saw a video of a pub brawl involving two men. They then
described the brawl to a student having previously been told this
student believed person A was (or was not) the culprit. The
participants' retelling of the event reflected the student's biased
views. On a subsequent unexpected test of free recall for the crime
event, participants' recall was systematically influenced by their
earlier retelling. Free recall was most distorted in those participants
whose retelling of the event had been most biased.

What should be done? Research on human memory should ideally possess
ecological validity (i.e., applicability to real life; see Glossary).
Ecological validity has two aspects: (1) representativeness (the
naturalness of the experimental situation and task); and (2)
generalisability (the extent to which a study's findings apply to the
real world). It is often (mistakenly) assumed that everyday memory
research has greater ecological validity than traditional laboratory
research. This is simply incorrect. Generalisability is more important
than representativeness (Kvavilashvili & Ellis, 2004). Laboratory
research is generally carried out under well-controlled conditions and
very often produces findings that

345

KEY TERM Saying-is-believing effect Tailoring a message about an event
to suit a given audience causes subsequent inaccuracies in memory for
that event.

346

Memory

KEY TERMS

apply to the real world. Indeed, the fact that the level of experimental
control is generally higher in laboratory research than in more
naturalistic research means that the findings obtained often have
greater generalisability. Laboratory research also often satisfies the
criterion of representativeness because the experimental situation
captures key features of the real world. In sum, the distinction between
traditional laboratory research and everyday memory research is blurred
and indistinct. In practice, there is much cross-fertilisation, with the
insights from both kinds of memory research enhancing our understanding
of human memory.

Autobiographical memory Long-term memory for the events of one's own
life. Mentalising The ability to perceive and interpret behaviour in
terms of mental states (e.g., goals; needs).

AUTOBIOGRAPHICAL MEMORY: INTRODUCTION We have hundreds of thousands of
memories relating to an endless variety of things. However, those
relating to the experiences we have had and those of other people
important to us have special significance and form our autobiographical
memory (memory for the events of one's own life). What is the
relationship between autobiographical memory and episodic memory
(concerned with events at a given time in a specific place; see Chapter
7)? One important similarity is that both types of memory relate to
personally experienced events. In addition, both are susceptible to
proactive and retroactive interference and unusual or distinctive events
are especially well remembered. There are also several differences
between them. First, autobiographical memory typically relates to events
of personal significance whereas episodic memory (sometimes called
"laboratory memory") often relates to trivial events (e.g., was the word
chair presented in the first list?). As a consequence, autobiographical
memories are often thought about more often than episodic ones. They
also tend to be more organised than episodic memories because they
relate to the self. Second, neuroimaging evidence suggests
autobiographical memory is more complex and involves more brain regions
than episodic memory. Andrews-Hanna et al. (2014) carried out a
meta-analysis (see Glossary) of studies on autobiographical memory,
episodic memory and mentalising (understanding the mental states of
oneself and others) (see Figure 8.1). Episodic memory retrieval involved
medial temporal regions (including the hippocampus) whereas mentalising
involved the dorsal medial regions (including the dorsal medial
prefrontal cortex). Of most importance, the brain regions associated
with autobiographical memory overlapped with those associated with
episodic memory and mentalising. Thus, autobiographical memory seems to
involve both episodic memory and mentalising. Third, some people have
large discrepancies between their autobiographical and episodic memory
(Roediger & McDermott, 2013). For example, Patihis et al. (2013) found
individuals with exceptionally good autobiographical memory had only
average episodic memory performance when recalling information learned
under laboratory conditions (see below). Fourth, the role of motivation
differs between autobiographical and episodic memory (Marsh & Roediger,
2012). We are much more interested in our own personal history than
episodic memories formed in the

Everyday memory

347

laboratory. In addition, as mentioned earlier, we are motivated to
recall autobiographical memories reflecting well on ourselves. In
contrast, we are motivated to recall laboratory episodic memories
accurately. Fifth, some aspects of autobiographical memory involve
semantic memory (general knowledge; see Glossary) rather than episodic
memory (Prebble et al., 2013). For example, we know where and when we
were born but this is not based on episodic memory! Further evidence for
the involvement of semantic memory in autobiographical memory comes from
research on amnesic Figure 8.1 patients (Juskenaite et al., 2016). They
have Brain regions activated by autobiographical, episodic retrieval
little or no episodic memory but can never- and mentalising tasks
including regions of episodic (green); theless recall much information
about them- mentalising (blue); autobiographical (red-brown); episodic +
selves (e.g., aspects of their own personality). mentalising
(blue/green); episodic + autobiographical (yellow); Eustache et
al. (2016) distinguished mentalising + autobiographical (purple); all 3
(white). between episodic and semantic autobio- From Andrews-Hanna et
al. Reprinted with permission of Elsevier. graphical memory. Both forms
of autobiographical memory involve personal memories, but the latter
differ from the former because they lack any subjective sense of
recollection. Eustache et al. reviewed neuroimaging research supporting
the above distinction. Episodic autobiographical memory was associated
with activation in the occipital cortex and lateral parietal cortex. In
contrast, semantic autobiographical memory was associated with
activation in the middle and inferior frontal cortex. Other brain areas
(e.g., the lateral temporal cortex; the hippocampus) were activated by
both forms of autobiographical memory. More research indicating that
autobiographical memories vary in their relationship to episodic and
semantic memory is discussed in Chapter 7 (e.g., research of Renoult et
al., 2016; see p. 303). What are the main functions of autobiographical
memory? Bluck and Alea (2009) identified three key reasons: (1) (2) (3)

social function: bonding with others (e.g., shared memories); directive
function: using the past as a guide to the future; self-function:
creating a sense of self-continuity over time.

Vranić et al. (2018) obtained support for all three functions in a
questionnaire-based approach. The social and self-functions were
positively correlated with each other and there was some evidence these
functions were more important than the directive function. Demiray and
Janssen (2013) identified an additional function: selfenhancement. Most
people feel closer to their positive memories than their negative ones,
and this effect is stronger among individuals having high self-esteem.
Below we discuss major topics within autobiographical memory. First, we
consider unusually vivid autobiographical memories for dramatic personal
or world events. Second, we focus on those periods in individuals'

348

Memory

lives from which disproportionately many or few autobiographical
memories are retrieved. Third, we discuss major theoretical approaches.
Note that research on autobiographical memories for traumatic childhood
events is discussed in Chapter 7.

IN THE REAL WORLD: HIGHLY SUPERIOR AUTOBIOGRAPHICAL MEMORY (HSAM) Many
people bemoan their deficient autobiographical memories. However, a few
individuals have remarkably efficient autobiographical memory. Consider
Jill Price (see photo). She has an incredible ability to recall detailed
information about almost every day of her life and thus possesses what
is known as highly superior autobiographical memory (HSAM). You may envy
Jill Price's phenomenal autobiographical memory. However, she regards it
as a disadvantage: "I call it a burden. I run my entire life through my
head every day and it drives me crazy!!!" (Parker et al., 2006, p. 35).
Strangely, her memory generally is very ordinary (e.g., recalling word
lists). You can see Jill Price on YouTube: "The Woman Who Could Not
Forget -- Jill Price". Why is her autobiographical memory so
outstanding? First, she has obsessional tendencies and focuses
excessively on her personal past. As she said, "This is OCD
\[obsessive-compulsive disorder\]. I have OCD of my memories." Second,
she has poor inhibitory processes Jill Price and so finds it very hard
to switch off her personal memories. Third, Dan Tuffs/Getty Images. she
makes time seem more concrete by representing it in spatial form (e.g.,
positions on a circle). More recent research (e.g., LePort et al., 2012,
2016; Santangelo et al., 2018) indicates the great majority of
individuals with HSAM possess similar obsessional characteristics to
Jill Price. Indeed, they often have as many obsessional symptoms as
patients with obsessive-compulsive disorder.

From LePort et al. (2016).

60

Controls

- 

HSAMs

- # Internal details

Figure 8.2 Number of internal details (those specific to an
autobiographical event) recalled at various time delays (by controls and
individuals with highly superior autobiographical memory (HSAM)).

- 

40 +

- 
- 

20

- 
- 
- 

0 1 week

1 month

1 year Delay

10 years

Everyday memory

349

Recent research also indicates the performance of those with HSAM is
only average on standard laboratory memory tasks. LePort et al. (2016)
found individuals with HSAM had comparable autobiographical memory to
controls one week after an event. However, they were dramatically better
than controls thereafter (see Figure 8.2). These findings suggest the
memory differences between the two groups depended mainly on processes
occurring after acquisition (e.g., consolidation; frequent rehearsal)
rather than encoding at the time of the event. Santangelo et al. (2018)
found that individuals with HSAM retrieved autobiographical memories
(but not other memories) much faster than controls. During retrieval of
autobiographical memories, twice as many brain areas were activated in
HSAM individuals as controls and they had enhanced connectivity between
brain areas important in memory retrieval. Some individuals with HSAM
may have brains differing from those of other people (Palombo et al.,
2018). LePort et al. (2012) found that HK (a man with HSAM) had a larger
right amygdala than most people and enhanced connectivity between the
amygdala and hippocampus. This could be important because the amygdala
is involved in emotional processing and the hippocampus is crucial to
forming long-term memories. However, such brain differences may be a
consequence (rather than cause) of remarkable autobiographical memory.

Flashbulb memories

KEY TERMS

Most people believe they have extremely clear and long-lasting memories
for their personal experiences following important and dramatic public
events (e.g., the terrorist attacks on the United States on 11 September
2001). Such memories were termed flashbulb memories by Brown and Kulik
(1977). They claimed dramatic events perceived as surprising and as
having real consequences for the individual (making them of relevance to
autobiographical memory) activate a special neural mechanism which
"prints" the details of such events permanently in memory. Brown and
Kulik (1977) argued the following information is typically included in
flashbulb memories: ● ● ● ● ● ●

informant (person who supplied the information); place where the news
was heard; ongoing event; individual's own emotional state; emotional
state of others; consequences of the event for the individual.

Highly superior autobiographical memory (HSAM) Exceptional ability to
recall autobiographical memories in detail, generally accompanied by
only average ability to recall other memories. Flashbulb memories Vivid
and detailed personal memories of dramatic events (e.g., 9/11).

Findings Sharot et al. (2007) compared the memories of individuals close
to the World Trade Centre (about 2 miles) on 9/11 with those somewhat
further away (about 4½ miles) three years afterwards. The flashbulb
memories of those close to the event were more vivid and detailed and
involved more activation of the amygdala (strongly involved in emotion).
These findings suggest it may require intense emotional experience to
produce genuine flashbulb memories.

World Trade Center attacks on 9/11. Tammy KLEIN/Gamma-Rapho via Getty
Images.

350

Memory

KEY TERM

Support for the involvement of the amygdala was reported by Spanel et
al. (2018). Recall of flashbulb memories was much worse in patients with
damage to the amygdala than those without damage to that brain area.
Flashbulb memories not based on an intense emotional experience are
often surprisingly inaccurate. For example, videotape of the first plane
striking the first tower on 9/11 was not available on the day it
happened. However, 73% of those questioned said they had seen it on that
day (Pezdek, 2003)! Their memories were distorted because videotape of
the second tower being hit was available on the day itself. Hirst et
al. (2015) studied flashbulb memories and event memories (memories for
facts associated with events causing flashbulb memories) of 9/11 over a
10-year period. There was rapid forgetting for both types of memories
within the first year after 9/11 but very little thereafter. Of
interest, participants had very high confidence in the accuracy of their
flashbulb memories despite considerable forgetting. Rimmele et
al. (2012) studied the consistency of flashbulb memories (i.e., lack of
change) over time. There was high consistency between one week and three
years after 9/11 for remembering the location at which participants
heard about the event (83%), but lower consistency for informant (70%),
ongoing activity (62%) and their own immediate reaction (34%). In spite
of much inconsistency in individuals' flashbulb memories, these memories
are generally associated with high confidence levels. Talarico and Rubin
(2003) found flashbulb memories for 9/11 showed no more consistency over
a 32-week period than did everyday memories but the reported vividness
of flashbulb memories was much greater. Why are confidence levels so
high? Day and Ross (2014) assessed flashbulb memories for Michael
Jackson's death. Participants having a strong social bond with Michael
Jackson had greater confidence in the accuracy of their flashbulb
memories than those with a weak social bond, because they experienced
Jackson's death with greater emotional intensity and also rehearsed the
event more often. However, memory consistency was not influenced by
social bond, emotional intensity or rehearsal.

Flashbacks Intense emotional memories of traumatic events that are
recalled involuntarily by patients suffering from posttraumatic stress
disorder.

Conclusions

Interactive exercise: Flashbulb memories

Most findings suggest flashbulb memories are not special except perhaps
when their formation is associated with high emotion. Most flashbulb
memories exhibit forgetting and/or distortions resembling those found
with ordinary memories (Hirst & Phelps, 2016). However, such memories
may be more detailed and long-lasting if the relevant event directly
affected their lives (Sharot et al., 2007; see Chapter 15). Flashbulb
memories are associated with excessively high levels of confidence in
their accuracy for various reasons (e.g., the intensity of emotional
experience involved; rehearsal: Day & Ross, 2014). Excellent memory for
the location at which individuals heard about the traumatic event may
cause them to exaggerate the accuracy of their flashbulb memories
(Rimmele et al., 2012). Finally, there are interesting links between
flashbulb memories and flashbacks ("the intrusive re-experiencing of
traumatic experiences in the present": Brewin, 2015, p. 1). Healthy
individuals viewing a trauma film are

Everyday memory

most likely to experience flashbacks subsequently if the amygdala
(involved in emotional processing) and areas within the occipital cortex
involved in imagery are activated (James et al., 2016). With such
research, it is possible to assess individuals' immediate cognitive and
emotional reactions to the traumatic event, which cannot be done when
studying flashbulb memories.

MEMORIES ACROSS THE LIFETIME Suppose we ask 70-year-olds to recall
personal memories suggested by cue words (e.g., nouns referring to
common objects). From which points in their lives would most memories
come? Rubin et al. (1986) answered this question by combining findings
from several studies. Two findings were of theoretical interest: ●

Infantile amnesia (or childhood amnesia) shown by the almost total

●

Reminiscence bump, consisting of a surprisingly large number of mem-

lack of memories from the first three years of life. ories coming from
the years between 10 and 30 (especially between 15 and 25).

Infantile amnesia Adults sometimes claim their first autobiographical
memory dates back to 2 years of age or earlier but such memories are
typically fictional (Akhtar et al., 2018). Adults' genuine first
memories rarely date back to earlier than 2½ or 3 years of age and they
also show limited recall for events occurring between 3 and 6 (see
Figure 8.3). How can we explain this phenomenon (infantile amnesia or
childhood amnesia)? Freud famously (notoriously?) attributed it to
repression, with threat-related thoughts and experiences being consigned
to the unconscious (see Chapter 6). This dramatic theory does not
explain why adults cannot remember positive and neutral events from
early childhood.

Psychological theories Howe and Courage (1997) argued the development of
the cognitive self (self-awareness) occurs during the second year of
life. This plays an important role in the end of infantile amnesia and
the onset of autobiographical memory. The reason is that possession of a
cognitive self provides a framework for the organisation of
autobiographical memories. The social-cultural developmental theory
(e.g., Fivush, 2010) provides an alternative account, according to which
language and culture are both central to autobiographical memory
development. Language is important because we use it to communicate our
memories. Experiences occurring before children develop language are
hard to express in language later on. Evidence indicating the importance
of language was reported by Jack et al. (2009): the age of first
recalled memory was earlier in adolescents whose mothers reminisced
elaborately about the past with their children. Jack and Hayne (2010)
argued the common assumption of a gradual decline in infantile amnesia
is incorrect. In their study, adults'

351

KEY TERMS Infantile amnesia The inability of adults to recall
autobiographical memories from early childhood; also known as childhood
amnesia. Reminiscence bump The tendency of older people to recall a
disproportionate number of autobiographical memories from adolescence
and early adulthood.

352

Memory

earliest memory dated from 23 months of age. However, their memories for
the first 4--6 years of life were sparse. These findings suggest
infantile amnesia is a two-stage process: (1) absolute amnesia for the
first two years of life; and (2) relative amnesia for the remaining
preschool years. How can we account for these two stages? According to
Jack and Hayne (2010), absolute amnesia ends with the onset of the
cognitive self (consistent with Howe and Courage's theory). The
subsequent strong tendency for information recalled about childhood
events to increase as the individual's age at the time increases
probably reflects children's rapid development of language in early life
(consistent with Fivush's theory).

Hippocampal neurogenesis Infantile amnesia has been observed in all
altricial species (those showing considerable post-birth development).
Such infantile amnesia cannot be explained with reference to notions
such as the cognitive self or language development. However, it can
potentially be From Josselyn and Frankland (2012). © 2012 Cold Spring
Harbor Laboratory Press. Reproduced with permission of author and Cold
explained by processes occurring within the Spring Harbor Laboratory
Press. hippocampus (crucially involved in declarative memory including
autobiographical memory). We need to focus on hippocampal neurogenesis,
a process in which new neurons are generated within the hippocampus
(especially the dentate gyrus) early in development. According to
Josselyn and Frankland (2012, p. 423), "High neurogenesis levels
negatively regulate the ability to form enduring memories, most likely
by replacing synaptic connections in pre-existing hippocampal memory
circuits." Madsen and Kim (2016) reviewed evidence indicating the
importance of hippocampal neurogenesis in producing infantile amnesia.
For example, long-term retrieval in mice was impaired when drugs
increased hippocampal neurogenesis. In contrast, long-term retrieval was
enhanced when drugs reduced hippocampal neurogenesis. Travaglia et
al. (2016) found rats during the infantile amnesia period formed lasting
(but relatively inaccessible) memories. However, when activity in the
hippocampus was blocked prior to learning, such memories were not
acquired. Finally, Travaglia et al. showed that changing patterns of
activation in the hippocampus KEY TERM signalled the end of the
infantile amnesia period. Figure 8.3 Childhood amnesia based on data
reported by Rubin and Schulkind (1997). Participants (20, 35 and 70
years of age) reported very few autobiographical memories before the age
of 3 and there was later a levelling off between the ages of 7 and 10.

Hippocampal neurogenesis The process of generating new neurons in the
hippocampus during early development.

Forgetting Defining "infantile amnesia" on the basis of adults'
inability to recall autobiographical memories from the earliest years of
life can lead to the erroneous

Everyday memory

353

assumption that young children cannot form autobiographical memories. A
simple explanation of infantile amnesia is that young children form
autobiographical memories but these memories are very susceptible to
forgetting. Supporting evidence was reported by Tustin and Hayne (2016).
Threeyear-old children learned how to operate a train and their memory
for this event was tested after 1 day and 1 year. They exhibited
accurate memory (including verbal autobiographical memory) on both tests
and there was no effect of retention interval. However, the children's
memories of the event contained only a few details which may help to
explain why most early memories cannot be recalled by adults.

Overall evaluation Infantile amnesia depends on several factors (see
Howe, 2019, for a review). Absolute amnesia can probably be explained by
hippocampal neurogenesis. After that, the onset of autobiographical
memory in infants probably depends on reductions in hippocampal
neurogenesis plus the emergence of the cognitive self. Its subsequent
expression depends heavily on social and cultural factors and children's
language development and possibly also on their development of semantic
memory. What are the limitations of research in this area? First, most
research has focused on adults' inability to recall autobiographical
memories from the first three years of life. It is generally unclear
whether this inability is due to severely deficient initial encoding of
such memories, to difficulties in retrieval or both. Second, most
research is correlational making it hard to establish causality (e.g.,
the finding that the end of infantile amnesia occurs around the time the
cognitive self emerges does not prove the latter causes the former).

Reminiscence bump As mentioned earlier, older people asked to produce
personal memories recall numerous events from adolescence and early
childhood (the reminiscence bump). Conway et al. (2005) found a
reminiscence bump in older individuals in five countries (America,
China, Japan, England and Bangladesh). Of interest, the Chinese (with a
collectivistic culture emphasising group cohesion) were most likely to
recall events with a social or group orientation. In contrast, the
Americans (with an individualistic culture emphasising personal
responsibility and achievement) were most likely to recall events
relating to themselves. It has typically been assumed (incorrectly)
there is a single reminiscence bump. Koppel & Berntsen (2015) carried
out a meta-analysis using two techniques to assess the reminiscence
bump: (1) (2)

cue-word method in which individuals generate memories to cue words; the
important memories method in which individuals report important personal
memories.

Their key findings were as follows (see Figure 8.4). First, the midpoint
of the reminiscence bump was 15.5 years using cue words but 21.5 for
important

Interactive exercise: Reminiscence bump

Figure 8.4 Temporal distribution of autobiographical memories across the
lifespan. (a) Top panel: word-cued memories; (b) bottom panel: important
memories. From Koppel & Berntsen (2015). Reprinted with permission of
Elsevier.

Memory

(a) 20

Percentage of memories

354

15

10

5

0 --7

5 --6

66

0 --6

61

5

0

--5

56

51

5

--5 46

0

--4 41

5

--4 36

0

--3 31

5

--3 26

0

--2 20

5

--2 16

10

--1 11

6--

0--

5

0

Age in years at time of event

Percentage of memories

(b) 20

15

10

5

0 --7

5 --6

66

0 --6

61

5

0

--5

56

51

5

--5 46

0

--4 41

5

--4 36

0

--3 31

5

--3 26

0

--2 20

--2 16

5

10

--1 11

6--

0--

5

0

Age in years at time of event

KEY TERM Life script A schema based on cultural expectations concerning
the nature and order of a typical person's major life events.

memories. Second, the reminiscence bump was much stronger using the
important memories method. How can we explain the reminiscence bump(s)?
One influential approach is Rubin and Berntsen's (2003) theory based on
the notion of a life script (cultural expectations about the major life
events in most people's lives). Examples include falling in love,
marriage and having children. Most such events occur between the ages of
15 and 30. According to the theory, the life script guides and organises
the retrieval of autobiographical memories. Several predictions from the
life-script account have been supported. First, most life events are
emotionally positive, and so we would expect to find a reminiscence bump
only for positive events. That is precisely what Berntsen et al. (2011)
found. As expected, the positive events recalled were rated as much more
central to the participants' life story than the negative ones. Second,
there was no reminiscence bump for positive events not forming part of
the life script (Berntsen et al.). Third, Scherman (2013)

Everyday memory

355

found life scripts had a lifespan distribution resembling the
reminiscence bump in four countries (Denmark, USA, Turkey and the
Netherlands). Most positive events forming part of the life script
involve major transitions (e.g., going to college; marriage; having
children). Evidence transitions not directly forming part of the life
script are important were reported by Enz et al. (2016). Older adults
recalled autobiographical events occurring between the ages of 40 and
60. Many events recalled occurred close in time to the major transition
of a residential move: a relocation bump. Thus, autobiographical
memories associated with transitions (even if not part of the life
script) seem to be especially easy to recall, perhaps because such
memories tend to be novel and distinctive. Why does the reminiscence
bump depend on the method used? It has been argued (Koppel & Berntsen,
2016) that the crucial difference between the cue word and important
memories methods is the retrieval strategy used. Koppel and Berntsen
(2016) asked students (mean age = 23) to generate the autobiographical
memories they imagined a hypothetical 70-yearold would produce. With the
important memories method, the timing and nature of the reminiscence
bump were strikingly similar for imagined important memories and those
of actual 70-year-olds. Similar (but much less striking) findings were
obtained when comparing imagined and actual memories using the cue-word
method. Koppel and Berntsen (2016) concluded the different reminiscence
bumps produced using the two methods "are largely produced by general
schematic processes operative at retrieval" (p. 97). In sum, the
reminiscence bump produced using the important memories method depends
on the life script and its associated cultural expectations. In
addition, it is probably relevant that major life events generally
involve important transitions. In contrast, memories recalled using the
cue-word method are much less influenced by the life script (Koppel &
Berntsen, 2015). The finding (Koppel & Berntsen, 2016) that imagined
memories differed substantially from actual ones using that method
suggests specifically memory-based processes underlie the reminiscence
bump associated with that method.

THEORETICAL APPROACHES TO AUTOBIOGRAPHICAL MEMORY Many theories of
autobiographical memory have been proposed over the years. Here we will
focus mainly on Conway and Pleydell-Pearce's (2000) self-memory system
model and its subsequent development. Then, we discuss how cognitive
neuroscience has contributed to our understanding of autobiographical
memory.

Self-memory system model Conway and Pleydell-Pearce (2000) argued we
possess a self-memory system having two major components: (1)

Autobiographical memory knowledge base: this contains personal
information at three levels of specificity:

Research activity: Memory for personal events

356

Memory

●

KEY TERMS Generative retrieval Deliberate or voluntary construction of
autobiographical memories based on an individual's current goals; see
direct retrieval. Direct retrieval Effortless recall of autobiographical
memories triggered by a specific cue (e.g., being in the same place as
the original event); see generative retrieval.

●

●

(2) 

Lifetime periods: they are defined by major ongoing events and generally
cover substantial periods of time (mean length between 4 and 15 years:
Thomsen, 2015). Different lifetime periods often overlap in time (e.g.,
living with someone may overlap with having a particular job). General
events: these include repeated events (e.g., visits to a sports club)
and single events (e.g., a holiday in Botswana). General events are
often related to each other and to lifetime periods. Event-specific
knowledge: this consists of images, feelings and other details relating
to general events and spanning time periods from seconds to hours. Event
knowledge is usually organised in the correct temporal order.

Working self: this is concerned with the self, what it may become and
the individual's current goals. The working self's goals influence the
memories stored within the autobiographical memory knowledge base and
the autobiographical memories we recall. As a result, "Autobiographical
memories are primarily records of success or failure in goal attainment"
(Conway & Pleydell-Pearce, 2000, p. 266).

According to the theory, autobiographical memories can be accessed in
two ways. First, there is generative retrieval which involves
deliberately constructing autobiographical memories by applying the
working self to information in the autobiographical memory knowledge
base. Second, there is direct retrieval: autobiographical memories are
triggered effortlessly or "automatically" by specific cues (e.g.,
hearing the word Paris may trigger retrieval of a holiday there). It was
predicted recalled autobiographical memories would mostly be
goal-relevant regardless of retrieval mode. However, events relating to
current goals are more likely to be recalled with generative retrieval
(which involves top-down processes) than with direct retrieval (which
typically depends on bottom-up processes triggered by environmental
cues). Conway (2005) developed the above theory (see Figure 8.5). The
knowledge structures divided into the conceptual self and episodic
memories (previously called event-specific knowledge). At the top of the
hierarchy, the life story and themes have been added. The life story
consists of very general factual and evaluative knowledge we possess
about ourselves and themes referring to major life domains (e.g., work;
relationships). Conway (2005) argued we want our autobiographical
memories to exhibit coherence (consistency with our current goals and
beliefs). However, we also often want them to exhibit correspondence
(accuracy). Over time, coherence tends to win out over correspondence.
Conway (2009) refined the theory. He argued the working self consists of
the individual's goal system (goals; plans; projects) plus their
conceptual self. It determines which autobiographical memories can be
accessed. In addition, it is assumed that simple episodic memories
resembling each other often form complex episodic memories. Finally,
Conway et al. (2016) developed the notion of episodic memories within
the self-memory system. They identified a remembering--imagining

Everyday memory

357

Figure 8.5 The knowledge structures within autobiographical memory, as
proposed by Conway (2005). Reprinted from Conway (2005). Reprinted with
permission of Elsevier.

system where episodic memories formed today are most accessible, with
accessibility decreasing for episodic memories further in the past or
future. This system "serves the purpose of integrating past, current,
and future goal-related activities" (p. 256). Participants listed all
the personal events they could remember from the past 5 days and events
they imagined were likely to occur over the next 5 days. The findings
were as predicted (see Figure 8.6).

Findings Research on patients with retrograde amnesia (widespread
forgetting of events preceding brain injury; see Chapter 7) supports the
notion there are different types of autobiographical knowledge. These
patients often have greater difficulties recalling episodic memories
than general events and lifetime periods (Conway & Pleydell-Pearce,
2000). For example, Rosenbaum et al. (2005) found an amnesic patient
(KC) with no episodic memories could nevertheless access some general
autobiographical knowledge.

Now

9

Past

Future

8 7 6 5 4 3 2 1

ay Fr id

ay ur

Th

sd ne

sd

ay

ay sd W ed

Tu e

da y on

ay M

Fr id

ay sd ur

Th

sd ne

W ed

Tu e

sd

ay

ay

0

da y

From Conway et al. (2016).

10

on

Figure 8.6 The mean number of events participants could remember from
the past 5 days and those they imagined were likely over the next 5
days.

Memory

M

358

How do amnesic patients (with their severely impaired episodic memory)
cope when recalling autobiographical events? Lenton-Brym et al. (2017)
found amnesic patients were more likely than healthy controls to recall
frequently occurring events. This probably happened because it is easier
to use semantic memory processes to recall general rather than unique
events. McCormick et al. (2018) supported this viewpoint in a review.
Amnesic patients use brain areas associated with retrieval of general or
schematic information (e.g., the ventromedial prefrontal cortex; see
Chapter 7) when retrieving autobiographical memories. According to the
self-memory system model, the accessibility of autobiographical memories
depends on individuals' goals. Woike et al. (1999) compared individuals
with an agentic personality type (motivated by independence, achievement
and personal power) and those with a communal personality type
(motivated by interdependence and similarity to others). When they
recalled a positive personal memory, 65% of agentic individuals recalled
agentic memories (e.g., involving success) whereas 90% of communal
individuals recalled communal memories (e.g., involving love or
friendship). With negative personal memories, 47% of agentic individuals
recalled agentic memories whereas 90% of communal individuals recalled
communal memories. The model predicts faster recall of autobiographical
memories with direct retrieval than generative retrieval. This
prediction has support. Barzykowski and Staugaard (2016) both found
direct retrieval was twice as fast as generative retrieval. According to
the model, the individual's working self and goals are more involved in
generative than direct retrieval. Johannessen and Berntsen (2010)
supported this assumption: memories elicited by generative retrieval
were more significant and relevant to the individual's personal identity
than those involving direct retrieval. Addis et al. (2012) found
generative retrieval was associated with more activation in prefrontal
areas involved in strategic search for autobiographical information.
This finding is consistent with the plausible notion

Everyday memory

that generative retrieval involves more top-down processing than direct
retrieval. It has typically been assumed direct retrieval is involuntary
whereas generative retrieval is voluntary. This assumption is
oversimplified. Barzykowski and Staugaard (2016) distinguished between
retrieval effort (high with generative retrieval and low with direct
retrieval) and conscious intention (voluntary vs involuntary retrieval).
They identified three types of autobiographical memories: (1)
involuntary memories; (2) directly retrieved voluntary memories; and (3)
generatively retrieved voluntary memories. According to the model,
lifetime periods differ importantly from specific episodic memories.
Various findings support this assumption (Thomsen, 2015). First,
lifetime periods are regarded as more important than specific memories
to an individual's identity and personality. Second, memory for lifetime
periods is less affected by ageing than specific memories. Third,
lifetime period memories are generally less vivid and emotional than
specific memories and are associated with less activation in frontal
areas and the medial temporal lobes (Ford et al., 2011).

Evaluation The theoretical approach of Conway and Pleydell-Pearce (2000)
and Conway (2009) provides a comprehensive account of autobiographical
memory. Several of their main theoretical assumptions (e.g., the
hierarchical structure of autobiographical memory; the intimate
relationship between autobiographical memory and the self; the
importance of goals in autobiographical memory) are well supported.
There is also good support for the distinction between generative and
direct retrieval. What are the limitations of the self-memory system
model? First, we need to know more about how the working self interacts
with the autobiographical knowledge base to produce recall of specific
autobiographical memories. Second, autobiographical memories vary in how
much episodic information (e.g., contextual details) and semantic
information (e.g., world knowledge) they contain. This issue is not
addressed fully within the model. Third, the distinction between direct
and generative retrieval is oversimplified. Fourth, the model does not
fully account for the complexities of autobiographical memory revealed
by cognitive neuroscience studies (discussed next).

Cognitive neuroscience The prefrontal cortex plays a major role in
autobiographical memory retrieval (especially during generative
retrieval). Svoboda et al. (2006) found in a meta-analytic review that
the medial and ventromedial prefrontal cortex was nearly always
activated during autobiographical retrieval. Autobiographical memories
are often of personally significant events and so are associated with
emotion. The amygdala, buried deep within the temporal lobe, is strongly
associated with emotion. As expected, amnesic patients who also have
damage to the amygdala find it harder to retrieve emotional
autobiographical memories (Buchanan et al., 2006). St. Jacques et
al. (2011) found four brain networks (with strong bidirectional
connections between them) were activated when individuals

359

360

Memory

Figure 8.7 A model of the bidirectional relationships between neural
networks involved in the construction and/or elaboration of
autobiographical memories. MTL = medial temporal lobe network; medial
PFC = medial prefrontal cortex. From St. Jacques et al. (2011).
Reprinted with permission of Elsevier.

produced autobiographical memories to emotionally arousing words by
generative retrieval (see Figure 8.7): (1)

(2) 
(3) 
(4) 

Fronto-parietal network: it is involved in the construction of
autobiographical memories, associated with adaptive controlled processes
and is probably involved in verbal retrieval. Cingulo-operculum network:
it is also involved in the construction of autobiographical memories and
with goal maintenance. Medial prefrontal cortex network: it is involved
in the construction and subsequent elaboration of autobiographical
memories and selfreferential processing. Medial temporal lobe network:
it is involved in the construction and subsequent elaboration of
autobiographical memories and associated with declarative memory
conscious recollection.

Inman et al. (2018) studied dynamic changes in brain activation during
two stages of generative retrieval of autobiographical memories. First,
processes involved in searching for and accessing autobiographical
memories involved a ventral frontal to temporal-parietal network.
Second, subsequent elaborative processing of these memories involved
strong connections between occipital-parietal areas and dorsal
fronto-parietal regions. There was no sudden switch between the two
processing stages: rather, the relative dominance of access-related and
elaboration-related processing altered over time.

Everyday memory

361

IN THE REAL WORLD: DEPRESSION AND AUTOBIOGRAPHICAL MEMORY It is assumed
within the self-memory system model that information stored in (and
retrieved from) autobiographical memory reflects the individual's
personality and sense of self. This assumption has been applied in
studies on depressed individuals. Research has often involved
participants recalling autobiographical memories of events lasting less
than one day to word cues. Depressed individuals typically produce
over-general negative memories (Fisk et al., 2019). For example, a
depressed person might respond "Arguing with other people" to the cue
"angry". Most evidence shows only an association or correlation between
over-general memories and depression and so does not demonstrate the
former partially causes the latter. Stange et al. (2013) reported more
convincing evidence. The extent of over-general autobiographical memory
predicted increases in depressive symptoms 8 months later in those
exposed to high levels of familial emotional abuse. Dalgleish et
al. (2011) asked patients with current major depressive disorder,
patients in remission from that disorder and healthy controls to list
their most important lifetime periods. After that, the patients decided
which positive and negative items (words or phrases) applied to each
period. Four measures were identified: (1) (2) (3) (4)

the proportion of items that was negative; compartmentalisation (the
extent to which the proportion of items that was negative varied across
lifetime periods); positive redundancy (the extent to which the same
positive terms were used across periods); negative redundancy (the
extent to which the same negative terms were used across periods).

Figure 8.8 Life structure scores (proportion negative,
compartmentalisation, positive redundancy, negative redundancy) for
patients with major depressive disorder, patients in remission from
major depressive disorder and healthy controls. From Dalgleish et
al. (2011). © 2010 American Psychological Association.

362

Memory

The proportion of selected terms that was negative was much greater for
current depressed patients than controls (see Figure 8.8). In addition,
current patients had a less integrated sense of self (i.e., greater
compartmentalisation). This occurred in part because current depressed
patients showed little consistency in their use of positive terms across
lifetime periods (i.e., low positive redundancy). Finally, depressed
patients in remission were intermediate between current patients and
controls on most measures. What do these findings mean? First, the
organisation of autobiographical knowledge in currently depressed
patients is relevant to their working self (Conway & Pleydell-Pearce,
2000). More generally, current patients' perceived self is revealed in
the predominantly negative and nonintegrated structure of their
autobiographical knowledge. Second, the structure of autobiographical
knowledge is more integrated and less pervasively negative in patients
in remission than current patients. Thus, recovery from major depressive
disorder involves having a "healthier" perspective on one's life
history. Third, patients in remission nevertheless had a more negative
and less integrated view of their life history than healthy controls.
These findings suggest these patients were at risk of a subsequent
depressive episode. Dalgleish and Werner-Seidler (2014) identified four
cognitive biases in depression associated with autobiographical memory
recall (see Figure 8.9). First, there is a strong tendency to recall
negative autobiographical memories. Second, there is impoverished access
to positive memories. Third, depressed individuals recall over-general
negative memories. Fourth, depressed individuals have an altered
relationship to their emotional memories in that they try (typically
unsuccessfully) to avoid or suppress negative memories.

Biased recollection of negative memories

Impoverished positive memories

Depression

Over-general memory

Altered relationship to emotional memories

Figure 8.9 Four cognitive biases related to autobiographical memory
recall that maintain depression and increase the risk of recurrence
following remission. The Figure is Figure 1 in an article by Dalgleish
and Werner-Seidler (2014) in Trends in Cognitive Sciences published by
Cell Press.

Everyday memory

363

Interventions How can we use our knowledge of depressed individuals'
biases relating to autobiographical memory to reduce their level of
depression? Some answers were discussed by Dalgleish and Werner-Seidler
(2014). One approach is to use MEmory Specificity Training (MEST) where
the emphasis is on training depressed patients to generate more specific
autobiographical memories (e.g., for homework, patients produce specific
memories to 10 cue words). MEST reduces rumination (repeated negative
self-focused thoughts and images) and cognitive avoidance.
Werner-Seidler et al. (2018) found in patients with major depressive
disorder that MEST increased the specificity of their autobiographical
memories and reduced their depressive symptoms. Hitchcock et al. (2016)
used memory flexibility (MemFlex) training with individuals in remission
from depression. This training focuses on the development of three
important autobiographical memory skills: (1) (2) (3)

Balancing involves enabling depressed individuals to recollect positive
and negative, specific and general memories, with equal ease.
Elaboration focuses on allowing depressed individuals to store richer
and more elaborative positive memories by focusing on emotional and
situational details of such memories. Flexibility involves training
individuals to control whether the memories they recall are general or
specific. They also learn to identify situations where specific memories
are optimal (e.g., solving a problem) and those where general memories
are optimal (e.g., when considering the strength of a friendship).

Hitchcock et al. (2016) found MemFlex training increased the specificity
of recalled autobiographical memories, reduced rumination and improved
social problem solving.

EYEWITNESS TESTIMONY Suppose you are the only eyewitness to a very
serious crime. Subsequently the person you identify as the murderer on a
line-up is found guilty although there is no other strong evidence. Is
it safe to rely on eyewitness testimony? Simons and Chabris (2011) found
37% of Americans believe the testimony of a single confident eyewitness
is sufficient to convict a criminal defendant. In fact, as we will see,
eyewitness testimony can be very fallible.

IN THE REAL WORLD: IS EYEWITNESS CONFIDENCE TRUSTWORTHY? In the United
States, over 200 individuals convicted on the basis of mistaken
eyewitness identification have been proved innocent by DNA tests.
Garrett (2011) reviewed 161 such cases and discovered virtually all the
mistaken eyewitnesses were certain at trial they had identified the
culprit. These findings suggest we should ignore the confidence (or
otherwise) eyewitnesses express in their identifications. However, that
conclusion is not warranted. One case Garrett (2011) examined was that
of Ronald Cotton. In 1985, he was found guilty of raping Jennifer
Thompson because of her confident eyewitness identification of him as
the culprit. However, he was exonerated by DNA evidence, after having
spent over 10 years in prison. Of crucial importance, when Jennifer
Thompson initially identified Cotton from a photo line-up, she hesitated
for almost 5 minutes before eventually saying "I think this is the guy".
This case

364

Memory

is not unique. Garrett (2011, p. 49) found "In 57% of trials transcripts
(92 out of 161 cases), the witnesses reported they had not been certain
at the time of their earlier identifications". Why does eyewitness
confidence often increase substantially from initial identification to
courtroom? With Jennifer Thompson, positive feedback from the police
following her initial identification caused her to become increasingly
confident she had identified the culprit. Douglass and Steblay (2006)
showed the importance of such feedback in a metaanalytic review.
Eyewitnesses receiving confirming feedback after an identification
(e.g., "Good, you identified the suspect") believed mistakenly they
Jennifer Thompson and Ronald Cotton. Ronald had been very confident in
the accuracy of their Cotton was mistakenly found guilty of raping
Jennifer identification before receiving feedback: the "post- Thompson
and spent many years in prison before identification feedback effect".
being exonerated. In sum, two conclusions are warranted. First, From
Wixted and Wells (2017). Image provided courtesy of the we can generally
trust eyewitnesses' confidence PopTech Institute. in their
identifications provided we focus on their initial level of confidence.
Wixted et al. (2016) supported this conclusion in a large-scale
real-life study of eyewitnesses' initial identifications. When
eyewitness confidence was low, only 20% of identifications were of the
suspect. This increased dramatically to approximately 80% when their
confidence was high. Second, "Testimony-relevant witness judgements
should be collected and documented, preferably with videotape, before
feedback can occur" (Steblay et al., 2014).

Eyewitness memory is inaccurate for several reasons. We start with
confirmation bias -- eyewitnesses' memory is influenced by their expec-

KEY TERM Conﬁrmation bias A tendency for eyewitnesses' memory to be
distorted by their prior expectations.

tations. For example, Lindholm and Christianson (1998) found Swedish and
immigrant students who saw a simulated robbery were twice as likely to
select an innocent immigrant as an innocent Swede as the culprit.
Participants' expectations were influenced by the fact that immigrants
are over-represented in Swedish crime statistics. Bartlett (1932) argued
we have numerous schemas (packets of knowledge) in long-term memory
strongly influencing what we remember (see Chapter 10). Most people's
bank-robbery schema includes information that robbers are typically
male, wear disguises and have a getaway car with a driver (Tuckey &
Brewer, 2003a). Tuckey and Brewer showed eyewitnesses a video of a
simulated bank robbery. As predicted, eyewitnesses recalled information
relevant to the bank-robbery schema better than irrelevant information
(e.g., the colour of the getaway car). Schemas can also cause memory
distortions because we reconstruct an event's details based on "what
must have been true". In a study by Tuckey and Brewer (2003b), some
eyewitnesses saw a robber's head covered by a balaclava (ski mask) so
their gender was ambiguous. Eyewitnesses mostly interpreted the
ambiguous information as being consistent with their bank-robbery
schema. Thus, their recall was systematically distorted by including
information from their bank-robbery schema.

Everyday memory

365

Misinformation effect

KEY TERM

The most obvious reason why eyewitnesses' memories are often inaccurate
is that they fail to attend fully to the crime situation. After all, it
typically occurs suddenly and unexpectedly. However, Loftus and Palmer
(1974) emphasised a different reason -- eyewitness memories are fragile
and can easily be distorted by misleading information provided after the
witnessed event: the misinformation effect.

Misinformation effect The distorting effect on eyewitness memory of
misleading information presented after a crime or other event.

Findings Loftus and Palmer (1974) showed eyewitnesses a film of a car
accident. Afterwards, some were asked "About how fast were the cars
going when they smashed into each other". For other eyewitnesses, the
word "hit" replaced "smashed into". The estimated speed averaged 41 mph
when the verb "smashed" was used versus 34 mph when "hit" was used.
Thus, information implicit in the question influenced memory for the
accident. One week later, all eyewitnesses were asked whether they had
seen any broken glass. There was no broken glass, but 32% of those
previously asked about speed using the verb "smashed" said they had seen
broken glass compared to only 14% of those asked using the verb "hit". A
misinformation effect involving more directly misleading information was
reported by Loftus et al. (1978). Eyewitnesses saw several slides, one
showing a red Datsun car stopping at a stop or yield sign. Afterwards
they were asked, "Did another car pass the red Datsun while it was
stopped at the stop sign?" or the word "stop" was replaced by "yield".
In a third condition, the key question did not refer to a sign at all.
Finally, the eyewitnesses decided which of two slides (car with a stop
sign and car with a yield sign) they had seen previously. Eyewitness
more often selected the wrong slide when the earlier question was
misleading than when it was accurate or did not refer to the sign.
Eyewitness memory can also be distorted by information presented before
an event. Lindsay et al. (2004) showed eyewitnesses a video of a museum
burglary. Eyewitnesses who had listened to a thematically similar
narrative (a palace burglary) the previous day made many more errors
when recalling information from the video than those who had listened to
a thematically dissimilar narrative (a school trip to a palace). This
finding is important because eyewitnesses often have relevant past
experiences that may distort their memory for a crime. The
misinformation effect has generally been found for peripheral or minor
details (e.g., presence of broken glass in the study by Loftus and
Palmer, 1974) rather than central ones. In similar fashion, Putnam et
al. (2017) found the misinformation effect was much greater for
relatively unmemorable than memorable details (see Figure 8.10). Putnam
et al. (2017) pointed out that most textbook accounts assume the
misinformation effect is nearly always found. However, they obtained
contrary evidence. Misinformation led to enhanced recognition memory for
an event when participants detected (and remembered) changes between
that event and the post-event misinformation. What is happening here?

Memory

1.00 False alarm rate: Misinformation condition

366

0.80

r = --0.55

0.60

0.40

0.20

0.00 0.00

0.20

0.40

0.60

0.80

1.00

Hit rate: Neutral condition

Figure 8.10 Size of the misinformation effect as a function of detail
memorability in the neutral condition (i.e., absence of misleading
information). From Putnam et al. (2017).

Misinformation sometimes acts as a cue that facilitates retrieval of
details from the actual event.

Theoretical accounts How does misleading information distort what
eyewitnesses report? Is the original memory permanently altered or does
it still exist but is inaccessible? Loftus (1979) argued misinformation
causes the previously formed memory of an event to be "overwritten" and
destroyed. Loftus (1992) argued for a less extreme position -- the
original memory remains but eyewitnesses "accept" misinformation as
forming part of the event memory. Edelson et al. (2011) had eyewitnesses
watch a crime scene in small groups and then recall the crime events
three days later (Test 1). Four days later, they were misinformed their
fellow eyewitnesses remembered several events differently from them.
This was followed immediately by a memory test (Test 2) during which
their brain activity was recorded. A week later, the eyewitnesses were
told the answers allegedly given by their fellow eyewitnesses had been
generated at random. Finally, they received another memory test (Test
3). Edelson et al. (2011) decided whether eyewitnesses pretended to
agree with the group on Test 2 or whether their memories had genuinely
changed by seeing if they maintained their incorrect answers on Test 3.
Brain activity during Test 2 indicated enhanced connectivity between the
amygdala and hippocampus (both centrally involved in memory formation)
was associated only with memories that had genuinely changed. Edelson et
al.

Everyday memory

(2011, p. 108) concluded that a long-lasting misinformation effect
occurred only when there was a reconsolidation process (see Glossary)
that "modified the neural representation of memory". Oeberst and Blank
(2012) argued misinformation does not cause permanent alteration of
memory traces of a witnessed event. According to them, the
misinformation effect occurs because eyewitnesses are instructed to
recall the single correct account of an event. Oeberst and Blank told
eyewitnesses they had received contradictory information and encouraged
them to recall everything from the event and the misinformation. This
manipulation completely eliminated the misinformation effect! Thus, the
original memory traces were essentially intact. Blank and Launay (2014)
carried out a meta-analysis of studies on the misinformation effect
where eyewitnesses were warned of the presence of misinformation after
viewing an event. Post-warning reduced the misinformation effect to
between one-third and one-half of its size when no warning was provided
(see Figure 8.11). Higham et al. (2017) found the misinformation effect
was eliminated when the post-warning was specific (i.e., it identified
event details for which misinformation had been presented earlier) but
not when it was general (i.e., indicating there had been
misinformation). One reason event memories are inaccessible is source
misattribution (Johnson et al., 1993). In essence, a memory probe (e.g.,
question) activates memory traces overlapping with it in information.
Source misattribution is most likely when the memories from one source
resemble those from a second source (e.g., Lindsay et al., 2004,
discussed above, p. 366). Prull and Yockelson (2013) reported evidence
suggesting the importance of source misattribution. The misinformation
effect was much smaller when eyewitnesses received a source-recognition
test encouraging them to retrieve source information.

7 6 Odds ratio

5 4 3 2 No misinformation eﬀort

1 0 Post-warning

No warning

Original memory

Post-warning

No warning

Misinformation Endorsement

Figure 8.11 Extent of misinformation effects (expressed as an odds
ratio) as a function of condition (post-warning vs no warning) for the
original memory and endorsement of the misinformation presented
previously. From Blank & Launay (2014). Reprinted with permission of
Elsevier.

367

368

Memory

KEY TERM

In sum, the misinformation effect is often due to inaccessibility of
information about the original event rather than altered memory traces.
However, some evidence supports the latter explanation (Edelson et al.,
2011). Overall, the findings suggest the effects of misinformation on
memory performance are not direct. Instead, memory performance is
influenced flexibly by the precise strategies used by eyewitnesses to
combine and integrate the information available to them. Other factors
can also be involved (Wright & Loftus, 2008). One example is the vacant
slot explanation (misinformation is more likely to be accepted when
related information from the original event was not stored in memory).
Another example is the blend explanation (misinformation and information
from the original event are integrated in memory). Finally, the
misinformation effect involves retroactive interference (see Glossary).
Since retroactive interference with standard verbal memory tasks can be
caused by several factors (see Chapter 6), it is unsurprising that the
same is true of retroactive interference for criminal and other events.

Weapon focus effect The finding that eyewitnesses pay so much attention
to the presence of a weapon (e.g., gun) that they ignore other details
and so cannot remember them subsequently.

Weapon focus, anxiety and violence How do anxiety and violence influence
eyewitness memory? There is evidence for the weapon focus effect --
eyewitnesses attend to the criminal's weapon, which reduces their memory
for other information. For example, Biggs et al. (2013) found observers
fixated weapons more than neutral objects and so faces were fixated less
often in the weapon condition. Harada et al. (2015) found observers'
memory for peripheral stimuli was reduced in the presence of a weapon.
This finding is consistent with Easterbrook's (1959) hypothesis.
According to this hypothesis, anxiety causes a narrowing of attention to
central or important stimuli causing a reduction in individuals' ability
to remember peripheral details (see Chapter 15). Pickel (2009) pointed
out that individuals often attend to stimuli that are unexpected in the
current situation (inconsistent with their situational schema), which
impairs their memory for other stimuli. She argued the weapon focus
effect would be greater when the presence of a weapon was very
unexpected. As predicted, the effect was especially strong when a
criminal carrying a folding knife was female, because seeing a woman
with a knife is unexpected. In similar fashion, the weapon focus effect
was stronger when a male criminal carrying a handgun was white rather
than black because of the mistaken stereotype linking black men with
weapons. Fawcett et al. (2013) carried out a meta-analysis on the weapon
focus effect. There was a moderate effect that was comparable in the
laboratory and the real world. Peripheral details were often poorly
remembered when the central object was unusual or unexpected in the
current situation (even when the object was not a weapon). Fawcett et
al. (2016) discussed studies showing the presence of a weapon made it
harder for eyewitnesses to discriminate the culprit from innocent
individuals on a line-up. It also increased the probability of making
false identifications. How do stress and anxiety influence eyewitness
memory? Deffenbacher et al. (2004) carried out a meta-analysis.
Culprits' faces were identified 54%

Everyday memory

of the time in low-stress conditions versus 42% in high-stress
conditions and the findings were comparable for recall of details. Thus,
stress and anxiety generally impair eyewitness memory. Morgan et
al. (2013) considered the effects of very high stress. Military
personnel endured a 3-minute stressful interrogation involving physical
assault (e.g., slamming into a wall; facial slaps). Participants' memory
was generally poor and over 50% failed to identify their interrogator
correctly. One reason stress impairs eyewitness memory is because it
causes a narrowing of attention (see Easterbrook's hypothesis discussed
above). Yegiyan and Lang (2010) presented people with distressing
pictures. As picture stressfulness increased, recognition memory for the
central details improved progressively. In contrast, memory for
peripheral details was much worse with highly stressful pictures than
with moderately stressful ones. Thus, the findings supported
Easterbrook's hypothesis. Note, however, that "memory narrowing" is not
always directly caused by "attentional narrowing" (see Chapter 15).

Ageing and memory Older eyewitnesses' memory is less accurate than that
of younger adults and they exhibit greater misinformation effects.
Jacoby et al. (2005) presented misleading information to younger and
older adults. The older adults had a 43% chance of producing false
memories at recall compared to only 4% for the younger adults. Older
adults have impaired ability to use cognitive control effectively to
focus retrieval on correct information (Keating et al., 2017) and are
also less likely to monitor their own recall to reduce errors (Morcom,
2016). Wright and Stroud (2002) studied differences between younger and
older adults identifying culprits after viewing crime videos. There was
an own-age bias -- both groups performed better when the culprit was of
a similar age to themselves. Eyewitnesses may sometimes attend more
closely to culprits of their own age. However, Neumann et al. (2015)
found young adults did not attend more to young faces than older ones.
Own-age bias might be due to expertise: most people have greater
exposure to (and familiarity with) faces of individuals of their own
age. Wiese et al. (2013) reported supporting evidence. Young geriatric
nurses had no own-age bias because, due to their experience with older
people, they recognised old faces much better than did young controls.

Eyewitness identiﬁcation: face recognition Eyewitness identification
typically depends mainly on face recognition although other factors
(e.g., an individual's build and/or clothing) can be relevant. There is
compelling evidence that most people find it surprisingly hard to
recognise unfamiliar faces; this is of direct relevance to eyewitnesses'
memory for culprits' faces. Poor recognition of unfamiliar faces occurs
in part because different photographs of the same person display
considerable variability and are often regarded incorrectly as coming
from different individuals (see Figure 3.18) (Jenkins et al., 2011;
Young & Burton, 2018).

369

KEY TERMS Own-age bias The tendency for eyewitnesses to identify the
culprit more often when they are of similar age to the eyewitness than
when they are of a different age.

370

Memory

KEY TERMS

The police often ask eyewitnesses to identify the person responsible for
a crime from several individuals physically present in a line-up or
shown in photographs. Valentine et al. (2003) found eyewitness
identification is very fallible. Of 640 eyewitnesses trying to identify
suspects in 314 real lineups, only 40% identified the suspect, 20%
identified a non-suspect and 40% failed to make an identification.
Eyewitnesses who are very confident about face identification tend to be
more accurate than those less confident (Brewer & Wells, 2011). For
example, Odinot et al. (2009) studied the memory of 14 eyewitnesses of
an actual supermarket robbery in the Netherlands. There was a moderate
correlation (+.38) between eyewitness confidence and accuracy. Wixted et
al. (2016; discussed earlier, see p. 364) also found that eyewitness
confidence predicted accuracy of culprit identification in a real-life
study. Eyewitnesses sometimes remember a face but fail to remember the
precise circumstances in which they saw it. Ross et al. (1994) had
eyewitnesses observe an event where a bystander and the culprit were
present. They were three times more likely to select the bystander from
a line-up than someone else not seen before when the culprit was not
present. This is unconscious transference -- a face is correctly
recognised as having been seen before but incorrectly judged to be
responsible for a crime. In similar fashion, eyewitnesses are more
likely to identify a suspect on a line-up if they have previously been
seen in a line-up (Steblay & Dysart, 2016). Another relevant finding is
the other-race effect -- same-race faces are identified better than
other-race faces (Young et al., 2012). Unsurprisingly, eyewitnesses
having the most experience with members of another race have a
relatively small other-race effect (Hugenberg et al., 2010). Contrary to
common belief, the other-race effect does not depend entirely on
problems with remembering other-race faces. Megreya et al. (2013) found
perceptual processes are also involved (see Figure 8.12). British and
Egyptian participants viewed a target face and an array of ten faces.
They decided whether the target face was in the array; if so, they
identified it. There were minimal memory demands on memory as all the
photographs were visible. Megreya et al. obtained the other-race effect:
(1) the target was correctly identified more often with same-race faces
than other-race ones (70% vs 64%, respectively); and (2) when the target
face was absent, mistaken identification of a non-target face was more
frequent with other-race than same-race faces (47% vs 34%,
respectively). Brown et al. (2017) replicated the other-race effect.
There was greater activation of fronto-parietal networks (involved in
top-down attention and cognitive control) during encoding of same-race
than other-race faces. These findings suggest that problems with
remembering other-race effects are due to reduced attention to (and
processing of) such faces. In a study by Jenkins et al. (2011),
observers showed very poor face recognition because photographs of the
same face often show considerable variability (see Chapter 3). As a
consequence, it is generally hard for eyewitnesses to make a correct
identification from a single photograph as they are typically requested
to do. It follows that eyewitnesses' ability to identify unfamiliar
faces might be enhanced if presented with multiple photographs of the
same person.

Unconscious transference The tendency of eyewitnesses to misidentify a
familiar (but innocent) face as being the person responsible for a
crime. Other-race effect The finding that recognition memory for
same-race faces is generally more accurate than for other-race faces.

Everyday memory

371

Figure 8.12 Examples of Egyptian (left) and UK (right) face-matching
arrays. The task was to decide whether the person shown at the top was
present in the array underneath. From Megreya et al. (2013). © Taylor &
Francis.

Jones et al. (2017) tested the above implication. Participants viewed a
single front-view photograph of an individual (the target), seven
photographs of that individual at different orientations or seven
computergenerated synthesised images of that individual at different
orientations (see Figure 8.13). Subsequently, participants selected the
target face from

Figure 8.13 Panel (a): seven photographs of the same individual taken
from different angles; Panel (b): seven synthesised images of the same
individual at different orientations. From Jones et al. (2017).

372

Memory

an array of five faces. As predicted, face-recognition performance was
worst following presentation of a single photograph and best following
presentation of synthesised images. This is important because police can
generate such synthesised images from a single photograph.

From laboratory to courtroom Can we apply findings from laboratory
studies to real-life crimes? There are several differences. First,
eyewitnesses are much more likely to be the victims in real life than
the laboratory. Second, it is much less stressful to watch a video of a
violent crime than to experience it. Third, in laboratory research the
consequences of an eyewitness making a mistake are trivial but can
literally be a matter of life or death in an American trial. There are
also important similarities. Ihlebaek et al. (2003) used a staged
robbery involving two robbers with handguns. In the live condition,
eyewitnesses were ordered repeatedly to "Stay down!". A video taken
during the live condition was presented to eyewitnesses in the video
condition. Eyewitnesses in both conditions exaggerated event duration
and showed similar patterns in what they remembered. However, those in
the video condition recalled more information. In another study (Pozzulo
et al., 2008), eyewitnesses observed a staged theft live or via video.
Eyewitnesses in the live condition reported more stress and arousal but
correct identification of the culprit was comparable in the two
conditions. Tollestrup et al. (1994) analysed police records concerning
the identifications by eyewitnesses to crimes involving fraud and
robbery. Factors important in laboratory studies (e.g., weapon focus;
retention interval) were also important in real-life crimes. In sum,
artificial laboratory conditions typically distort the findings only
modestly. If anything, the errors in eyewitness memory under laboratory
conditions underestimate memory deficiencies for real-life events. This
is due in part to the generally greater stressfulness of witnessing
real-life crimes. Overall, laboratory research is definitely relevant to
the legal system.

ENHANCING EYEWITNESS MEMORY The police obviously have no control over
the circumstances at the time of the crime (e.g., lighting; event
duration). Such uncontrollable factors are known as estimator variables
(Albright, 2017). There are also factors (known as system variables)
that can be controlled by the criminal justice system; they include how
line-ups are presented to eyewitnesses and interview techniques used to
question eyewitnesses. These system variables are discussed below.

Line-ups Line-ups can be divided into those involving double-blind and
those involving single-blind administration. With double-blind
administration, the line-up is conducted by administrators who do not
know which line-up member is the suspect, whereas they do have such
knowledge with singleblind administration. Double-blind administration
is preferable because

Everyday memory

single-blind administration can cause systematic bias in the
identification made by the eyewitness (Kovera et al., 2017). Line-ups
can be simultaneous (the eyewitness sees everyone at the same time) or
sequential (the eyewitness sees only one person at a time). Which
approach is more effective? Steblay et al. (2011) conducted a
meta-analysis. When the culprit was present, they were selected 52% of
the time with simultaneous line-ups compared to 44% with sequential
ones. When the culprit was absent, eyewitnesses mistakenly selected
someone with simultaneous line-ups more often than with sequential ones
(54% vs 32%, respectively). Thus, eyewitnesses adopt a more stringent
criterion with sequential line-ups. Misidentifications with sequential
line-ups in the laboratory can be reduced by providing a "not sure"
option. This reduced misidentifications from 22% to only 12% (Steblay &
Phillips, 2011). Warning eyewitnesses the culprit may not be in the
line-up also reduces misidentification errors (Steblay, 1997). Wells et
al. (2015) carried out a large-scale study differing from most studies
reviewed by Steblay et al. (2011) in two main ways. First, it involved
eyewitnesses to actual crimes rather than videoed or staged laboratory
crimes. Second, the eyewitnesses were permitted to say they were "not
sure" (as happens in most real-life crime cases). In contrast, the great
majority of laboratory studies require eyewitnesses to make definite
"yes" or "no" decisions. What did Wells et al. (2015) find? First, the
suspect was identified 25% of the time with both simultaneous and
sequential line-ups. Second, an innocent person was identified
incorrectly more often with simultaneous than sequential line-ups (18%
vs 11%). Third, eyewitnesses used the "not sure" response more often in
the sequential line-up: eyewitnesses were unsure whether a subsequently
viewed person might resemble the culprit more than the current one.
Wixted et al. (2016) also studied eyewitnesses to real-life crimes and
obtained confidence ratings from these eyewitnesses when exposed to
sequential or simultaneous line-ups. Eyewitnesses identified 91% of
suspects having independent evidence of guilt against them with
simultaneous line-ups compared to 76% with sequential line-ups. When
account was taken of eyewitnesses' confidence ratings, their overall
performance was slightly better with simultaneous line-ups. In sum,
eyewitnesses are more likely to identify the culprit with simultaneous
line-ups. However, innocent individuals are also more likely to be
selected on simultaneous line-ups. Which type of line-up is preferable
depends on the precise magnitude of these two effects.

Cognitive interview Psychologists have contributed substantially to the
goal of maximising the information provided by eyewitnesses being
interviewed by developing the cognitive interview. This is based on four
retrieval rules (Geiselman & Fisher, 1997): (1) (2)

mental reinstatement of the environment and any personal contact
experience during the crime (context reinstatement); encouraging the
reporting of every detail including minor ones;

373

374

Memory

(3) 
(4) 

describing the incident in several different orders (e.g., backwards in
time); reporting the incident from different viewpoints, including those
of other eyewitnesses; Anderson and Pichert (1978) found this strategy
useful (see Chapter 10).

These retrieval rules are based on our knowledge of human memory. The
first two rules derive from the encoding specificity principle (Tulving,
1979; see Chapter 7). According to this principle, recall depends on the
overlap or match between the context in which an event is witnessed and
that at recall. The third and fourth rules are based on the assumption
that memory traces contain several kinds of information. As a result,
crime information can be retrieved using different retrieval routes.
There have been two major changes in the cognitive interview (Memon et
al., 2010a). First, researchers developed an enhanced cognitive
interview. This differed from the basic cognitive interview by
emphasising the importance of creating rapport between interviewer and
eyewitness. Roy (1991, p. 399) indicated how this can be achieved:
Investigators should minimise distractions, induce the eyewitness to
speak slowly, allow a pause between the response and next question,
tailor language to suit the individual eyewitness, follow up with
interpretive comment, try to reduce eyewitness anxiety and avoid
judgemental and personal comments. Second, the police typically shorten
the cognitive interview emphasising the first two retrieval rules
discussed earlier. This is done in part because the entire cognitive
interview can be very time-consuming.

Findings Memon et al. (2010a) carried out a meta-analysis comparing the
cognitive interview with the standard police interview. Many more
details were correctly recalled by eyewitnesses with the cognitive
interview (basic or enhanced). However, its beneficial effects were
reduced in highly arousing situations or with a long retention interval
between the incident and interview. Nevertheless, the cognitive
interview remained effective even with high arousal and a long retention
interval. The main limitation of the cognitive interview was that there
was a fairly small increase in recall of correct details compared to the
standard interview. In addition, the cognitive interview does not reduce
the adverse effects of misleading information presented beforehand
(Menon et al., 2009b). Are all four components of the cognitive
interview equally important? No. Colomb and Ginet (2012) found mental or
context reinstatement of the situation and reporting all the details
both enhanced recall. However, altering the eyewitness's perspective and
changing the order of recall were ineffective. Dando et al. (2011) found
requiring eyewitnesses to recall information in a backward temporal
order reduced correct recall and increased memory errors. These negative
effects occurred because backward recall disrupted the temporal
organisation of eyewitness memory for the crime.

Everyday memory

How can we increase eyewitness accuracy using the cognitive interview?
Paulo et al. (2016) found eyewitnesses' error rate was 6% when they
seemed certain of what they were recalling but 23% when they seemed
uncertain. Thus, accuracy can be improved by taking account of
eyewitnesses' confidence. Paulo et al. (2017) adapted the cognitive
interview to include category clustering recall -- eyewitnesses
organised their recall in categories (e.g., person details; location
details; action details). This produced enhanced recall compared to the
standard cognitive interview and reduced errors. Category clustering
recall was effective because it provided eyewitnesses with cues
providing an organised structure to facilitate retrieval of event
information.

375

KEY TERMS Retrospective memory Memory for events, people and so on
experienced in the past; see prospective memory. Prospective memory
Remembering to carry out some intended action in the absence of an
explicit reminder to do so; see retrospective memory.

Evaluation The cognitive interview has a well-established theoretical
and empirical basis. It is an effective method for obtaining as much
accurate information as possible from eyewitnesses under most
circumstances. There is increasing evidence concerning the relative
effectiveness of the four main components of the cognitive interview.
Potentially important refinements of the cognitive interview (e.g.,
category clustering recall; taking account of eyewitnesses' confidence)
have been proposed. What are the main limitations with the cognitive
interview? First, the small increase in incorrect eyewitness recall can
lead detectives to misinterpret the evidence. Second, it does not reduce
the negative effects of misinformation. Third, mental or context
reinstatement can have a negative effect on recognition memory by
increasing the perceived familiarity of non-target faces (Wong & Read,
2011). Fourth, the cognitive interview is less effective when the
witnessed event was stressful and there is a long delay between the
event and the interview.

PROSPECTIVE MEMORY The great majority of memory studies have focused on
retrospective memory, in which the emphasis is on the past (especially
individuals' ability to remember previous events or knowledge stored in
long-term memory). In contrast, prospective memory is "the cognitive
function we use for formulating plans and promises, for retaining them,
and for recollecting them subsequently either at the right time or on
the occurrence of appropriate cues" (Graf, 2012, pp. 7--8). Examples
include remembering to go to meet a friend at a coffee shop or to attend
a revision session for a course in psychology. Failures of prospective
memory are responsible for at least 50% of everyday memory problems.
Tragic events occurring as a result of failures of prospective memory
also indicate its importance. Einstein and McDaniel (2005, p. 286)
discussed an example: After a change in his usual routine, an adoring
father forgot to turn toward the day-care centre and instead drove his
usual route to work at the university. Several hours later, his infant
son, who had been quietly asleep in the back seat, was dead.

Case study: Cognitive interview and eyewitness confidence

376

Memory

KEY TERMS

Prospective memory vs retrospective memory

Time-based prospective memory A form of prospective memory which
involves remembering to carry out an intended action at the appropriate
time. Event-based prospective memory A form of prospective memory that
involves remembering to perform an intended action (e.g., buying
groceries) when the circumstances are appropriate.

How different are retrospective and prospective memory? Failures of the
two types of memory are interpreted differently (Graf, 2012). Failures
of prospective memory involving promises to another person are often
regarded as indicating poor motivation and reliability. In contrast,
failures of retrospective memory are attributed to poor memory. Thus,
deficient prospective memory means a "flaky person" whereas deficient
retrospective memory a means "faulty brain" (Graf, 2012). There are
other differences: (1)

(2) 
(3) 
(4) 

Retrospective memory generally involves remembering what we know about
something and can be high in informational content (Baddeley et al.,
2015). In contrast, prospective memory typically focuses on when to do
something and has low informational content. Prospective memory is more
relevant to our everyday plans and goals. More external cues (e.g.,
"What did you have for breakfast yesterday?") are typically available
with retrospective than prospective memory. Anderson and McDaniel (2019)
found in a naturalistic study that only 39% of individuals'
prospective-memory thoughts were triggered by external cues. Prospective
memory is the form of memory "in which the problem is not memory itself,
but the uses to which memory is put" (Moscovitch, 2008, p. 309).

Remembering and forgetting often involve both prospective and
retrospective memory. For example, achieving the task of buying goods
from the local supermarket requires memory of the intention to go there
(prospective memory) and memory of what you had decided to buy
(retrospective memory). Crawford et al. (2003) identified separate
prospective and retrospective memory factors from a questionnaire
designed to assess prospective and retrospective memory. There was also
a general memory factor based on elements of prospective and
retrospective memory. In sum, there are several similarities and
differences between prospective and retrospective memory. McBride and
Workman (2017) provide a thorough review.

Event-based vs time-based prospective memory There is an important
distinction between time-based and event-based prospective memory.
Time-based prospective memory involves performing a given action at a
particular time (e.g., phone a friend at 8 pm). Eventbased prospective
memory involves performing an action in the appropriate circumstances
(e.g., passing on a message when you see a given person).
Unsurprisingly, performance on event-based tasks depends in part on the
accuracy (or inaccuracy) of any given individual's time estimation
(Waldum & McDaniel, 2016). There has been much more research on
event-based prospective memory. With event-based tasks, researchers can
manipulate the precise

Everyday memory

nature and timing of cues indicating the intended action should be
performed. That provides more control over retrieval conditions than is
generally possible with time-based tasks. In the real world, the
requirement to use prospective memory typically occurs while individuals
are busily involved in performing some unrelated task. Most laboratory
research is similar because participants are generally engaged in an
unrelated ongoing task while performing a prospective-memory task.
Event-based tasks tend to be easier than time-based tasks. For example,
Kim and Mayhorn (2008) found event-based prospective memory was superior
under both laboratory and naturalistic conditions because the intended
actions are more likely to be triggered by external cues on event-based
tasks. Hicks et al. (2005) confirmed event-based tasks are generally
less demanding than time-based ones. However, both kinds of tasks were
more demanding when the task was ill-specified (e.g., detect animal
words) rather than well-specified (e.g., detect the words nice and hit).
A well-specified timebased task was no more demanding than an
ill-specified event-based task. The strategies used on time-based and
event-based tasks often differ considerably. The occurrence of
prospective-memory cues is typically more predictable on time-based
tasks. As a result, individuals generally engage in only sporadic
monitoring of prospective-memory cues on time-based tasks with this
monitoring increasing as the occurrence of the cue approaches (Cona et
al., 2015). In contrast, as we will see, there is much more evidence of
continuous monitoring on event-based tasks because of unpredictability
concerning the cue's occurrence. Cona et al. (2015) showed the
importance of predictability with event-based tasks: the pattern of
monitoring resembled that typically found with time-based tasks when the
occurrence of prospective-memory cues was predictable.

Stages in prospective memory Prospective memory typically involves
several separate processes or stages. As a consequence, there are
various ways prospective memory can fail. Zogg et al. (2012) provided a
sketch map of the main processes/stages involved (see Figure 8.14): (1)

(2) 
(3) 
(4) 

Intention formation: the individual forms or encodes an intention linked
to a specific cue (e.g., "I will discuss the weekend with my friend when
I see him"). Retention interval: there is a delay (minutes, hours or
weeks) between intention formation and intention execution. As we have
seen, there is typically frequent environmental monitoring for event
cues on eventbased tasks but sporadic monitoring for time cues on
time-based tasks. Cue detection and intention retrieval: the individual
detects and recognises the relevant cue (e.g., sighting your friend;
seeing it is 4 o'clock); this is followed by self-initiated retrieval of
the appropriate intention. Intention recall: the individual retrieves
the intention from retrospective memory; there may be problems because
of the intention's complexity, its relationship to other stored
intentions or the presence of competing intentions.

377

KEY TERM ongoing task A task performed at the same time as a
prospective-memory task in studies on prospective memory.

378

Memory

Figure 8.14 A model of the component processes involved in prospective
memory. Intention formation is followed by monitoring for event and/or
time cues. Successful monitoring leads to cue detection and intention
retrieval, intention recall and intention execution. From Zogg et
al. (2012). Reprinted with permission of Springer Science+Business
Media.

(5) 

Intention execution: this is typically fairly "automatic" and
undemanding.

Prospective memory in real life In this section, we discuss prospective
memory in various groups of people. In the Box, we consider individuals
(e.g., pilots; air traffic controllers) for whom forgetting of intended
actions can prove fatal. We also discuss people often regarded as having
poor prospective memory.

IN THE REAL WORLD: PLANE CRASHES -- PILOTS AND AIR TRAFFIC CONTROLLERS
Dismukes and Nowinski (2006) studied pilot errors involving memory
failures. There were failures of prospective memory in 74 out of 75
incidents or accidents! There was an almost total absence of
retrospective memory failures because pilots have excellent knowledge
and memory of the operations needed to fly a plane. Here is an example
of a plane crash caused by failure of prospective memory. On 31 August
1988, a Boeing 727 (Flight 1141) was in a long queue awaiting departure
from Dallas-Fort Worth airport. The air traffic controller unexpectedly
told the crew to move up past the other planes to the runway. This
caused the crew to forget to set the wing flaps and leading edge slat to
15 degrees (a failure of prospective memory). As a result, the plane
crashed beyond the end of the runway leading to several deaths. What
causes pilots to exhibit prospective-memory failures? Relevant evidence
was reported by Latorella (1998). Commercial pilots interrupted while
flying a simulator made 53% more errors than those not interrupted. Such
interruptions are relatively common. Gontar et al. (2017) discovered
pilots on average experienced eight interruptions (e.g., from
colleagues; from outside the cockpit) during preparations for each
flight. Unsurprisingly, the adverse effects of interruption on task
performance are greater with longer interruptions (Altmann et al.,
2017).

Everyday memory

379

Interruptions increase performance errors because they impair
prospective memory for intentions that could not be performed at the
typical point in a sequence of actions. More specifically, we can
explain the effects of interruptions with Shelton and Scullin's (2017)
dynamic multiprocess framework (discussed later, pp. 382--386).
According to this framework, we can remember to perform an intended
action because of bottom-up processes (e.g., encountering a relevant
cue). When pilots are not interrupted, each item in an action sequence
cues the next action. Such cueing is lacking if actions are performed
out of sequence. According to Shelton and Scullin (2017), we can also
remember to perform an intended action because of top-down processes
(i.e., monitoring for cues and rehearsing the intention). It is
effortful using these processes when one is interrupted during task
performance (Altmann et al., 2017). As a result, pilots can find it
difficult to continue with a sequence of actions while monitoring and
rehearsing. How can we reduce pilot errors following interruptions?
Engaging in effortful top-down processes is one answer. Alternatively,
retrieval cues such as the humble egg timer could be used to remind
pilots to resume an interrupted task (Gontar et al., 2017). For example,
pilots might only activate an egg timer when some task has been
interrupted and will need to be attended to shortly. Errors made by air
traffic controllers often involve prospective memory (failures to
perform intended actions while monitoring a display). Loft and Remington
(2010) found prospectivememory errors by participants in a simulated air
traffic control task were more common when interruptions led them to
deviate from well-practised or strong routines rather than
less-practised ones. This is important because air traffic controllers
(and pilots) devote much of their time to habitual tasks involving
strong routines. Such tasks are carried out fairly "automatically" due
to habit capture which can cause prospective-memory failures when
something unexpected happens (Dismukes, 2012).

5000 15%

4000 Response time

Resumption failure proportion

20%

10%

5%

3000 2000 1000

0%

2.37%

3.39%

10.85%

No-interruption

Blank

ATC

0

2369

4501

4951

No-interruption

Blank

ATC

Figure 8.15 Mean failures to resume an interrupted task (left side) and
mean resumption times in msec (right side) for the conditions:
no-interruption, blank-screen interruption and secondary air traffic
control task interruption. From Wilson et al. (2018).

Wilson et al. (2018) explored the effects of interruptions on a
simulated air traffic control task. There were three conditions: (1)
interruption involved a blank screen; (2) interruption involved a
secondary air traffic control (ATC) task resembling the main one; and
(3) a no-interruption control

380

Memory

condition. Both interruption conditions increased the time taken to
resume the main air traffic control task (see Figure 8.15) because
participants took some time to re-activate information relevant to the
main ATC task. In addition, there were more failures to resume the
interrupted task following a secondary ATC task than in the other two
conditions because the demands of the secondary task caused increased
forgetting of the interrupted task. Loft et al. (2013, 2016) found
prospective-memory errors were reduced when flashing visual aids
accompanied the appearance of target planes. However, participants
experiencing severe scheduling demands sometimes failed to take
advantage of these visual aids.

Obsessive-compulsive disorder and checking behaviour

KEY TERMS Obsessive-compulsive disorder (OCD) An anxiety disorder in
which the symptoms include unwanted thoughts (obsessions) and repetitive
behaviours (compulsions) in response to those thoughts. Meta-memory
Beliefs and knowledge about one's own memory including strategies for
learning and memory.

Most patients with obsessive-compulsive disorder (OCD) have checking
compulsions. They check repeatedly they have locked their front door,
the gas has been turned off and so on but remain uncertain whether they
have actually performed their intended actions. How can we explain this
checking behaviour? Perhaps obsessional individuals have poor
retrospective memory ability causing them to forget whether they have
recently engaged in checking behaviour. However, compulsive checkers are
generally comparable to healthy controls in retrospective memory
(Cuttler & Graf, 2009a). Perhaps checkers have poor prospective memory.
Cuttler and Graf (2009b) found checkers had impaired performance on
event-based and timebased prospective-memory tasks. Similarly, Yang et
al. (2015) found patients with OCD had impaired performance on
time-based tasks and were slower than controls on event-based tasks.
Yang et al. reported evidence the poor prospective memory of OCD
patients involved impaired mental flexibility. It is possible poor
prospective memory leads obsessionals to engage in excessive checking.
However, excessive checking may lead to poor prospective memory. Suppose
you check several times every day you have locked your front door. You
would remember you had checked it numerous times. However, you might
well be unsure whether you have checked your front door today because of
all the competing memories. Van den Hout and Kindt (2004) asked some
participants to engage in repeated checking of a gas stove. On the final
trial, those checking repeatedly had less vivid and detailed memories of
what had happened. Linkovski et al. (2013) carried out a similar study.
They also assessed participants' level of inhibitory control because
obsessional patients have deficient inhibitory control, which may lead
to intrusive thoughts and memory problems. What did Linkovski et
al. (2013) find? Repeated checking did not impair prospective-memory
performance. However, it reduced memory vividness and detail and also
lowered participants' confidence in their memory. These effects were all
much stronger in participants with poor inhibitory control (see Figure
8.16). Toffolo et al. (2016) emphasised the distinction between memory
performance (i.e., memory accuracy) and meta-memory (knowledge and
beliefs about one's own memory). Meta-memory encompasses measures of
memory confidence, memory vividness and memory detail. Toffolo et
al. identified three main research findings:

Everyday memory

Figure 8.16 Self-reported memory vividness, memory details and
confidence in memory for individuals with good and poor inhibitory
control before (pre-) and after (post-) repeated checking. From
Linkovski et al. (2013). Reprinted with permission of Elsevier.

(1) 
(2) 
(3) 

Patients with OCD engage in more checking behaviour than those lacking
obsessional tendencies. Repeated checking typically produces large
reductions in metamemory ratings which are comparable in OCD patients
and controls (e.g., Radomsky et al., 2014). Even though repeated
checking reduces meta-memory ratings substantially, it typically has no
effect on memory accuracy (e.g., Radomsky et al., 2014).

In sum, patients with OCD often exhibit impaired prospective memory. The
following conclusions seem warranted: Even though it is still unknown
what comes first (the tendency to use more checking behaviour in general
or OCD), . . . when people who are vulnerable for OCD use more checking,
this may \[reduce\] memory confidence. This may subsequently lead to the
vicious cycle of increased checking behaviour and memory distrust,
eventually contributing to the development of new OC \[obsessional
compulsive\] symptoms. (Toffolo et al., 2016, p. 60) Purdon (2018)
discusses further evidence for the notion that checking behaviour
impairs memory confidence. She also argues that patients with OCD have a
need for certainty that contributes to their excessive checking
behaviour.

THEORETICAL PERSPECTIVES ON PROSPECTIVE MEMORY Our main emphasis here is
on event-based prospective memory. What typically happens is that two
tasks are performed during the same period of time. One task is the
ongoing task and the other is the prospective-memory task. As we will
see, performance on the prospective-memory task depends on its
relationship to the ongoing task.

381

382

Memory

KEY TERMS

The multiprocess framework (Einstein and McDaniel, 2005) has been very
influential. According to this framework, various cognitive processes
(including attentional ones) are used during prospective-memory tasks.
However, the detection of cues for response is typically "automatic"
(i.e., not requiring attentional processes) when the following criteria
(especially the first) are fulfilled:

Focal task An ongoing task that involves similar processing to that
involved in encoding the target on a prospective-memory task performed
at the same time; see non-focal task. Non-focal task An ongoing task
that involves different processes to those involved in encoding the
target on a prospectivememory task performed at the same time; see focal
task.

(1) 
(2) 
(3) 
(4) 

The ongoing task is a focal task -- one that "encourages processing of
the target \[on the prospective-memory task\] and especially those
features that were processed at encoding \[of the prospective-memory
target\]" (McDaniel et al., 2015, p. 2). Here is an example: the ongoing
task requires participants to decide whether each letter string is a
word and the prospective-memory task involves responding to the word
"sleep". The cue on the prospective-memory task and the to-be-performed
action are highly associated. The cue is conspicuous or salient. The
intended action is simple.

McDaniel et al. (2015) developed the multiprocess framework into the
dual-pathways model (see Figure 8.17) based on the distinction between
focal and non-focal ongoing tasks. A non-focal task "does not encourage
processing of those features . . . processed at encoding \[of the
prospective-memory target\]" (p. 2). For example, the ongoing task
requires participants to decide whether each letter string is a word and
the prospective-memory task involves responding to words starting with
the letter r. Thus, there is much less overlap between the processing
required on the prospective-memory and ongoing tasks when the latter is
non-focal. It is assumed the processes typically used with focal and
non-focal tasks differ substantially (see Figure 8.17). Strategic
monitoring involves top-down attentional control processes to maintain
the prospectivememory intention and to search for relevant cues on that
task. It is used much more often with non-focal than with focal tasks.
According to the dual-pathways model, retrieval on the prospectivememory
task can occur in two ways: (1) spontaneous retrieval involves bottom-up
processes triggered by the relevant stimulus and does not require prior
monitoring; (2) intentional retrieval is based more on top-down
processes and requires prior monitoring. Non-focal tasks involve
intentional retrieval. In contrast, focal tasks generally involve
spontaneous retrieval but can also involve intentional retrieval.
Finally, the main brain areas associated with the cognitive processes
involved in prospective memory are identified. Shelton and Scullin
(2017) presented a dynamic multiprocess framework largely consistent
with the dual-pathways model. Two cognitive processes underlie
successful prospective-memory performance: (1) (2)

Monitoring: this involves top-down attentional control to search for
cues indicating the prospective-memory action should be performed.
Spontaneous retrieval: this involves bottom-up processing triggered by
processing a cue.

Everyday memory

Non-focal

Figure 8.17 The dual-pathways model of prospective memory (based on the
multiprocess framework) for non-focal and focal tasks separately. The
solid black arrows indicate the sequence of processing over time. The
dashed-line arrows indicate that strategic monitoring processes are
sometimes involved even with focal tasks.

Focal

Maintenance Sustained activation

Encoding

Strategic monitoring: DLPFC, VLPFC, insula, anterior cingulate, FEF,
lateral BA 10, BA 47, precuneus

Retrieval Transient activation

From McDaniel et al. (2015).

Intentional retrieval:

Spontaneous retrieval:

BA 40, insula, lateral BA 10, anterior cingulate

Ventral frontoparietal network, BA 9, MTL, especially hippocampus

Example 1: Monitoring only view Context:

Committee meeting

Oﬃce

Driving home

Remember to pick up wine after work.

Are you going to the holiday party?

Advertisement

Store sign

Top-down processes No monitoring

Example 2: Spontaneous retrieval only view Context:

Committee meeting

Oﬃce

Driving home

Remember to pick up wine after work.

Are you going to the holiday party?

Advertisement

No monitoring

Spontaneous retrieval

Spontaneous retrieval

Spontaneous retrieval

Example 3: Dynamic multiprocess view Committee meeting

Oﬃce

Driving home

Remember to pick up wine after work.

Are you going to the holiday party?

Advertisement

Store sign

Top-down processes No monitoring

Spontaneous retrieval

Figure 8.18 Example 1: top-down monitoring processes operating in
isolation; Example 2: bottom-up spontaneous retrieval processes
operating in isolation; Example 3: dual processes operating dynamically.
From Shelton and Scullin (2017).

Store sign

Top-down processes

Context:

383

Spontaneous retrieval

What determines which process is used? First, monitoring is effortful
and often impairs ongoing task performance because it creates
competition for processing capacity. As a consequence, monitoring is
rarely used when the ongoing task is important (e.g., a committee
meeting). Second, monitoring is used primarily when prospective-memory
cues are expected (e.g., when close to a wine shop as shown in Figure
8.18).

384

Memory

KEY TERMS

Third, Shelton and Scullin (2017) assumed top-down and bottom-up
processes interact dynamically on prospective-memory tasks. For example,
monitoring depends importantly on meta-cognition (knowledge and beliefs
about one's own cognitive processes and performance). Suppose you
perform a prospective-memory task. If you are confident the task will be
easy (e.g., there will be strong retrieval cues), you might choose to
rely on spontaneous retrieval rather than monitoring. However, if you
expect the task to be difficult (e.g., retrieval cues will be weak or
non-existent), you would probably choose to use extensive monitoring. In
sum, the dynamic multiprocess framework differs from previous theories
in that the processing strategies used on prospective-memory tasks are
flexibly influenced by meta-cognitive processes. The multiprocess theory
is less flexible -- it assumes processing on prospective-memory tasks is
predominantly determined by the task (focal vs non-focal).

Meta-cognition Beliefs and knowledge concerning one's own cognitive
processes and likely level of performance.

Findings The requirement to perform a prospective-memory task at the
same time as an ongoing task generally leads to impaired performance on
the ongoing task. According to the above theories, this occurs when the
ongoing and prospective-memory tasks compete for processing resources.
Such competition is especially great when demanding top-down processes
(e.g., monitoring) are used on the prospective-memory task. Support for
the above theoretical assumptions was reported by Moyes et al. (2019).
They found impaired performance on the ongoing task when it was
non-focal and so demanding processing (especially monitoring) was
required on the prospective-memory task. In contrast, performance was
not impaired on the ongoing task when it was focal and so demanding
monitoring processes on the prospective-memory task were not required.
In spite of findings such as those of Moyes et al. (2019), the above
theoretical assumptions are oversimplified. Rummel et al. (2017) argued
the requirement to perform two tasks at the same time reduces
mind-wandering (task-unrelated thoughts) as participants try to cope
with the overall processing demands. They obtained clear support for
this argument. Rummel et al. (2017) also found performance on a
prospectivememory task was much better (71% vs 42%) when financial
incentives were provided for good performance. Strikingly, the extra
processing resources invested in the prospective-memory task when
incentives were provided did not affect performance on the ongoing task
because incentives reduced participants' mind-wandering. Support for the
general approach of the dual-pathways model was reported by McDaniel et
al. (2013). They argued the monitoring required to perform a non-focal
task would involve top-down attentional control. As a result, there
would be sustained activity in the anterior prefrontal cortex, an area
associated with attentional control. In contrast, the lesser demands of
a focal task would produce only transient activity in that brain area.
That is precisely what they found (see Figure 8.19). Cona et al. (2016)
conducted a meta-analysis of neuroimaging studies involving focal and
non-focal tasks. As predicted by the dual-pathways model, patterns of
brain activity differed between these two task types

Everyday memory

385

Figure 8.19 (a) Sustained (PM Sus) and (b) transient (PM) activity in
the left anterior prefrontal cortex (c) for non-focal (blue) and focal
(red) prospective-memory (PM) tasks. The other conditions shown (i.e.,
CTL, Ong PM and Ong CTL) are not of theoretical relevance. From McDaniel
(2013). Reprinted with permission of the Association for Psychological
Science.

during maintenance and retrieval. Overall, non-focal tasks were
associated with more activity in parts of the anterior prefrontal cortex
(BA10). In contrast, focal tasks were associated with more activity than
focal ones in the anterior cerebellum, ventral parietal regions (BA40)
and BA9. Cona et al. (2016, p. 1) concluded as follows: "Prospective
remembering is mediated mainly by top-down and stimulus-independent
processes in non-focal, but by more automatic, bottom-up, processes in
focal tasks." According to the dual-pathways model, automatic cue
detection sometimes occurs on prospective-memory tasks. Beck et
al. (2014b) provided relevant evidence. Participants initially performed
a block of trials with an ongoing task and a prospective-memory task.
This was followed by a block of trials where they were instructed not to
perform the prospective-memory task even though prospective-memory
targets appeared. These instructions presumably prevented deliberate
target monitoring. Nevertheless, targets in this second block were
associated with activation in brain regions (e.g., the ventral parietal
cortex) associated with spontaneous retrieval. Scullin et al. (2010)
also obtained findings suggesting the existence of spontaneous retrieval
of prospective-memory cues. They almost eliminated monitoring for
prospective-memory cues by presenting only a single prospective-memory
target after over 500 trials and by emphasising the importance of the
ongoing task. This target was detected by 73% of participants when on a
focal task but only 18% on a non-focal task. This is consistent with the
model's assumption that spontaneous retrieval occurs much more often
with focal tasks. We turn now to the role of meta-cognition (emphasised
within the dynamic multiprocess framework). Clear evidence of its
importance was shown by Lourenço et al. (2015). Two tasks were performed
at the same time: (1) an ongoing lexical decision task (see Glossary);
(2) a prospective-memory

386

Memory

task that involved responding to animal words. During practice, the
target animal words were atypical (e.g., raccoon) or typical (e.g.,
dog). On the following experimental trials, only atypical animal words
were presented as prospective-memory targets. What did Lourenço et
al. (2015) discover? We will focus on participants for whom the target
words on the prospective-memory task were typical during practice but
atypical on experimental trials. These participants showed little or no
monitoring during the initial experimental trials because they expected
the prospective-memory task to be easy. However, they used monitoring
much more when they realised that task was actually harder than they had
expected. The take-home message is that strategy use is flexible: our
use of monitoring increases (or decreases) as a result of experience and
expectation. Suppose you perform an ongoing task of counting the number
of living objects presented on a screen containing approximately 20
objects. At the same time, you must perform a prospective-memory task of
detecting a given target (e.g., apple) presented in the upper right
corner of the screen. On some trials, an object semantically related to
the target (e.g., banana) is presented on the ongoing task. According to
the dynamic multiprocess framework, fixating the semantically related
object should often cause spontaneous retrieval of the intention on the
prospective-memory task. This in turn should lead to monitoring
(revealed by rapid fixation on the upper right corner of the screen).
Shelton and Christopher (2016) carried out the experiment described in
the previous paragraph. Their findings were precisely as predicted by
the dynamic multiprocess framework (see Figure 8.20). Thus, top-down
monitoring is often triggered by bottom-up spontaneous retrieval. In
sum, performance on most prospective-memory tasks is determined by
interactive bottom-up (e.g., spontaneous retrieval) and top-down (e.g.,
monitoring) processes. The various theories discussed are mostly
consistent with each other. However, the dynamic multiprocess framework
has advanced our understanding with its assumption that the strategies
used on prospective-memory tasks are flexibly influenced by
meta-cognitive processes.

5

Figure 8.20 Frequency of cue-driven monitoring following the
presentation of semantically related or unrelated cues; there was no
prospectivememory task in the control condition. From Shelton and
Christopher (2016).

Monitoring frequency

4.5 4 3.5 3 2.5

Related cue

2

Unrelated cue

1.5 1 0.5 0 Prospective memory

Control

Everyday memory

Improving prospective memory Failures of prospective memory caused by
task interruptions can be reduced by forming an explicit intention to
resume the interrupted task (Dodhia & Dismukes, 2009). Alternatively, we
can place distinctive reminder cues where they will be seen at the
appropriate time (Dismukes, 2012). For example, if you need to take a
book into college tomorrow, you could leave it close to your keys.
Motivation is also important. Cook et al. (2015) found prospective
memory was better using monetary rewards for good performance or
monetary punishments for poor performance (Cook et al., 2015). These
benefits were achieved without impairing performance of the ongoing
task. These findings may have occurred because of reduced mind-wandering
(Rummel et al., 2017, discussed earlier, p. 384) in the high-motivation
conditions. A relatively simple (but effective) technique for enhancing
prospective memory is based on Gollwitzer's notion of implementation
intentions: "'If situation Y is encountered, then I will perform the
goal-directed response Z!' Thus, implementation intentions define
exactly when, where, and how one wants to act toward realizing one's
goals" (Gollwitzer, 2014, p. 306). Chen et al. (2015) found in a
meta-analysis that implementation intentions enhanced prospective
memory. Why are implementation intentions effective? Scullin et
al. (2017) asked participants what they were thinking shortly after
receiving implementation-intention instructions. These instructions
increased the tendency for participants to focus on specific aspects of
the prospective-memory task and reduced mind-wandering. Gollwitzer
argued that forming an implementation intention is like forming an
"instant habit" that reduces the processing costs when intentions are
retrieved on a prospective-memory task. Support was reported by Rummel
et al. (2012). Participants receiving implementation intentions
performed better on a prospective-memory task within an ongoing task.
They also included trials where participants were told not to respond to
target words from the prospective-memory task. These target words caused
more disruption to the ongoing task (see Glossary) for participants
previously given implementation intentions. This happened because
participants were more likely to retrieve their intentions relatively
"automatically".

Overall evaluation There are several ways progress has been made in
understanding prospective memory: (1) (2) (3)

The number and nature of the processes involved have been identified
with increasing clarity. Reasons for prospective-memory failures in
various groups (e.g., pilots; obsessional individuals) have been
identified. There have been several theoretical advances. The dynamic
multiprocess framework (Shelton & Scullin, 2017) provides a coherent
account of most findings with its emphasis on complex interactions
between top-down and bottom-up processes.

387

KEY TERM Implementation intentions Action plans designed consciously to
achieve some goal (e.g., healthier eating) based on specific information
concerning where, when and how the goal will be achieved.

388

Memory

(4) 
(5) 

The cognitive neuroscience approach has identified brain areas
associated with different prospective-memory processes. Researchers are
developing a new field of "prospection" or future thinking including
prospective memory.

What are the limitations of theory and research on prospective memory?
First, it is assumed within several theories (e.g., the dual-pathways
model; see Figure 8.17) that monitoring will typically be used with
nonfocal ongoing tasks. However, this is not entirely correct. Anderson
et al. (2018) instructed participants to engage in monitoring on every
trial on the prospective-memory task or simply instructed them to
perform that task. Both groups engaged in monitoring but the former
group did so to a greater extent: they detected 73% of
prospective-memory targets compared to only 59% for the latter group.
Second, most theories de-emphasise individual differences in processing
on prospective-memory tasks. For example, Scullin et al. (2018) gave
participants the task of pressing the Q key whenever they saw a word
belonging to the category of "fruits". Thus, they should have encoded
fruit as an abstract category. However, participants often encoded fruit
as a specific example (e.g., apple), or they hardly thought at all about
the instruction to focus on "fruits" (see Figure 8.21). Third,
participants in most laboratory experiments lack strong incentives to
exhibit good prospective-memory performance. In contrast, the incentives
in real life can include saving lives (e.g., air traffic controllers).
Fourth, moment-by-moment decisions to use top-down or bottom-up
processes often involve meta-cognition (Shelton & Scullin, 2017).
However, much remains to be discovered about meta-cognitive processes.
Fifth, the processes involved in prospective memory are more complex
than typically assumed. For example, the joint demands of performing a
prospective-memory task and an ongoing task produce a reduction in
mind-wandering (Rummel et al., 2017). Our limited understanding of the
factors determining mind-wandering often makes it hard to predict
prospective-memory performance.

Hardly thought about it 22.5%

Figure 8.21 Different ways the instruction to press Q for fruit words
was encoded. From Scullin et al. (2018).

Specific exemplar bias 26.4%

Category bias 51.1%

Everyday memory

Sixth, prospective memory in everyday life differs from the laboratory
because it is more common in everyday life to maintain our intentions
for long periods of time, which reduces the involvement of attentional
and monitoring processes.

CHAPTER SUMMARY •

Introduction. What people remember in traditional memory studies is
largely determined by the experimenter's demands for accuracy. In
contrast, remembering in everyday life is determined by our personal
goals. Tailoring our message to create an impression causes subsequent
memory distortions. Memory research should strive for generalisability
and representativeness. The distinction between traditional and everyday
memory research is imprecise.

•

Autobiographical memory: introduction. Autobiographical memories
generally have greater personal significance and complexity than
episodic memories and can involve semantic memory. Autobiographical
memory helps to maintain social bonds, a sense of self-continuity and
self-enhancement. Individuals with highly superior autobiographical
memory often have obsessional symptoms and devote much time to thinking
about past events. Flashbulb memories are perceived as more vivid than
other memories even though they are often inaccurate and have only
moderate consistency. Flashbulb memories generally resemble other
memories in their susceptibility to interference and forgetting.

•

Memories across the lifetime. There is infantile amnesia for memories of
the first two years of life. It occurs because the cognitive self only
emerges towards the end of the second year of life and because of
hippocampal neurogenesis (generation of new neurons within the
hippocampus). Relative amnesia for the preschool years ends when
children have a good command of language. The reminiscence bump for
important personal memories is much stronger for positive memories than
negative ones because the retrieval of autobiographical memories is
often guided by the life script.

•

Theoretical approaches to autobiographical memory. According to the
self-memory system model, autobiographical information is stored
hierarchically. An individual's goals and personality influence the
retrieval of autobiographical memories. Autobiographical memories can be
accessed via direct or generative retrieval. The prefrontal cortex
(associated with controlled processing) and the amygdala (involved in
emotional processing) are activated during autobiographical retrieval.
Several interconnected brain networks are involved in autobiographical
retrieval, with the brain areas activated shifting between initial
searching for memories and their subsequent elaboration. Depressed
individuals exhibit over-general

389

390

Memory

autobiographical memory. Therapy to increase the specificity of
depressed patients' autobiographical memories has proved successful in
reducing depressive symptoms. •

Eyewitness testimony. Eyewitnesses' initial confidence in their initial
identification provides valid evidence concerning its accuracy.
Eyewitness memory is influenced by several factors including
confirmation bias, stress and ageing. Misinformation typically produces
distorted eyewitness memory but often does not cause permanent
alteration of memory traces. Misinformation can enhance eyewitness
memory if it acts as a cue facilitating retrieval of an event.
Eyewitness memory for faces is affected by the crossrace effect, and
also by difficulties in recognising a given unfamiliar face from
different photographs of that person.

•

Enhancing eyewitness memory. Culprits are more likely to be identified
from simultaneous than from sequential line-ups, but more innocent
individuals are identified with simultaneous line-ups. Which type of
line-up is preferable depends on the magnitude of these two effects. The
cognitive interview leads eyewitnesses to produce many more detailed
memories with a small increase in inaccurate memories. Inaccurate
memories can be detected because eyewitnesses often have low confidence
in the accuracy of such memories. Mental reinstatement and the
requirement to report all details are both crucial to the success of the
cognitive interview.

•

Prospective memory. Prospective memory involves successive stages of
intention formation, monitoring, cue detection, intention retrieval and
intention execution. Event-based prospective memory is often better than
time-based prospective memory because the intended actions are more
likely to be triggered by external cues. Many failures of prospective
memory (e.g., by pilots) occur when individuals are interrupted while
carrying out an action plan and lack time to form a new plan.
Individuals with obsessive-compulsive disorder engage in excessive
checking behaviour which may reduce their confidence in their
prospective-memory ability.

•

Theoretical perspectives on prospective memory. According to the dynamic
multiprocess framework, prospective memory involves interactions between
top-down processes (e.g., monitoring) and bottom-up ones (e.g.,
spontaneous retrieval). The extent to which effortful monitoring is used
depends on meta-cognitive processes assessing how well the
prospective-memory task would be performed in its absence. Neuroimaging
evidence supports the distinction between top-down and bottom-up
processes. Implementation intentions enhance prospective-memory
performance by facilitating the relatively "automatic" retrieval of
intentions.

Everyday memory

FURTHER READING Baddeley, A., Eysenck, M.W. & Anderson, M.C. (2020).
Memory (3rd edn). Abingdon, Oxon.: Psychology Press. This textbook
provides detailed coverage of research and theory on all the main topics
discussed in this chapter. Conway, M.A., Justice, L.V., D'Argembeau, A.
(2019). The self-memory system revisited: Past, present, and future. In
J.H.Mace (ed). The Organisation and Structure of Autobiographical Memory
(pp. 28--51). New York: Oxford University Press. Martin Conway provides
an update of his influential theoretical approach to autobiographical
memory. Davis, D. & Loftus, E.F. (2018). Eyewitness science in the 21st
century: What do we know and where do we go from here? In E.A. Phelps,
L. Davachi & J.T. Wixted (eds), Stevens' Handbook of Experimental
Psychology and Cognitive Neuroscience, Vol. 1: Learning and Memory (4th
edn; pp. 529--566). New York: Wiley. Deborah Davis and Beth Loftus
discuss theory and research in the field of eyewitness testimony.
Putnam, A.L., Sungkhasettee, V.W. & Roediger, H.L. (2017). When
misinformation improves memory: The effects of recollecting change.
Psychological Science, 28, 36--46. Adam Putnam and colleagues shed new
light on the circumstances in which eyewitness memory is (or is not)
adversely affected by misinformation. Sheldon, S., Nicholas B., Diamond,
N.B., Armson, M.J., Daniela J. Palombo, D.J., (2018). Assessing
autobiographical memory: Implications for understanding the underlying
neurocognitive mechanisms. In E.A. Phelps, L. Davachi & J.T. Wixted
(eds), Stevens' Handbook of Experimental Psychology and Cognitive
Neuroscience, Vol. 1: Learning and Memory (4th edn; pp. 363--396). New
York: Wiley. This chapter emphasises the importance of cognitive
neuroscience to an understanding of autobiographical memory. Shelton,
J.T. & Scullin, M.K. (2017). The dynamic interplay between bottom-up and
top-down processes supporting prospective remembering. Current
Directions in Psychological Science, 26, 352--358. This article updates
the influential dynamic multiprocess framework including relevant
research. Smith, R.E. (2017). Prospective memory in context. Psychology
of Learning and Motivation, 66, 211--249. Contemporary views on
prospective memory are discussed by Rebekah Smith with an emphasis on
the role played by contextual information.

391

LANGUAGE

What is language? According to Harley (2013, p. 5), language: "is a
system of symbols and rules that enable us to communicate. Symbols stand
for other things: Words (written or spoken) are symbols. The rules
specify how words are ordered to form sentences." Communication is the
primary function of language. However, Crystal (1997) identified eight
different functions. In addition to communication, we use language for
thinking, to record information, to express emotion (e.g., "I love
you"), to pretend to be animals (e.g., "Woof! Woof!"), to express
identity with a group (e.g., singing in church), and so on. It is
somewhat surprising there was little research on language prior to the
late 1950s. The behaviourists (e.g., Skinner, 1957) argued that the
language we produce consists of rewarded conditioned responses.
According to this analysis, there is nothing special about language and
no reason other species should not be able to develop language. The
situation was transformed by Noam Chomsky (1957, 1959). He claimed
(correctly!) that the behaviourist approach to language was woefully
inadequate. According to him, language possesses several unique features
(e.g., grammar or syntax) and can only be acquired by humans. Chomsky's
ideas led to a dramatic increase in language research (Harley &
McAndrew, 2015). As a result, language has been of central importance
within cognitive psychology ever since.

Is language unique to humans? Bonobos (a species of great ape) have
developed better language skills than any other non-human species.
Panbanisha (1985--2012) was trained on a special keypad with about 400
geometric patterns or lexigrams on it.

VISUAL PERCEPTION AND ATTENTION

Our lives would be remarkably limited without language. Our social
interactions depend very heavily on language and all students need a
good command of language. The main reason we know much more than
previous generations is because knowledge is passed on from one
generation to the next via language.

PART III

Language

394

Language

KEY TERM

He acquired a vocabulary of 3,000 words by the age of 14 years and often
combined symbols in their correct order (e.g., "Please can I have an
iced coffee?").

Lexigrams Symbols used to represent words in studies on communication.

It has often been argued that apes' use of language lacks spontaneity
and refers almost exclusively to the present. This matters because these
are two criteria for language. However, 74% of the utterances of
Panbanisha and two other great apes were spontaneous (Lyn et al., 2011).
In addition, the apes referred to the past as often as young children
and produced more responses referring to future intentions. Lyn et
al. (2014) found bonobos (including Panbanisha and her half-brother
Kanzi) could communicate about displaced objects (i.e., those no longer
present). Genty et al. (2015) found bonobos were more likely to repeat a
message with a familiar recipient but to elaborate the original message
with an unfamiliar recipient. This ability to vary communications to
accommodate the recipient's needs is characteristic of children's use of
language. Clay and Genty (2017) reviewed the research on bonobos,
concluding that their behaviour exhibits "considerable communicative
complexity, flexibility, and intentionality". What are the main
limitations of bonobos' language acquisition? First, bonobos' utterances
are much less likely than those of young children (aged 12--24 months)
to reflect motivation to engage in social interaction. Children's
statements often refer to intentions, attention seeking or offering
something to someone else, whereas 80% of bonobos' utterances are
requests (e.g., for food) (Lyn et al., 2014). Such evidence led
Scott-Phillips (2015) to argue that apes lack our ability to engage in
"mind reading", which allows us to infer how our utterances are likely
to be interpreted. This is at least partly correct but probably
overstated (Moore, 2015). Second, children's language skills develop
dramatically after the age of 2 years and so become markedly superior to
those of bonobos. For example, children's language exhibits much more
productivity (expressing numerous ideas) and is much more complex (e.g.,
sentence length; use of grammatical structures). Third, as Chomsky
(quoted in Atkinson et al., 1993) pointed out, "If an animal had a
capacity as biologically advantageous as language but somehow hadn't
used it until now, it would be an evolutionary miracle, like finding an
island of humans who could be taught to fly." Fourth, an increasingly
common view (e.g., Christiansen & Chater, 2008, 2016; discussed below)
is that several non-language cognitive processes (e.g., short-term
memory; thinking; learning) play a vital role in the development of
language. Bonobos can acquire only some aspects of language, in part
because their non-language cognitive processes are considerably inferior
to ours.

Language

395

Is language innate?

KEY TERMS

There has been fierce controversy on the issue of whether language is
innate. Chomsky claimed humans possess an innate universal grammar (a
set of grammatical principles found in all human languages). In
Chomsky's own words, "Whatever universal grammar is, it's just the name
for \[our\] genetic structure" (Baptista, 2012, pp. 362--363).

Linguistic universals Features (e.g., preferred word order; the
distinction between nouns and verbs) found in the great majority of the
world's languages.

According to Chomsky, there are several linguistic universals (features
common to nearly every language) that jointly form a universal grammar.
One possible linguistic universal (feature common to nearly every
language) is recursion (embedding clauses within sentences to generate
increasingly long sentences). For example, we can use recursion to
expand the sentence "John met Mary in Brighton" to "John, who was a
handsome man, met Mary in Brighton". Other possible linguistic
universals are lexical categories (e.g., nouns; verbs; adjectives) and
word order (subject-verb-object or subject-object-verb). Chomsky
proposed an innate universal grammar for various reasons. First, he
argued, it explains why only humans fully develop language. Second, it
explains the alleged broad similarities among the world's languages.
Third, he claimed that young children develop language much faster than
would be predicted on the basis of their exposure to spoken language.
However, experience obviously determines which language any given child
learns. Christiansen and Chater (2008) totally disagreed with Chomsky.
Their main points were as follows: (1) (2)

(3) 
(4) 
(5) 

Languages differ enormously, which is inconsistent with the notions of
universal grammar and linguistic universals. The notion that natural
selection has provided us with genes responsive to abstract features of
languages we have never encountered is mystifying. Languages change
amazingly rapidly. For example, all Indo-European languages emerged from
a common source in under 10,000 years (Baronchelli et al., 2012).
Natural selection could not have kept pace. "Language has been shaped by
the brain: language reflects preexisting, and hence
non-language-specific, human learning and processing mechanisms"
(Christiansen & Chater, 2008, p. 491). In other words, our language
ability is less special and less different from our other cognitive
abilities than implied by Chomsky. Children find it easy to acquire
language because it was invented by humans to take account of human
abilities: "language has adapted to our brains" (Christiansen & Chater,
2008, p. 490).

In what follows, we discuss relevant research. As we will see, this
research has revealed many limitations in Chomsky's theoretical
approach.

Recursion Turning simple sentences into longer and more complex ones by
placing one or more additional clauses within them.

396

Language

Findings: linguistic universals and genes How different are the world's
languages? The main European languages are very similar, but large
differences appear when all the world's 6,000 to 8,000 languages are
considered. Evans and Levinson (2009, p. 429) did precisely that and
concluded, "There are vanishingly few universals of language in the
direct sense that all languages exhibit them". For example, there is
limited evidence that recursion (discussed above, p. 395) is lacking in
the Amazonian language Pirahã. However, Futrell et al.'s (2016) thorough
attempt failed to find any strong evidence for it. Evidence concerning
other suggested language universals is hotly contested. Evans and
Levinson (2009) concluded some languages (e.g., the Austronesian
language Charrosso) lack one or more of the lexical categories of noun,
verbs and adjectives. However Chung (2012) analysed Charrosso in
considerable detail and concluded that in fact it has nouns, verbs and
adjectives! She concluded the failure to identify the three main lexical
categories in some languages occurs because they are insufficiently
studied. Word order has claims to be a linguistic universal. Greenberg
(1963) found the subject preceded the object in 98% of numerous
languages. The word order subject-verb-object (S-V-O) was most common
followed by subject-object-verb (S-O-V). Sandler et al. (2005) studied
the Al-Sayyid group living in an isolated Israeli community. High levels
of congenital deafness in this community led them to develop Bedouin
Sign Language, which uses the S-O-V word order even though it differs
from other languages to which they are exposed. The above findings can
be interpreted in more than one way. It can be argued the central
importance of the subject in a sentence means it makes sense for the
subject to precede the object regardless of any genetic considerations;
and that ordering facilitates communication. Fedzechkina et al. (2018)
argued that word-order preferences in any language reflect the
limitations of human information processing. More specifically, they
predicted that words strongly associated grammatically (and in meaning)
should appear close together within sentences to minimise processing
costs. This is, indeed, the case across languages that otherwise appear
superficially different. Bickerton (1984) proposed the language
bioprogram hypothesis, which is closely related to Chomsky's views.
According to this hypothesis, children will create a grammar even if
hardly exposed to a proper language. Senghas et al. (2004) studied deaf
Nicaraguan children at special schools. These children developed a new
system of gestures that expanded into a basic sign language (Nicaraguan
Sign Language) passed on to successive groups of children. Since this
sign language does not resemble Spanish or the gestures of hearing
children, it is a genuinely new language. Nicaraguan Sign Language is
still developing -- Kocab et al. (2016) found that only later

Language

generations of signers could successfully communicate complex temporal
information. The above findings suggest humans have a strong innate
motivation to acquire language (including grammatical rules) and to
communicate with others. However, they provide only modest support for a
universal grammar. According to Chomsky, only humans have the genetic
make-up permitting language acquisition. Relevant evidence comes from
research on the KE family in London. Across three generations, about 50%
of family members have suffered from severe language problems (e.g.,
difficulties in understanding speech; slow and ungrammatical speech).
Their complex language disorder was controlled by a specific gene FOCP2
(Lai et al., 2001). More specifically, mutations of this gene were found
only in affected family members. Why does FOXP2 cause these language
impairments? It is probably a hub in various gene networks leading to
impaired functioning of brain areas directly involved in language.
However, we must not exaggerate the importance of FOXP2 for various
reasons: (1) (2) (3)

The FOXP2 sequence is found in numerous vertebrate species not
possessing language. Other genes such as ATP2C2 and CMIP are also
associated with specific language impairment (Graham & Fisher, 2013).
Mueller et al. (2016) found common genetic variants in FOXP2 had
negligible effects on language ability within a normal sample.

Findings: child-directed speech Chomsky claimed children's rapid
acquisition of language cannot be explained solely on the basis of their
exposure to language. However, he minimised the richness of the
linguistic input to which children are exposed. Parents and other adults
use child-directed speech involving very short, simple sentences, a slow
rate of speaking and use of a restricted vocabulary. Unsurprisingly,
children whose parents use a lot of child-directed speech show faster
language development than other children (Rowe, 2008). Thus, most
parents are "in tune" with children's current language abilities and so
provide strong environmental support. Chomsky exaggerated the speed with
which young children master language. Children's speech during their
first two years of speaking is remarkably limited (Bannard et al., 2009)
-- they use a small set of familiar verbs and often repeat back what
they have just heard. Bannard et al. (2013) found 3-year-olds often
engage in "blind copying" -- they imitate everything an adult has just
said even when part of it does not add any useful information.

397

KEY TERM Child-directed speech The short, simple, slowly spoken
sentences used by parents and others when talking to young children.

398

Language

Findings: is language special? Much evidence indicates that language is
less special (in the sense of being different from other cognitive
functions) than assumed by Chomsky. Campbell and Tyler (2018) reviewed
neuroimaging research indicating that many brain regions are included
within the "language network". Most of these areas are associated with
general cognitive functions (e.g., attention; memory). However, some
brain areas (e.g., BA45; posterior middle temporal gyrus) form a "syntax
system" involved in syntactic processing, which is damaged in patients
with impaired syntactic processing. This syntax system could be regarded
as "special". Other research has indicated that language comprehension
and production both depend on general cognitive processes such as
attention and cognitive control (see McClain & Goldrick, 2018, for a
review). There is also much evidence for a "language-as-skill"
framework, according to which language acquisition is a type of skill
acquisition resembling learning to play a musical instrument (Chater &
Christiansen, 2018). Within this framework "Language is connected to
basic psychological mechanisms of learning and processing" (p. 207). In
other words, language skills are not "special".

Evaluation Chomsky's theoretical approach receives some support from
evidence suggesting only humans possess fully developed language. His
general approach also receives limited support from the identification
of specific genes that sometimes influence language acquisition. What
are the limitations of Chomsky's approach? First, the world's languages
differ far more than he predicted. Second, Chomsky now admits the
universal grammar is very restricted in scope and so there are very few
linguistic universals. Third, the notion that children's linguistic
input is too impoverished to produce language acquisition is highly
debatable. Fourth, Chomsky de-emphasised the importance of our
high-level cognitive abilities in explaining why only humans have fully
developed language skills.

Whorfian hypothesis The best-known theory about the relationship between
language and thought was proposed by Benjamin Lee Whorf (1956). He was a
fire prevention officer for an insurance company, and his hobby was
linguistics. Whorf's views have often been distorted to imply that he
believed that language necessarily determines thought (and behaviour).
Whorf's actual views were far more reasonable. For example, he discussed
a hypothetical case in which an explosion occurred when workers were
careless with cigarettes near empty gasoline drums. The workers'
carelessness may have been due in part to the word empty, which suggests
there is nothing in the drum (not even vaporous fumes). This example
could be interpreted as meaning that Whorf believed that language
determines

Language

399

thought and behaviour. However, he clarified his views (quoted in Lee,
1996, p. 153): "I don't wish to imply that language is the sole or even
the leading factor in . . . the ﬁre-causing carelessness through
misunderstandings induced by language, but that this is simply a
coordinate factor along with others."

KEY TERMS

According to the Whorfian hypothesis, language influences thinking and
behaviour in various ways. Of central importance is the notion of
linguistic relativity -- how speakers of any given language think are
influenced by the language they speak.

Linguistic relativity The notion that speakers of different languages
think differently.

Findings Categorical perception means observers find it easier to
discriminate between stimuli belonging to different categories than
those in the same category (see Chapter 9). Categorical perception is
assumed to depend in part on language. Suppose we compared the
categorical perception of colour in people speaking different languages
that varied in the number of basic colour terms. According to the
Whorfian hypothesis, we might predict these linguistic differences would
influence the perception (and memory for) colour. Support for this
prediction was reported by Winawer et al. (2007). Russian differs from
English in having separate words for dark blue (siniy) and light blue
(goluboy). Russian participants found it easier than English ones to
discriminate between dark and light blue stimuli. Other studies have
produced different findings. For example, Wright et al. (2015) compared
colour memory in English speakers (11 basic colour terms) and Himba
speakers (5 basic colour terms) but found no differences. Wright et
al. also reviewed other research in which the findings were a mixture of
significant and non-significant with no obvious explanation for the
differences. Manner of motion (e.g., hopping; running) is expressed more
prominently in English than Spanish. As a result, Kersten et al. (2010)
argued English speakers should outperform Spanish ones on a task where
novel animated objects were categorised on the basis of manner of
motion. The findings were as predicted, suggesting language can
influence thinking and performance. We must not exaggerate language's
impact on thinking. Consider a study by Li et al. (2009). Observers saw
objects made of a given substance (e.g., a plastic whisk). English
speakers focused on the object itself (whisk) rather than the substance
(plastic), whereas Mandarin and Japanese speakers focused on the
substance. The above differences may reflect differences in the three
languages and so support the Whorfian hypothesis. However, when
participants simply indicated how likely they would be to think of
various objects as objects or as substances, there were no differences
across the three languages. Thus, the effects of language were very task
specific.

Whorfian hypothesis The theoretical assumption that language influences
perception, thinking and behaviour.

400

Language

Frank et al. (2008) studied the Pirahã, an Amazonian tribe. They have no
words to express precise quantities or numbers, not even "one".
Nevertheless, the Pirahã could perform exact quantitative matches even
with large numbers of objects. However, their performance was inaccurate
when information needed to be remembered. Thus, language is not
essential for certain numerical tasks. However, it provides an efficient
way of encoding information and so boosts performance when memory is
required.

Evaluation Language influences our thinking and performance on many
tasks (Wolff & Holmes, 2011). For example, it can enhance memory (Frank
et al., 2008) and increase categorical perception (Winawer et al.,
2007). This is unsurprising: "Language mobilises ordinary cognitive
mechanisms whose effects on people's thoughts, feelings, and judgments
should be uncontroversial" (Casasanto, 2016, p. 715). The crucial issue
is not whether the Whorfian hypothesis is correct but rather it is to
identify the conditions in which language does (and does not) influence
cognition. Regier and Xu (2017) addressed the latter issue by focusing
on mental uncertainty. High mental uncertainty "opens the door to
language to fill in some of the missing elements, and there should be a
relatively strong effect of language" (p. 1). For example, Bae et
al. (2015) asked American participants to identify the colour they had
seen immediately or after a delay. There was greater bias reflecting
colour categories in the English language in the latter condition where
there was greater uncertainty concerning the colour presented.

Language chapters We possess four main language skills (listening to
speech; reading; speaking; and writing). It is perhaps natural to assume
any given person will have generally strong or weak language skills.
That assumption is often incorrect with respect to people's first
language -- for example, many people speak fluently and coherently but
find writing difficult. The assumption is even less exact with respect
to people's second language. The first author has spent numerous summer
holidays in France and can just about read newspapers and easy novels in
French. However, he finds it agonisingly hard to understand rapidly
spoken French and his ability to speak French is poor. The three
chapters in this section (Chapters 9--11) in this section focus on the
four main language skills. Chapter 9 deals with the basic processes
involved in reading and listening to speech. The emphasis is on how
readers and listeners identify and make sense of individual words. As we
will see, the study of brain-damaged patients has clarified the complex
processes underlying reading and speech perception. Chapter 10 deals
mostly with the processes involved in the comprehension of sentences and
discourse (connected text or speech). Most of these processes are common
to text and speech. An important part of sentence

Language

understanding involves parsing (working out the sentence's grammatical
structure). Understanding discourse involves drawing numerous inferences
and often forming a mental model of the situation described. Chapter 11
deals with the remaining two main language abilities: speaking and
writing. We spend much more of our time speaking than writing. This
helps to explain why we know much more about speech production than
writing. Research on writing has been somewhat neglected until recently.
This is regrettable given the importance of writing skills in many
cultures. The processes discussed in these three chapters are
interdependent. For example, listeners use language production processes
to predict what speakers will say next (Pickering & Garrod, 2013). More
generally, Chater et al. (2016, p. 244) argued that "Language
comprehension and production are facets of a unitary skill".

401

Chapter

Speech perception and reading

INTRODUCTION Humans excel in their command of language. Language is so
important that this chapter and the following two are devoted to it. In
this chapter, we consider basic processes involved in recognising spoken
words and reading words. As discussed in Chapter 10, many comprehension
processes are very similar whether we listen to someone talking or read
a text. For example, you would probably understand the sentence, "You
have done exceptionally well in your cognitive psychology examination",
equally well whether you read or heard it. Rayner and Clifton (2009)
identified two important similarities between speech perception and
reading. First, both are typically fast. Adult readers can read between
250 and 350 words per minute. Speech perception is slower but can
approach typical reading rates. Second, reading and speech perception
are incremental -- much processing (e.g., semantic; syntactic) occurs
while a word is attended to. Another similarity concerns anticipatory
language processing. Readers and listeners devote resources during
sentence processing to predicting upcoming words or phrases (Huettig,
2015). The complexities involved are discussed fully later (see
pp. 415--416). There is a final important similarity. Children learn to
understand speech before they learn to read. Unsurprisingly, some
processes and abilities involved in understanding speech are also
relevant in reading. For example, individuals with severe reading
problems frequently have problems with auditory processing (Farmer &
Klein, 1995). More specifically, such individuals are often impaired at
categorising phonemes (speech sounds) (O'Brien et al., 2018). There are
also several differences between reading and speech perception. In
reading, most words can be seen as a whole and remain in vision. In
contrast, spoken words are spread out in time and are transitory. In
addition, it is harder to decide where one word ends and the next
starts. Speech generally provides a more ambiguous signal than printed
text. For example, when words were spliced out of spoken sentences

9

404

Language

and presented on their own, they were recognised only 50% of the time
(Lieberman, 1963). Our ability to hear what a speaker is saying is often
impaired by other speakers close by and/or irrelevant noises. In
contrast, readers are rarely distracted by other visual stimuli.
Finally, demands are greater when listening to speech than reading a
text because previous words are inaccessible. So far we have indicated
why speech perception can be harder than reading. However, speech
perception can be easier in some ways. Speech often contains prosodic
cues (see Glossary and Chapter 10), which are hints to sentence
structure and intended meaning provided by the speaker's pitch,
intonation, stress and timing. Speakers also often accompany their
speech with meaningful gestures. In contrast, the main cues to sentence
structure in text are punctuation marks (e.g., commas; semi-colons).
These cues are often less informative than speakers' prosodic cues. Some
adult brain-damaged patients can understand spoken language but cannot
read. Other patients have good reading skills but cannot understand the
spoken word. Thus, reading and speech perception involve somewhat
different brain areas and cognitive processes. This chapter starts with
the basic processes specific to speech perception (e.g., those required
to divide the speech signal into separate words and to recognise those
words). After that, we consider the basic processes specific to reading
(e.g., those involved in recognising, reading individual words and
guiding our eye movements). Why have we adopted this ordering (speech
perception followed by reading)? As mentioned earlier, most children
develop competence in speech perception several years before they can
read. In addition, some processes that children use while learning to
read closely resemble those acquired earlier when learning to understand
spoken language. In Chapter 10, we discuss comprehension processes
common to reading and listening. The emphasis there is on larger units
of language consisting of several sentences.

SPEECH (AND MUSIC) PERCEPTION Speech perception is easily the most
important form of auditory perception. However, "The human relationship
with sound is much deeper and more ancient than our relationship with
words" (Kraus & Slater, 2016, p. 84). Important forms of auditory
perception not involving words include music perception and identifying
the nature and sources of environmental sounds. The relationship between
speech perception and auditory perception is controversial. Perhaps
humans have special speech-perception mechanisms: the "speech is
special" approach (e.g. Trout, 2001). Alternatively, the same general
mechanisms may process speech and non-speech sounds (Carbonell & Lotto,
2014). Brandt et al. (2012, p. 1) claimed controversially that we can
"describe language as a special type of music". There is some support
for this claim. First, music and language perception both involve the
goal of "grouping acoustic features together to form meaningful objects
and streams" (Kraus & Slater, 2016, p. 86).

Speech perception and reading

Second, if you listen repeatedly to the same looped recording of speech,
it often starts to sound like singing when you stop attending to its
meaning (Tierney et al., 2013). Brain areas associated with music
perception were more activated by repeated speech perceived as song than
repeated speech not perceived as song. Tierney et al. (2018) also
studied the speech-to-song illusion. Ratings of the musicality of spoken
phrases increased when these phrases were repeated and listeners became
more responsive to the musical structure (e.g., melodic structure) of
the phrases. Further evidence on the relationship between speech and
music perception is discussed briefly below.

405

KEY TERM Categorical perception A sound intermediate between two
phonemes is perceived as being one or other of the phonemes; a similar
phenomenon is found in vision with colour perception.

Categorical perception Suppose listeners are presented with a series of
sounds, starting with /ba/ and gradually moving towards /da/, and report
what sound they hear. What typically happens is categorical perception
-- speech stimuli intermediate between two phonemes are categorised as
one of those phonemes (discussed later in a section entitled "Ganong
effect", p. 415). Below we consider whether categorical perception is
unique to speech perception. Raizada and Poldrack (2007) presented
listeners with two auditory stimuli and asked them to decide whether
they represented the same phoneme. There was evidence of categorical
perception. The differences in brain activation associated with the two
stimuli were amplified when they were on opposite sides of the boundary
between the two phonemes. There is often only limited evidence for
categorical perception with speech sounds. It is less evident with
vowels than consonants, and listeners are often sensitive to variations
within a given perceptual category (Monahan, 2018). Bidelman and Walker
(2017) reviewed findings indicating categorical perception is also
present in music. However, it was stronger for speech than music
(especially among non-musician listeners). These findings suggest
categorical perception occurs mostly with familiar stimuli. Finally,
Weidema et al. (2016) presented various pitch contours embedded in
linguistic or melodic phrases. There was evidence of categorical
perception in both the language and music contexts. However, identical
pitch contours were categorised differently depending on whether they
were perceived as language or music. Thus, there are both similarities
and differences in categorical perception in speech and music.

Do music and speech perception involve the same brain areas? The
relationship between music and speech perception can be studied by
comparing the brain areas activated with each form of perception.
However, "The extent of neural overlap between music and speech remains
hotly debated" (Jantzen et al., 2016, p. 1). Some neuroimaging research
has reported mostly non-overlapping brain regions are involved in music
and speech perception. However, Slevc and Okada (2015) argued this is
not the case when relatively complex tasks are used. They found complex
music and speech perception both involved cognitive control (using the
prefrontal cortex areas), which is used "to

Case study: American Sign Language

406 Figure 9.1 (a) Areas activated during passive music listening (blue)
and passive speech listening (orange); (b) Areas activated more by
listening to music than speech (blue) or the opposite (orange).

Language

(a) Single condition activation likelihood estimates: Passive listening
    to speech & music Left hemisphere

a --55

Right hemisphere

--46

--50

--42 b c d

Lacroix et al. (2015).

c

55

50

46

42 d

Music passive listening Speech passive listening

b a

(b) Passive listening contrasts: Music passive listening \> Speech
    passive listening L

--50

L

--8

R

R

50

L

6

Speech passive listening \> Music passive listening

R

detect and resolve conflict that occurs when expectations are violated
and interpretations must be revised" (p. 637). Lacroix et al. (2015)
conducted a meta-analytic review. Passive music and speech listening
were both associated with activation in large areas of the superior
temporal gyrus. However, the precise areas differed between music and
speech perception (see Figure 9.1). In addition, Broca's area (in the
inferior frontal gyrus) was more activated during speech perception than
music perception. Lacroix et al. concluded: "Our findings of spatially
distinct regions for music and speech clearly suggest the recruitment of
distinct brain networks for speech and music" (p. 15). Research on
brain-damaged patients has also revealed important differences between
speech and music perception. Some patients have intact speech perception
but impaired music perception whereas others have intact music
perception but impaired speech perception (Peretz & Coltheart, 2003). In
sum, there are important similarities between music and speech
perception (e.g., the involvement of cognitive control). However, they
differ with respect to underlying brain areas and cognitive processes.
Note that the specific tasks used to assess music or speech perception
greatly influence the precise brain areas activated (Lacroix et al.,
2015).

Processing stages KEY TERM Syllable A unit of speech consisting of one
vowel sound with or without one or more additional consonants (e.g.,
water has two syllables: wa and ter).

A sketch map of the main processes involved in speech perception is
shown in Figure 9.2. Initially, listeners often have to select out the
speech signal of interest from several other irrelevant auditory inputs
(e.g., other voices; see Chapter 5). After that, decoding involves
extracting discrete elements (e.g., phonemes or other basic speech
sounds) from the speech signal. There is controversy as to whether
decoding involves identifying phonemes (small units of sound; see
Glossary) or syllables (speech units based on a vowel sound often plus
one or more consonants). Goldinger

Speech perception and reading

407 Figure 9.2 The main processes involved in speech perception and
comprehension. From Cutler and Clifton (1999). By permission of Oxford
University Press.

and Azuma (2003) argued the unit in speech perception varies flexibly.
Listeners heard lists of non-words recorded by speakers who had been
told phonemes or syllables were the basic units of perception. Listeners
detected phoneme targets faster than syllable targets when the speaker
believed phonemes were the basic units, but the opposite was the case
when the speaker believed syllables were the basic units. These findings
suggest either phonemes or syllables can form the perceptual units in
speech perception. There is an important distinction between phonemes
and allophones (variant forms of any given phoneme). Consider the words
pit and spit. They both contain the same phoneme /p/. However, there are
slight differences in the way /p/ is pronounced in the two words. Thus,
there are two allophones relating to /p/ but only one phoneme and so
allophones are context-dependent whereas phonemes are
context-independent. There has been controversy as to whether phonemes
or allophones are the basic units in spoken word recognition. However,
Mitterer et al. (2018) reviewed the literature and reported several
experiments suggesting that early processing of spoken words is based on
allophones rather than phonemes. The third stage (word identification)
is of special importance. Various problems in word identification are
discussed shortly. However, one

KEY TERM Allophones Variant forms of a given phoneme; for example, the
phoneme /p/ is associated with various allophones (e.g., in pit and
spit; Harley, 2013).

408

Language

KEY TERM

problem will be mentioned here. All English words are formed from only
about 35 phonemes. As a result, most spoken words resemble many other
words at the phonemic level, making them hard to distinguish. However,
the task becomes easier if listeners make use of allophones rather than
phonemes (discussed above). The fourth and fifth stages both emphasise
speech comprehension. The fourth stage focuses on utterance
interpretation. This involves constructing a coherent meaning for each
sentence based on information about individual words and their order
within the sentence. Finally, the fifth stage involves integrating the
meaning of the current sentence with preceding speech to construct an
overall model of the speaker's message. In sum, speech perception and
comprehension involve several processing stages. However, it is an
oversimplification to assume speech perception typically involves serial
processes occurring in the neat-and-tidy fashion shown in Figure 9.2.

Segmentation Dividing the almost continuous sounds of speech into
separate phonemes and words.

LISTENING TO SPEECH Understanding speech is often difficult for two
broad types of reasons. First, speech perception depends on several
aspects of the speech signal (discussed shortly, pp. 409--412). Second,
it depends on whether speech is heard under optimal or adverse
conditions. Mattys et al. (2012, p. 953) defined an adverse condition as
"any factor leading to a decrease in speech intelligibility on a given
task relative to the level of intelligibility when the same task is
performed in optimal listening conditions". Mattys et al. (2009)
identified two major types of adverse conditions. First, there is
energetic masking: distracting sounds cause the intelligibility of
target words to be degraded. Energetic masking, which mostly affects
bottom-up processing, is a serious problem in everyday life (e.g.,
several people talking at once; noise of traffic). Until recently, most
laboratory research on speech perception lacked ecological validity (see
Glossary) because listeners were rarely confronted by distracting
sounds. Second, there is informational masking: cognitive load (e.g.,
performing a second task while listening to speech) makes speech
perception harder. Informational masking mainly affects top-down
processing. For example, Mitterer and Mattys (2017) found speech
perception was impaired by cognitive load even when the second task was
visual in nature (face processing). Alain et al. (2018) found listeners
use different processes depending on why speech perception is difficult.
They conducted a meta-analysis (see Glossary) of three types of studies:
(1) speech in noise; (2) degraded speech; and (3) complexity of the
linguistic input. Their key finding was that patterns of brain
activation varied across these three types of studies.

Problems with the speech signal Here are some specific problems with the
speech signal often faced by listeners: (1)

There is segmentation, which involves separating out or distinguishing
phonemes (units of sound) and words from the pattern of

Speech perception and reading

(2) 
(3) 
(4) 
(5) 

speech sounds. Most speech has few periods of silence, as you have
probably noticed when listening to someone speaking an unfamiliar
foreign language. This makes it hard to decide when one word ends and
the next begins. There is coarticulation: a speaker's pronunciation of a
phoneme depends on the preceding and following phonemes. Harley (2010,
p. 148) provides an example: "The /b/ phonemes in 'bill', 'ball',
'able', and 'rub' are all acoustically slightly different."
Coarticulation is problematical because it increases the variability of
the speech signal. However, it can provide a useful cue, because it
allows listeners to predict the next phoneme to some extent. Speakers
differ in several ways (e.g., sex; dialect; speaking rate) and yet we
generally cope well with such variability. Kriengwatana et al. (2016)
trained Dutch and Australian-English listeners to discriminate two Dutch
vowels from a single speaker. Both groups subsequently successfully
categorised the same vowels when spoken by a speaker of the opposite
sex. However, both groups performed poorly and required feedback when
the vowels were spoken by someone with a different accent. Thus,
adapting to a different-sexed speaker is relatively "automatic" but
adapting to a different accent requires active processing of additional
information (e.g., feedback; context). Expectations are important
(Magnuson & Nusbaum, 2007). Some listeners expected to hear two speakers
with similar voices whereas others expected to hear only one speaker. In
fact, there was only one speaker. Those expecting two speakers showed
worse listening performance. Language is spoken at 10 phonemes (basic
speech sounds) per second and much acoustic information is lost within
50 ms (Remez et al., 2010). As a consequence, "If linguistic information
is not processed rapidly, that information is lost for good"
Christiansen & Chater, 2016, p. 1). Non-native speakers often produce
speech errors (e.g., saying words in the wrong order). Listeners cope by
using top-down processes to infer what non-native speakers are trying to
say (Lev-Ari, 2014; see Chapter 10).

Coping with listening problems We have seen listeners experience various
problems in understanding the speech signal. How do they cope? Multiple
sources of information are used flexibly depending on the immediate
situation. There are bottom-up processes stemming directly from the
acoustic signal. There are also top-down processes based on the
listener's past knowledge and contextual information (e.g., the
speaker's previous utterance). Below we discuss how these processes
assist speech perception.

Segmentation Dividing the speech signal into its constituent words
(i.e., segmentation) is crucial for listeners. Segmentation involves
using several cues. Some are

409

KEY TERM Coarticulation A speaker's production of a phoneme is
influenced by their production of the previous sound and by preparations
for the next sound.

410

Language

acoustic-phonetic (e.g., coarticulation; stress) whereas others depend
on the listener's knowledge (e.g., of words) and the immediate context
(Mattys et al., 2012). Segmentation is influenced by constraints on what
words are possible (e.g., a stretch of speech lacking a vowel is not a
possible word in English). Listeners found it hard to identify the word
apple in fapple because fapple could not possibly be an English word
(Morris et al., 1997). In contrast, listeners easily detected the word
apple in wuffapple because wuff could be an English word. Evidence
indicating segmentation can be based on possible word constraints has
been obtained in several languages. However, it does not apply to
Russian, a language which has some single-consonant words lacking a
vowel (Alexeeva et al., 2017). Stress is an important acoustic cue. In
English, the initial syllable of most content words (e.g., nouns; verbs)
is typically stressed. Strings of words without the stress on the first
syllable are misperceived (e.g., "conduct ascents uphill" is perceived
as "A duck descends some pill"). There are other acoustic cues. For
example, there is generally more coarticulation within than between
words. In addition, segments and syllables at the start and end of words
are lengthened relative to those in the middle (Kim et al., 2012).
Mattys et al. (2005) identified three main categories of cues: lexical
(e.g., syntax; word knowledge); segmental (e.g., coarticulation); and
metrical prosody (e.g., word stress) in his hierarchical approach (see
Figure 9.3). When all cues are available, we prefer to use lexical cues
(Tier 1). When lexical information is impoverished, we use segmental
cues such as coarticulation and allophony (one phoneme may be associated
with two or more similar sounds or allophones) (Tier 2). For example,
the

Figure 9.3 A hierarchical approach to speech segmentation involving
three levels or tiers. The relative importance of the different types of
cue is indicated by the width of the purple triangle. From Mattys et
al. (2005). © American Psychological Association.

Speech perception and reading

phoneme /p/ is pronounced differently in pit and spit. Finally, we
resort to metrical prosody cues (e.g., stress) when it is hard to use
Tier 1 or 2 cues. One reason we often avoid using stress cues is because
stress information can be misleading when a word's initial syllable is
not stressed (Cutler & Butterfield, 1992). Mattys (2004) found
coarticulation (Tier 2) was more useful than stress (Tier 3) for
identifying word boundaries when the speech signal was intact. In
contrast, when the speech signal was impoverished and made it hard to
use Tier 1 or 2 cues, stress was more useful than coarticulation.

Speaker variability Earlier we discussed problems listeners have when
dealing with variations across speakers in accent, speaking rate, and so
on. Cai et al. (2017) proposed a model to explain how listeners cope
with variability (see Figure 9.4). They assumed listeners use
information provided by the speech signal to infer characteristics of
the speaker (i.e., to construct a speaker model) and this influences how
speech is perceived. Cai et al. (2017) tested their model using words
typically having somewhat different meanings when heard in an American
or English accent. For example, the American meaning of bonnet is
usually hat whereas the British meaning is usually part of a car. As
predicted, British listeners were more likely to interpret such words as
having the American meaning when spoken in an American rather than
British accent. The crucial condition involved presenting such words in
a neutral accent. These words were presented in the context of other
words spoken in an American or British accent. As predicted, the neutral
words were more likely to be interpreted in their American meaning when
the context consisted of words spoken in an American accent. Thus, the
listeners' speaker model biased their interpretations.

McGurk effect Listeners (even with intact hearing) often make extensive
use of lipreading when listening to speech. McGurk and MacDonald (1976)
provided a striking demonstration of the McGurk effect (reviewed by
Marques et al., 2016). They prepared a videotape of someone saying "ba"
repeatedly. Then the sound channel changed so there was a voice saying
"ga" repeatedly in synchronisation with lip movements still indicating
"ba". Listeners reported hearing "da", a blending of the visual and
auditory information (see this on YouTube: "McGurk effect (with
explanation)". On average, the McGurk effect is strongest when the
auditory input lags 100 ms behind the visual input (Ipser et al., 2017).
This probably happens because lip movements can be used predictively to
anticipate the next sound to be produced. Soto-Faraco and Alsius (2009)
found the McGurk effect is unexpectedly robust: listeners showed the
effect even when they were aware of a temporal mismatch between the
visual and auditory input (one started before the other).

411

KEY TERM McGurk effect A mismatch between spoken and visual (lipbased)
information leads listeners to perceive a sound or word involving a
blending of the auditory and visual information.

Indexical pathway

Lexical-semantic pathway

Lexical-semantic representations

ul at

io n

Meaning access

BonnetUK BonnetUS

od Di al ec

Cai et al. (2017). Reprinted with permission of Elsevier.

Wordform representations

Dialect, age, gender, ... stable over words

... /bonrt/ ... Changes over words

rs Pe

n

Speaker model

ion

cat

tiﬁ

en

id on

Wo rd ide nti ﬁca tio

Figure 9.4 A model of spoken word comprehension. Its key assumption is
that the speech signal contains information about who is speaking
(indexical information) and what they are saying (lexical-semantic
pathway). These two kinds of information interact during speech
perception.

Language

tm

412

Auditory input

Vocal features

...

...

...

...

Top-down processes are important. The McGurk effect was stronger when
the crucial word formed by blending auditory and visual input was
presented in a semantically congruent (rather than incongruent) sentence
(Windmann, 2004).

CONTEXT EFFECTS Context consists of relevant information not contained
directly in the auditory signal currently available to listeners. There
are several types of contextual information including that provided by
previous input (e.g., earlier parts of a sentence) and that provided by
our knowledge of language and words.

Speech perception and reading

413

IN REAL LIFE: MISHEARD LYRICS AND MISCARRIAGES OF JUSTICE We easily
mishear the lyrics of songs if provided with the wrong words (or
context) beforehand. The comedian Peter Kay provides hilarious examples
(YouTube: "Peter Kay Misheard Lyrics"). For example, he suggested the
song "My heart will go on" from the Titanic movie contains the line "I
believe the hot dogs go on" instead of the actual line "I believe the
heart does go on". The effect is strong -- the first author cannot stop
misperceiving that line! As Liden et al. (2016, p. 12) pointed out, song
lyrics are susceptible to misperception because of "atypical
pronunciation resulting in ambivalent speech signals in combination with
. . . the presence of other acoustic signals (i.e., the instrumental
music)". Misleading context leading to misperceptions can have serious
consequences when we consider the use of covert recordings of suspects
in criminal trials. These recordings are often indistinct, and so what
happens is that detectives provide a transcript of their interpretation
of what was said. If this transcript is incorrect (perhaps because
detectives assume the suspect is guilty), this can strongly bias what
jurors believe they hear (Fraser, 2018a). Consider the real-life case of
a man sentenced to a 30-year prison sentence for murder largely because
of an inaccurate police transcript. Hear the crucial recording at
forensictranscription.com. au/audio (the one-minute recording is under
the heading "'Assisting' listeners to hear words that aren't there").
What do you think the man is saying? Jurors at the trial were told what
a detective claimed to hear (given at the bottom of this Box). Fraser
(2018b) carried out an experiment in which listeners initially heard the
recording without any context. No listeners reported hearing anything
like the incriminating sentence. When primed with the detective's
transcript, however, 15% said they definitely heard that sentence and
16% said they thought they heard it. In sum, top-down effects of context
can be so strong that they lead listeners to misperceive speech. Such
effects can be durable. Many listeners told explicitly they were being
given incorrect words for a song (visual context) subsequently
misperceived the song lyrics in the absence of the misleading visual
context (Beck et al., 2014a). The detective's transcript: "At the start
we made a pact."

It is indisputable that context typically influences spoken word
recognition. However, it is hard to clarify when and how context exerts
its influence. Harley (2013) identified two extreme positions. According
to the interactionist account, contextual information influences
processing at an early stage and may influence word perception. In
contrast, the autonomous account claims context has its effects late in
processing. According to this account: "context cannot have an effect
prior to word recognition. It can only contribute to the evaluation and
integration of the output of lexical processing, not its generation"
(Harley, 2013). These theoretical approaches are discussed in the next
section. Evidence that context can rapidly influence spoken word
recognition was reported by Brock and Nation (2014). Participants viewed
a display containing four objects and then heard a sentence. Their task
was to click on any object mentioned in the sentence. In the first three
conditions (see below), the sentence object was not in the display, but
a critical distractor object was present:

414

Language

(1) 

Competitor constraining (e.g., "Alex fastened the button"; butter in
display) (2) Competitor neutral (e.g., "Alex chose the button"; butter
in display) (3) Unrelated neutral (e.g., "Alex chose the button";
lettuce in display) (4) Target neutral (e.g., "Joe chose the button";
button in display)

Figure 9.5 Gaze probability for critical objects over the first 1,000 ms
since target word onset for target neutral, competitor neutral,
competitor constraining and unrelated neutral conditions (described in
text).

Brock and Nation (2014) recorded eye movements (see Figure 9.5). When
the sentence context made the critical object improbable (condition 1),
participants were far less likely to fixate it than when the sentence
context was less constraining (condition 2). This difference was
apparent early on and indicates sentence context has almost immediate
effects on word processing. This is consistent with the interactionist
account. In what follows, we discuss various context effects. These
effects will be related to the interactionist and autonomous accounts.

Phonemic restoration effect

From Brock and Nelson (2014).

Warren and Warren (1970) obtained strong evidence that sentence context
can influence phoneme perception in the phonemic restoration effect.
Listeners heard a sentence with a missing phoneme that had been replaced
with a meaningless sound (cough). The sentences used were as follows (\*
= missing phoneme): ● ● ● ●

KEY TERM Phonemic restoration effect The finding that listeners are
unaware that a phoneme has been deleted and replaced by a non-speech
sound (e.g., cough) within a sentence.

It was found that the *eel was on the axle. It was found that the* eel
was on the shoe. It was found that the *eel was on the table. It was
found that the* eel was on the orange.

The perception of the crucial element in the sentence (i.e., *eel) was
influenced by the sentence in which it appeared. Participants listening
to the first sentence heard wheel, those listening to the second
sentence heard heel, and those exposed to the third and fourth sentences
heard meal and peel, respectively. The crucial auditory stimulus (i.e.,*
eel) was always the same so all that differed was the contextual
information. What causes the phonemic restoration effect? There may be a
fairly direct effect on speech processing, with the missing phoneme
being processed almost as if it were present (Samuel, 2011).
Alternatively, there may an indirect effect with listeners guessing the
identity of the missing phoneme after basic speech processing has
occurred. Leonard et al. (2016) obtained findings strongly supporting
the notion of a direct effect. The noise input was followed almost
immediately by activation in language areas within the left frontal
cortex associated with predicting

Speech perception and reading

which word had been presented. This was followed very rapidly by
appropriate phonemic processing in the auditory cortex. This latter
finding strongly suggests a direct effect consistent with the
interactionist perspective rather than an indirect effect consistent
with the autonomous approach.

Ganong effect Earlier we saw listeners often show categorical perception
(see p. 405), with speech signals intermediate between two phonemes
being categorised as one phoneme or the other. Ganong (1980) wondered
whether categorical perception of phonemes would be influenced by the
immediate context. Accordingly, he presented listeners with various
sounds ranging between a word (e.g., dash) and a non-word (e.g., tash).
There was a context effect -- an ambiguous initial phoneme was more
likely to be assigned to a given phoneme category when it produced a
word. This is the Ganong effect. In order to understand the processes
underlying the Ganong effect, it is important to ascertain when lexical
(word-based) processing influences phonemic processing. Kingston et
al. (2016) obtained clear evidence on this issue. Listeners categorised
phonemes by choosing between two visually presented options (one
completing a word and the other not). Listeners directed their eye
movements to the word-completing option almost immediately. This finding
strongly suggests there is a remarkably rapid merging of phonemic and
lexical processing. This seems inconsistent with the notion that
phonemic processing is completed prior to the use of wordbased
processing.

Interactionist vs autonomous accounts So far we have considered how
contextual information is used with respect to specific phenomena
(phonemic restoration effect; Ganong effect). More broadly, we can
consider the role of prediction in spoken word recognition. Predictive
influences should generally occur more rapidly on interactionist than
autonomous accounts (see Kuperberg and Jaeger, 2016, for a review). Van
Berkum et al. (2005) presented sentences in Dutch such as the following:
The burglar had no trouble locating the secret family safe. Of course,
it was situated behind a . . . It is reasonable to predict the following
noun will be painting, which has the neuter gender in Dutch. The word a
was followed by the Dutch adjective big in the neuter gender or common
gender. Event-related potentials (ERPs; see Glossary) to the adjective
differed depending on whether its gender was consistent with the
predicted noun (i.e., painting). Thus, story context can influence
speech processing before the predicted word is presented. In similar
fashion, Grisoni et al. (2017) presented spoken sentences in which the
final word was relatively easy to predict (e.g., "I take the pen and I
\[write\]"; "I take some grapes and I \[eat\]"). Patterns of brain
activity reflected the meaning of the predicted final word before it was
presented. More specifically, brain areas associated with hand-related
actions were

415

KEY TERM Ganong effect The finding that perception of an ambiguous
phoneme is biased towards a sound that produces a word rather than a
non-word.

416

Language

activated prior to a semantically relevant final word (e.g., write) and
those associated with face-related actions were also activated prior to
a semantically relevant word (e.g., eat). Further evidence supporting
the interactionist position was reported by Wild et al. (2012; see also
Chapter 1). Listeners heard sentences presented in clear speech or
degraded (but potentially intelligible) speech. Each sentence was
accompanied by context: a text matching the spoken words or a random
consonant string. The rated perceptual clarity of the sentences was
greater when they were accompanied by matching text. How can we explain
the above context effect? According to the interactionist position,
matching context might influence the early stages of spoken word
processing within primary auditory cortex. In contrast, it follows from
the autonomous position that context should influence only later
processing stages and so should not influence processing in the primary
auditory cortex. The findings were entirely consistent with the
interactionist position. In similar fashion, Sohoglu et al. (2014) found
the perceived clarity of a degraded spoken word was greater when
preceded by written text (context) containing that word. However, when
the same contextual information was presented after a spoken word, it
had very little effect on the word's perceived clarity. This seems
inconsistent with the autonomous position, according to which context
has its effects late in processing. Finally, we return to Wild et al.'s
(2012) study. There was no effect of matching context on activation
within primary motor cortex when sentences were presented in clear
speech. Why do these findings differ from those with degraded speech?
Speech perception was so straightforward with clear speech there was no
need (and also insufficient time) for context to activate primary
auditory cortex.

Overall evaluation Research on context effects (including the Ganong and
phonemic restoration effects) mostly indicates context can influence
early stages of speech perception. It is thus more supportive of the
interactionist position than the autonomous one. This issue is discussed
again later when we consider theories of speech perception (see
pp. 417--429). There are two qualifications on the conclusion that
top-down effects of context influence the early stages of speech
perception. First, such effects are less likely to be found when speech
is clear and unambiguous (e.g., Wild et al., 2012). Top-down processes
may often be unnecessary when bottom-up processes provide ample
information for word recognition. Second, much research on context
effects in spoken word recognition (e.g., Grisoni et al., 2017) has used
sentence contexts in which the target word is highly predictable.
Huettig and Mani (2016) argued that topdown influences may be much
weaker when prediction is harder (as is often the case in real life). In
addition, listeners may often not engage in top-down predictive
processes because they are too demanding of resources.

Speech perception and reading

THEORIES OF SPEECH PERCEPTION In this section, we consider theories of
processes involved in identifying spoken words and sentences. Some of
these theories also explain findings on segmentation and context effects
discussed earlier. As we have seen, phonological processing plays a
major role in speech perception. We start by considering whether
orthographic processing (processing related to word spellings) is also
involved. Then we discuss major theories of spoken word recognition.
First, we consider the motor theory of speech perception (e.g., Liberman
et al., 1967), followed by a discussion of the TRACE and cohort models.
The TRACE model (McClelland & Elman, 1986) claims word recognition
involves interactions between top-down and bottom-up processes. The
original cohort model (MarslenWilson & Tyler, 1980) also emphasised such
interactions. Subsequently, Marslen-Wilson (e.g., 1990) revised his
cohort model to increase the emphasis on bottom-up processes driven by
the speech signal.

Orthographic influences Suppose you listen to spoken words. Would this
activate their spellings? Chiarello et al. (2018) studied spoken word
identification under difficult conditions (multi-speaker babble). The
researchers computed the proportion of similar sounding words
(phonological neighbours) also spelled similarly (orthographic
neighbours) for each spoken word. Word identification rates were lower
for words having many orthographic neighbours as well as phonological
neighbours. Thus, word identification was influenced by orthography. How
does orthography influence speech perception? Perhaps hearing a word
leads fairly "automatically" to activation of its orthographic codes and
so influences lexical access. Alternatively, a spoken word's orthography
may influence its processing only after lexical access. This issue has
been addressed using event-related potentials (ERPs; see Glossary).
Pattamadilok et al. (2011) asked listeners to decide whether spoken
words had a given final syllable. Orthographic information influenced
ERPs at 175--250 ms, suggesting orthography affects early processing
prior to lexical access (lexical access is often reflected in the N400
component of the ERP occurring 400 ms after word onset). In similar
fashion, Kwon et al. (2016) found, with the Korean language, that
orthographic information influenced the P200 component of the ERP
(occurring between 150 and 300 ms) on a spoken word recognition task.
Finally, Pattamadilok et al. (2011) reviewed research indicating that
orthographic information often influences word processing 300--350 ms
after word onset. Such findings suggest orthographic information can
influence various stages of word processing.

Motor theory Liberman et al. (1967) argued that a key issue is
explaining how listeners perceive spoken words accurately even though
the speech signal is variable. In their motor theory, they proposed
listeners mimic the speaker's

417

KEY TERMS Lexical access Accessing detailed information about a given
word by entering the lexicon.

418

Language

articulatory movements. It was claimed this motor signal provides much
less variable and inconsistent information about the speaker's words
than does the speech signal and so facilitates speech perception. Halle
and Stevens (1962) also emphasised the role of speechproduction
processes in speech perception. They proposed an analysis-bysynthesis
approach where "Cues from the input signal triggered guesses about the
identity of phonemes \[using speech-production processes\], and
subsequently, the internal synthesis of potential phonemes is compared
to the input sequence" (Poeppel & Monahan, 2011, p. 2). Thus,
speechproduction processes predict the speech input and enhance speech
perception when the speech signal is ambiguous. Much research has
assumed there is a single motor speech system. This is a drastic
oversimplification. There are actually several motor systems or
networks, but their precise number and nature remain unclear (Skipper et
al., 2017).

Findings According to motor theories, the brain areas activated during
speech perception and speech production should overlap substantially,
whereas such overlap should be limited if speech-production processes
are not involved in speech perception. Skipper et al. (2017) reported a
meta-analysis comparing activation during speech perception and
production. Several areas were common to speech perception and speech
production, including the pars opercularis, ventral central sulcus,
ventral precentral sulcus and gyrus, supplementary motor area, and
anterior insula. The above meta-analysis was concerned only with
perception and production of words and non-words. Silbert et al. (2014)
reported a more naturalistic study assessing brain areas activated
during production and perception of a 15-minute spoken narrative. They
divided brain areas activated during both perception and production into
those where activity was correlated or coupled over time and those where
it was not coupled. An absence of coupling may mean a given area is used
for different functions during speech perception and speech production.
What did Silbert et al. (2014) find? Several brain areas exhibited
perception--production coupling (see Figure 11.1 in Chapter 11). These
areas included the superior temporal gyrus, the medial temporal gyrus,
the temporal pole, the angular gyrus, the inferior temporal gyrus, the
insula and the premotor cortex. The above neuroimaging research is
inconclusive because listeners may use speech-production processes only
following speech perception. More direct evidence can be obtained by
applying transcranial magnetic stimulation (TMS; see Glossary) to part
of the speech-production system during a speech-perception task to
influence its functioning. Liebenthal and Möttönen (2018) concluded
their review of TMS research as follows: "Disruptions in the
articulatory motor areas impair speech perception and modulate early . .
. processing of speech sounds in the auditory areas" (p. 38). Thus,
processes in speech-production areas can causally influence speech
perception. Additional support for motor theories comes from studies
using event-related potentials (ERPs; see Glossary). The key finding is
that

Speech perception and reading

articulatory motor areas are activated early in speech processing (under
100 ms) (Liebenthal & Möttönen, 2018). Thus, speech-production processes
occur early enough to influence speech perception. Listeners sometimes
make more use of speech-production processes when the speech input is
unclear and provides insufficient auditory information. For example,
Nuttall et al. (2016) found listeners had greater activation in the
motor cortex when speech perception was made harder (e.g., presented
with background noise). However, they used rather artificial speech
stimuli (i.e., syllables). In contrast, Panouillères et al. (2018)
presented more naturalistic sentences. Speech-production areas were
involved in speech processing to the same extent regardless of the
extent to which noise reduced the clarity of the speech input. Evidence
from brain-damaged patients might clarify the role of motor processes in
speech perception. If patients whose motor cortex is destroyed can still
perceive speech, we might conclude motor processes are unnecessary for
speech perception. This approach is simplistic, because many different
brain areas are involved in speech production (see Figure 11.1).
However, the overall picture is clear: "Speech perception deteriorates
with a wide range of damage to speech-production systems caused by
stroke, focal excitation for epilepsy, cerebral palsy, and Parkinson's
disease" (Skipper et al., 2017, p. 95). Finally, we consider an
important study by Uddin et al. (2018). They focused on how long a
target needed to be presented for listeners to recognise it when
presented in isolation or within a relevant sentence context. The target
was a noun that could be represented by a word (e.g., sheep) or by a
sound (e.g., a sheep bleating). What would we expect to find according
to the motor-theory approach? First, there should be a beneficial effect
of sentence context on speed of target identification because context
facilitates prediction of the final sound. Second, and more importantly,
the context effect should be much greater when the target is a word. Why
is that? As Uddin et al. pointed out, "It is not possible to make neural
predictions via motor systems \[for\] environmental sounds \[that\] do
not have clear speech . . . representations" (p. 140). However, the
context effect was as great with the environmental sounds as the words
(see Figure 9.6). Thus, listeners make predictions at the level of
conceptual meaning (i.e., predicting the meaning that will be
represented by the target sound rather than the sound itself).

Evaluation As Skipper et al. (2017, p. 97) concluded their review,
"Brain regions and networks involved in speech production are
ubiquitously involved in speech perception." This conclusion is
supported by several kinds of evidence: (1) (2)

neuroimaging evidence for overlapping brain areas for speech perception
and speech production; rapid activation of motor areas during speech
perception revealed by research using event-related potentials;

419

420

Language

Figure 9.6 Mean target duration required for target recognition for
words and sounds presented in isolation or within a general sentence
context.

Target duration (sec)

0.4

From Uddin et al. (2018). Reprinted with permission of Elsevier.

0.3 Sentence ending Sound Word

0.2

0.1

0.0 Isolated

General

Context

(3) 
(4) 

impaired speech perception following damage to speech-production
systems; adverse effects on speech perception of transcranial magnetic
stimulation applied to speech-production areas on speech perception.

What are the limitations of motor theories? First, Uddin et al.'s (2018)
findings suggest listeners do not simply predict the sounds that will be
presented. Instead, most theories of speech perception (including motor
theories) "should be modified to include a larger contribution from
general cognitive processes that take conceptual meaning into account"
(Uddin et al., 2018, p. 141). Second, the available evidence suggests,
"Multiple speech productionrelated networks and sub-networks dynamically
self-organise to constrain interpretations of indeterminate acoustic
patterns as listening context requires" (Skipper et al., 2017, p. 77).
No theory explains these complexities. Third, many brain areas are
involved in speech perception but not speech production (see Figure
11.1). Thus, motor theories would need development to provide
comprehensive accounts of speech perception. Fourth, when speech input
is clear, comprehension can be achieved with minimal involvement of
speech-production processes. That may limit the applicability of motor
theories to speech perception in typical conditions.

TRACE model McClelland and Elman (1986) proposed a network model of
speech perception based on connectionist principles (see Chapter 1).
Their TRACE model assumes bottom-up and top-down processes interact
flexibly in spoken word recognition. It makes the following assumptions
(see Figure 9.7): ●

There are individual processing units or nodes at three different
levels: features (e.g., voicing; manner of production); phonemes; and
words.

Speech perception and reading

●

●

●

●

●

●

●

421

Feature nodes are connected to phoneme nodes, and phoneme nodes are
connected to word nodes. Connections between levels operate in both
directions and are always facilitatory. There are connections among
units or nodes at the same level; these connections are inhibitory.
Nodes influence each other in proportion to their activation levels and
the strengths of their interconnections. As excitation and inhibition
spread among nodes, a pattern of activation or trace develops. All
activated words are involved in a competitive process in which these
words inhibit each other. The word with the strongest activation wins
the competition. "Words are recognised incrementally by slowly ramping
up the activation of the correct words at the phoneme and word levels"
(Joanisse & McClelland, 2015, p. 237).

The TRACE model assumes bottom-up and top-down processes interact.
Bottom-up activation proceeds upwards from the feature level to the
phoneme level and on to the word level. In contrast, top-down activation
proceeds in the opposite direction from the word level to the phoneme
level and on to the feature level.

Findings Suppose participants hear the word beaker. In front of them is
a visual display containing four objects' drawings showing a beaker,
beetle, speaker and carriage. Eye tracking is used to identify which
drawing is being fixated. As Joanisse and McClelland (2015) pointed out,
we can make several

Figure 9.7 The basic TRACE model, showing how activation between the
three levels (word, phoneme and feature) is influenced by bottom-up and
top-down processing.

422

Language

predictions from the model assuming there are close links between eye
fixations and the activation levels of the words fixated: (1)

The object corresponding to the spoken word (i.e., beaker) should
receive the most fixations. Phonological competitors (beaker; speaker)
should receive more fixations than an unrelated competitor (carriage)
because of phonemic processing. A phonological competitor sharing its
first phoneme (beetle) with the spoken word should receive more
fixations than a phonological competitor sharing its last phoneme
(speaker) with the spoken word.

(2) 
(3) 

Allopenna et al. (1998) carried out a study along the lines indicated
above. Their findings are shown in Figure 9.8. As you can see, there was
a reasonably close fit between the behavioural data and predictions
following from the model. Suppose we asked listeners to detect target
phonemes presented in words and non-words. According to the TRACE model,
performance should be better in the word condition. Why is that? In that
condition, activation from the word level to the phoneme level would
facilitate phoneme detection. Mirman et al. (2008) required listeners to
detect a target phoneme (/t/ or /k/) in words and non-words. Words were
presented on 80% or 20% of trials. It was assumed attention to (and
activation at) the word level would be greater when most auditory
stimuli were words, which would increase the performance advantage in
the word condition. What did Mirman et al. (2008) find? First, there was
a consistent advantage for the word conditions over the non-word
conditions (see Figure 9.9). Second, the magnitude of this effect was
greater when 80% of the auditory stimuli were words. These findings
indicate the involvement of top-down processes in speech perception. The
TRACE model explains the basic Ganong effect (discussed earlier, p. 415)
where there is a bias towards perceiving an ambiguous phoneme so a word
is formed. It is assumed within the TRACE model that top-down

1.0

From Allopenna et al. (1998).

Activation in TRACE

0.8

TRACE model

1.0

Referent (e.g., "beaker") Cohort (e.g., "beetle") Rhyme (e.g.,
"speaker") Unrelated (e.g., "carriage")

0.9

Figure 9.8 (a) Actual eye fixations on the object corresponding to a
spoken word or related to it; (b) predicted eye fixations from the TRACE
model.

(b) 

Behavioral data

Referent (e.g., "beaker") Cohort (e.g., "beetle") Rhyme (e.g.,
"speaker") Unrelated (e.g., "carriage")

0.9 Predicted ﬁxation probability

(a) 

0.7 0.6 0.5 0.4 0.3 0.2 0.1

0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1

0.0

0.0 0

10

20

30

40

50

Cycle

60

70

80

80

0

200

400

600

800

Time since target onset (scaled to msec)

1000

Speech perception and reading

423

activation from the word level is responsible. Norris et al. (2003)
reported additional evidence that phoneme identification can be
influenced directly by top-down processing. Listeners categorised
ambiguous phonemes as /f/ or /s/. Those who had previously heard this
phoneme in /f/-ending words favoured the /f/ categorisation, whereas
those who had heard it in /s/-ending words favoured the /s/
categorisation. The TRACE model explains categorical speech perception
(discussed earlier) by assuming the boundary between phonemes becomes
sharper because of mutual inhibition between phoneme units. These
inhibitory processes produce a "winner takes all" situation with one
phoneme becoming increasingly Figure 9.9 more activated than other
phonemes, thus Mean reaction times (in ms) for recognition of /t/ and
/k/ phonemes in words and non-words when words were producing
categorical perception. High-frequency words (those encountered
presented on a high (80%) or low (20%) proportion of trials. frequently)
are generally recognised faster From Mirman et al. (2008). Reprinted
with permission of the Cognitive Science Society Inc. than low-frequency
ones (Harley, 2013). It would be consistent with the TRACE model's
approach to assume this finding occurs because high-frequency words have
higher resting activation levels. If so, word frequency should influence
even early stages of word processing. Dufour et al. (2013) obtained
supporting evidence. Word frequency influenced event-related potentials
as early as 350 ms after word onset during spoken word recognition. We
turn now to problematical findings for the model. It assumes topdown
influences originate at the word level. Thus, top-down effects (e.g.,
produced by relevant context) should benefit target identification more
when the target is a word (e.g., sheep) rather than an environmental
sound (e.g., a sheep bleating). However, context effects are as great
with environmental sounds as with words (Uddin et al., 2018; see Figure
9.6), suggesting top-down processing activates general conceptual
meanings rather than specific words. Frauenfelder et al. (1990) asked
listeners to detect a given phoneme. In the key condition, a non-word
closely resembling an actual word was presented (e.g., vocabutaire
instead of vocabulaire). The model predicts top-down effects from the
word node corresponding to vocabulaire should have impaired the task of
identifying the t in vocabutaire. However, they did not. McQueen (1991)
asked listeners to categorise ambiguous phonemes at the end of auditory
stimuli. Each ambiguous phoneme could be interpreted as completing a
word or non-word. The TRACE model predicts listeners should have shown a
preference for perceiving the phonemes as completing words. This
prediction was confirmed when the stimulus was degraded but not when it
was not degraded. The TRACE model ignores the role of context provided
by verbs in influencing spoken word recognition. Rohde and Ettlinger
(2012) presented

424

Language

listeners with sentences such as the following ( \_\_\_ indicates an
ambiguous phoneme interpretable as he or she): (1) (2)

Abigail annoyed Bruce because \_\_\_ was in a bad mood. Luis reproached
Heidi because \_\_\_ was getting grouchy.

They predicted (and found) that listeners would hear the ambiguous
phoneme as she in both sentences. Annoyed is typically followed by a
pronoun referring to the subject, whereas reproached is followed by a
pronoun referring to the object. Zhang and Samuel (2018) investigated
the effects of cognitive load (in the form of a phonological load) on
speech perception. The effects were much greater on later processing
(maintaining competing word candidates) than earlier processing (lexical
access: see Glossary). Thus, early processes are more "automatic" than
later ones. These findings are inconsistent with the TRACE model, which
"makes no distinctions in terms of automaticity of sub-processes during
speech recognition" (p. 43).

Evaluation The TRACE model has several successes to its credit. First,
even though it was proposed in 1986, "The rate of citations of the
original work has increased since 2001" (Joanisse & McClelland, 2015,
p. 238). Second, it provides plausible accounts of phenomena such as the
phonemic restoration effect, categorical perception, the Ganong effect
and the word superiority effect in phoneme monitoring. Third, the TRACE
model assumes bottom-up and top-down processes both contribute directly
to spoken word recognition. As such, it is an excellent example of the
interactionist approach (discussed earlier, pp. 415--416). Fourth, the
TRACE model "copes extremely well with noisy input -- which is a
considerable advantage given the noise present in natural language"
(Harley, 2013). It does so through its emphasis on top-down processes
that become increasingly important when the speech input is degraded and
so provides only limited information. What are the model's limitations?
First, its focus is rather narrow, being on word recognition, and it has
little to say about speech comprehension. Second, the model assumes
top-down processes influence the activation of specific words. However,
Uddin et al.'s (2018) findings indicate top-down processes can initially
activate higher-level conceptual meanings rather than specific words.
Thus, the model would be enhanced by adding a conceptual meaning level
above the word level (see Figure 9.7). Third, the model sometimes
exaggerates the importance of top-down effects on speech perception.
More specifically, the model predicts topdown activation from the word
level will cause mispronunciations and ambiguous sounds to be identified
as words more often than actually happens (Frauenfelder et al., 1990;
McQueen, 1991). Fourth, the TRACE model incorporates many different
theoretical assumptions. This may make the model "too powerful, in that
it can accommodate any result" (Harley, 2013).

Speech perception and reading

Fifth, the model is incomplete in various ways. For example, it ignores
the impact of orthographic information on speech perception. It also
cannot account for the differential effects of cognitive load on early
and late speech-perception processes. Sixth, Gwilliams et al. (2018)
found that the primary auditory cortex was sensitive to ambiguity in a
word's initial phoneme only 50 ms after word onset. None of the
assumptions incorporated within the TRACE model provide an explanation
of this rapid effect.

Cohort model The cohort model focuses on the processes involved during
spoken word recognition. It differs from the TRACE model in focusing
more on bottom-up processes and less on top-down ones. Several versions
have been proposed, starting with Marslen-Wilson and Tyler (1980). Here
are the main assumptions of the original version: ●

●

●

Early in the auditory presentation of a word, all words conforming to
the sound sequence heard so far become active: this is the word-initial
cohort. There is competition among these words to be selected. Words
within the cohort are eliminated if they cease to match further
information from the presented word or because they are inconsistent
with the semantic or other context. For example, crocodile and crockery
might both belong to the initial cohort with the latter word being
excluded when the sound /d/ is heard. Processing continues until
information from the word itself and contextual information permit
elimination of all but one of the cohort words. The uniqueness point is
the point at which only one word is consistent with the acoustic signal.

How do later versions of the cohort model differ from the original
version? In the original model, it was assumed any word was in or out of
the cohort at a given moment. This assumption is too extreme. In revised
versions of the model (e.g., Marslen-Wilson, 1987, 1990), it is assumed
words vary in their level of activation and so membership of the word
cohort is a matter of degree. Marslen-Wilson also assumed the
word-initial cohort may contain words having similar initial phonemes to
the presented word rather than consisting only of words having the same
initial phoneme. In the original version of the model, it was assumed
words not matching the context (e.g., preceding words) drop out of the
word cohort. As Marslen-Wilson (1987) pointed out, this assumption is
too extreme. For example, suppose you heard the sentence, "John slept
the guitar", in which the word guitar is totally inappropriate in the
sentence context. However, it was nearly always accurately perceived
reasonably rapidly (320 ms on average). In the revised version, it is
assumed context-inappropriate words are eliminated later in processing
(see below). Three processing stages are identified within the cohort
model (Marslen-Wilson, 1987):

425

KEY TERM Uniqueness point The point in time in spoken word recognition
at which the available perceptual information is consistent with only
one word.

426

Language

(1) 
(2) 
(3) 

access stage during which a word cohort is activated; selection stage
during which one word is chosen from the cohort; integration stage
during which the word's semantic and syntactic (grammatical) properties
are integrated within the sentence.

According to the model's original version, context influences the
selection process. In the revised version, in contrast, "Context plays
no role in the processes of access and selection" (Marslen-Wilson, 1987,
p. 71). The assumptions of the revised model are more flexible than the
original ones. As we will see shortly, they predict processes in spoken
word recognition more accurately. Finally, Gaskell and Marslen-Wilson
(2002) proposed another variant of the cohort model. Its central
assumption was that there is "continuous integration" of information
from the speech input and context. If the speech input is degraded or
the context is strongly predictive, top-down processes relating to
prediction of the next word are likely to dominate within this
continuous integration. In contrast, bottom-up processes triggered by
the speech signal are dominant within continuous integration if the
speech signal is unambiguous and there is no constraining context.

Findings Evidence the initial phoneme of a spoken word is often
especially important was reported by Allopenna et al. (1998; discussed
earlier, p. 422). For example, when listeners heard the word beaker, the
competition from a word starting with the same phoneme (e.g., beetle)
was greater than from a rhyming competitor having the same last phoneme
(e.g., speaker). McQueen and Huettig (2012) replicated this finding.
According to the original version of the model (Marslen-Wilson, 1987),
spoken words would not be recognised if their initial phoneme was
unclear or ambiguous. Contrary evidence was reported by Frauenfelder et
al. (2001). French-speaking listeners activated words even when the
initial phoneme of spoken words was distorted (e.g., hearing focabulaire
activated the word vocabulaire). However, the listeners took some time
to overcome the effects of the mismatch in the initial phoneme. We now
consider evidence that spoken words are identified when their uniqueness
point (see p. 425) is reached. O'Rourke and Holcomb (2012) presented
words with an early uniqueness point (mean of 427 ms after onset) and
those with a late uniqueness point (mean of 533 ms after onset). They
used event-related potentials and focused on the N400 component. The
N400 (reflecting access to word meaning) occurred 100 ms earlier for
words having an early uniqueness point. Kocagoncu et al. (2017) used
magneto-encephalography (MEG; see Glossary) while presenting spoken
words with varying uniqueness points. As predicted, each word's
uniqueness point was associated with increased semantic processing of
that word plus a marked reduction in lexical and semantic processing of
competitor words. The latter finding was predicted because all
competitor words have been eliminated from the word cohort when the
uniqueness point is reached.

Speech perception and reading

Access to word meaning sometimes occurs prior to the uniqueness point if
the preceding context is very constraining. Van Petten et al. (1999)
presented listeners with sentence frames (e.g., Sir Lancelot spared the
man's life when he begged for \_\_\_\_ ) followed by a contextually
congruent (e.g., mercy) or incongruent (e.g., mermaid) word. There were
differences in the N400 to contextually congruent and incongruent words
200 ms before the uniqueness point. However, as Nieuwland (2019) pointed
out, word recognition prior to the uniqueness point probably occurs only
in those rare situations where a spoken word is very predictable within
its context. How does context influence word-recognition processes?
According to the revised version of the model, context influences only
the later stages of word recognition. Zwitserlood (1989) supported this
assumption. Listeners performed a lexical decision task (deciding
whether visually presented letter strings were words) immediately after
hearing part of a word. When only cap \_\_\_ had been presented, it was
consistent with captain and capital. Lexical decisions were faster when
the presented word was related in meaning to either word (e.g., ship;
money). In another condition, the part word was preceded by a biasing
context (e.g., With dampened spirits the men stood around the grave.
They mourned the loss of their cap \_\_\_ ). As predicted, such context
did not prevent activation of the word capital even though it was
inconsistent with the context. In a similar study, Friedrich and Kotz
(2007) presented sentences ending with incomplete words (e.g. To light
up the dark she needed her can \_\_\_ ). Immediately afterwards,
listeners saw a visual word matched to the incomplete word in form and
meaning (e.g., candle), in meaning only (e.g., lantern), in form only
(e.g., candy) or in neither (e.g., number). As predicted by the cohort
model, the word candy was activated even though it was inconsistent with
the context. However, Weber and Crocker (2012) found context can
sometimes exert a very early influence on speech processing. Listeners
heard German sentences (e.g., The woman irons the \_\_\_\_. Bluse
(German for blouse) is a likely final word whereas the similar-sounding
word Blume (meaning flower) is implausible. Weber and Crocker studied
eye fixations to pictures of the target word (e.g., Bluse), a
similar-sounding word (e.g., Blume), and an irrelevant distractor (e.g.,
Wolke meaning cloud). Context had a powerful effect. More fixations were
directed at the target object than the other objects before the final
word was presented and this tendency increased during and after its
presentation (see Figure 9.10). However, similar-sounding words were
fixated more than irrelevant distractors shortly after the final word in
the sentence was presented. Thus, as predicted by the cohort model,
words phonologically related to a spoken word were activated even when
inconsistent with the context. Finally, we consider the notion of
"continuous integration" (Gaskell & Marslen-Wilson, 2002). As predicted
by this approach, context often influences the early stages of word
processing via top-down processes (see above, pp. 412--416).
Theoretically, the extent of such contextual effects should also depend
in part on bottom-up influences from the to-berecognised word itself.
Supporting evidence for the above predictions was reported by Strand et
al. (2018). Participants received a grammatically constraining context

427

428

Language

Figure 9.10 Fixation proportions to high-frequency target words,
high-frequency competitors that are phonologically similar to target
words, and unrelated distractor words during the first 1,000 ms after
target onset. From Weber and Crocker (2012). With kind permission from
Springer Science+Business Media.

Figure 9.11 A sample display showing two nouns ("bench" and "rug") and
two verbs ("pray" and "run"). From Strand et al. (2018).

(e.g., "They thought about the ***) or an unconstraining context (e.g.,
"The word is*** ) accompanied by a visual display (see Figure 9.11).
Suppose the target word is rug. The constraining context implies the
target should be a noun. As predicted, top-down processes led to faster
target fixation with a

Speech perception and reading

constraining context. In addition, the phonologically similar distractor
(i.e., run) was not fixated more than the phonologically dissimilar
distractors (i.e., bench; pray). However, the word run was fixated more
than other distractors when pronounced to sound more similar to the
target. What is the take-home message from the above findings? As
predicted by Gaskell and Marslen-Wilson's (2002) approach, "Listeners
make use of contextual constraints very early in word processing while
remaining sensitive to bottom-up acoustic input as words unfold" (Strand
et al., 2018, p. 969).

Evaluation The cohort model has several strengths. First, the assumption
that accurate perception of a spoken word is typically accompanied by
some processing of several competitor words is generally correct.
Second, the processing of spoken words is sequential and changes
considerably during the course of their presentation. Third, the
uniqueness point is of great importance in spoken word recognition.
Fourth, context effects often (but not always) occur during the
integration stage following word identification as predicted by the
model. Fifth, the revised versions of the model are superior to the
original version. For example, the assumption that membership of the
word cohort is a matter of degree rather than all-or-none is more in
line with the evidence. What are the model's limitations? First, context
sometimes influences word processing earlier than the integration stage.
This is especially the case when the context is strongly predictive
(e.g., Grisoni et al., 2017; discussed earlier, p. 415) or the speech
input is degraded (e.g., Wild et al., 2012; discussed earlier, p. 416).
However, Gaskell and Marslen-Wilson's (2002) more flexible approach
based on continuous integration can accommodate these (and many other)
findings. Second, the revised cohort model de-emphasises the role of
word meaning in spoken word recognition. One aspect of word meaning is
imageability (ease of forming an image of a word's referent). When there
are many words in the word cohort, high-imageability words are easier to
recognise than low-imageability ones (Tyler et al., 2000) and they are
associated with greater activation in brain areas involved in speech
perception (Zhuang et al., 2011). Thus, word selection depends on
semantic factors as well as phonological ones. Third, mechanisms
involved in spoken word recognition may differ from those emphasised
within the model. More specifically, predictive coding and enhanced
processing of speech features inconsistent with prediction may be more
important than assumed within the cohort model.

COGNITIVE NEUROPSYCHOLOGY So far we have focused on the processes used
by healthy listeners to recognise spoken words. Here we consider how
research on brain-damaged

429

430

Language

KEY TERM

patients has clarified processes involved in speech perception. Our
focus will be on repeating spoken words immediately after hearing them.
We will use the theoretical framework proposed by Ellis and Young (1988;
see Figure 9.12). There are five components:

Pure word deafness A condition involving severely impaired speech
perception but intact speech production, reading, writing, and
perception of non-speech sounds.

●

●

● ● ●

The auditory analysis system extracts phonemes or other sounds from the
speech wave. The auditory input lexicon contains information about
spoken words known to the listener but not about their meaning. Word
meanings are stored in the semantic system. The speech output lexicon
provides the spoken form of words. The phoneme response buffer provides
distinctive speech sounds.

The framework's most striking assumption is that three different routes
can be used when saying spoken words. We will discuss these routes after
considering the auditory analysis system.

Auditory analysis system Figure 9.12 Processing and repetition of spoken
words according to the three-route framework. Adapted from Ellis and
Young (1988).

Consider patients with damage only to the auditory analysis system
causing deficient phonemic processing. The expected consequences are
found in patients with pure word deafness: "an inability to understand
spoken language in the absence of any other linguistic disturbance . . .
\[they\] are perfectly capable of speaking, writing, and reading"
(Kasselimis et al., 2017,

Speech perception and reading

p. 11). Of importance, such patients should have intact perception for
nonspeech sounds (e.g., whistles) not containing phonemes. Maffei et
al. (2017) studied a female patient (FO) with pure word deafness. She
had a selective impairment in auditory language processing but intact
processing of environmental sounds and music (e.g., identifying which
musical instrument was being played). She also had intact speech,
reading and writing. Unsurprisingly, FO had damage to regions of a brain
network dedicated to speech sound processing. Slevc et al. (2011) argued
that speech perception differs from the perception of most non-speech
sounds because listeners must cope with rapid stimulus changes. They
found NL, a patient with pure word deafness, had great difficulties
discriminating sounds (speech or non-speech) differing in rapid temporal
changes. Thus, the rapid stimulus changes in spoken words may partially
explain why patients with pure word deafness have severe
speech-perception problems.

Three-route framework Ellis and Young's (1988) framework specifies three
routes that can be used when individuals process and repeat words they
have just heard (see Figure 9.12). All three routes involve the auditory
analysis system and the phonemic response buffer. Route 1 also involves
the other three components (auditory input lexicon; semantic system;
speech output lexicon). Route 2 involves two additional components
(auditory input lexicon; speech output lexicon), and Route 3 involves an
additional rule-based system converting acoustic information into words
that can be spoken. According to the three-route framework, Routes 1 and
2 are used with unfamiliar words and non-words.

Findings Patients using predominantly Route 2 should recognise familiar
words but not understand their meaning. Since they can use the input
lexicon, they should distinguish between words and non-words. Finally,
they should have problems saying unfamiliar words and non-words.
Patients with word meaning deafness fit the above description. For
example, Dr O had reasonable use of the input lexicon as shown by his
excellent ability to distinguish between words and non-words (Franklin
et al., 1996). O repeated words much more successfully than non-words
(80% vs 7%, respectively). He had impaired auditory comprehension.
However, he had intact written word comprehension indicating his
semantic system was probably not damaged. BB, a female patient with word
meaning deafness, could distinguish between words and non-words. She was
severely impaired in identifying pictures matching spoken words but not
when identifying pictures matching written words (Bormann & Weiller,
2012). Thus, BB could not access the meanings of spoken words although
her semantic processing ability was intact. Patients using only Route 3
could repeat spoken words and non-words but would have very little
comprehension of the words. Patients with

431

KEY TERM Word meaning deafness A condition in which there is selective
impairment of the ability to understand spoken (but not written)
language.

432

Language

KEY TERMS

transcortical sensory aphasia exhibit this pattern. For example, Kim et
al.

Transcortical sensory aphasia A condition in which spoken words can be
repeated but comprehension of spoken and written language is severely
impaired. Deep dysphasia A condition involving semantic errors when
trying to repeat spoken words and a generally poor ability to repeat
spoken words and non-words.

(2009) studied a male patient. He repeated spoken words but had severely
       impaired auditory and reading comprehension. These findings
       suggested he had damage within the semantic system. Kwon et
       al. (2017) studied two patients with transcortical sensory
       aphasia. Their impaired auditory comprehension appeared to be due
       to greatly decreased functional connectivity between language
       centres in the brain. Patients with deep dysphasia have extensive
       problems with speech perception and production. They make
       semantic errors when repeating spoken words by producing words
       related in meaning to those spoken (e.g., saying sky instead of
       cloud). They also have very impaired ability to repeat words and
       non-words. Ablinger et al. (2008) discussed findings from JR, a
       man with deep dysphasia. In spite of severely impaired speech
       perception, he was only slightly impaired at reading aloud words
       and non-words. We could explain deep dysphasia by arguing all
       three routes shown in Figure 9.12 are damaged. However, Jefferies
       et al. (2007) argued plausibly that the central problem in deep
       dysphasia is a general phonological impairment (i.e., impaired
       processing of word sounds). This produces semantic errors because
       it increases patients' reliance on word meanings when repeating
       spoken words. Jefferies et al. (2007) found deep dysphasics had
       poor phonological production when repeating words, reading aloud
       and naming pictures. As predicted, they also performed very
       poorly on tasks involving manipulating phonology such as the
       phoneme subtraction task (e.g., remove the initial phoneme from
       cat). Furthermore, they showed speech perception problems (e.g.,
       impaired performance when deciding whether words rhymed).

Evaluation The three-route framework is along the right lines. Patients
have various problems with speech perception (and speech production) and
evidence exists for all three routes. Conditions such as pure word
deafness, word meaning deafness and transcortical sensory aphasia can
readily be related to the framework. What are the limitations with this
theoretical approach? First, it provides only a sketch map of the
underlying mechanisms. For example, what detailed processes occur within
the semantic or auditory analysis systems? Second, it is sometimes hard
to relate patients' symptoms to the framework. For example, it is
debatable whether deep dysphasia involves impairments to all three
routes or a general phonological impairment.

READING: INTRODUCTION Reading is a very important skill -- adults
lacking effective reading skills are severely disadvantaged. Thus, we
need to understand the processes involved in reading. Reading requires
several perceptual and other cognitive processes plus a good knowledge
of language and grammar.

Speech perception and reading

Figure 9.13 A general framework of the processes and structures involved
in reading comprehension. For details, refer to text.

Linguistic and writing system knowledge Linguistic system

Orthographic system

phonology, syntax, morphology

mapping to phonology

From Perfetti and Stafura (2014).

Parser

Text representation

Inferences

Meaning morphology syntax -- argument structure -- thematic roles

Meaning and form selection

Phonological units

processes

Lexicon Word identiﬁcation

Visual input

Comprehension Orthographic units

Situation model

General knowledge (including text structure)

In this chapter, we focus mostly on basic processes used in reading
single words. Research and theory relating to reading sentences and
complete texts are discussed in Chapter 10. An overview of what is
involved in reading across all these levels is shown in Figure 9.13.
Here are its key features: (1)

(2) 
(3) 

433

Reading requires various kinds of stored information: word meanings
stored in a lexicon (mental dictionary); word spellings (orthographic
knowledge); general knowledge about the world; and linguistic knowledge.
Readers use the above knowledge sources to produce word identification
followed by text comprehension. Processes required for text
comprehension include working out the syntactical or grammatical
structure of each sentence (the parser), drawing inferences, and
producing a situation model (an integrated mental representation). The
order in which reading processes occur is flexible. This is indicated in
Figure 9.13 by bidirectional arrows (e.g., between the lexicon and
comprehension processes).

You may well feel (and you would be right!) that Figure 9.13 implies
that reading involves many complex processes. However, the good news is
that all aspects of the framework shown in that figure are discussed in
detail in this chapter and Chapter 10.

Anglocentricities Most research on reading considers only the English
language. Does this matter? Share (2008) argued strongly the
"anglocentricities" of reading research are important because the
relationship between orthography

434

Language

KEY TERMS

(spelling) and phonology (sound) is much less consistent in English than
most other languages. Caravolas et al. (2013) found English children
learned to read more slowly than children learning more consistent
languages (e.g., Spanish or Czech; see Figure 9.14).

Lexical decision task Participants presented with a string of letters or
auditory stimulus decide rapidly whether it forms a word. Naming task A
task in which visually presented words are pronounced aloud rapidly.
Orthography The study of letters and word spellings. Phonology The study
of the sounds of words and parts of words. Semantics The study of the
meaning conveyed by words, phrases and sentences.

Figure 9.14 Estimated reading ability over a 30-month period with
initial testing at a mean age of 66 months for English, Spanish and
Czech children. From Caravolas et al. (2013). Reprinted by permission of
SAGE Publications.

Research methods Numerous methods are available for studying reading.
For example, consider ways of assessing the time taken for word
identification or recognition (e.g., deciding a word is familiar;
accessing its meaning). The lexical decision task involves deciding
rapidly whether a letter string forms a word. The naming task involves
saying a printed word out loud as rapidly as possible. Both tasks have
limitations. Normal reading times are disrupted by the requirement to
respond to task demands and it is hard to identify the underlying
processes. Balota et al. (1999) argued reading involves several kinds of
processing: orthography (the spelling of words); phonology (the sound of
words); semantics (word meaning); syntax or grammar; and higher-level
discourse integration. The naming task emphasises links between
orthography and phonology, whereas the lexical decision task emphasises
links between orthography and semantics. Normal reading also involves
processing of syntax and higher-level integration, processes irrelevant
to naming or lexical decision. Recording eye movements provides an
unobtrusive and detailed on-line record of attention-related processes.
The main problem is deciding what processing occurs during each fixation
(time period during which the eye remains still). Next there is priming
(see Glossary) where a prime word is presented shortly before the target
word. This prime word is related to the target word in spelling, meaning
or sound. What is of interest is to observe the effects of the prime on
processing of (and response to) the

Speech perception and reading

target word. For example, when reading clip, do you access information
about its pronunciation? The answer is "Yes". A word preceded by a
non-word having identical pronunciation (klip) presented below the level
of conscious awareness is processed faster (Rastle & Brysbaert, 2006;
see below, p. 436). Finally, there has been a dramatic increase in
reading research using event-related potentials. ERPs provide a precise
measure of the time taken for certain processes to occur. For example,
consider the N400, a negative wave peaking at about 400 ms after word
onset. It has been assumed to reflect the time taken to access word
meaning. More specifically, a large N400 often indicates a change in the
meaning assigned to a word (Rabovsky et al., 2018; see Chapter 10).

435

KEY TERM Homophones Words pronounced in the same way but that differ in
their spellings (e.g., pain/ pane; sale/sail).

Phonological processes You are currently reading this sentence. Did you
access the relevant sounds when identifying the words in it? More
technically, did you engage in phonological processing of the words? We
guess your answer is "Yes", given that most readers experience an "inner
voice" or "inner speech" during reading. For example, readers reading a
text said they had engaged in inner speech immediately before being
questioned on 59% of occasions (Moore & Schwitzgebel, 2018). However,
subjective reports cannot demonstrate phonological processes play a
causal role in the reading process. Various answers to the above
questions have been proposed (Leinenger, 2014). Van Orden (1987) argued
phonological processing is necessary very early in word reading because
it plays a role in activating lexical entries (stored words). In
contrast, Coltheart et al. (2001) argued phonological processing is
relatively slow, and mostly inessential for word identification. Why
might we expect phonological processing to be important? Children often
learn to read using the phonics approach, which involves forming
connections between letters or groups of letters and the sounds of
spoken English (Share, 2008). Children's early phonemic skills predict
(and are probably causally related to) their future word-reading skills
(MelbyLervåg et al., 2012).

Findings Much evidence supports the hypothesis that phonological
processing is important in word reading. One approach involves the use
of homophones (words with one pronunciation but two spellings). Van
Orden (1987) found readers made many more errors when asked, "Is it a
flower? ROWS", than when asked, "Is it a flower? ROBS. The errors
occurred because readers engaged in phonological processing of the word
ROWS which is homophonic with the flower name ROSE. Jared and O'Donnell
(2017) also used homophones. Eye movements were recorded while skilled
adult readers read sentences such as: (1) Last night I made pasta for
dinner; (2) Last night I maid pasta for dinner; and (3) Last night I
mate pasta for dinner. Eye movements on incorrect sentences differed
depending on whether the incorrect word was phonologically

Case study: Phonological processes

436

Language

KEY TERM

identical to the correct one (e.g., sentence 2) or not (e.g., sentence
3). Thus, the readers used phonological processing. We can use
phonological priming (mentioned earlier, p. 434), to assess the role of
phonology in word processing. A word (e.g., clip) is immediately
preceded by a phonologically identical non-word prime (e.g., klip)
presented below the level of conscious awareness. Rastle and Brysbaert
(2006) found in a meta-analytic review that words were processed faster
when preceded by phonologically identical non-word primes than by
unrelated primes. This suggests phonological processing of visually
presented words occurs rapidly and automatically. Another approach
involves the notion of phonological neighbourhood. Two words are
phonological neighbours if they differ in only one phoneme (e.g., gate
has bait and get as neighbours). If reading involves phonological
processing, word recognition should be influenced by the number of its
phonological neighbours. This is the case (Carrasco-Ortiz et al., 2017).
Phonological processing typically occurs during reading. However, such
processing is not necessarily essential (e.g., it may occur after word
recognition has occurred) and may simply be a byproduct of reading.
However, various types of research support the hypothesis that
phonological processing causally facilitates reading. First,
phonological processing often starts within 80--100 ms of the first
fixation on a word (Leinenger, 2014). That would be fast enough to
influence word recognition. For example, Sliwinska et al. (2012) found
transcranial magnetic stimulation (TMS; see Glossary) to the
supramarginal gyrus (an area associated with phonological processing) 80
ms after word onset impaired performance on a phonological task. Second,
we can study profoundly deaf adult readers who initially learned a sign
language (e.g., American Sign Language) and so did not learn to read by
reading aloud and sounding out the letters of words. They often make
extensive use of phonological processing during the early stages of
visual word recognition (Gutierrez-Sigut et al., 2017). Suggestive
evidence that word meaning can be accessed without access to phonology
was reported by Hanley and McDonnell (1997). Their patient, PS, could
not gain access to the other meaning of homophones when he saw one of
the spellings (e.g., air) and could not pronounce written words
accurately. However, PS provided accurate definitions of printed words
suggesting he had full access to the meanings of words for which he
lacked the appropriate phonology. Similar findings were obtained from a
Chinese male patient, YGA (Han & Bi, 2009). In sum, phonological
processing is typically involved in reading and much evidence suggests
it plays a causal role. However, the findings from patients with
severely impaired phonological processing suggest some caution in
assuming that is invariably the case.

Phonological neighbourhood Words are phonological neighbours if they
differ in only one phoneme (e.g. wipe, pipe and tap are phonological
neighbours of type).

WORD RECOGNITION College students typically read at about 300 words per
minute (200 ms per word). How long does word recognition take? It is
hard to say because of imprecision about the meaning of the "word
recognition". The term can

Speech perception and reading

437

refer to deciding a word is familiar, accessing a word's name or
accessing its meaning. As a result, estimates of the time taken for word
recognition vary.

Interactive activation model McClelland and Rumelhart (1981) proposed an
influential interactive activation model of visual word processing. It
is a computational model involving considerable parallel processing and
based on the assumption that bottom-up and top-down processes interact
(see Figure 9.15): ●

●

●

●

There are recognition units at three levels: the feature level at the
bottom; the letter level in the middle; and the word level at the top.
When a feature in a letter is detected Figure 9.15 (e.g., vertical line
at the right-hand side McClelland and Rumelhart's (1981) interactive
activation model of a letter), activation goes to all letter of visual
word recognition. units containing that feature (e.g., H, M, Adapted
from Ellis (1984). N), and inhibition goes to all other letter units.
Letters are identified at the letter level. When a letter within a word
is identified, activation is sent to the word level for all four-letter
word units containing that letter in that position within the word, and
inhibition is sent to all other word units. Words are recognised at the
word level. Activated word units increase the level of activation in the
letter-level units for that word's letters.

Findings Much research has used the following task. A letter string is
presented very briefly followed by a pattern mask and participants
decide which of two letters was presented in a given position (e.g., the
third letter). Task performance is better when the letter string forms a
word -- the word superiority effect. This effect is explained by
assuming there are top-down processes from the word to the letter level.
Suppose the word SEAT is presented and participants decide whether the
third letter is A or N. If the word unit for SEAT is activated, this
increases activation of A and inhibits activation of N. Sand et
al. (2016) obtained the word superiority effect when stimuli were
presented in central vision. However, the effect disappeared when
stimuli were presented in peripheral vision. These findings suggest
topdown processes from the word level do not apply in peripheral vision.
Much research has considered orthographic neighbours (the words formed
by changing one of a target word's letters. For example, stem has

KEY TERMS Word superiority effect A target letter is more readily
detected in a letter string when the string forms a word than when it
does not. Orthographic neighbours With reference to a target word, the
number of words that can be formed by changing one of its letters.

438

Language

several orthographic neighbours (e.g., seem, step, stew). When a word is
presented, its orthographic neighbours are activated and influence its
recognition time. Orthographic neighbours facilitate word recognition if
they are less common than the word itself but have an inhibitory effect
if they are more common. Chen and Mirman (2012) developed a
computational model based on the interactive activation model's
assumptions (especially that common words are activated more than
uncommon ones) to predict these findings. The model assumes each letter
within a word is rigidly assigned to a specific position. As a
consequence, "WROD is no more like WORD than is WXYD" (Norris &
Kinoshita, 2012, p. 517). It follows that readers should have great
problems reading the "Cambridge email: Aoccrdnig to a rscheearch at
Cmabrigde Uinervtisy it deosn't mttaer in waht oredr the ltteers in a
wrod are. The olny iprmoatnt tihng is that the frist and lsat ltteer be
at the rghit pclae. The rset can be a toatl mses and you can still raed
it wouthit porbelm. Tihs is bcusease the huamn mnid deos not raed ervey
lteter by istlef but the wrod as a wlohe. In fact, most readers find it
easy to read the Cambridge email even though numerous letters are
transposed (Norris & Kinoshita, 2012). In the original research on this
topic, however, transpositions involving the ending letters of words
slowed reading rate by 26% (Rayner et al., 2006).

Evaluation The interactive activation model was an early (and extremely
influential) example of how a connectionist model (see Chapter 1) could
explain visual word processing. There is considerable support for its
central assumption that "Participants in language-processing tasks use
all the available information and start to show sensitivity to it within
a third of a second" (McClelland et al., 2014, p. 1179). Within the
model, this involves readers simultaneously using top-down and bottom-up
processes. The model accounts for the word superiority effect and a
revised version accounts for the effects of orthographic neighbours on
word recognition. What are the model's limitations? (1)

(2) 
(3) 

The model is narrow in that it ignores the role of meaning in visual
word recognition. It also ignores "how recognition processes may be
influenced by surrounding words and contexts" (Snell et al., 2018,
p. 969). Phonological processing is often involved in word recognition
(e.g., Jared & O'Donnell, 2017; discussed earlier, pp. 435--436), but
that is not considered within the model. The model exaggerates readers'
focus on the precise positions of letters within words. As Grainger
(2018, p. 341) pointed out, "\[Many\] empirical findings . . . point to
the need for a more flexible letterposition coding scheme." For example,
readers should struggle

Speech perception and reading

(4) 

to read the sentence howcanwereadwithoutspaces? because it lacks precise
information about where words start and end. In similar fashion, the
model cannot explain why the Cambridge email is easy to read. The
model's accounts for the processing of four-letter words and its
applicability to word recognition for longer words is unclear.

Semantic priming Many words within most sentences are related in meaning
and this facilitates word recognition. This often involves semantic
priming -- a word is recognised or identified more rapidly if
immediately preceded by a semantically related word. For example, we
decide faster that "doctor" is a word when preceded by a semantically
related priming word (e.g., "nurse") than by a semantically unrelated
word (e.g., "library") (Meyer & Schvaneveldt, 1971). Why does semantic
priming occur? Perhaps the priming word "automatically" activates the
stored representations of all words related to it due to massive
previous learning. Alternatively, controlled processes may be involved,
with a prime such as "nurse" leading readers to expect a semantically
related word to follow. Neely (1977) showed both the above explanations
are valid. The priming word was a category name (e.g., BIRD) followed by
a letter string at 250, 400, or 700 ms. Participants decided whether the
letter string (target) formed a word (lexical decision task).
Participants were instructed the prime BIRD would mostly be followed by
a type of bird, whereas the prime BODY would mostly be followed by part
of a building. This gives us four conditions: (1) (2) (3) (4)

Expected, semantically related (e.g., BIRD--robin) Expected,
semantically unrelated (e.g., BODY--door) Unexpected, semantically
related (e.g., BODY--heart) Unexpected, semantically unrelated (e.g.,
BIRD--arm)

It was assumed "automatic" facilitatory processes would be activated if
the target were semantically related to the prime but not if it were
semantically unrelated. In contrast, controlled processes might be
involved if the target were expected but not if it were unexpected.
Neely (1977) obtained two priming or context effects (see Figure 9.16).
First, there was a rapid, short-lived facilitatory effect based on
semantic relatedness. Second, there was a slower but more long-lasting
effect based on expectations, with expected target words showing
facilitation and unexpected ones showing an inhibitory effect. Andrews
et al. (2017) reported additional support for "automatic" semantic
priming. Skilled readers showed semantic priming even when the prime
words were presented very briefly below the level of conscious
awareness. However, there are issues concerning the interpretation of
such findings. It is hard to assess whether there is any conscious
awareness of stimuli (see Chapter 2) and the notion of "automaticity" is
imprecise (see Chapter 5).

439

KEY TERM Semantic priming The finding that word recognition is
facilitated by the prior presentation of a semantically related word.

440

Language

Sentential context effects Sentence context is used extensively during
reading. Of particular importance is word predictability. This is
typically assessed by a word's Cloze Score (the proportion of
participants provided with the first few words of a sentence guessing it
would be the next word). Readers consistently fixate for shorter periods
of time on predictable words and are more likely to skip them (Staub,
2015). These effects occur in part because there is generally more
semantic priming of predictable than unpredictable words. Word
predictability also influences eventrelated potentials. This is
especially true of the N400 component (a negative wave peaking at about
400 ms), which is larger when a word is semantically unexpected. Van
Petten and Luka (2012) reviewed the relevant ERP research and found the
N400 is smaller when a word's predictability is high within the sentence
context. They concluded, "the N400 . . . reliably indexes the benefits
of semantic context" (p. 176). Figure 9.16 The time course of inhibitory
and facilitatory effects of priming as a function of whether or not the
target word was related semantically to the prime, and of whether or not
the target word belonged to the expected category.

Early or late effects?

How can we explain the effects of word predictability? Perhaps
anticipatory processing Data from Neely (1977). © American Psychological
Association. triggered by sentence context allows readers to process
predictable words faster than unpredictable ones. Alternatively, it may
simply be easier to integrate predictable words with the preceding
context. According to this latter explanation, readers would use
contextual information only after accessing the word's meaning. Evidence
suggesting readers can use anticipatory processing was reported by
DeLong et al. (2005). Here is a sample sentence they used: The day was
breezy so the boy went outside to fly \[a kite/an airplane\] in the
park. In this sentence, a kite is highly predictable whereas an airplane
is not. There was a smaller N400 to the more predictable noun (e.g.,
kite) than the less predictable one (e.g., airplane). This finding was
replicated in a large-scale study (Nieuwland et al., 2018). More
strikingly, DeLong et al. (2005) reported a larger N400 to the article
an (preceding airplane) than to a (preceding kite). These effects on
processing prior to the presentation of a predictable or unpredictable
noun

Speech perception and reading

suggest readers predicted in advance the most likely subsequent noun.
However, this finding was not replicated (Nieuwland et al., 2018).
Freunberger and Roehm (2017) measured the N400 to more predictable and
less predictable nouns presented in sentences as well as the N400 to the
immediately preceding adverbs. There were two key findings. First, the
N400 to the noun was smaller when it was more predictable in the
sentence context. More importantly, adverbs strongly predicting the
following noun had larger N400s than less predictive ones. This was
because strongly predictive adverbs led to increased activation of
information relevant to the following noun before it was presented.

Lexical prediction vs graded prediction Luke and Christianson (2016)
distinguished between two types of prediction readers might use: (1) (2)

Lexical prediction: readers activate one specific word prior to its
presentation. Graded prediction: readers generate more partial and
general predictions (e.g., the approximate meaning of the next word;
whether the next word is a noun, verb, or some other part of speech).

Lexical prediction involves "putting all your eggs in one basket" -- if
the actual word is not the one predicted, this would probably disrupt
reading. Luke and Christianson (2016) analysed 55 text passages and
discovered only 21% of content words (words having meaning) and 40% of
function words (words clarifying grammatical structure) in these
passages were the ones most commonly guessed. Thus, most lexical
predictions would be wrong. However, word predictability speeded up
reading time across the entire range from very low to very high
(consistent with the notion of graded prediction). Frisson et al. (2017)
compared the reading time for an unpredictable (but plausible) word in a
sentence when another word was (or was not) highly predictable at that
point. Reading times were comparable. Thus, there was no prediction
error cost when an incorrect word was far more predictable than the one
actually presented. Nieuwland (2019) reviewed relevant neuroimaging
research. He concluded that the evidence for lexical prediction in
reading is "weak and inconsistent" (p. 367).

Conclusions In sum, processing can be influenced at an early stage by
word predictability (perhaps prior to the presentation of the target
word). The evidence strongly favours graded over lexical prediction.
However, lexical prediction may sometimes be used when a sentence
context very strongly predicts a given word (see DeLong et al., 2005,
above). The most convincing evidence for graded prediction is that it
has proved hard to identify any processing costs associated with
prediction errors. What is involved in graded prediction? Luke and
Christianson (2016) found readers could accurately predict general
characteristics of the next

441

442

Language

KEY TERM

word (e.g., part of speech; whether a noun will be singular or plural).
Most beneficial effects of word predictability depend on predicting such
general characteristics rather than predicting the word itself.

Pseudowords Non-words consisting of strings of letters that can be
pronounced (e.g., mantiness; fass).

READING ALOUD Read aloud the following words and non-words
(pronounceable non-words are pseudowords but we will generally use the
term non-words): CAT

FOG

COMB PINT

MANTINESS

FASS

You probably regarded that as a simple task although it involves hidden
complexities. For example, how do you know the b in comb is silent and
that pint does not rhyme with hint? Presumably you have specific
information stored in long-term memory about how to pronounce these
words. However, that does not explain your ability to pronounce
non-words such as mantiness and fass. Perhaps non-words are pronounced
by analogy with real words (e.g., fass is pronounced to rhyme with
mass). Alternatively, we may use rules governing the translation of
letter strings into sounds to generate pronunciations for non-words. The
above description is incomplete. There are different reading disorders
in brain-damaged patients depending on which parts of the language
system are damaged. We turn now to two major theoretical approaches
addressing these issues. First, there is the dual-route cascaded model
(Coltheart et al., 2001). Second, there is the distributed connectionist
approach or triangle model (Harm & Seidenberg, 2004; Plaut et al., 1996)
extended to explain reading disorders (Patterson & Lambon Ralph, 1999).
The above theoretical approaches are both connectionist models (see
Glossary). Why is this? The processes involved in skilled reading are
complex and interactive, and computational models can handle such
complexity. Of particular importance, computational models make it
easier to predict what follows from various theoretical assumptions
(Norris, 2013). There are key differences between the above approaches.
According to the dual-route approach, reading words and non-words
involves different processes. These processes are relatively neat and
tidy and some are rulebased. Alas, the dual-route approach has become
less neat and tidy over time! According to the connectionist triangle
approach, reading processes are used more flexibly than within the
dual-route model. Reading involves interactive processes -- all the
relevant knowledge we possess about word sounds, word spellings and word
meanings is used in parallel (at the same time) whether reading words or
non-words. Of importance, reading aloud involves more involvement of the
semantic system within this model. The most important difference between
the two approaches concerns whether the processes involved in reading
are specific to reading or whether they are more general. According to
the triangle approach, "Reading is, in evolutionary terms, a recently
developed skill . . . underpinned by the more mature primary systems of
vision, phonology, and semantics" (Hoffman et al., 2015, p. E3719).
Thus, reading involves relatively general systems. In contrast, the
dual-route model focuses more on reading-specific processes.

Speech perception and reading

443

We first consider each model's major assumptions plus relevant
supporting evidence. After that, we directly compare the two models on
controversial issues.

Dual-route cascaded model Coltheart et al.'s (2001) dual-route cascaded
model of reading (see Figure 9.17) accounts for reading aloud and silent
reading. There are two main routes between printed words and speech,
both starting with orthographic analysis (used for identifying and
grouping letters in words). There is a non-lexical route using
grapheme-phoneme rules to convert letters into sounds (see later
discussion). The identification of these rules is somewhat arbitrary and
open to question (Eysenck & Brysbaert, 2018). There is also a lexical
route involving lexical or dictionary look-up. In Figure 9.17, the
non-lexical route is Route 1 and the lexical route is divided into two
sub-routes (Routes 2 and 3) depending on whether the semantic system
(meanings of words) is used.

Interactive exercise: Dual-route cascade model

Figure 9.17 Basic architecture of the dual-route cascaded model. Adapted
from Coltheart et al. (2001).

444

Language

KEY TERMS

Healthy individuals use both routes in parallel when reading aloud.
However, naming visually presented words typically depends mostly on the
lexical route because it operates faster. It is a cascaded model because
it involves cascade processing with activation at one level being passed
on to the next level prior to completion of processing at the first
level. Cascaded models differ from threshold models where activation at
one level is only passed on to other levels after a given threshold of
activation is reached. Earlier we discussed the role of phonological
processing in visual word identification. Coltheart et al. (2001) argued
for a weak phonological model where word identification generally does
not depend on phonological processing. Coltheart et al. (2001) produced
a detailed computational model to test their dual-route cascaded model.
They started with 7,981 one-syllable words and used McClelland and
Rumelhart's (1981) interactive activation model (discussed earlier,
pp. 437--439), to provide the orthographic component of their model.
They predicted the pronunciation most activated by processing in the
lexical and non-lexical routes would determine the naming response.
Coltheart et al. (2001) found 99% of words and one-syllable words were
read accurately.

Cascade processing Later processing stages start before earlier
processing stages have been completed when performing a task. Grapheme A
small unit of written language corresponding to a phoneme (e.g., the ph
in photo). Phonemes The smallest units of sound that distinguish one
word from another and contribute to word meaning; the number and nature
of phonemes varies across languages. Surface dyslexia A condition in
which regular words and nonwords can be read but there is impaired
ability to read irregular or exception words.

Route 1 (grapheme--phoneme conversion) Route 1 differs from the other
routes in using grapheme--phoneme conversion, which involves converting
spelling (graphemes) into sound (phonemes). A grapheme is a basic unit
of written language whereas a phoneme is a basic unit of spoken
language. Examples of graphemes are the i in pig and the igh in high. If
a brain-damaged patient used only Route 1, what would we expect? Use of
grapheme--phoneme conversion rules (converting each grapheme into the
phoneme most closely associated with it) should permit accurate
pronunciations of words with regular spelling--sound correspondence.
However, these rules would not permit accurate pronunciation of
irregular words not conforming to the conversion rules. For example, if
the irregular word pint has grapheme--phoneme conversion rules applied
to it, it would be pronounced to rhyme with hint. This is
regularisation. Finally, grapheme-- phoneme conversion rules can provide
pronunciations of non-words. Surface dyslexics are apparently largely
reliant on Route 1. Surface dyslexia involves special problems in
reading irregular words. For example, KT, a surface dyslexic, read 81%
of regular words and 100% of non-words accurately but only 41% of
irregular words (McCarthy & Warrington, 1984). Over 70% of KT's errors
with irregular words involved regularisation. We might not expect to
find cases of surface dyslexia in languages (e.g., Greek) lacking
irregular words (i.e., all words follow grapheme--phoneme rules).
However, Sotiropoulos and Hanley (2017) identified Greek individuals
whose slow reading of Greek words suggested they might have surface
dyslexia. When these individuals read English words and non-words, they
showed the classic pattern associated with surface dyslexia: high
accuracy

Speech perception and reading

with regular words and non-words but severely impaired performance with
irregular words.

Route 2 (lexicon + semantic knowledge) and Route 3 (lexicon only) The
basic idea behind Route 2 is that representations of thousands of
familiar words are stored in an orthographic input lexicon. Visual
presentation of a word produces activation within this lexicon. This is
followed by obtaining its meaning from the semantic system, after which
its sound pattern is generated by the phonological output lexicon. Route
3 also involves the orthographic input and phonological output lexicons
but bypasses the semantic system. What would we expect to find in
patients using Route 2 or 3 but not Route 1? Their intact orthographic
input and phonological output lexicons means they could pronounce
familiar words (regular or irregular). However, their inability to use
grapheme-phoneme conversion rules means they should find it very hard to
pronounce unfamiliar words and non-words. Phonological dyslexics fit
this predicted pattern fairly well. Phonological dyslexia involves
special problems with reading unfamiliar words and non-words.
Caccappolo-van Vliet et al. (2004) studied two phonological dyslexics --
their performance on reading familiar regular and irregular words
exceeded 90% compared to under 60% with non-words. In a study discussed
above, Sotiropoulos and Hanley (2017) identified two Greek individuals
with phonological dyslexia: they had problems with non-words in Greek
and English but not words.

Deep dyslexia Deep dyslexia involves problems in reading unfamiliar
words and an inability to read non-words. However, its most striking
symptom consists of semantic reading errors (e.g., ship read as boat).
According to Coltheart et al. (2001), deep dyslexics use a completely
different reading system based in the right hemisphere (it is in the
left hemisphere for 90% of people). Accordingly, they concluded deep
dyslexia cannot be explained by the dual-route cascaded model. Most
evidence is inconsistent with this righthemisphere hypothesis.

Two routes? Findings from brain-damaged patients support the notion of
two different routes (lexical vs non-lexical) in reading words. However,
neuroimaging studies reveal individual differences. Jobard et al. (2011)
found only individuals with low working memory capacity (see Glossary)
had activation in brain areas associated with grapheme--phoneme
conversion. FischerBaum et al. (2018) found significant individual
differences in the use of the non-lexical route by skilled readers.
According to the dual-route model, the non-lexical route to reading
involves grapheme--phoneme conversion. This requires serial
left-to-right processing and so the time taken to start saying non-words
should depend

445

KEY TERMS Phonological dyslexia A condition in which familiar words can
be read but there is impaired ability to read unfamiliar words and
non-words. Deep dyslexia A condition in which reading unfamiliar words
and non-words is impaired and there are semantic errors (e.g., reading
missile as rocket).

446

Language

on their length. In contrast, the lexical route involves parallel
processing and so there should be minimal effects of length on the time
taken to start saying words. Juphard et al. (2011) found the time to
start saying three-syllable nonwords was 26% longer than one-syllable
ones, but for words this difference was only 11%. Syllabic length of
non-words (but not words) influenced the duration of activity in brain
areas associated with phonological processing. These findings suggest
producing phonological representations of non-words is a slow, serial
process whereas it is fast and parallel for words.

Preliminary evaluation The dual-route cascaded model was the first
systematic attempt to account for basic reading processes in
brain-damaged and healthy individuals. The notion there are two routes
in reading has been very influential and has attracted support from
research on patients with various reading disorders (e.g., surface
dyslexia; phonological dyslexia). The specific assumption there are
separate lexical and non-lexical routes involving parallel and serial
processing, respectively, has received behavioural and neuroimaging
support from healthy individuals. What are the model's limitations?
First, it de-emphasises semantic processes in reading (discussed later,
pp. 447--449). For example, Cattinelli et al. (2013) found in a
meta-analytic review that reading was associated with activation in
brain areas (e.g., parts of the temporal lobe; the anterior fusiform
region) associated with semantic processing. Second, the model focuses
on the reading of individual words. However, word reading in everyday
life typically occurs within sentences. Third, the model does not
exhibit learning and so cannot explain how children acquire
grapheme--phoneme rules. However, Perry et al. (2007) developed a new
connectionist dual-process model (the CDP+ model) based on the
dual-route cascaded model. This model learns and also eliminates other
problems with the dual-route model. Fourth, the model assumes
phonological processing of words typically occurs relatively slowly and
has little effect on word recognition and reading. In fact, however,
phonological processing often occurs rapidly and automatically (Rastle &
Brysbaert, 2006; discussed earlier, p. 436). Fifth, Adelman et
al. (2014) found the model did not provide an adequate account of
individual differences in reading. In addition, its assumption that
readers have perfect knowledge of letter positions within words is
incorrect. Sixth, it is desirable for computational models to have
relatively few parameters (values free to change). The dual-route model
has over 30 parameters, so it is unsurprising it fits the data well.
Seventh, there are issues concerning the model's applicability to
nonEnglish languages. For example, French orthography is unusual in that
numerous letters are silent and so lack a phonological representation.
However, the CDP+ model accounts for reading in French (Perry et al.,
2014). Eighth, the model only accounts for the reading of one-syllable
words. However, Mousikou et al. (2017) found stress, pronunciation and
naming

Speech perception and reading

times for two-syllable non-words were predicted by models incorporating
aspects of the dual-route model.

Connectionist triangle model Within the dual-route model, it is assumed
different routes are used to pronounce irregular words and non-words.
According to the connectionist triangle approach, in contrast, All of
the system's knowledge of spelling-sound correspondences is brought to
bear in pronouncing all types of letter strings \[words and non-words\].
Conflicts among possible alternative pronunciations of a letter string
are resolved . . . by co-operative and competitive interactions based on
how the letter string relates to all known words and their
pronunciations. (Plaut et al., 1996, p. 58) Thus, reading depends on a
highly interactive system based on "all hands to the pump". The triangle
model (which has been instantiated in distributed connectionist form) is
shown in Figure 9.18. The three sides of the triangle are orthography
(spelling), phonology (sound) and semantics (meaning). Of importance,
the triangle model learns to produce the correct output (i.e., spoken
word or non-word) from the input (i.e., written word or non-word) using
back-propagation (see Glossary) by comparing actual responses against
correct ones. If you compare Figure 9.18 with Figure 9.17, you can see
semantics is more important in the triangle model. Note that this model
(unlike the dual-route model) has no lexicons for orthographic or
phonological words and lacks grapheme--phoneme rules. There are two
routes from spelling to sound in the triangle model: (1) a direct
pathway from orthography to phonology (O → P pathway); (2) an indirect
pathway from orthography to phonology proceeding via semantics or word
meanings (O → S → P pathway). The direct, non-semantic pathway is
typically used when reading high-frequency and regular or consistent
words, whereas the indirect, semantic pathway is mostly used when
reading low-frequency and irregular or inconsistent words. Hoffman et
al. (2015) found brain areas associated with orthographic, phonological
and semantic processing were all activated during word reading (see
Figure 9.18). These findings are as predicted by the triangle model.
According to the triangle model, words and non-words vary in consistency
-- the extent to which their pronunciation agrees with those of
similarly spelled words (neighbours). Harley (2010) gives the examples
of TAZE and TAVE. TAZE has consistent neighbours (gaze; laze; maze),
whereas TAVE does not (have as well as gave, rave, and save). The
prediction (discussed later, p. 451) is that consistent words and
nonwords should be said faster than inconsistent ones. In contrast, the
dualroute model focuses on dividing words into regular ones (conforming

447

448

Language

Figure 9.18 The three components of the triangle model (left) and their
associated neural regions (right). O = orthography; P = phonology; S =
semantics. Orthographic processing involves the ventral
occipito-temporal cortex; phonological processing involves the
precentral gyrus; semantic processing involves the anterior temporal
lobes.

P

P

S S

O

P

S

O

From Hoffman et al. (2015).

to grapheme-phoneme rules) and irregular (not conforming to those
rules). How does the triangle model account for the different dyslexias?
It is assumed surface dyslexia mostly involves damage to the semantic
system. Plaut et al. (1996) lesioned or damaged their connectionist
model to reduce the contribution of semantics. Its performance matched
the pattern with surface dyslexics: very good with all consistent words
and non-words, worse on inconsistent high-frequency words, and worst on
inconsistent low-frequency words. The model assumes that phonological
dyslexia (involving problems in reading unfamiliar words and non-words)
involves a general impairment of phonological processing. Relevant
evidence is discussed later (see p. 450). Finally, there is deep
dyslexia (involving problems in reading unfamiliar words and non-words
plus semantic errors). Within the triangle model, deep dyslexia
represents a serious form of phonological dyslexia with severely
impaired phonological processing, leading to increased reliance on
semantic processing.

Findings Plaut et al. (1996) gave the model prolonged training with
2,998 words. Its performance resembled that of adult readers in various
ways: (1) (2) (3) (4)

Inconsistent words took longer to name than consistent ones. Rare words
took longer to name than common ones. The effects of consistency were
much greater for rare words than common ones. The network pronounced
over 90% of non-words "correctly" (comparable to adult readers). This is
impressive given the network received no direct training on non-words.

The triangle model assumes semantic processing (involving the O → S → P
pathway) is generally involved when inconsistent/irregular words are
read.

Speech perception and reading

are read. As predicted, Hoffman et al. (2015) found greater activation
within the anterior temporal lobe (associated with semantic processing)
when participants read inconsistent/irregular words than when they read
consistent/regular ones. Hoffman et al.'s (2015) findings do not show
that semantic processing within the anterior temporal lobe plays a
causal role. Ueno et al. (2018) obtained more direct evidence. They
administered transcranial magnetic stimulation (TMS; see Glossary) to
the anterior temporal lobe to impair its functioning while participants
read words. As predicted, TMS reduced reading accuracy when
inconsistent/irregular words were read but not consistent/regular words.
According to the triangle model, the O → P pathway should be used mostly
when participants read regular/consistent words. As predicted, Hoffman
et al. (2015) found functional connectivity between the brain areas
involved in orthographic (ventral occipito-temporal cortex) and
phonological processing (the precentral gyrus) was much greater with
such words than inconsistent/irregular words.

Preliminary evaluation The triangle model has several successes to its
credit. First, there is much support for the two pathways assumed to be
involved in reading aloud. Second, and most important, semantic
processing plays a major role in reading especially with inconsistent or
irregular words. Third, the triangle model focuses on how we learn to
pronounce words, unlike the original dual-route cascaded model. Fourth,
the model provides important insights into the mechanisms underlying the
dyslexias (discussed below). What are the model's limitations? First,
the model "focused on the recognition of simple, often monosyllabic
words" (Harley, 2013). Second, its emphasis is on explaining the reading
of words presented in isolation, whereas words are typically read within
a sentential context. Third, in its original version, as Plaut et
al. (1996, p. 108) admitted, "The nature of processing within the
semantic pathway has been characterised in only the coarsest way".
However, Harm and Seidenberg (2004) improved the model by implementing
its semantic component to map orthography and phonology onto semantics.

Controversial topics We turn now to controversial topics where the two
models make different predictions. Note, however, that both models have
evolved over time, and so some predictions have changed.

1 Surface dyslexia Surface dyslexics have problems reading irregular or
inconsistent words but perform reasonably well with regular or
consistent ones and with nonwords. According to the dual-route model,
surface dyslexics have damage to Routes 2 and 3 and so rely heavily on
Route 1 (grapheme--phoneme conversion). In contrast, the triangle model
claims the major problem in surface dyslexia is extensive damage to the
semantic system.

449

450

Language

Woollams et al. (2007) studied 51 patients with semantic dementia (see
Glossary), a condition involving severe loss of knowledge about word
meanings. Surface dyslexia was present in 48 of the patients, and the
remaining 3 patients became surface dyslexics as their semantic
knowledge deteriorated. Of crucial importance, there was a large
negative correlation between the ability to read low-frequency
irregular/inconsistent words and the extent of patients' semantic
knowledge. In sum, both models provide reasonable accounts of surface
dyslexia. However, evidence that surface dyslexia is associated with
severe problems within the semantic system is easier to account for on
the triangle model.

2 Phonological dyslexia Phonological dyslexia involves severe
difficulties in reading unfamiliar words and non-words. According to the
dual-route model, phonological dyslexics have an inability to use Route
1 (grapheme--phoneme conversion) -- their problems are specific to
reading. According to the triangle model, in contrast, phonological
dyslexics have a more general phonological deficit. The evidence is
mixed. Support for the dual-route model was obtained by Caccappolo-van
Vliet et al. (2004) (discussed earlier, p. 445). Their two phonological
dyslexics showed essentially intact performance on various non-reading
phonological tasks. However, Woollams and Patterson (2012) studied
patients exhibiting symptoms of phonological dyslexia when reading
aloud. The number of phonological errors these patients made in picture
naming predicted their reading performance, indicating they had a
relatively general phonological deficit. Henry et al. (2012, 2016) found
patients with symptoms of phonological dyslexia had brain damage in
areas associated with phonological processing. In addition, their
performance when reading non-words depended on phonological processes
also involved in speech production and speech perception. These findings
support the triangle model. In sum, the available evidence indicates
most (but not all) phonological dyslexics have fairly general
phonological impairments. Thus, the findings are mostly more supportive
of the triangle model.

3 Deep dyslexia Deep dyslexics make many semantic errors when reading
aloud and have problems in reading unfamiliar words and non-words. As
discussed earlier, Coltheart et al. (2001) (p. 445) argued that an
account of deep dyslexia is outside the scope of the dual-route model
because deep dyslexics predominantly use the right (rather than left)
hemisphere when reading. According to the triangle model, deep dyslexia
and phonological dyslexia both involve severe impairments in
phonological processing. The triangle model's assumptions were supported
by Jefferies et al. (2007). Deep dyslexics performed poorly on various
phonologically based tasks (e.g., phoneme addition; phoneme
subtraction). They concluded deep dyslexics have a general phonological
impairment as do phonological dyslexics. Crisp et al. (2011) found deep
dyslexics and phonological dyslexics

Speech perception and reading

451

had substantially impaired ability to translate orthography (spelling)
into phonology as predicted by the triangle model. It is plausible the
semantic errors made by deep dyslexics occur because their very severe
problems with phonological processing force them to rely heavily on the
semantic system. Ablinger and Radach (2016) studied a deep dyslexic, KJ,
who relied excessively on semantic processing while reading aloud.
Therapy based on increasing the involvement of phonological processing
enhanced his ability to read words aloud. In sum, the triangle model
provides a generally persuasive account of deep dyslexia. However, it is
probably not applicable to all deep dyslexics (Harley, 2013).

4 Word regularity vs word consistency According to the dual-route model,
regular words (those conforming to the grapheme--phoneme rules in
Route 1) can often be named faster than irregular words. According to
the triangle model, what matters is consistency. The letter patterns in
consistent words are pronounced in the same way in all words in which
they appear and such words are predicted to be read faster than
inconsistent words. Since irregular words tend to be inconsistent, we
need careful experimentation to decide whether regularity or consistency
is more important. Jared (2002) presented words belonging to the four
following categories: (1) (2) (3) (4)

Regular consistent (e.g., bean) Regular inconsistent (e.g., beak)
Irregular consistent (e.g., both) Irregular inconsistent (e.g., bear)

The findings were reasonably clear-cut: word naming times were affected
much more by consistency than regularity (see Figure 9.19). Lee et
al. (2005) studied Chinese speakers naming Chinese characters.
Performance was influenced by character consistency and character
regularity with low-frequency characters but only by consistency with
high-frequency characters. Thus, consistency and regularity both played
a role. In sum, research provides some support for the dual-route and
triangle models. However, the findings provide stronger support for the
triangle model.

5 Pronouncing non-words The dual-route model assumes non-word
pronunciations depend on the application of grapheme--phoneme rules and
so are inflexible. In contrast, the triangle model predicts

Figure 9.19 Mean naming latencies for high-frequency (HF) and
lowfrequency (LF) words that were irregular (exception words: EXC) or
regular and inconsistent (RI). Mean naming latencies of regular
consistent words matched with each of these word types are also shown.
The differences between consistent and inconsistent words were much
greater than those between regular and irregular words (EXC compared to
RI). From Jared (2002). Reprinted with permission from Elsevier.

452

Language

flexibility because non-word pronunciations depend on an individual's
previous reading experience. As predicted by the triangle model,
Coltheart and Ulicheva (2018) discovered considerable evidence of
flexibility in the pronunciations of non-words. The triangle model makes
another prediction. Variability in pronunciation should be greater with
inconsistent non-words than consistent ones because orthographically
similar words provide more possible pronunciations for the former. Zevin
and Seidenberg (2006) studied the pronunciations of consistent and
inconsistent non-words. As predicted, the pronunciations of inconsistent
words were more variable. This finding is not predicted by the
dual-route model, according to which grapheme-- phoneme rules should
typically generate only one pronunciation for all non-words. Buetler et
al. (2014) studied the influence of language context on pronunciation of
non-words. German/French bilinguals read non-words presented in a
context of French or German words. Grapheme--phoneme rules were used
more often in the German context. Why was this? The relationship between
spelling and sound is much more consistent in German than French and so
grapheme--phoneme conversion is easier to use in German.

6 General vs language-specific processes? More research supports the
triangle model's assumption that reading involves general processes than
the dual-route's assumption that it involves mostly reading-specific
processes. Woollams et al. (2018) studied stroke patients suffering from
aphasia (severe language problems). They assessed general phonological
and semantic processing abilities in these patients using tasks not
involving reading. They then related individual differences in these
abilities to reading performance. What did Woollams et al. (2018) find?
First, phonological processing ability strongly predicted reading
performance with both words and non-words. Second, semantic processing
ability strongly predicted reading performance with words but only
weakly predicted reading performance with non-words. These findings are
as predicted by the triangle model and strengthen the argument that poor
reading performance often reflects impaired general cognitive processes.
Much research on reading (and its disorders) has focused on the role of
orthography (spelling; written form of words). However, poor readers may
also have general problems with complex visual processing rather than
more specific problems relating to correctly identifying letters and
combinations of letters. Evidence that general visual processes may be
involved was reported by Sigurdardottir et al. (2018). Individuals who
were poor at reading also tended to have difficulties with face
matching. In sum, the triangle approach suggests we should stop putting
individuals with reading impairments into categories such as
"phonological dyslexia", "surface dyslexia" and "deep dyslexia".
Instead, we should assess their general semantic, phonological and
visual abilities so their underlying cognitive impairments can be
interpreted within a three-dimensional space formed by those three
abilities.

Speech perception and reading

Conclusions The dual-route and triangle models share several impressive
strengths and have deservedly been highly influential. First, both
models assume correctly that reading words and non-words aloud is a
complex achievement. Second, both models provide plausible accounts of
reading applicable to dyslexics and those with intact reading skills.
Third, both models have been implemented as computational models and so
make precise predictions. With respect to the above six controversial
issues, the triangle model has the edge (although this is less true of
relatively recent theoretical developments). Why is this so? It is
assumed within the triangle model that reading is a skill that developed
only recently in our evolutionary history. As a result, reading depends
heavily on general processes not specific to reading. In contrast, the
dual-route model's emphasis is on reading-specific processes and
structures (e.g., grapheme--phoneme rule system). This emphasis may be
misplaced if evolutionary development has not provided us with the
relevant neural architecture.

453

KEY TERMS Saccades Rapid eye movements separated by eye fixations
lasting about 250 ms. Perceptual span The effective field of view in
reading (letters to the left and right of fixation that can be
processed). Parafovea The area in the retina immediately surrounding the
fovea.

READING: EYE-MOVEMENT RESEARCH Several theoretical approaches discussed
earlier (e.g., interactive activation model; dual-route cascaded model;
triangle model) focus on explaining the processing of isolated words. In
contrast, research on eye movements during text reading has led to
theories focusing on word reading within sentential contexts (Snell et
al., 2018).

Basic processes Eye movements are crucial to reading. Most text
information we process relates to the word currently fixated. However,
limited information from other words may also be processed. Our eyes
move in rapid jerks (saccades). Saccades are ballistic (once initiated
their direction cannot be changed). Regressions (the eyes moving
backwards in the text) account for 10% of saccades. Saccades take 20--30
ms to complete and are separated by fixations lasting 200--250 ms. The
length of each saccade is about 8 letters or spaces. Information is
extracted from text only during each fixation. The amount of text from
which useful information can be extracted on each fixation has been
assessed using the "moving window" technique (Rayner et al., 2012). The
text is mutilated except for an experimenterdefined area or window
surrounding fixation point. When readers move their eyes, different
parts of the text are mutilated to permit normal reading only within the
window region. The perceptual span (effective field of view) extends 3
or 4 letters to left of fixation and up to 15 letters to the right in
English and is affected by text difficulty. The size of the perceptual
span means information from the parafovea (the area surrounding the
fovea: see Glossary) is used during reading. Convincing evidence comes
from the boundary technique. There is a preview word just to the right
of fixation. When readers make a saccade to this word, it changes into
the target word. The fixation time on the target

Interactive exercise: Dual-route reading

454

Language

KEY TERM

word is less when it is the same as the preview word (Vasilev & Angele,
2017). Readers fixate 80% of content words (nouns, verbs and adjectives)
but only 20% of function words (e.g., a, the, and, or). Words not
fixated tend to be those easily processed (e.g., common, short or
predictable). Finally, a word's fixation time is longer if preceded by a
rare word (the spillover effect). There are numerous theories of reading
based on eye-movement data. We will focus on the most influential one:
the E-Z Reader model.

Spillover effect Any given word is fixated longer during reading when
preceded by a rare word rather than a common one.

E-Z Reader model The original version of the E-Z Reader model was
proposed by Reichle et al. (1998) and has been followed by several other
versions (Sheridan & Reichle, 2016). The model assumes the mind and eyes
are tightly coupled, and so patterns of eye movements provide
potentially rich data concerning readers' processing strategies. The
most obvious model would assume we fixate a word until it is processed
adequately, after which we immediately fixate the next word. Alas, there
are two major problems with this model. First, it takes 85--200 ms to
execute an eye-movement programme and so readers would waste time
waiting for their eyes to move to the next word. Second, readers
sometimes skip words. According to the model, readers know nothing about
the next word until it is fixated. How, then, could they decide which
words to skip? The E-Z Reader model provides elegant solutions to the
above problems. A crucial assumption is that the next eye movement is
programmed after only partial processing of the current word (word n).
This greatly reduces the time between completing processing of word n
and an eye movement to the next word (word n+1). There is typically less
spare time available with rare words than common ones -- this accounts
for the spillover effect. If the processing of word n+1 is completed
rapidly enough, it is skipped. According to the model, readers can
attend to two words (words n and n+1) during a single fixation. However,
it is a serial processing model -- at any given moment, only one word is
processed. Here are its main assumptions (see Figure 9.20): (1) (2) (3)
(4) (5)

Readers check the familiarity of the word currently fixated (word n).
Completion of the familiarity check (the first stage of lexical access)
is the signal to initiate an eye-movement programme. Readers then engage
in the second stage of lexical access, which involves accessing word n's
semantic and phonological forms. Familiarity checking and lexical access
are completed faster for easily processed words (e.g., common; short;
predictable). Completion of lexical access to word n signals a shift of
covert (internal) attention to word n+1.

Several findings support the model (Reingold et al., 2012). First,
common words are fixated for less time than rare ones. Second, a word
following a rare word is fixated longer than one following a common word
(the

Speech perception and reading

Eyes ﬁxate word n + 1 Focus of attention on word n + 1 Lexical access of
word n

Preview time

Familiarity check on word n

Time (ms)

455 Figure 9.20 Key assumptions of the E-Z Reader model. The x-axis
shows the processing difficulty of the word currently being fixated
(word n). The preview time (shaded area) is the time available for
parafoveal processing of word n+1 (covert attention) prior to eye
fixation on that word. From Sheridan & Reichle (2016).

Easy

Difficult

Word n processing difficulty

spillover effect) because it receives less parafoveal processing when
word n is rare (Luke, 2018). Third, word n+1 is skipped when its lexical
access has been completed during fixation on word n. This typically
occurs when word n is common, short or predictable. The E-Z Reader model
(which emphasises serial processing) can be contrasted with parallel
processing models such as the SWIFT model (Saccade-Generation With
Inhibition by Foveal Targets) model (e.g., Engbert et al., 2005; Schad &
Engbert, 2012). This model assumes the durations of eye fixations in
reading are often influenced by parallel processing of the previous and
next words as well as the current one. Attentional processes are of
central importance to both models. The E-Z Reader model assumes an
attentional spotlight moves from one word to the next. Within the SWIFT
model, in contrast, attention is more like a zoom lens because its scope
can change (see Chapter 5). Attention is widely distributed when foveal
processing is easy but more narrowly focused when it is hard. The two
models both account for most findings. However, they differ with respect
to lexical parafoveal-on-foveal effects. This sounds complicated but
simply means lexical properties of the next word (e.g., its frequency
and/ or predictability) influence the fixation duration on the current
word. Such effects should not occur according to the serial processing
E-Z Reader model, but they can occur according to the parallel
processing SWIFT model.

Findings

KEY TERM

According to the E-Z Reader model, there are two stages of lexical
processing for words: (1) checking word familiarity; (2) lexical access
(accessing semantic and phonological information about the word).
Sheridan and Reingold (2013) argued that presenting words faintly
disrupts stage (1) but not stage (2). In contrast, case alternation
(e.g., tAbLe) disrupts only stage (2). Their findings were as predicted,
thus supporting the notion that lexical processing occurs in two stages.

Lexical parafoveal-onfoveal effects The finding that fixation duration
on the current word (word n) is influenced by lexical properties of the
next word (word n+1).

456

Language

According to the E-Z Reader model, readers use parafoveal processing to
extract limited information from the next word (n+1) before it is
fixated (this occurs during the preview time shown in Figure 9.20). As a
result, fixation time on word n+1 is reduced when parafoveal processing
is possible. Vasilev and Angele (2017) found in a meta-analysis that
parafoveal review reduced gaze duration on word n+1 by an average of 40
ms. What information is extracted from word n+1 during parafoveal
review? Schotter et al. (2012) found that orthographic (word spelling),
phonological (word sound) and morphological (word structure) information
can all be processed parafoveally. As mentioned earlier, readers
sometimes skip word n+1 (i.e., do not fixate it) when reading. This
suggests a complete identification of word n+1 can occur during
parafoveal review. Consistent with these findings, Angele et al. (2016)
found evidence for two stages of parafoveal processing: (1) early
orthography-based processing; and (2) late attentionally dependent
lexical access. Most research has focused only on the English language.
Rayner et al. (2007) studied eye movements in Chinese individuals
reading Chinese text. Chinese differs from English in that it is written
without spaces between characters. Nevertheless, the pattern of eye
movements resembled that found in readers of English. We turn now to
lexical parafoveal-on-foveal effects where lexical properties (e.g.,
frequency) of the next word influence the processing of the current
word. Remember the SWIFT model predicts such effects whereas the E-Z
Reader model does not. There would be evidence for parafoveal-on-foveal
effects if gaze duration on word n were greater when word n+1 was a
low-frequency rather than high-frequency word. Brothers et al. (2017)
conducted a meta-analytic review of research where the frequency of word
n+1 was manipulated. There was no evidence for parafoveal-on-foveal
effects across several languages (e.g., English; Finnish; Spanish;
Chinese). Brothers et al. reported a similar absence of lexical
parafoveal-on-foveal effects in further meta-analyses focusing on other
features of word n+1 related to lexical access (i.e., semantic
plausibility; lexical predictability). Degno et al. (2019) pointed out
that most previous research had used very artificial reading conditions.
They used a more natural reading task, but also failed to find any
evidence of lexical parafoveal-on-foveal effects.

Evaluation The E-Z Reader model is very successful in several ways.
First, there is ample justification for its emphasis on eye-movement
patterns, because "the control of eye movements is part and parcel of
the dynamics of information processing within the task of reading
itself" (Radach & Kennedy, 2013, p. 429). Second, it identifies several
factors (e.g., word frequency; word predictability) determining eye
fixations in reading. Third, there is support for the assumption lexical
processing occurs in two separate stages (i.e., familiarity checking and
lexical access). Fourth, parafoveal preview of the next word typically
facilitates its subsequent processing when fixated. Fifth, the
assumption there are close

Speech perception and reading

connections between eye (fixations) and mind (cognitive processes) has
received support (e.g., Bixler & D'Mello, 2016). Sixth, the absence of
lexical parafoveal-on-fovea effects supports serial models (e.g., E-Z
Reader) over parallel models (e.g., SWIFT). What are the model's
limitations? (1)

(2) 
(3) 
(4) 

The E-Z Reader and SWIFT models both explain where and when the eyes
move during reading. Such approaches have proceeded independently of
approaches (e.g., McClelland & Rumelhart's, 1981, interactive activation
model) designed to identify the processes involved in word recognition.
However, Snell et al. (2018) produced a computational model of reading
(OB1-reader) integrating insights from eye-movement and word-recognition
models. The role of higher-level processes is de-emphasised. For
example, the processes involved in inference drawing, integration of
information within sentences, and the use of schematic and other
knowledge in text comprehension are outside the model's scope (see
Chapter 10). We do not know in detail how readers perform the
familiarity check. Reingold et al. (2015) argued it depends on the
fluency of orthographic processing (processing the pattern of letters)
but the evidence is inconclusive. There may be more parallel processing
during reading than acknowledged by the E-Z model. For example, Snell et
al.'s (2018) OB1-reader model (which assumes extensive parallel
processing) successfully accounts for many aspects of reading behaviour.

CHAPTER SUMMARY •

Speech (and music) perception: introduction. Speech and music perception
both involve categorical perception. However, there are typically
substantial differences in the brain areas activated during speech and
music perception. In addition, some patients have selective impairment
of speech or music perception. Speech perception involves various stages
starting with selection of speech from the acoustic background and
including word recognition and utterance interpretation. Speech
perception is often more variable than implied by the notion of
sequential stages.

•

Listening to speech. Among the problems faced by listeners are the speed
of spoken language, the segmentation problem, co-articulation,
individual differences in speech patterns, and degraded speech.
Listeners prefer to use lexical (e.g., syntax) information to achieve
word segmentation but can also use co-articulation, allophony and
syllable stress. Listeners often cope with variations between speakers
by forming a speaker model. The McGurk effect shows listeners often make
use of visual information (i.e., lip-reading) during speech perception.

457

458

Language

•

Context effects. Context influences speech perception in several ways
(e.g., phonemic restoration effect; Ganong effect) There is much
controversy concerning how context influences speech perception. The
main divide is between those arguing such effects occur late in
processing (autonomous position) and those arguing they can also occur
early in processing (interactionist position). The interactionist
position has received much support recently. However, it is more
applicable when speech is degraded than when it is clear and
unambiguous.

•

Theories of speech perception. Spoken word recognition is often
influenced by orthography (word spellings). According to the motor
theory, motor processes can facilitate speech perception. In support,
brain areas involved in speech production are typically involved in
speech perception. Impaired speech perception following damage to
speech-production systems also supports the theory. However, many brain
areas are involved in speech perception but not speech production. The
TRACE model assumes bottom-up and top-down processes interact flexibly
in spoken word recognition. The model accounts for several phenomena
(e.g., word superiority effect, the Ganong effect, categorical
perception and the phonemic restoration effect). However, it has a
narrow focus on word recognition, it exaggerates the importance of
top-down processes and it de-emphasises the role of conceptual meaning.
The cohort model assumes spoken word recognition involves rejecting
competitors in a sequential process. It also assumes that context
effects occur during the integration stage following word
identification. However, context sometimes influences word processing
prior to the integration stage. The model also de-emphasises the role of
word meanings in spoken word recognition. There is support for the more
recent assumption that there is continuous integration of information
from the speech input and context.

•

Cognitive neuropsychology. Brain-damaged patients exhibit various
patterns of impairment in speech perception. Some of these patterns can
be explained by assuming the existence of three routes between sound and
speech. Support has been obtained by studying patients with pure word
deafness, word meaning deafness and transcranial sensory aphasia. The
threeroute approach provides a sketch map rather than a detailed
theoretical account.

•

Reading: introduction. It is harder to read English than most other
languages because the relationship between spelling and sound is very
inconsistent. Lexical decision, naming and priming tasks are used to
assess word identification. Studies of masked phonological priming
suggest that visual word recognition typically depends on

Speech perception and reading

prior phonological processing. The finding that word recognition depends
on the number of phonologically similar words also indicates the
importance of phonological processing. •

Word recognition. According to the interactive activation model,
bottom-up and top-down processes interact during word recognition. The
model accounts for the word-superiority effect and the effects of
orthographic neighbours on word recognition but not for the roles of
meaning and sound. Semantic priming can facilitate word recognition
"automatically" or in a more controlled fashion. More generally,
semantic priming reduces the amount of visual information required for
word recognition. Words predictable within the sentence context are
processed faster than those less predictable. Readers' predictions are
typically general or graded rather than specific, which minimises
prediction-error costs.

•

Reading aloud. According to the dual-route model, reading involves
lexical and non-lexical routes (the latter involving grapheme--phoneme
conversion rules). Surface dyslexics rely mainly on the non-lexical
route whereas phonological dyslexics use mostly the lexical route. The
triangle model consists of orthographic, phonological and semantic
systems. The reading of regular or consistent words involves a pathway
from orthography to phonology, whereas the reading of
irregular/inconsistent words involves a pathway from orthography to
phonology via semantics. Surface dyslexia is attributed to damage within
the semantic system, whereas phonological dyslexia stems from a general
phonological impairment. The triangle model emphasises general processes
not specific to reading whereas the dual-route model focuses on
reading-specific processes. The triangle model provides a more adequate
account (e.g., the importance it attaches to semantic processing is well
supported).

•

Reading: eye-movement research. According to the E-Z Reader model, the
completion of familiarity checking of the current word is the signal to
initiate an eye-movement programme, and the completion of lexical access
is the signal to shift attention covertly to the next word. It is a
serial processing model in contrast to parallel processing models (e.g.,
SWIFT). The absence of lexical parafoveal-on-foveal effects (lexical
effects of the next word on processing of the current word) supports
serial models. The E-Z Reader model is limited because it de-emphasises
the processes involved in word recognition and higher-level reading
processes (e.g., use of knowledge in text comprehension).

459

460

Language

FURTHER READING Cai, Z.G. & Vigliocco, G. (2018). Word processing. In S.
Thompson-Schill (ed.), Stevens' Handbook of Experimental Psychology and
Cognitive Neuroscience, Vol. 3: Language and Thought (4th edn;
pp. 75--110). New York: Wiley. The processes involved in processing
words presented in text and in speech are discussed in detail. Eisner,
F. & McQueen, J.M. (2018). Speech perception. In S. Thompson-Schill
(ed.), Stevens' Handbook of Experimental Psychology and Cognitive
Neuroscience, Vol. 3: Language and Thought (4th edn; pp. 1--46). New
York: Wiley. This chapter contains a comprehensive account of basic
processes involved in speech perception. Grainger, J. (2018).
Orthographic processing: A "mid-level" vision of reading: The 44th Sir
Frederic Bartlett lecture. Quarterly Journal of Experimental Psychology,
71, 335-- 359. Basic processes involved in word recognition and reading
are discussed in detail in this article by Jonathan Grainger. Nieuwland,
M.S. (2019). Do "early" brain responses reveal word form prediction
during language comprehension? A critical review. Neuroscience and
Biobehavioral Reviews, 96, 367--400. Mante Nieuwland discusses how
contextual information is used by readers and listeners. Pickering, M.J.
& Gambi, C. (2018). Predicting while comprehending language: A theory
and review. Psychological Bulletin, 144, 1002--1044. Martin Pickering
and Chiara Gambi provide a thorough discussion of research supporting
the theoretical assumption that listeners' speech perception often
depends on their speech-production system. Schwanenflugel, P.J. & Knapp,
N.F. (2016). The Psychology of Reading: Theory and Applications. New
York: Guilford Press. Paula Schwanenflugel and Nancy Knapp provide a
comprehensive account of theory and research on reading. Snell, J., van
Leipsig, S., Grainger, J. & Meeter, M. (2018b). OB1-reader: A model of
word recognition and eye movements in text reading. Psychological
Review, 125, 969--984. Joshua Snell and colleagues provide a theoretical
model of reading based on word-recognition and eye-movement research.

Chapter

Language comprehension

10

INTRODUCTION Basic processes involved in the identification of
individual words during the initial stages of reading and listening to
speech were discussed in Chapter 9. In this chapter, we discuss how
phrases, sentences and entire texts (e.g., stories) are processed and
understood during reading and listening. Sentence comprehension is
complex. Neural activity within the brain increases steadily during the
reading of a sentence but not with non-word lists or meaningless
sentences (Fedorenko et al., 2016). This progressive increase "reflects
the increasing complexity of the evolving representation of the meaning
of the sentence" (Fedorenko et al., 2016, p. E6262). The previous
chapter dealt mainly with aspects of language processing differing
between reading and listening to speech. In contrast, higher-level
comprehension processes are similar whether a story is listened to or
read. The research focus has been on comprehension processes in reading
rather than listening and so our emphasis will be on reading. However,
what is true of reading is mostly also true of comprehending speech.
What is the structure of this chapter? We start by considering
comprehension at the sentence level and finish by focusing on
comprehension processes with larger language units (e.g., complete
texts). More detail is given below. There are two main levels of
analysis in sentence comprehension. First, there is an analysis of the
syntactical structure of each sentence. Syntax involves a study of the
rules of word order. Grammar is somewhat broader in meaning. It focuses
on the structure of a language (especially syntax and inflections).
Inflections involve modifying nouns or verbs to indicate grammatical
changes (e.g., adding -ed to a verb to indicate the past tense). Second,
there is an analysis of sentence meaning. The intended meaning of a
sentence often differs from its literal meaning as in irony, sarcasm or
metaphor. For example, someone may say "Don't overdo it!" when talking
to a notoriously lazy colleague. The study of intended meaning is
pragmatics. The context in which a sentence is spoken can also influence
its intended meaning. Issues concerning pragmatics are discussed
immediately after the section on parsing. In the third section, we
consider processes involved when individuals are presented with a text
or speech consisting of several or numerous

KEY TERMS Syntax The set of rules concerning word order to create
well-formed sentences. Grammar The set of rules governing the structure
of a language (especially syntax and inflections). Inflections
Grammatical changes to nouns or verbs (e.g., adding -s to a noun to
indicate the plural; adding -ed to a verb to indicate the past tense).

462

Language

KEY TERMS

sentences. Our focus will mainly be on the inferences readers and
listeners draw during comprehension. The major theoretical issue is the
following: what determines which inferences are (or are not) drawn
during language comprehension? In the fourth section, we consider
processing involving larger units of language. When we read a text, we
typically try to integrate the information within it. Such integration
often involves drawing inferences, identifying the main themes in the
text, and so on. These integrative processes (and theories put forward
to explain them) are discussed in this section.

Parsing Analysing the syntactical or grammatical structure of sentences.
Morphology The study of words and how they are formed from morphemes.

PARSING: OVERVIEW This section is devoted to parsing (analysis of the
syntactical or grammatical structure of sentences) plus the processes
readers and listeners use to comprehend sentences. Parsing allows
readers and listeners "to say who did what to whom (or how, when, and
where)" (Traxler, 2014, p. 605). Most parsing research has focused only
on the English language. Does this matter? The short answer is "Yes".
Information about grammar can be provided by word order or by inflection
(see Glossary). Many languages (e.g., Arabic; German; French) are more
inflectional than English and thus have a richer morphology (analysis of
the morphemes or basic units of meaning within words). Such languages
permit greater flexibility of word order than English. As a consequence,
it has proved easier to develop computational models of parsing for
English than most other languages (Tsarfaty et al., 2013).

Syntax and grammar We can produce an infinite number of grammatically
correct sentences in any language (this is known as productivity).
Linguists (e.g., Chomsky, 1957) have produced rules explaining the
productivity and regularity of language. A set of rules focusing on
syntax or word order and inflections forms a grammar. Ideally, we can
use a grammar to decide whether any given sentence is permissible or
unacceptable. Numerous sentences are ambiguous. Some are globally
ambiguous meaning the entire sentence has two interpretations (e.g.,
"Kids make nutritious snacks"). Others are locally ambiguous -- various
interpretations are possible during parsing. Why are so many sentences
ambiguous? Language users apply a least effort principle because it
would be very demanding for speakers and writers to produce only
unambiguous sentences (Solé & Seoane, 2015). Piantadosi et al. (2012)
argued listeners and readers can usually deal with some ambiguity. The
context typically provides useful information about sentence meaning. In
addition, it would be inefficient (and extremely boring for listeners
and readers!) if spoken or written language duplicated that information.
Why does much research on parsing use ambiguous sentences? Parsing
generally occurs very rapidly, which makes it hard to study the
processes

Language comprehension

involved. Assessing the problems encountered by listeners and readers
struggling with ambiguous sentences is revealing about parsing
processes.

Prosodic cues One way that listeners work out the syntactic or
grammatical structure of spoken languages is by using prosodic cues
(e.g., stress; intonation; rhythm; word duration). When each syllable is
spoken in a monotone lacking prosodic cues, listeners struggle to
understand the speaker (Duffy & Pisoni, 1992). The use of prosodic cues
by speakers and writers is discussed in Chapter 11. Suppose a spoken
sentence contains a prosodic cue (pause) that occurs misleadingly at a
place conflicting with its syntactic structure. Pauker et al. (2011)
found this made the sentence much harder to understand, thus showing the
impact of prosodic cues (this study is discussed in more detail later,
see p. 466). Prosodic cues are most valuable with ambiguous spoken
sentences. Consider the ambiguous sentence, "The old men and women sat
on the bench". If the women are not old, the spoken duration of men will
be relatively long and the stressed syllable in women will have a steep
rise in pitch contour. Listeners often use prosodic cues very rapidly to
facilitate the understanding of ambiguous sentences. Holzgrefe et
al. (2013) presented word strings such as Mona oder Lena und Lola \[Mona
or Lena and Lola\] auditorily with a pause and other prosodic cues
occurring after the word Mona (early pause) or Lena (late pause). When
the pause came after the word Lena to indicate it was Mona or Lena as
well as Lola, listeners immediately integrated the prosodic information
into their parsing. In a similar study, Petrone et al. (2017) found
parsing was more influenced by pauses at phrase boundaries than other
prosodic cues (e.g., phrase-final lengthening: longer sound at the end
of a phrase). As Drury et al. (2016, p. 1) pointed out, "Unlike speech,
written language does not provide the same wealth of prosodic
information". How do readers cope? According to Fodor's (1998) implicit
prosody hypothesis, readers activate prosodic patterns during silent
reading using their "inner voice". Support for Fodor's (1998) hypothesis
was reported by Steinhauer and Friederici (2001), who asked participants
to listen to sentences containing pauses and read sentences containing
commas. Event-related potentials (ERPs; see Glossary) were similar in
both cases suggesting participants used their "inner voice" while
reading. In a similar reading study, Drury et al. (2016) manipulated the
plausibility of sentences via the presence or absence of commas (e.g.,
John, said Mary, was the nicest boy at the party vs John said Mary was
the nicest boy at the party). The impact of this manipulation on ERPs
closely resembled the impact of manipulating pauses with similar spoken
sentences in previous research. These findings are also consistent with
the implicit prosody hypothesis. Direct evidence implicit prosody
benefits reading was reported by Calet et al. (2017). Prosody training
(reading with an emphasis on sensitivity to prosody) increased reading
fluency and comprehension in primary-school children.

463

464

Language

The effects of prosody are more complex than indicated so far in three
ways. First, we must consider the overall pattern of prosodic phrasing
within a sentence rather than simply what happens at one particular
point. Consider the following ambiguous sentence: I met the daughter
(#1) of the colonel (#2) who was on the balcony. Frazier et al. (2006)
found the interpretation of this sentence depended on the relationship
between the phrase boundaries at #1 and #2. Listeners were much more
likely to assume the colonel was on the balcony when the first boundary
was greater than the second one than when the first boundary was smaller
than the second. Second, there is much evidence that individual speakers
differ considerably in their production of prosody (Cole, 2015). This
variability makes it harder for listeners to understand what any given
speaker is saying. Third, Fodor (1998) assumed implicit prosody in
reading (based on inner speech) is very similar to explicit or spoken
prosody. Research findings supporting this assumption were discussed
earlier. However, it is not always supported. Jun (2010) found
systematic differences between prosody generated in silent reading and
prosody generated in reading aloud when the text had not been skimmed in
advance. Thus, the implicit prosody hypothesis may have limited
applicability.

THEORETICAL APPROACHES: PARSING AND PREDICTION An important theoretical
issue is to work out when different kinds of information are used during
sentence comprehension. Much research on parsing concerns the
relationship between syntactic and semantic analysis. There are at least
four major possibilities: (1) (2) (3) (4)

Syntactic analysis generally precedes (and influences) semantic
analysis. Semantic analysis usually occurs prior to syntactic analysis.
Syntactic and semantic analysis occur at the same time. Syntax and
semantics are very closely associated and have a hand-inglove
relationship (Altmann, personal communication).

At the risk of oversimplification, early theories of parsing tended to
favour possibility (1) above, whereas later ones focus more on the
remaining possibilities (Traxler, 2014). There are more models of
parsing than you can shake a stick at. However, many belong to two
categories: (1) two-stage, serial processing theories; (2) one-stage,
parallel processing models. The garden-path model (Frazier & Rayner,
1982) has been the most influential one in the first category. Its key
assumption is that the initial attempt to parse a sentence uses only
syntactic information. MacDonald et al.'s (1994) constraint-based model
has been the most influential example of a one-stage, parallel
processing model. Its key

Language comprehension

assumption is that all information sources (syntactic; semantic;
contextual) are used from the outset to construct a syntactic model of
each sentence. We initially consider the above two models. After that,
we turn to alternative models. One of these is the unrestricted race
model, which combines aspects of the garden-path and constraint-based
models. We will discover many apparent inconsistencies in research
findings on parsing. Why is that? Most people are very sensitive to
language subtleties. As a result, sentence parsing often varies because
of relatively minor differences in the sentences presented. It has often
been assumed in linguistics and cognitive psychology that nearly all
adult native speakers have fully mastered the grammar of their language
(Chomsky, 1965), and this assumption is implicit in many theories and
much research. It follows from the above assumption that inaccurate
sentence parsing reflects deficient processing rather than deficient
grammatical knowledge and competence. In fact, non-verbal IQ correlates
+.46 with grammatical knowledge, meaning that many individuals with low
non-verbal IQ have severely deficient grammatical knowledge (Dąbrowska,
2018). However, researchers rarely consider deficient grammatical
knowledge as a potential explanation for poor parsing performance.

Garden-path model Frazier and Rayner's (1982) garden-path model was an
early theory of parsing. It is so-called because readers (and listeners)
can be misled or "led up the garden path" by ambiguous sentences. A
famous (or notorious!) example of such a sentence is "The horse raced
past the barn fell". It is notorious because it is very hard to
understand (partly because such sentences occur exceptionally rarely in
naturally produced sentences). The model incorporates the following
assumptions: ● ●

●

●

●

●

●

Only one syntactical structure is initially considered for any sentence.
Meaning is not involved in the selection of the initial syntactical
structure. Two general principles influence the initial syntactical
structure: minimal attachment and late closure. According to the
principle of minimal attachment, the structure producing the fewest
nodes (major parts of a sentence such as noun phrase and verb phrase) is
preferred. The principle of late closure is that new words encountered
in a sentence are attached to the current phrase or clause if
grammatically permissible. Conflict between the above two principles is
resolved in favour of the minimal attachment principle. If the initial
syntactic structure is incompatible with additional information (e.g.,
semantic), it is revised during a second processing stage.

465

466

Language

Why do readers use the minimal attachment and late closure principles?
According to Clifton et al. (2016, p. 8): they arise "out of the
pressure to interpret a sentence as quickly as possible . . . relating
new words to phrases currently in active memory is faster than building
new or more complex structures".

Findings The relevance of the principle of minimal attachment was shown
by Frazier and Rayner (1982). Consider the following sentences: (1) (2)

The girl knew the answer by heart. The girl knew the answer was wrong.

The minimal attachment principle produces a grammatical structure in
which the answer is treated as the direct object of the verb "knew".
This is appropriate only for the first sentence. As predicted, Frazier
and Rayner found eye fixations were longer with the second sentence.
Frazier and Rayner (1982) also showed the importance of the principle of
late closure. Consider the following sentences: (1) (2)

Since Jay always jogs a mile it seems like a short distance to him.
Since Jay always jogs a mile seems like a short distance to him.

Use of the principle of late closure leads a mile to be included in the
first clause as the object of jogs. This is appropriate only for the
first sentence. Readers had very long fixations on the word seems in the
second sentence when it became clear the principle of late closure was
not applicable. However, the second sentence is much easier to read with
a comma (a prosodic cue) after jogs (Rayner et al., 2012). According to
the garden-path model, the syntactic structure of sentences can often be
worked out in the almost complete absence of semantic information.
Supporting evidence comes from patients with semantic dementia (a
condition involving loss of word meanings; see Glossary and Chapter 7).
Such patients sometimes show essentially intact performance on tasks
involving grammaticality judgements (e.g., Garrard et al., 2004). In a
study mentioned earlier, Pauker et al. (2011) presented listeners with
sentences such as the following including prosodic cues (pauses
indicated by #): (1) (2)

When a bear is approaching the people \# the dogs come running. When a
bear is approaching \# the people \# the dogs came running.

According to the model, listeners should apply the principle of late
closure and so find it easy to identify the correct syntactical
structure. This was found with sentences such as (1) where the pause's
location coincided with the syntactic structure. In contrast,
performance was very poor with sentences such as (2) because of the
misleading pause (e.g. between approaching and people). Thus, listeners'
adherence to the principle of late closure can be greatly disrupted by
misleading prosodic cues. Drury et al. (2016),

Language comprehension

in a study discussed earlier (p. 463), obtained similar findings when
readers were presented with ambiguous sentences and commas which
indicated (or failed to indicate) the appropriate syntactic structure.
According to the garden-path model, the initial parsing of an ambiguous
sentence should be uninfluenced by visual context providing information
relevant to the sentence's interpretation. Coco and Keller (2015)
presented listeners with ambiguous sentences and with relevant visual
context. Ambiguity resolution within the sentence depended mostly on
linguistic information, which is broadly consistent with the model.
However, visual context had more influence on sentence processing than
expected by the model. Finally, when readers initially construct an
incorrect syntactic structure for a garden-path sentence, the model
predicts they should revise it in the light of additional information
and so typically produce the correct syntactic structure. Findings
reported by Qian et al. (2018) are inconsistent with this prediction.
Readers were presented with garden-path sentences such as the following:
While the man hunted, the deer that was brown and graceful ran into the
woods. This was followed by the question, Did the man hunt the deer?
Readers produced numerous incorrect "Yes" responses with such sentences
(approximately 50% errors). Thus, they often failed to work out the
correct syntactic structure.

Evaluation The model provides a simple and coherent account of parsing.
The principles of minimal attachment and late closure often influence
the selection of an initial syntactic structure for sentences. The model
is plausible in that these two principles reduce processing demands on
the reader or listener. What are the model's limitations? First, it
assumes parsers who discover that their initial preferred syntactic
structure is incorrect go back to square one and form an alternative
structure. As Kuperberg and Jaeger (2016) pointed out, this
"all-or-nothing" assumption is simply incorrect. More generally, the
model mistakenly assumes initial attempts at parsing are inflexible (see
below, pp. 468--470). Second, opposed to the model's assumptions, den
Ouden et al. (2016) found syntactic processing typically does not occur
in the absence of other forms of processing. This conclusion was based
on patterns of brain activation during the processing of garden-path
sentences. Behavioural evidence discussed shortly indicates that several
factors (including misleading prosody and prior context) prevent readers
and listeners from adhering to the principles of minimal attachment and
late closure. Third, the model assumes readers will ultimately generate
a correct syntactic structure even for complex sentences. However, this
is often not the case when sentences are complex and hard to comprehend
(e.g., Qian et al., 2018).

467

468

Language

Fourth, the model is hard to test. For example, evidence that
nonsyntactic information is used early in sentence processing seems
inconsistent with the model. However, the second stage of parsing
(following the first, syntactic stage) may simply start very rapidly.
Fifth, the model is more applicable to English than other languages. For
example, there is a preference for early (rather than late) closure in
several languages (e.g., Spanish; Russian; French) (Harley, 2013).
Mandarin differs from most European languages in having fewer reliable
cues to syntactic structure and a more flexible word order (Huang et
al., 2016). Thus, principles such as those of minimal attachment and
late closure are not directly relevant to Mandarin.

Constraint-based model According to MacDonald et al.'s (1994)
constraint-based model, initial sentence interpretation depends on
multiple information sources (e.g., syntactic; semantic; general world
knowledge) called constraints. These constraints limit (or constrain)
the number of possible interpretations. The model is based on a
connectionist architecture (see Chapter 1) which exhibits learning
through experience. It is assumed all relevant sources of information
are immediately available to the parser. Competing analyses of the
current sentence are activated at the same time. The syntactic structure
receiving most support from the various constraints is more activated
than other syntactic structures. Confusion occurs if the correct
syntactic structure is less activated than one or more incorrect
structures. The processing system uses four language characteristics to
resolve sentence ambiguities: (1) (2) (3) (4)

Grammatical knowledge constrains possible sentence interpretations. The
various forms of information associated with any given word are
typically not independent of each other. A word may be less ambiguous in
some ways than in others (e.g., ambiguous tense but not grammatical
category). The various interpretations permissible according to
grammatical rules generally differ considerably in frequency and
probability based on past experience. The syntactic interpretation most
consistent with such experience is typically selected.

MacDonald (2013) developed her constraint-based model. She started by
assuming speakers use various strategies to reduce processing demands on
them (see also Chapter 11). Here is one strategy: the speaker can start
with common words and syntactically simple phrases while planning the
rest of the utterance. Another strategy is for the speaker to re-use
sentence plans -- that is, to favour practised and easy sentence plans.
MacDonald's (2013) key assumption is that listeners' comprehension
processes are sensitive to these strategies, which increases their
ability to predict the speaker's next utterance. In sum, "Rarer patterns
\[produced by speakers\] are more difficult to comprehend than frequent
patterns" (Momma & Phillips, 2018, p. 236). Momma and Phillips broadened
this

Language comprehension

approach, arguing that a single mechanism is used in parsing by
listeners and utterances produced by speakers.

Findings According to the constraint-based model, several kinds of
non-syntactic information are used very early in sentence processing. In
contrast, this occurs only after an initial stage of syntactic
processing within the gardenpath model. Much research is more consistent
with the constraint-based model. For example, researchers (e.g., Hagoort
et al., 2004) using eventrelated potentials have found sentence
processing is influenced very rapidly by semantic factors (discussed
further later, pp. 475--476). The constraint-based model assumes
sentence processing is parallel whereas the garden-path model assumes it
is serial. Cai et al. (2012) compared the models' predictions using
ambiguous sentences such as the following: Because it was John that
Ralph threatened the neighbour recorded their conversation. This
sentence is initially ambiguous because it is unclear whether the
neighbour is the subject of the main clause (recorded their
conversation: subject analysis) or the object of the preceding verb
(threatened: object analysis). Readers interpreted the sentence in line
with the subject analysis. However, the object analysis disrupted
sentence processing even though it was not adopted. This finding
suggests there was parallel processing of the two analyses as predicted
by the constraint-based model. According to the model, verbs are an
important constraint that often strongly influence initial attempts at
parsing. The focus has been especially on verb bias -- some verbs (e.g.,
read ) are associated with two different syntactic structures (but more
frequently with one). Consider the following two sentences: (1) (2)

The professor read the newspaper had been destroyed. The professor read
the newspaper during his break.

The second sentence is easier to understand because the verb read is
generally followed by a direct object, as in (2). However, it can also
be followed by an embedded clause, as in (1). According to the
constraint-based model, readers should find it easier to resolve
ambiguities (and identify the correct syntactic structure) when the
sentence structure is consistent with the verb bias. According to the
garden-path model, in contrast, verb bias should have no initial effect.
Wilson and Garnsey (2009) studied verb bias in ambiguous sentences. As
predicted by the constraint-based model, it took longer to resolve the
ambiguity when the sentence structure was inconsistent with the verb
bias. Thus, readers' previous experience with verbs immediately
influenced sentence processing. Fine et al. (2013) asked participants to
read sentences such as the following:

469

KEY TERM Verb bias An imbalance in the frequency with which a verb is
associated with different syntactic structures.

470

Language

(1) 
(2) 

The experienced soldiers warned about the dangers before the midnight
raid. The experienced soldiers warned about the dangers conducted the
midnight raid.

Both sentences are temporarily ambiguous. However, verbs such as warned
are far more likely to occur as a main verb, as in sentence (1), than as
the verb in a relative clause, as in sentence (2). Accordingly, readers
find it much easier to process sentences such as (1) than those such as
(2). Fine et al. (2013) used a condition in which 50% of sentences
resembled sentence (1) and 50% resembled sentence (2). Readers rapidly
adapted their syntactic expectations so they increasingly read sentences
such as (2) with relative ease. The take-home message is that the
initial syntactic structure considered by readers is flexible and
influenced by recent past experience. This flexibility is entirely
consistent with the constraint-based model but not the garden-path
model.

Evaluation What are the constraint-based model's strengths? First, it
seems efficient that readers and listeners should use all relevant
information from the outset when working out a sentence's syntactic
structure. As we have seen, non-syntactic factors (e.g., word meaning;
verb bias) are often used very rapidly. Second, the model predicts much
flexibility in parsing because it is influenced by our past linguistic
experience. There is strong support for this prediction (e.g., Fine et
al., 2013). Brysbaert and Mitchell (1996) found substantial individual
differences among Dutch readers in their parsing decisions, providing
further evidence of flexibility. What are the model's limitations?
First, its predictions are often imprecise. As Rayner et al. (2012,
p. 229) pointed out, "It is difficult . . . to falsify the general claim
that parsing is interactive and constraint-based . . . it does not by
itself make any clear predictions about which things actually matter, or
how and when they have their influence." Second, much experimental
support for the model consists of findings showing that non-syntactic
factors influence early sentence processing. Such findings are clearly
consistent with the model. However, some can be accounted for by the
garden-path model by assuming the second, nonsyntactic, stage of parsing
starts very rapidly.

Unrestricted race model Van Gompel et al. (2000) proposed the
unrestricted race model combining aspects of the garden-path and
constraint-based models. Here are its main assumptions: (1) (2)

All information sources (semantic + syntactic) are used to identify a
syntactic structure (consistent with the constraint-based model). All
other syntactic structures are ignored unless the favoured syntactic
structure is disconfirmed by subsequent information.

Language comprehension

(3) 

If the initial syntactic structure is discarded, there is an extensive
re-analysis to form a new one. This resembles the garden-path model in
that parsing often involves two distinct stages.

Findings Van Gompel et al. (2001) compared the unrestricted race model
against other models. Participants read three kinds of sentences
(examples provided): (1)

(2) 
(3) 

Ambiguous sentences: The burglar stabbed only the guy with the dagger
during the night. (It could be the burglar or the guy who had the
dagger). Verb-phrase attachment: The burglar stabbed only the dog with
the dagger during the night. (Here the burglar stabbed with the dagger).
Noun-phrase attachment: The burglar stabbed only the dog with the collar
during the night.

According to the garden-path model, the principle of minimal attachment
means readers should always adopt the verb-phrase analysis. This
produces rapid processing of sentences such as (2) but slow processing
of sentences such as (3). Ambiguous sentences are processed rapidly
because the verb-phrase analysis is acceptable. According to the
constraint-based theory, sentences such as (2) and (3) are processed
rapidly because the word meanings support only the correct
interpretation. However, there will be competition between the two
possible interpretations of sentence (1) and so processing will be slow.
What actually happened? There was an ambiguity advantage: ambiguous
sentences were processed faster than either of the other sentence types
(see Figure 10.1). According to the unrestricted race model, readers
rapidly use syntactic and semantic information in ambiguous sentences to
form a syntactic structure, and no re-analysis is necessary. In
contrast, re-analysis is sometimes required with noun-phrase and
verb-phrase sentences. Mohamed and Clifton (2011) compared the same
three models. Participants read temporarily ambiguous sentences (e.g.,
The second wife will claim the entire family inheritance for herself ).
This sentence has Figure 10.1 Total sentence processing time as a
function of sentence ambiguous (the entire family inheritance) and type
(ambiguous; verb-phrase attachment; noun-phrase disambiguating (for
herself ) regions. The sen- attachment). tence was sometimes preceded by
a context Data from van Gompel et al. (2001). Reprinted with permission
of Elsevier. biasing the incorrect syntactic structure.

471

472

Language

What do the three models predict? Since the actual syntactic structure
is the simplest possible, the garden-path model predicts readers will
not be slowed down in the ambiguous or disambiguating regions. According
to the constraint-based theory, both syntactic structures are activated
in the ambiguous region, which slows down reading. Readers then select
one syntactic structure in the disambiguating region, which also slows
reading time. According to the unrestricted race model, reading is not
slowed in the ambiguous region because only one syntactic structure is
produced. However, it will often be the incorrect syntactic structure,
which slows reading in the disambiguating region. Which model was the
winner? Reading times in the ambiguous and disambiguating regions were
most consistent with the predictions of the unrestricted race model.
According to the unrestricted race model, parsing terminates when a
permissible syntactic structure is produced. Logačev and Vasishth (2016)
argued that this assumption is too limited because it takes no account
of task demands. When they asked readers to construct all possible
syntactic structures, there was an ambiguity disadvantage (i.e.,
ambiguous sentences were processed more slowly than unambiguous ones).
This finding is contrary to the unrestricted race model's prediction.

Evaluation The unrestricted race model combines successful features of
the garden-path and constraint-based models. It is reasonable that all
information sources are used from the outset, and that the initial
syntactic structure is retained unless subsequent evidence is
inconsistent with it. It differs from most other models in predicting
the surprising finding there can be an ambiguity advantage in sentence
processing. What are the model's limitations? First, it assumes readers
and listeners typically identify a sentence's correct syntactic
structure. That is by no means always the case (see below). Second, the
model assumes an ambiguity advantage will typically be found. In fact,
task conditions determine whether there is an ambiguity advantage or
disadvantage.

Good-enough representations Until recently, nearly all theories of
sentence processing (including those discussed above) assumed the
language processor "generates representations of the linguistic input
that are complete, detailed, and accurate" (Ferreira et al., 2002,
p. 11). There are two reasons why this assumption is incorrect. First,
as discussed earlier, many individuals with low non-verbal IQs have very
limited grammatical knowledge (Dąbrowska, 2018). Second, the good-enough
processing approach "emphasises the tendency of the comprehension system
to perform superficial analyses of linguistic input, which sometimes
result in inaccurate interpretations" (Ferreira & Lowder, 2016, p. 218).
Karimi and Ferreira (2016) proposed a model of comprehension based on
the notion of good-enough representations (see Figure 10.2). It assumes
two routes are used in language processing, both starting at the same
time.

Language comprehension

Heuristic route

473 Figure 10.2 A model of language processing involving heuristic and
algorithmic routes.

Interim output equilibrium Final output

Algorithmic route

Interim output reﬁned if necessary

Time

First, the heuristic route uses simple, error-prone heuristics (rules of
thumb) and typically produces a rapid output. This route is "quick and
dirty" but has the advantage of involving minimal effort. Second, the
algorithmic route is more demanding on resources -- it uses strict and
well-defined syntactic rules "to compute precise representations for the
given linguistic input" (Karimi & Ferreira, 2016, p. 1014). What are the
model's implications? First, listeners and readers generally accept the
output of the heuristic route as correct. Comprehenders emphasise
heuristic processing because they have limited cognitive resources and
processing time is limited. Second, if the output of the heuristic route
is not accepted as correct (or listeners and readers strive for high
levels of comprehension accuracy), algorithmic processing continues and
typically determines the outcome of the comprehension process. Third,
individuals with poor comprehension skills are less likely than those
with good comprehension skills to make effective use of algorithmic
processing.

Findings As predicted by the model, comprehension processes are often
superficial and inaccurate. For example, consider the Moses illusion.
When asked "How many animals of each sort did Moses put on the ark?",
approximately 50% of people reply "Two". In fact, the correct answer is
"None" (think about it!). The Moses illusion occurs because of
superficial or heuristic processing. Successful avoidance of the Moses
illusion requires more thorough processing to inhibit the outcome of
heuristic processing (Raposo & Marques, 2013). In similar fashion,
Ferreira (2003) found listeners who heard "The mouse was eaten by the
cheese" sometimes misinterpreted it as meaning the mouse ate the cheese!
Ferreira argued this was due to a common heuristic (the noun-verb-noun
or NVN strategy). This involves the assumption that the subject of a
sentence is the agent of some action whereas the object is

From Karimi & Ferreira (2016).

474

Language

the recipient. We use this heuristic because most English sentences
conform to this pattern. Christianson et al. (2010) argued that
listeners in the Ferreira (2003) study faced a conflict between the
syntactic structure of the passive sentences and their semantic
knowledge of what is typically the case. They found listeners hearing
implausible passive sentences (e.g., "The angler was caught by the
fish") paid little attention to their syntactic structure. Swets et
al. (2008) argued readers would engage in increased algorithmic
processing if they anticipated detailed (rather than superficial)
comprehension questions. Participants read sentences more slowly in the
former case (see Figure 10.3). Ambiguous sentences were read more
rapidly than unambiguous ones when superficial questions were asked
(suggesting heuristic processing). However, this ambiguity advantage
disappeared when more challenging comprehension questions were
anticipated (suggesting more algorithmic processing). Reliance on
heuristic processing can be so great that readers fail to repair their
preferred syntactic structure of a sentence even when inadequate.
Ferreira and Lowder (2016) discussed studies where readers received
sentences such as "While Anna bathed the baby played in the crib". Many
readers mistakenly understood this sentence to mean Anna bathed the baby
and the baby played in the crib. What happened was many readers
initially assumed Anna bathed the baby and maintained this assumption
even though this structure breaks down when they reach the verb played
which then has no subject. Finally, we consider individual differences.
Individuals high in working memory capacity (high intelligence and
attentional control; see Glossary) answered comprehension questions
about garden-path sentences 70%

Figure 10.3 Sentence reading times as a function of the way in which
comprehension was assessed: detailed (relative clause) questions;
superficial questions on all trials; or occasional superficial
questions. Sample sentence: The maid of the princess who scratched
herself in public was terribly humiliated. From Swets et al. (2008).
With kind permission from Springer Science+Business Media.

Language comprehension

of the time. In contrast, the comparable figure for those low in working
memory capacity was 50% (chance performance) (MacDonald et al., 1992).

Evaluation Sentence comprehension can depend on precise algorithmic
processes or imprecise heuristic ones. As predicted by the model,
language processing often uses good-enough representations and so is
error-prone. It follows from the model that language processing should
be flexible. As predicted, there is more evidence of algorithmic
processing when readers or listeners have high IQ or working memory
capacity or when they are expecting detailed comprehension questions.
What are the model's limitations? First, as Karimi and Ferreira (2016,
p. 1019) admitted, "The nature of the simple rules that guide heuristic
processing is unclear". Second, heuristic processing can involve very
limited processing or top-down semantic processing (e.g., the Moses
illusion). It is not clear all forms of heuristic processing (especially
top-down semantic processing) are relatively effortless (Koornneef &
Reuland, 2016). Third, it is often assumed theoretically that
re-analysis of ambiguous sentences using precise or algorithmic
processes reduces misinterpretations. According to this viewpoint,
readers spending the most time processing the disambiguating region of
ambiguous sentences should be less likely to misinterpret them. However,
Qian et al. (2018; discussed above, p. 467), found that spending extra
time processing the disambiguating region (and so presumably engaging in
re-analysis) was ineffective when events described in the
misinterpretation seemed highly probable. Fourth, it is assumed within
the model that misinterpretations of sentences such as "The mouse was
eaten by the cheese" occur because heuristic processing produces
incorrect syntactic representations. However, there is another
possibility. Perhaps listeners/readers typically form correct syntactic
representations with misinterpretations due to memory limitations (i.e.,
incomplete retrieval of relevant information) (Bader & Meng, 2018). The
crucial point is that misinterpretation errors may reflect processes
(e.g., involving memory) occurring after an initial correct sentence
interpretation.

Cognitive neuroscience: event-related potentials Cognitive neuroscience
has enhanced our understanding of parsing and sentence comprehension.
Since the precise timing of different processes is so important, much
use has been made of event-related potentials (ERPs; see Glossary). As
we will see, semantic information of various kinds is actively processed
very early on, which is broadly consistent with predictions from the
constraint-based and unrestricted race models. The literature is
reviewed by Beres (2017). The N400 component in the ERP waveform is of
special relevance. It is a negative wave with an onset at 250 ms and
peak at 400 ms. The N400 to a sentence word is smaller when its meaning
matches the sentence context. Other factors influencing N400 during
sentence processing mostly relate to semantic processing. As a result,
N400 has often been assumed to reflect difficulty with achieving
semantic access. However, it is more likely

475

476

Language

that N400 reflects "the input-driven update of a representation of
sentence meaning" (Rabovsky et al., 2018, p. 693). As we will see,
research within cognitive neuroscience has provided evidence for
top-down predictive processes in sentence processing. There is further
discussion of such predictive processes with respect to reading and
speech perception in Chapter 9.

Findings How does meaning influence initial sentence processing? The
traditional view was that initially we process only word meanings with
aspects of meaning going beyond the sentence itself (e.g., our world
knowledge) processed subsequently. Hagoort et al. (2004) reported
contrary evidence. Dutch participants read sentences such as the
following (critical words are in italics): (1) (2) (3)

The Dutch trains are yellow and very crowded. (This sentence is true).
The Dutch trains are sour and very crowded. (This sentence is false
because of the meaning of the word "sour"). The Dutch trains are white
and very crowded. (This sentence is false because of world knowledge --
Dutch trains are yellow).

According to the traditional view, the semantic mismatch in a sentence
such as (3) should have taken longer to detect than the mismatch in a
sentence such as (2). However, the effects of these different kinds of
semantic mismatch on N400 were very similar (see Figure 10.4). What do
the above findings mean? First, "While reading a sentence, the brain
retrieves and integrates word meanings and world knowledge at the same
time" (Hagoort et al., 2004, p. 440). Thus, the traditional view that we
process word meaning before information about world knowledge may be
wrong. Second, word meaning and world knowledge are both integrated into
the reader's sentence comprehension within about 400 ms. This suggests
sentence processing involves making almost immediate Figure 10.4 The
N400 response to the critical word in a correct sentence ("The Dutch
trains are yellow": green line), a sentence incorrect on the basis of
world knowledge ("The Dutch trains are white": orange line) and a
sentence incorrect on the basis of word meanings ("The Dutch trains are
sour": purple line). The N400 response was very similar with both
incorrect sentences. From Hagoort et al. (2004). Reprinted with
permission from AAAS.

Language comprehension

use of all relevant information, consistent with MacDonald et al.'s
(1994) constraint-based theory. The traditional view also assumed
contextual information is processed after information about word
meanings. Contrary evidence was reported by Nieuwland and van Berkum
(2006a, p. 1106) using scenarios such as this one: A woman saw a dancing
peanut who had a big smile on his face. The peanut was singing about a
girl he had just met. And judging from the song, the peanut was totally
crazy about her. The woman thought it was really cute to see the peanut
singing and dancing like that. The peanut was salted/in love, and by the
sound of it, this was definitely mutual. Some listeners heard "salted ",
which was appropriate in terms of word meanings but inappropriate within
the story context. Others heard "in love", which was appropriate within
the story context but not word meanings. The N400 was greater for
"salted " than "in love" because it did not fit the story context. Thus,
contextual information can have a very rapid major impact. Van den Brink
et al. (2012) argued that listeners take rapid account of stereotyped
inferences about the speaker. For example, suppose you heard a woman say
"I have a large tattoo on my back". This would conflict with
stereotypical views if she had an upper-class accent but not if she had
a working-class accent. As predicted, there was a larger N400 to the
word "tattoo" when spoken in an upper-class accent.

Evaluation Behavioural measures (e.g., time to read a sentence) provide
only indirect evidence concerning the nature and timing of underlying
language processes. In contrast, research using event-related potentials
indicates listeners make use of several kinds of information (e.g.,
context; world knowledge; knowledge of the speaker; syntax) very early
in processing, before the end of each spoken word. Such findings are
more supportive of constraint-based theories than the garden-path model.
How can we explain the above findings? According to Hagoort (2017,
p. 200), Very likely, lexical, semantic and syntactic cues conspire to
predict characteristics of the next anticipated word, including its
syntactic and semantic make-up. A mismatch between contextual prediction
and the output of bottom-up analysis results in an immediate brain
response recruiting additional processing resources for the sake of
salvaging the on-line interpretation process. More research using
event-related potentials to assess the extent to which readers/listeners
predict upcoming text is discussed in the section entitled "Discourse
processes: inferences" (see pp. 490--498). What are the limitations of
research in this area? First, most research is artificial because
sentences are presented word-by-word to stop eye

477

478

Language

KEY TERMS

movements contaminating the ERPs. Findings are generally similar in
word-by-word and free reading. However, comprehension is better in free
reading because it permits regressions (eyes moving backwards in the
text) (Metzner et al., 2017). These regressions are associated with a
P600 effect (an ERP component produced by syntactic and semantic
violations in the text). Second, much research differs from naturalistic
language comprehension in important ways. The latter more often involves
processes not specific to language (e.g., relating text to pre-existing
knowledge and to context) whereas the former is generally concerned
primarily with language processing (Hasson et al., 2018). Third, a small
N400 to a predictable word in a sentence may indicate successful
prediction. Alternatively, however, it might also indicate easy
integration of that word into the developing sentence meaning.

Pragmatics The study of the ways language is used and understood in the
real world including a consideration of its intended meaning; in
general, the impact of contextual factors on meaning. Figurative
language Language that is not intended to be taken literally; examples
include metaphor, irony and idiom. Autism spectrum disorder (ASD) A
disorder involving difficulties in social interaction and communication
and repetitive patterns of behaviour and thinking. Central coherence The
ability to make use of all the information when interpreting an
utterance or situation. Asperger syndrome An autism spectrum disorder
involving problems with social communication in spite of at least
average intelligence and no delays in language development.

PRAGMATICS Pragmatics is concerned with practical language use and
comprehension.

It relates to the intended rather than literal meaning expressed by
speakers and understood by listeners and often involves drawing
inferences. For example, we assume someone who says "The weather's
really great!", when it has been raining non-stop for several days,
actually thinks the weather is terrible. Pragmatics is also important
when readers comprehend text. Pragmatics is "meaning minus semantics".
Suppose someone says something in an unfamiliar language. Using a
dictionary would partly clarify what the speaker intended to
communicate. Most of what the dictionary (plus knowledge of the
language's grammatical structure) fails to tell you about the speaker's
intended meaning lies within the field of pragmatics. A full
understanding of intended meaning generally requires taking account of
contextual information (e.g., the speaker's tone; the speaker's relevant
behaviour; the current environment). An important area within pragmatics
is figurative language (language not intended to be taken literally).
Metaphor is figurative language where a word or phrase is used
figuratively to mean something it resembles (e.g., "Time is a thief").
There is also irony where the intended meaning differs substantially
from the literal meaning. Here is an example from the film Dr
Strangelove: "Gentlemen, you can't fight in here! This is the War Room."
There are also idioms, which are common figurative expressions (e.g.,
"kick the bucket". Bohrn et al. (2012) carried out a meta-analysis (see
Glossary) comparing brain activation with figurative and literal
language processing. There were two main findings: (1) (2)

Figurative language processing involves essentially the same brain
network as literal processing. Several areas in (and close) to the
inferior frontal gyrus (BA45/36/47/13) (especially in the left
hemisphere) were more activated during figurative than literal language
processing. Häuser et al. (2016) applied repetitive transcranial
magnetic stimulation (rTMS; see Glossary) to part of this network
(BA45), which they hypothesised provides

Language comprehension

479

cognitive control to resolve semantic conflicts. As predicted, rTMS
impaired the processing of idioms involving maximal semantic conflict
between literal and idiomatic meanings.

IN THE REAL WORLD: AUTISTIC SPECTRUM DISORDERS AND PRAGMATICS We can see
the importance of pragmatics by studying individuals who have difficulty
in distinguishing between literal and intended meanings. For example,
individuals with autism spectrum disorder (ASD) are poor at
understanding others' intentions and beliefs and so find social
communication very hard. They also have weak central coherence (the
ability to integrate information from different sources). It follows
that individuals with autism spectrum disorder should have severe
problems understanding the intended meanings of figurative language.
Much evidence has been obtained from individuals with Asperger syndrome
(relatively mild ASD). Children with Asperger's often develop language
normally but have impaired pragmatic language comprehension (see Volden,
2017, for a review). For example, Kaland et al. (2005) found they were
deficient at drawing inferences when presented with jokes, white lies,
figurative language or irony. Here is an example involving irony: Ann's
mother has spent a long time cooking Ann's favourite meal: fish and
chips. But when she brings it to Ann, she is watching TV, and she
doesn't even say thank you. Ann's mother is cross and says, "Well,
that's very nice, isn't it! That is what I call politeness!" Individuals
with Asperger syndrome were less able than healthy controls to explain
why Ann's mother said what she did. This illustrates their general
inability to understand what other people are thinking. Of importance,
Asperger's individuals were comparable to controls when drawing
inferences not requiring social understanding. Loukusa et al. (2018)
extended the findings of Kaland et al. (2005). Two factors were jointly
responsible for the impaired ability of children with ASD to draw
correct pragmatic inferences during comprehension. First, they had
problems taking account of the context. Second, they found it hard to
infer someone's thoughts and feelings from what that person said. The
deficit in correct pragmatic inferences by ASD children went from 25%
when only context was important to 48% when someone's else thoughts and
feeling were also important. As mentioned already, deficient pragmatic
language comprehension in individuals with Asperger syndrome is partly
due to weak central coherence. Zalla et al. (2014) asked participants to
decide whether a speaker's compliments to another person were literal or
ironic. Healthy controls correctly recognised a speaker was being ironic
if they had a sarcastic/ironic occupation (e.g., comedian; chat show
host). In contrast, individuals with Asperger's typically ignored
information about the speaker's occupation. Language impairments in
autism spectrum disorder are not always specific to pragmatic language.
Whyte and Nelson (2015) found children with ASD also had poorer
knowledge of syntax and vocabulary. These language deficits mostly
explained their impaired pragmatic language comprehension. In sum,
individuals with ASD have impaired pragmatic language comprehension
especially when they need to take account of context and someone else's
thoughts and feelings. Their great difficulty in inferring others'
intentions and motivations from what they say and how they behave plays
a significant role in restricting their social horizons.

480

Language

KEY TERMS

Figurative language: metaphors

Metaphor interference effect The finding that it takes longer to judge
whether metaphorical sentences are literally true or false than control
sentences.

The central problem readers (and listeners) have with metaphors is that
they have separate literal and non-literal or metaphorical meanings. For
example, consider the unfamiliar metaphor "My mother says envy is rust"
(George & Wiley, 2016). The reader (or listener) has to ignore the
relatively meaningless literal meaning and identify the metaphorical
meaning (i.e., envy is like rust because it is corrosive). Olkoniemi et
al. (2016) obtained evidence suggesting that metaphor comprehension can
be relatively demanding. Readers low in working memory capacity
(associated with low intelligence; see Glossary) required more
processing time to comprehend metaphors. Theoretical approaches to
metaphor comprehension are reviewed in detail by Holyoak and Stamenković
(2018). According to the traditional standard pragmatic model (e.g.,
Grice, 1975), three sequential stages are involved in processing
metaphorical and other figurative statements: (1) (2) (3)

the literal meaning is accessed; the reader or listener decides whether
the literal meaning makes sense in the current context; if the literal
meaning is inadequate, there is a search for a suitable non-literal
meaning.

This model is oversimplified. Suppose we ask people to decide whether
sentences are literally true or false. According to the model, they
should not access the figurative meanings of metaphors on this task and
so should respond rapidly. However, that is not the case. Chouinard et
al. (2018) found participants took longer to decide whether metaphorical
sentences were literally true or false than when judging control
sentences (literally false; scrambled metaphor, e.g., "Some cats are
ribbons"; see Figure 10.5). This is the metaphor interference effect.
Why is the metaphor interference effect important? As Chouinard et
al. (2018, p. 14) concluded, it shows "metaphorical and literal meanings
are generated automatically and simultaneously during comprehension".

(b) 2280

(c) 1550 \*+

- 

From Chouinard et al. (2018).

Milliseconds

Figure 10.5 Response times for literally false (LF), scrambled metaphor
(SM) and metaphor (M) sentences in (a) written and (b) spoken
conditions.

Milliseconds

1500 1450 1400 1350 1300

LF

SM Sentence type

M

2260 2240 2220 2200 2180 2160 2140 2120 2100 2080

- 
- 

LF

SM Sentence type

M

Language comprehension

Several theorists (e.g., Barsalou, 2012) have argued that sensory
experience is relevant to the processing of metaphors and other forms of
language (see Chapter 7). Lacey et al. (2017) tested this viewpoint.
Participants were presented with metaphorical (e.g., "He had to foot the
bill") and literal (e.g., "He had to pay the bill"). All the
metaphorical sentences referred to body parts. The key finding was that
brain areas responsive to images of body parts were activated only by
the metaphorical sentences. These findings indicate that comprehension
of metaphors can be perceptually grounded.

Predication model Kintsch (2000) proposed a predication model of
metaphor comprehension involving two components: (1)

(2) 

The latent semantic analysis component: this represents word meanings
based on their relations with other words. Kintsch (2000) speculated
that metaphor comprehension is facilitated when both nouns in a metaphor
(e.g., "Lawyers are sharks") have strong semantic relationships to
numerous other words because that facilitates the task of establishing
connections between them. The construction-integration component: this
uses information from the first component to construct interpretations
of statements. Consider the statement "Lawyers are sharks". It has an
argument (lawyers) and a predicate or assertion (sharks). This component
selects predicate features relevant to the argument (e.g., vicious;
aggressive) and inhibits irrelevant predicate features (e.g., have fins;
swim).

Wolff and Gentner (2011) agreed with Kintsch (2000) that metaphors
involve a directional process with information from the argument (e.g.,
lawyers) being projected on to the predicate (e.g., sharks). However,
they also argued this directional process is preceded by a
non-directional process identifying commonalities in meaning between the
argument and predicate.

Findings The non-reversibility of metaphors is an important phenomenon.
For example, "My surgeon is a butcher" means something very different to
"My butcher is a surgeon". Kintsch's (2000) model explains
non-reversibility by assuming only those features of the predicate
(second noun) relevant to the argument (first noun) are selected. Thus,
changing the argument changes the features selected. Suppose we try to
understand a metaphor such as "My lawyer was a shark". According to
Kintsch's model, this should be harder to understand when literal
properties of sharks (e.g., can swim) irrelevant to its metaphorical
meaning have recently been activated. McGlone and Manfredi (2001) found
(as predicted by the model) that the above metaphor took longer to
understand when preceded by a contextual sentence emphasising the
literal meaning of shark (e.g., "Sharks can swim").

481

482

Language

Figure 10.6 Mean reaction times to verify metaphor-relevant (REL) and
metaphorirrelevant (IRR) properties.

REL

\*\* 1400 Property-veriﬁcation RT (ms)

From Solomon & ThompsonSchill (2017). Reprinted with permission of
Elsevier.

IRR

1300

1200

1100

1000 LIT

MET

According to the predication model, understanding metaphors involves
inhibiting the semantic properties of the predicate irrelevant to the
argument. Solomon and Thompson-Schill (2017) tested this assumption.
Participants saw metaphors (e.g., "The prisoners are sardines") and
literal sentences (e.g., "The fish are sardines"). After that,
participants decided whether a metaphor-relevant property (e.g., canned)
or metaphor-irrelevant property (e.g., salty) was true of the last word
in the sentence (e.g., sardines). Participants verified object
properties more slowly following a metaphorical sentence (the MET
condition in Figure 10.6) compared to a literal one (the LIT condition
in Figure 10.6). Thus, participants inhibited metaphor-irrelevant
information while reading metaphorical sentences. Carriedo et al. (2016)
investigated the effects of individual differences in inhibitory
processes on metaphor comprehension. As predicted, individuals having
superior inhibitory processes exhibit the best metaphor comprehension.
According to Kintsch (2000), metaphor comprehension should be greater
when both nouns in a metaphor are similar in meaning to numerous other
words. However, Al-Azary and Buchanan (2017) obtained the opposite
findings. They speculated that the activation of numerous semantically
similar words might make it harder to find shared meanings between the
two nouns. According to Wolff and Gentner (2011), initial processing of
metaphors involves a non-directional process focusing on finding
overlapping meanings between the argument and predicate. This process is
the same whether participants see forward metaphors (e.g., Some giraffes
are skyscrapers) or reversed metaphors (e.g., Some skyscrapers are
giraffes). It follows that rated comprehensibility should be the same
for forward and reversed metaphors if participants must respond rapidly.
In contrast, comprehensibility rating should be much higher for forward
than reversed metaphors if participants have sufficient time for
thorough processing. The predicted findings were obtained (see Figure
10.7).

Language comprehension

483 Figure 10.7 Mean proportion of statements rated comprehensible with
a response deadline of 500 or 1,600 ms. There were four statement types:
literal; forward metaphors; reversed metaphors; and scrambled metaphors.
From Wolff and Gentner (2011).

Evaluation What are the strengths of research in this area? First, it
has been established that metaphor processing depends on many factors,
including the listener's language ability, the familiarity of the
metaphor, and the listener's goal (e.g., understanding a metaphor;
judging its appropriateness in context) (Gibbs, 2013). Second, findings
indicate that literal and metaphorical meanings are processed
simultaneously. Third, inhibitory processes play a key role in
diminishing the impact of irrelevant information. Fourth, metaphor
comprehension involves a non-directional process followed by a
directional one. What are the limitations of research in this area?
First, insufficient attention has been paid to possible processing
differences between different types of metaphors. For example, we can
distinguish between "A is B" metaphors and correlation metaphors (Gibbs,
2013). "Lawyers are sharks" is an example of the former whereas "My
research is off to a great start" is an example of the latter. Kintsch's
(2000) prediction model is more applicable to the former type of
metaphor than the latter. Second, most research has not distinguished
clearly between novel and familiar metaphors. George and Wiley (2016)
found participants took longer to think of interpretations of novel than
familiar metaphors (7.6 seconds vs 4.9 seconds, respectively). Of
importance, inhibitory processes were used less often with familiar
metaphors, perhaps because overall processing demands were much less.

484

Language

KEY TERMS

Common ground

Common ground Shared knowledge and beliefs possessed by a speaker and a
listener; its use facilitates communication. Egocentric heuristic A
strategy used by listeners in which they interpret what they hear based
on their own knowledge rather than knowledge shared with the speaker.

Grice (1975) argued that speakers and listeners generally conform to the
cooperative principle -- they work together to ensure mutual
understanding. Of direct, relevance, speakers and listeners need to take
account of the common ground, which "describes a body of information
that people allegedly share" (Cowley and Harvey, 2016, p. 56). Listeners
expect speakers to refer mostly to information and knowledge that falls
in the common ground and often experience difficulties if that is not
the case. The extent to which that expectation is correct is discussed
in Chapter 11 (see pp. 544--547). Note that a major goal of conversation
is to extend the common ground between those involved (Brown-Schmidt &
Heller, 2014). Keysar et al. (2000) accepted listeners would benefit
from using the common ground existing between them and the speaker.
However, this can be very effortful for listeners, and so they generally
resort to a rapid and non-effortful egocentric heuristic. The egocentric
heuristic is "a tendency to consider as potential referents objects that
are not in the common ground, but are potential referents from one's own
perspective" (Keysar et al., 2000, p. 32). Use of the egocentric
heuristic will often cause listeners to misunderstand the speaker's
message. Accordingly, Keysar argued that listeners sometimes follow use
of the egocentric heuristic with an effortful process of trying to adopt
the speaker's perspective. Several theorists (e.g., Bezuidenhout, 2014)
have disagreed that listeners typically make use of the egocentric
heuristic. Instead, they argue listeners generally take account of the
common ground very early in processing. Heller et al. (2016) claimed it
is simplistic to assume listeners adopt a single perspective (egocentric
or that of the common ground). Instead, listeners use both perspectives
simultaneously.

Findings In Keysar's research (e.g., Keysar et al., 2000), listeners
often used the egocentric heuristic and ignored the common ground.
However, many studies (e.g., Heller et al., 2016, discussed shortly)
have found the opposite. How can we resolve these inconsistencies?
Dębska and Rączaszek-Leonardi (2018) argued that Keysar's approach was
biased. Suppose listeners were instructed to "Put the small candle . .
." from an array containing three candles (big, medium and small). The
candle hidden from the speaker was always the smallest one. Thus, one
reason why listeners used the egocentric heuristic by selecting the
smallest candle was because it was the one best described by the
instructions. Dębska and Rączaszek-Leonardi (2018) tested the above
ideas by using a set-up resembling that of Keysar. Listeners showed less
evidence of the egocentric heuristic when the object hidden from the
speaker was not the one best described by the instructions. Heller et
al. (2016) tested the various theories mentioned earlier. Figure 10.8
illustrates their four conditions viewing the display from the
listener's perspective when the task was to move the big candle (inside
the white oval). In the baseline conditions, all four objects were in
common ground. In the crucial privileged conditions, one object was
visible only to

Language comprehension

485 Figure 10.8 Sample displays seen from the listener's perspective;
instructions were to "pick up the big candle"; the target is within the
white oval. From Heller et al. (2016). Reprinted with permission of
Elsevier.

the listener. In the pairs conditions, two pairs of objects differed in
size, and in the triplet conditions, three similar objects differed in
size and there was also a completely different object. Eye-tracking
assessed listeners' attentional focus. What would we predict for the
crucial privileged conditions? We start with the privileged triplet
condition. If listeners used the egocentric heuristic, they would
mistakenly focus on the candle the speaker could not see (bottom left).
If they used common ground information, in contrast, they would focus on
the larger of the two candles the speaker could see (bottom right).
There was some evidence for the egocentric heuristic because listeners
focused to some extent on the candle the speaker could not see
(privileged big candle; see Figure 10.9). However, common ground
information was also used -- listeners consistently fixated the target
rapidly and to a much greater extent than any other object. The
privileged triplet condition is biased to elicit the egocentric
heuristic in that the object only the listener could see fitted the
speaker's instructions better than the intended target. This is not the
case in the privileged pairs condition. In this condition, use of the
egocentric heuristic would lead to equal fixations on the big funnel and
the big candle (the target) when the speaker has said "Pick up the big .
. .", but has not yet said "candle". In contrast, use of the common
ground would cause fixations to be allocated to the big candle rather
than the big funnel before the speaker says "candle". In the privileged
pairs condition, listeners used the common ground -- they attended more
to the big candle than the big funnel faster than in the

Language

Pairs

Triplet

0.9

0.3

900

1000

1100

1200

1000

1100

1200

800

0.9 Big candle (target) Small candle Big funnel (competitor)

0.7

Small funnel (PRIVILEGED)

0.3

Time (ms) after ADJ onset

Figure 10.9 Proportion of fixation on the four objects over time; 0 ms =
onset of adjective "big" and the shaded area covers processing of the
adjective. From Heller et al. (2016). Reprinted with permission of
Elsevier.

700

600

1200

1100

1000

900

800

700

600

500

400

300

200

100

0

--100

0 --200

0.1

0

500

0.2

0.1

400

0.2

0.4

300

0.3

0.5

200

0.4

--100

0.5

0.6

--200

Proportions of ﬁxations

Funnel

0.6

100

0.7

Medium candle (target) PRIVILEGED big candle Small candle

0.8

0

0.8

Privileged

700

Time (ms) after ADJ onset

0.9

Proportions of ﬁxations

900

Time (ms) after ADJ onset

800

--200

1200

1100

900

1000

800

700

500

600

400

300

200

0

100

0 --100

0.1

0

600

0.2

0.1

500

0.2

0.4

300

0.3

0.5

200

0.4

0.6

0

0.5

--100

Proportions of ﬁxations

0.7

0.6

--200

Baseline

0.7

Big candle (target) Medium candle Small candle Funnel

0.8

100

Big candle (target) Small candle Big funnel (competitor) Small funnel

0.8

Proportions of ﬁxations

0.9

400

486

Time (ms) after ADJ onset

baseline conditions (200 ms after the adjective "big" was presented
versus 350 ms). However, there was some evidence of the egocentric
heuristic -- listeners had some fixations on the object only they could
see (i.e., the small funnel) and also on the irrelevant big funnel. In
sum, Heller et al.'s (2016) findings indicate that listeners rapidly use
common ground. Of greatest importance, their findings are most
consistent with the theory that listeners make simultaneous use of an
egocentric perspective and common ground. Suppose listeners who were
given a task resembling the privileged triplet condition in Heller et
al.'s (2016) study performed a demanding second task at the same time.
According to Keysar et al.'s (2000) theory, this should increase their
use of the egocentric heuristic (compared to a control condition with an
undemanding second task) because they would lack the processing
resources to make use of the common ground. Lin et al. (2010) carried
out a study along those lines and obtained the predicted findings. Cane
et al. (2018) obtained similar findings using the demanding task of
remembering a sequence of five digits. Luk et al. (2012) studied
cultural differences in use of the egocentric heuristic.
Chinese--English bilinguals were primed to focus on the Chinese or
American culture. Only 5% of those focusing on the Chinese culture used
the egocentric heuristic on a listening task compared to 45% focusing on
the American culture. These findings are consistent with the common

Language comprehension

assumption that Western cultures are more individualistic and
self-focused than Eastern cultures (which are more collectivistic and
group-centred). Most research has focused only on whether specific
pieces of information are in common ground. This ignores the potential
richness of common ground representations, which can include cultural
and community information shared by speaker and listener. Brown-Schmidt
(2012) used a task where two individuals worked together to move various
game pieces. Their interactive discussions led to the formation and
maintenance of rich common ground representations. Brown-Schmidt also
found that the assumption that a given piece of information is or is not
in common ground between a speaker and listener is oversimplified. In
fact, a given piece of information can be in common ground to a greater
or lesser extent. Nearly all research in this area is limited because
speakers and listeners are strangers to each other. We might assume
friends share more common ground than strangers and so rely less on the
egocentric heuristic. However, Savitsky et al. (2011) obtained the
opposite finding because friends overestimated how well they
communicated with each other.

Evaluation The evidence suggests listeners make simultaneous use of both
their egocentric perspective and common ground. However, several factors
influence the relative importance of these two perspectives. First, the
egocentric perspective is used more often when the object hidden from
the speaker is the one best described by the instructions. Second, the
egocentric perspective is more frequent when listeners have limited
processing resources available. Second, it is used more often in Western
cultures than in Eastern ones. Third, the egocentric perspective may be
used more often by listeners when the speaker is a friend of theirs
rather than a stranger. What are the limitations of research in this
area? First, most research has focused on very specific aspects of
common ground. Second, findings from listener--speaker pairs who are
strangers may not generalise to pairs who are friends. Third, many
studies lack ecological validity (see Glossary): it is rare in everyday
life for an object between two individuals to be visible to the listener
but not to the speaker. Fourth, in most research, the participants act
only as listeners. In contrast, real-life conversations involve rapid
switching between listening and speaking. In such situations, it is
often useful for listeners to focus on information available only to
them (and thus not in the common ground) so they can communicate it to
the other person (Mozuraitis et al., 2015).

INDIVIDUAL DIFFERENCES: WORKING MEMORY CAPACITY There are considerable
individual differences in almost all complex cognitive activities.
Accordingly, theories based on the assumption (explicit or implicit)
that everyone comprehends text similarly are oversimplified. What are
the most important individual differences influencing reading
performance? Just and Carpenter (1992) emphasised individual differences
in

487

488

Language

IN THE REAL WORLD: UNDERSTANDING NON-NATIVE SPEAKERS As Ryskin et
al. (2018, p. 141) pointed out, "Everyday language use occurs amid
myriad sources of noise". For example, non-native speakers may make
errors because of deficient knowledge of the language including numerous
mispronunciations when engaged in conversation (Levis & Barriuso, 2011).
In such circumstances, listeners have to infer the intended meaning from
what is actually said. How do we cope when trying to understand what a
non-native speaker is saying? A crucial part of the answer was provided
by Lev-Ari (2014) in a study where a native speaker of Mandarin or of
English gave instructions in English to native English speakers.
Listeners to the non-native speaker increased their reliance on top-down
processes (e.g., predicting what the speaker would say next) and reduced
their reliance on what the speaker said. This strategy is entirely
appropriate given the lower language competence of the non-native
speaker. Gibson et al. (2017) also found listeners relied less on the
actual words spoken by non-native speakers and focused more on the
intended meaning. Native and non-native speakers produced many
utterances, some of which were implausible (e.g., "The tax law
benefitted from the businessman"). Listeners were more likely to
interpret such implausible utterances as plausible (e.g., "The
businessman benefited from the tax law") when spoken by a non-native
speaker. This makes sense given the assumption that non-native speakers
are more likely to put words in the wrong order. Suppose a listener is
exposed to the utterances of a non-native speaker whose errors consist
mainly of deletions (e.g., "We had nice time at the beach") or
insertions (e.g., "The earthquake shattered from the house"). Listeners
might simply assume in both cases that the speaker makes many errors
across the board. Alternatively, they might assume the speaker only has
a high probability of making specific speech errors (e.g., deletions or
insertions). Ryskin et al. (2018) found that listeners' inferences about
the speaker's intended meaning were influenced by the specific errors
they had heard previously. Thus, listeners are sensitive to fine-grained
information about the types of errors made by speakers.

working memory capacity (the ability to process and store information at
the same time) (see Glossary and Chapter 6). Engle and Kane (2004)
proposed an influential theory according to which individuals with high
working memory capacity have superior executive attention or attentional
control than low-capacity individuals. This manifests itself in the
superior monitoring of task goals and the ability to resolve response
competition. It follows that high-capacity individuals should have less
mind-wandering (task-unrelated thoughts) than low-capacity ones while
engaged in reading comprehension. As predicted, Unsworth and McMillan
(2013) found high-capacity individuals had superior reading
comprehension partly because of their reduced mind-wandering. There are
two key theoretical issues relating to the effects of working memory
capacity on reading comprehension. First, we can focus on relatively
specific individual differences in working memory capacity (e.g., verbal
working memory involving simultaneous processing and storage of verbal
information). An example is reading span (see Glossary). Alternatively,
we can focus on general individual differences in working memory
capacity (working memory involving simultaneous processing and storage
of different kinds of information). An example is operation span

Language comprehension

which involves numerical processing and verbal storage (see Glossary).
Are specific or general aspects of working memory capacity more
important in predicting reading comprehension? Second, there are two
possible types of explanation for positive correlations between working
memory capacity and reading comprehension. Just and Carpenter (1992)
assumed there was a direct relationship: individuals with low working
memory capacity have more limited processing resources than
high-capacity individuals and this directly impairs their reading
comprehension. Alternatively, there may be an indirect relationship: the
effects of working memory capacity on reading comprehension may occur
because it correlates with other reading-relevant factors (e.g.,
vocabulary; reading experience). Why does it matter whether the
relationship is direct or indirect? In essence, if the relationship
between working memory capacity and reading is indirect, it implies
factors other than working memory capacity itself are primarily
responsible for its effects on reading performance.

Findings Peng et al. (2018) reported a meta-analytic review based on 197
studies. Overall, they reported a correlation of +.29 between working
memory capacity and reading. Measures of general working memory capacity
correlated +.26 with reading comprehension. Among specific measures, the
correlation between verbal working memory capacity and reading was
somewhat higher (+.32). Thus, general and specific individual
differences in working memory capacity are both important predictors of
reading performance. Peng et al. (2018) also addressed the issue whether
the effects of working memory capacity on reading comprehension are
direct or indirect. More specifically, two factors they considered were
vocabulary size and decoding ("the ability to translate written language
into speech with accuracy and/or fluency", p. 52). They obtained
evidence for indirect effects: working memory capacity influenced
reading comprehension via its effects on vocabulary and decoding. Freed
et al. (2017) also considered whether the effects on reading
comprehension of working memory capacity are direct or indirect. They
discovered the relationship between working memory capacity and reading
comprehension was indirect. It depended on two factors: language
experience (e.g., reading habits) and general reasoning ability or fluid
intelligence (see Glossary).

Evaluation Theoretical approaches such as that of Just and Carpenter
(1992) have the advantage over most language theories in emphasising the
importance of individual differences. In contrast, as Kidd et al. (2018,
p. 154) pointed out, most theorists regard large individual differences
in language comprehension as "an inconvenient truth" which they ignore
or de-emphasise. Individual differences in working memory capacity
correlate moderately highly with measures of reading comprehension. This
is so whether

489

490

Language

KEY TERMS

working memory capacity is assessed by relatively specific measures
(e.g., verbal working memory) or more general ones. Other research
suggesting the importance of working memory capacity is discussed in the
next section (see p. 494). What are the limitations of research in this
area? First,

Discourse Language that is a minimum of several sentences in length; it
includes written text and connected speech. Logical inferences
Inferences that follow necessarily from the meanings of word (e.g., a
bachelor is a man who is unmarried). Bridging inferences Inferences or
conclusions drawn to increase coherence between the current and
preceding parts of a text; also known as backward inferences.

We have a huge literature . . . that has focused on the role of WMC
\[working memory capacity\] in language processing, based on the
assumption that WMC has a unique and direct effect on comprehension.
However, only one major study has found such an effect. (Freed et al.,
2017, p. 137) Second, and related to the first point, much more research
is required to clarify the interrelationships between the numerous
individual difference variables correlating with reading comprehension.
For example, Van Dyke et al. (2014) found IQ correlated +.61 with
working memory capacity, and that much of the relationship between
working memory capacity and reading comprehension depended on IQ.

DISCOURSE PROCESSING: INFERENCES So far we have focused primarily on
comprehension of single sentences. In real life, however, we mostly
encounter connected discourse (speech or written speech at least several
sentences long). Single sentences and discourse differ in various ways.
First, single sentences are more likely to be ambiguous because they
lack the context provided by previous sentences within discourse.
Second, discourse processing typically requires inference drawing for
full comprehension. We draw numerous inferences when exposed to
discourse (even though we are generally unaware of doing so). Why is so
much inference drawing required? Readers and listeners would be bored to
tears if writers and speakers spelled everything out in incredible
detail. Test your skill at inference drawing with this example taken
from Rumelhart and Ortony (1977): Mary heard the ice-cream van coming.
She remembered the pocket money. She rushed into the house.

Research activity: Text comprehension

You probably inferred that Mary wanted to buy some ice cream, that
buying ice cream costs money, that Mary had some pocket money in the
house, and that Mary had only limited time to get hold of some money
before the ice-cream van appeared. None of these inferences is
explicitly stated. There are several types of inference. First, logical
inferences depend only on the meanings of words. For example, we infer
that a widow is female. Second, bridging inferences establish coherence
between the current part of the text and the preceding text and so are
also known as backward inferences.

Language comprehension

Third, elaborative inferences embellish or add details to the text by
using world knowledge to expand on textual information. Predictive
inferences (or forward inferences) are an important form of elaborative
inference. Predictive inferences "allow readers to generate expectations
about what will happen next in a text" (Virtue et al., 2017, p. 456). It
is hard to work out how we typically access relevant information from
our huge store of world knowledge when forming elaborative inferences.
The differences between bridging and elaborative inferences are not
always clear-cut. Consider the following scenario (Kuperberg et al.,
2011): Jill had very fair skin. She forgot to put sunscreen on. She had
sunburn on Monday. When readers read the second sentence, they could
draw the elaborative inference that Jill had sunburn. When they read the
third sentence, they could draw the bridging or backward inference that
the sunburn has resulted from forgetting to put on sunscreen.

491

KEY TERMS Elaborative inferences Inferences based on our knowledge of
the world that involve adding details to a text that is being read (or
speech being listened to). Predictive inferences Expectations concerning
what will happen next (e.g., a new event) when reading text or listening
to someone. Mental model An internal representation of some possible
situation or event in the world having the same structure as that
situation or event.

Theoretical perspectives Readers (and listeners) typically draw logical
and bridging inferences, which are generally required for full
comprehension. However, the number and nature of elaborative inferences
(including predictive inferences) drawn remain controversial. Bransford
et al. (1972) in their constructionist approach argued readers typically
construct a fairly complete "mental model" of the situation described in
a text. They assumed numerous elaborative inferences are drawn during
reading even when not essential for comprehension. Several theories of
discourse comprehension (including the constructionintegration model,
the event-indexing model, and the event-segmentation theory) involve
very similar assumptions (see the later section entitled "Discourse
comprehension: theoretical approaches", pp. 498--510). McKoon and
Ratcliff's (1992) minimalist hypothesis (developed by Gerrig and
O'Brien, 2005) assumes far fewer inferences are drawn than does
Bransford et al.'s (1972) constructionist approach. This hypothesis is
based on the following assumptions: ● ●

●

●

●

Inferences are automatic or strategic (goal-directed). Some automatic
inferences establish local coherence (two or three sentences making
sense on their own or in combination with easily available general
knowledge). These inferences involve parts of the text in working memory
at the same time. Other automatic inferences rely on information readily
available because it is explicitly stated in the text. Strategic
inferences are formed in pursuit of the reader's goals; they sometimes
serve to produce local coherence. Most elaborative inferences are made
at recall rather than during reading.

Research activity: Inferences

492

Language

In sum, memory-based theories (e.g., minimalist hypothesis) "rely on a
passive and dumb \[memory\] activation mechanism" (Cook & O'Brien, 2017,
p. 2). In contrast, explanation-based theories (e.g., constructionist
approach) "assume more interaction between basic memory mechanisms and
reader goals and strategies" (Cook & O'Brien, 2017, p. 2). Van den Broek
and Helder (2017) provided a theoretical framework combining elements of
previous theories (see Figure 10.10). First, there are passive
"automatic" processes outside the reader's conscious control which
always occur. These processes resemble those assumed within the
minimalist hypothesis. Second, there are effortful reader-initiated
processes. The extent of such processes depends on the reader's
standards of coherence: "the criteria that a reader has for what
constitutes adequate comprehension and coherence in a particular reading
situation" (p. 364). For example, if a reader's goal includes a search
after meaning, they will use more reader-initiated processes and draw
more inferences than if that goal is missing (Graesser et al., 1994).
These processes correspond to those assumed within the constructionist
approach. The central prediction from the above theoretical framework is
as follows: When the passive processes alone yield adequate
comprehension by attaining the reader's standards of coherence, then no
further processing is necessary. However, if passive processes alone
lead to comprehension falling short of satisfying the reader's
standards, then reader-initiated, coherence-building processes are
likely. (van den Broek & Helder, 2017, p. 364) Research relevant to the
various theoretical approaches discussed above is discussed later
(pp. 494--497).

Processes

Product

Passive

Continue reading Figure 10.10 A theoretical framework for reading
comprehension involving interacting passive and reader-initiated
processes. From van den Broek and Helder (2017).

Standards of coherence?

Yes

No Reader-initiated

Mental representation of the text

Language comprehension

Bridging inferences: anaphors An anaphor is a word (e.g., pronoun)
referring back to a person or object previously mentioned in a text or
speech. Anaphor resolution is a very common form of bridging inference.
Here is an example: Fred sold John his lawn mower, and then he sold him
his garden hose. It requires a bridging inference to realise the
referent for "he" is Fred rather than John. How do readers/listeners
draw appropriate anaphoric inferences? Gender information can be very
helpful. Compare ease of anaphor resolution with the following sentence
compared to the one above: Juliet sold John her lawn mower, and then she
sold him her garden hose. Anaphor resolution is also facilitated by
having pronouns in the expected order. Harley (2013) provided the
following example: (1) (2)

Vlad sold Dirk his broomstick because he hated it. Vlad sold Dirk his
broomstick because he needed it.

The first sentence is easy to understand because "he" refers to the
firstnamed man (i.e., Vlad). The second sentence is harder to understand
because "he" refers to the second-named man (i.e., Dirk). Another factor
influencing anaphor resolution is working memory capacity (see
Glossary). Nieuwland and van Berkum (2006b) presented sentences
containing pronouns whose referents were ambiguous. Readers high in
working memory capacity were more likely to take account of both
possible referents. When pronouns have only a single possible referent,
it has often been assumed readers "automatically" identify the correct
one. Love and McKoon (2011) obtained support for this assumption only
when readers were highly engaged with the text. Most findings are
consistent with Kaiser et al.'s (2009) assumption that anaphor
resolution involves multiple constraints (e.g., gender; meaning)
operating interactively in parallel. Itzhak and Baum (2015) studied one
such constraint (i.e., verb bias) as in the following example: (1) (2)

John envied Bill because he was rich. John envied Bill because he was
poor.

Sentence (1) is easier to comprehend than sentence (2) because we expect
the pronoun he to refer to Bill. Itzhak and Baum (2015) argued anaphor
resolution would be easier with sentence (2) if the referent of he
(i.e., John) were emphasised when the sentence was spoken. That is what
they found, thus showing an interaction between verb bias and noun
emphasis.

493

KEY TERM Anaphor A word or phrase that refers back to a previous word or
phrase (e.g., a pronoun may refer back to a given individual mentioned
earlier).

494

Language

Bridging inferences: more complex inferences Causal inferences are a
common form of bridging inference. They require readers to work out the
causal relationship between the current sentence and a previous one.
Consider the following two sentences: Ken drove to London yesterday. The
car kept overheating. You had no trouble (hopefully!) in linking these
sentences based on the assumption that Ken drove to London in a car that
kept overheating. The above bridging inference may occur because the
verb drove in the first sentence activated concepts relating to driving
(especially car). Alternatively, readers may form a representation of
the situation described in the first sentence and then relate
information in the second sentence to it. The crucial difference is that
the sentential context is only relevant with the second explanation.
Garrod and Terras (2000) identified two stages in forming bridging
inferences. The first stage is bonding, a low-level process involving
the automatic activation of words from the preceding sentence
(explanation one). The second stage is resolution, which ensures the
overall interpretation is consistent with the contextual information
(explanation two). Resolution is influenced by context but bonding is
not. According to the minimalist hypothesis and van den Broek and
Helder's (2017) theoretical framework, the reader's goals influence
which inferences are drawn. Calvo et al. (2006) gave some participants
the goal of reading sentences for comprehension whereas others were
explicitly told to anticipate what might happen next. Participants in
the latter condition drew more predictive inferences. Even when
participants in the former condition drew predictive inferences, they
did so more slowly than those in the anticipation condition. Earlier
(see pp. 488--490), we discussed how individual differences in working
memory capacity influence language comprehension. Such individual
differences also influence inference drawing. Barreyro et al. (2012)
found readers with high working memory capacity drew more elaborative
causal inferences than did low-capacity readers. Of relevance, there is
a moderately high correlation between working memory capacity and IQ
(intelligence). However, Christopher et al. (2012) found working memory
capacity still predicted comprehension performance after controlling for
intelligence. Murray and Burke (2003) focused on predictive inferences
(e.g., inferring break when presented with a sentence such as The angry
husband threw the fragile vase against the wall. Only participants with
high reading skill drew such inferences "automatically'. In general,
individuals with poor reading skills draw fewer inferences than those
with good reading skills McKoon & Ratcliff, 2017). In sum, research on
individual differences in inference drawing and comprehension ability is
important. Any adequate theory of language comprehension (or inference
drawing) must provide an explanation for such individual differences.

Language comprehension

495

IN THE REAL WORLD: ANXIETY AND INFERENCE DRAWING So far we have focused
on factors determining whether readers draw inferences. It is also
important (but relatively neglected) to consider which inferences are
drawn when we read or listen to discourse. For example, suppose we
present individuals high and low in trait anxiety (see Glossary) with
ambiguous sentences such as the following: With hardly any visibility,
the plane quickly approached the dangerous mountain and, at the same
time, the passengers began to shout in panic. The plane . . . We might
expect that high-anxious individuals would be more likely than
low-anxious ones to be biased towards the negative or threatening
predictive inference (i.e., the plane crashed). Calvo and Castillo
(2001) tested this expectation. After reading the sentence above,
participants were presented with the word "crashed" or "swerved" and
named it rapidly. What did Calvo and Castillo (2001) find? When the time
interval between "The plane . . ." and the word was 1,500 ms,
high-anxious individuals named the word "crashed" faster than lowanxious
ones and named the word "swerved" slower. Thus, high-anxious individuals
were more likely to draw the threatening inference and less likely to
draw the non-threatening one. This group difference disappeared when the
time interval was less than 1,500 ms, suggesting the bias in predictive
inferencing shown by high-anxious individuals did not depend on rapid
"automatic" processes. Moser et al. (2012) obtained similar findings
among individuals meeting criteria for social anxiety disorder
(involving extreme fear and avoidance of social situations). They heard
ambiguous sentence stems resolved by a negative or positive final word.
Event-related potentials indicated that socially anxious listeners
expected (or predicted) the negative completion more than non-anxious
listeners. Do anxious individuals draw negative inferences from all
ambiguous situations? Walsh et al. (2015; see Chapter 15) addressed that
issue using four kinds of ambiguous text scenarios: (1) social
(potential threat of social embarrassment); (2) intellectual (potential
threat of appearing unintelligent); (3) health (potential threat of
severe illness; and (4) physical (potential threat of physical danger).
High-anxious individuals drew more negative inferences than low-anxious
ones only with the social and intellectual scenarios. This pattern of
inference drawing indicates that high-anxious individuals are especially
sensitive to situations involving social evaluation.

Findings: underlying processes The minimalist hypothesis and van den
Broek and Helder's (2017) theoretical framework are consistent with the
assumption that predictive inferences can be drawn automatically. This
issue was addressed by Gras et al. (2012) using short texts such as the
following: Charlotte was having her breakfast on the terrace when the
bees started flying about the pot of jam. She made a movement to brush
them away but one of them succeeded in landing on her arm. The
predictive inference is that Charlotte felt a sting. Gras et al. (2012)
followed the text with the word sting presented in blue, red or green
350, 750 or 1,000 milliseconds after the text with instructions to name
the colour. The speed of colour naming was slowed only at

496

Language

Figure 10.11 Reaction times to name colours when the word presented in
colour was predictable from the preceding text compared to a control
condition (scores below 0 ms indicate a slowing effect of predictive
inferences). Performance in the explicit condition is not relevant here.
From Gras et al. (2012). © American Psychological Association.

1,000 milliseconds (see Figure 10.11). This finding suggests it took
approximately 1 second for the predictive inference to be drawn. The
fact that participants could not prevent it from interfering with colour
naming suggests it was drawn automatically. Kuperberg et al. (2011) also
investigated the "automaticity" of inference drawing using short
scenarios such as one discussed earlier: Jill had very fair skin. She
forgot to put sunscreen on. She had sunburn on Monday. Kuperberg et
al. recorded event-related potentials to assess readers' processing of
these scenarios. Of particular interest was the N400 component which is
larger when the meaning of the word currently being processed does not
match its context. What did Kuperberg et al. (2011) find? Consider the
above scenario where the word sunburn in the third sentence is highly
causally related to its context. There was only a small N400 to this
word. Thus, processing of the causal inference explaining Jill's sunburn
in terms of her fair skin and failure to use sunscreen started very
rapidly and probably fairly "automatically". Kuperberg et al. (2011)
also focused on complex causal inferences using short scenarios such as
the following: Jill had very fair skin. She usually remembered to wear
sunscreen. She had sunburn on Monday. There was a small N400 to the word
sunburn, but it was not as small as in the previous case. Thus, some
inference processing is initiated very rapidly (and probably
"automatically') even with complex causal inferences.

Language comprehension

In spite of the above findings, there are circumstances where few
inferences are drawn via "automatic" or passive processes. For example,
Collins and Daniel (2018) studied trained speed readers whose reading
rate was 35% faster than that of untrained readers. These speed readers
did not appear to draw bridging or predictive inferences even when such
inferences were strongly implied by the text. Finally, listeners'
stereotypical inferences about the speaker can influence sentence
processing. For example, there was a large N400 when the sentence "I
have a large tattoo on my back" was spoken in an upper-class accent (Van
den Brink et al., 2012; discussed earlier, p. 477). Thus, listeners
rapidly draw inferences about the kinds of statement a given speaker is
likely (or unlikely) to make.

Overall evaluation There is an increasing consensus on several issues:
(1) (2) (3)

(4) 
(5) 
(6) 

Readers (and listeners) typically form bridging inferences (including
causal inferences) to make coherent sense of text or speech. Readers and
listeners rapidly use contextual information and their world knowledge
to draw inferences. Many inferences (including causal and predictive
ones) are often drawn relatively "automatically". However, the extent to
which this happens depends on various factors (e.g., working memory
capacity; engagement with the text; reading speed). Readers' goals
influence whether predictive inferences are drawn. Readers with superior
reading skills (including those having high working memory capacity)
draw more inferences than other readers. The major theories contribute
to our understanding of inference drawing: The minimalist hypothesis is
probably correct when the reader is very quickly reading the text, when
the text lacks global coherence, and when the reader has very little
background knowledge. The constructionist theory is on the mark when the
reader is attempting to comprehend the text for enjoyment or mastery at
a more leisurely pace. (Graesser et al., 1997, p. 183) Thus, inference
drawing is very flexible. This flexibility is captured by van den Broek
and Helder's (2017) theoretical framework allowing for both passive and
reader-initiated processes.

What are the limitations of theory and research in this area? First, it
is often hard to predict which inferences will be drawn because
inference drawing depends on several interacting factors (e.g., readers'
goals and reading ability). Second, it is also hard to predict which
inferences will be drawn because of theoretical imprecision. For
example, it is assumed within the minimalist hypothesis that automatic
inferences are drawn if the necessary information is "readily
available". How do we establish the precise degree of availability of
some piece of information? Third, the notion that

497

498

Language

inference drawing depends on two processes (passive and
reader-initiated: van den Broek & Helder, 2017) is oversimplified.
Fourth, we need more research on individual differences in which
inferences are drawn with ambiguous material.

DISCOURSE COMPREHENSION: THEORETICAL APPROACHES If someone asks us to
describe a story or book we have read recently, we discuss the main
events and themes omitting the minor details. Thus, our description is
highly selective based on the meaning extracted from the story while
reading it and on selective processes operating at retrieval. Imagine
our questioner's reaction if our description was not selective but
simply involved recalling random sentences from the story! Gomulicki
(1956) demonstrated the selectivity of story comprehension and memory.
Some participants wrote a précis (summary) of a story visible in front
of them whereas others recalled the story from memory. Still other
participants, who were provided only with each précis and recall, had
great difficulty in telling them apart. Thus, story memory resembles a
précis in focusing primarily on important information. Several factors
determine the importance of story information. For example, statements
causally connected to several other statements are judged as more
important than those lacking such causal connections (Trabasso & Sperry,
1985). Other factors are discussed later. Nearly all comprehension
research has presented readers with paperbased texts. In the real world,
however, readers increase use e-readers or computers (e.g., when
accessing information from the internet). Margolin et al. (2013) found
comprehension was comparable for paper, e-reader, and computer
presentation for both narrative (telling a story) and expository texts
(conveying facts and information). However, comprehension and learning
are often reduced when texts are presented on a computer screen rather
than on paper (Sidi et al., 2016). Why is this? First, readers engage in
more multi-tasking and discontinuous reading on screen. Second, screen
readers tend to be more confident than paper readers about their levels
of comprehension and learning. Third, in spite of this overconfidence,
screen readers perform comparably to paper readers in conditions
emphasising the importance of deep processing (e.g., high perceived task
importance) (Sidi et al., 2017). Below we discuss several theories or
models of discourse comprehension starting with Bartlett's (1932)
influential schema-based approach. Numerous theories have been put
proposed over the past 35 years or so (see McNamara and Magliano, 2009,
for a review) and a few of the most prominent ones will be considered.

Schema theory: Bartlett Our processing of texts involves relating
textual information to relevant structured knowledge stored in long-term
memory. What we process in texts, how we process textual information,
and what we remember about texts we have read all depend heavily on such
previously stored information.

Language comprehension

Much stored knowledge consists of schemas (well-integrated packets of
knowledge about the world, events, people and actions; see Chapter 7).
Schemas include scripts and frames. Scripts (see Glossary) deal with
knowledge about events and consequences of events whereas frames are
knowledge structures referring to some aspect of the world (e.g.,
buildings). Ghosh and Gilboa (2014) argued schemas possess four
necessary and sufficient features: (1) (2) (3) (4)

associative structure: schemas consist of interconnected units; basis in
multiple episodes: schemas consist of integrated information based on
several similar events; lack of unit detail: this follows from the
variability of events from which any given schema is formed;
adaptability: schemas change and adapt as they are updated in the light
of new information.

Several definitions of "schema" have been proposed. For example,
Bartlett (1932) attached great importance to adaptability. Of interest,
this is probably the feature least often found in recent definitions.
Why are schemas important? First, they contain relevant information
needed to understand what we hear and read. Second, schemas allow us to
form expectations (e.g., of the sequence of events in a restaurant) that
are generally confirmed, which makes the world relatively predictable.
Third, schemas contain higher-level information (based on commonalities
across events) making it easier to disregard trivial details during
comprehension. Bartlett (1932) claimed persuasively that schemas
strongly influence how we remember texts. More specifically,
comprehension of (and memory for) texts depends on top-down processes
triggered by schemas. He tested this hypothesis by presenting people
with stories from a different culture to produce a conflict between the
story itself and their prior knowledge. He found that what was
remembered might be inaccurate because it included schematic knowledge
not included in the story. Bartlett identified three main error types:
(1) (2) (3)

rationalisation (making recall more consistent with the reader's
cultural expectations); levelling (omitting unfamiliar details);
sharpening (elaborating on certain details).

The above errors might result from processes occurring during
comprehension or retrieval. Bartlett (1932) favoured the latter
explanation but others (e.g., Bransford & Johnson, 1972) emphasise
comprehension processes. Note that Henderson (1903) anticipated many of
Bartlett's theoretical ideas (Davis, 2018).

Findings Bartlett (1932) used stories (e.g., "The War of the Ghosts")
from the North American Indian culture. Unfortunately, his studies were
poorly controlled (Roediger, 2010). For example, he did not provide
specific instructions:

499

KEY TERM Rationalisation In Bartlett's theory, errors in story recall
that conform to the rememberer's cultural expectations.

Case study: Bartlett

500

Language

"I thought it best . . . to try to influence the subjects' procedure as
little as possible" (Bartlett, 1932, p. 78). As a result, many
distortions observed by Bartlett were due to conscious guessing rather
than deficient memory. Gauld and Stephenson (1967) found instructions
stressing the need for accurate recall (designed to reduce deliberate
guessing) eliminated almost half the errors obtained using Bartlett's
original instructions. Bartlett (1932) claimed discourse or text
information shows more rapid forgetting than schematic knowledge. Thus,
the tendency for schematic knowledge to produce memory distortions
should increase over time. Sulin and Dooling (1974) obtained support for
this prediction. Participants received a story about a ruthless dictator
identified as Gerald Martin or Adolf Hitler. It was assumed those told
it concerned Hitler would activate their schematic knowledge of him.
There was a recognition memory test at a short- or long-retention
interval including the sentence "He hated the Jews particularly and so
persecuted them". As predicted, participants told the story was about
Hitler were much more likely to falsely recognise the above
Hitler-relevant sentence at the long- rather than the short retention
interval. Strong evidence that memory distortions increase over time was
reported by Bergman and Roediger (1999). Their participants read "The
War of the Ghosts" and then recalled it three times. The proportion of
recall involving major distortions increased from 27% at the shortest
retention interval (15 minutes) to 59% at the longest (6 months).
Bartlett (1932) argued that schemas influence retrieval as well as
comprehension. Supporting evidence was reported by Anderson and Pichert
(1978). Participants read a story from the perspective of a burglar or a
potential homebuyer. After story recall, they recalled the story again
from the alternative perspective (or schema). This time, participants
recalled more information important only to the second perspective than
on the first recall. Anderson et al. (1983) found that manipulating the
reader's perspective while reading selectively enhanced encoding and
comprehension of schema-relevant story information. Bransford and
Johnson (1972) also found schemas influence story comprehension. Here is
part of the story they used: The procedure is quite simple. First, you
arrange items into different groups. Of course one pile may be
sufficient depending on how much there is to do. If you have to go
somewhere else due to lack of facilities that is the next step;
otherwise, you are pretty well set. It is important not to overdo
things. That is, it is better to do too few things at once than too
many. What on earth was that all about? Listeners hearing the passage in
the absence of a title rated it as incomprehensible and recalled only
2.8 idea units on average. However, listeners supplied beforehand with
the title "Washing clothes" found it easy to understand and recalled 5.8
idea units on average. Having relevant schema information (i.e., the
title) helped passage comprehension rather than simply acting as a
retrieval cue -- participants receiving the title after hearing the
passage but before recall recalled only 2.6 idea units on average.

Language comprehension

Research in cognitive neuroscience has established that the ventromedial
prefrontal cortex plays a key role in schema processing (Gilboa &
Marlatte, 2017; see Chapter 7). Van Kesteren et al. (2010) studied the
involvement of the ventromedial prefrontal cortex during comprehension.
Viewers watched a film with the first half providing a schema for the
second half. Activation in the ventromedial prefrontal cortex during
viewing of the second half depended on whether the first half was
presented in the typical sequential order (providing a strong schema) or
out of order (providing a weak schema). Activation was greater when
there was a weak schema because it was harder to integrate new
information with schematic information.

Evaluation Schematic knowledge assists text comprehension and memory. In
addition, many distortions in memory for stories and other texts reflect
the influence of schematic information. More generally, schema theory
emphasises the role of top-down processes in discourse comprehension and
memory (Wagoner, 2013). What are the limitations of schema theories?
First, "schema" has many definitions (Ghosh & Gilboa, 2014) and it is
hard to ascertain the precise information contained within any given
schema. Second, schema-based explanations require independent evidence
of the existence of relevant schemas, but this is usually lacking. As
Harley (2013) pointed out, "The primary accusation against schema and
script-based approaches is that they are nothing more than
re-descriptions of the data." Third, it is unclear when a given schema
will be activated. Theoretically, schemas facilitate inference drawing
during text comprehension, but many inferences are not drawn. In
contrast, the phrase "the five-hour journey from London to New York"
activates the "plane flight schema" even though no words in the phrase
have strong associations with flying by plane (Harley, 2013). Fourth,
schema theories exaggerate how error prone we are in everyday life. For
example, Wynn and Logie (1998) found students recalled "real-life"
events experienced during their first week at university reasonably
accurately up to six months later. Fifth, Bartlett (1932) argued that
schemas exert their influence at retrieval rather than during
comprehension. In fact, schemas often also influence comprehension
processes.

Kintsch's construction-integration model Kintsch's views on language
comprehension have been very influential. In his well-known
construction-integration model, Kintsch (1988, 1998) combined elements
of schema-based theories and Johnson-Laird's mental model approach (see
Chapter 14). Here are the model's main assumptions (see Figure 10.12):
(1)

Readers turn text sentences in the text into propositions (true or false
statements) representing their meaning.

501

KEY TERM Proposition A statement making an assertion or denial which can
be true or false.

502

Language

(2) 
(3) 
(4) 

The propositions constructed from the text are stored briefly along with
associatively related propositions (e.g., inferences). At this stage,
many irrelevant propositions are stored. Spreading activation (see
Glossary) selects propositions for the text representation. In this
integration process, clusters of highly interconnected propositions
attract most activation and have the greatest probability of inclusion
in the text representation. Within the text representation, it is hard
to distinguish between propositions based directly on the text and those
based on inferences. As a result of the above processes, three levels of
text representation can be constructed: (i) surface representation (the
text itself); (ii) propositional representation or textbase
(propositions formed from the text); (iii) situation representation (a
mental model describing the situation referred to in the text) -- this
is the only representation depending mostly on the integration process.

The construction-integration model sounds rather (very?) complex.
However, its major assumptions are straightforward. The initial
construction of many propositions involves relatively inefficient
processes with many irrelevant propositions being included. At this
stage, context provided by the overall theme of the text is ignored.
After that, the integration process uses contextual information from the
text to weed out irrelevant propositions. What is the relationship
between schemas (as proposed by Bartlett, 1932) and situation models?
Schemas are abstract and very general whereas situation models are more
specific. However, schemas are often used as the building blocks from
which situation models are formed.

Figure 10.12 The construction-integration model. Adapted from Kintsch
(1992).

Language comprehension

503

How does the construction-integration model differ from schema theory?
Schema theory emphasises top-down processes in discourse comprehension
and memory. This differs substantially from the constructionintegration
model: "During the construction phase, the text input launches a dumb
bottom-up process in the reader's knowledge base . . . top-down factors,
such as reading perspective or reading goal, exert their influence at
the integration phase" (Kaakinen & Hyönä, 2007, p. 1323).

Findings Kintsch et al. (1990) tested the assumption that text
processing produces three levels of representation. Participants read
brief descriptions of various situations and their recognition memory
was tested immediately or at times ranging up to four days later. As
predicted, forgetting was fastest for the least complete representation
(i.e., the surface representation) and there was no forgetting for the
most complete representation (i.e., the situation model). More evidence
for the existence of three levels of representation was reported by
Karlsson et al. (2018). They asked children aged 9 to 11 to think aloud
while reading texts. Some children (literal readers) stayed close to the
text and produced a surface level understanding. Other children
(paraphrasing readers) focused on the meaning of the text and produced a
textbase understanding. Finally, some children (elaborating readers)
made use of background knowledge and produced a situation model of the
text. As predicted, comprehension ability was greatest in elaborating
readers and least in literal readers. Nguyen and McDaniel (2016)
increased the extent to which some readers formed a situation model from
a text by given them instructions to reduce gaps in their situation
model. Readers given those instructions had higher comprehension levels
than those not given them. Another prediction is that readers should
often find it hard to discriminate between text information and
inferences drawn from the text. As we saw earlier, that prediction has
received much support.

Figure 10.13 Forgetting functions for situation, proposition and surface
information over a 4-day period. Adapted from Kintsch et al. (1990).

504

Language

Kaakinen and Hyönä (2007) disputed the model's assumption that the
reader's goal in reading influences the integration stage rather than
the construction stage. In their study, participants read a text
discussing four rare diseases. They were asked to assume a close friend
had been diagnosed with one of them and they had to inform the friends
they had in common about that disease. These instructions influenced the
construction stage of comprehension -- readers focused primarily on
sentences relating to their friend's disease. According to the model,
text information is linked with general world or semantic knowledge
before contextual information from the rest of the text. Cook and Myers
(2004) tested this assumption using various passages. Here is an excerpt
from one passage: The movie was a small independent film with a low
budget and small staff, so everyone involved had to take on extra jobs
and responsibilities. On the first day of filming "Action!" was called
by the actress so that shooting could begin . . . The model predicts
that readers' knowledge that actresses do not direct films should have
caused them to fixate the word actress for a long time. In fact,
however, that word was not fixated for long because readers immediately
used the contextual justification for someone other than the director
being in charge (in italics). Thus, in opposition to the model,
contextual information can be accessed before general world knowledge.
The precise processes involved in integration and leading to a situation
model are not spelled out within the model. However, it is probable that
various executive functions (see Glossary) are involved such as
inhibitory processes (suppressing irrelevant propositions), attention
shifting (cognitive flexibility), updating information in working
memory, and planning. Follmer (2018) reported in a meta-analysis that
individuals high in each of these executive functions had superior
comprehension ability to those low in these functions.

Evaluation The key notion that propositions for the text representation
are selected by spreading activation operating on propositions drawn
from the text and stored knowledge is plausible and consistent with most
of the evidence. There is also reasonable evidence for the model's three
levels of representation. The model predicts accurately that readers
often find it hard to discriminate between text information and related
inferences. The model has influenced the development of several
subsequent theories (especially the RI-Val model below). What are the
model's limitations? (1)

(2) 

The model is less applicable when texts are easy to process (McNamara &
Magliano, 2009). With easy texts, there is often no need to generate a
situation model. The assumption that only bottom-up processes are used
during the construction phase of text processing is dubious. The finding
that

Language comprehension

(3) 
(4) 
(5) 
(6) 
(7) 
(8) 

readers' goals can lead them to allocate attention selectively very
early in text processing (Kaakinen & Hyönä, 2007) suggests text
processing is more flexible than assumed theoretically. It is assumed
only general world and semantic knowledge is used in addition to text
information during the construction phase. In fact, other sources of
information (e.g., context) can also be used during this phase (e.g.,
Cook & Myers, 2004). The model is oversimplified. For example, O'Brien
and Cook (2016) argued persuasively that language comprehension involves
a validation stage continuing after the completion of the integration
stage (see below). The cognitive processes involved in the integration
stage of text comprehension are not specified clearly in the model. As
we have seen, inhibitory processes, attention shifting, updating and
planning are all involved (Follmer, 2018). The model accounts for the
relatively "automatic" inferences drawn during reading but not more
effortful ones (Reichle, 2015). Individual differences (e.g., in working
memory capacity) are de-emphasised. There is an exaggerated emphasis on
the role played by abstract propositions in forming situation models.
More recent theories (e.g., the event-indexing model discussed shortly)
assume situation models include more concrete information (e.g.,
perceptual details).

RI-Val model O'Brien and Cook (2016) developed Kintsch's
construction-integration model. Their model assumes there are three
stages in language comprehension: (1)

(2) 
(3) 

The activation or resonance (R) stage: there is a "dumb and unrestricted
process" (p. 329) in which any discourse-relevant information in
long-term memory can be activated and influence initial comprehension.
The integration (I) stage: activated concepts are linked to (or
integrated with) the contents of working memory. Integration is based on
conceptual overlap, making it possible that it results in "the
connection of related, but contradictory pieces of information"
(Williams et al., 2018, p. 1415). The validation (Val) stage: linkages
formed during the integration stage are validated against relevant
information (e.g., general knowledge) stored in long-term memory.

O'Brien and Cook's (2016) RI-Val model is shown in Figure 10.14. The
three processing stages overlap in time but start in the order described
above. It is assumed all three processes are passive (i.e., relatively
automatic) and always continue to completion. At some point in
processing, the reader (or listener) decides on the basis of the
validation process that they have an adequate comprehension of the
discourse: the coherence threshold has been reached.

505

506

Language

Figure 10.14 This is the RI-Val model showing the effects on
comprehension of resonance, integration and validation over time. Note
that these processes continue even after the coherence threshold has
been reached.

Degree of inﬂuence on comprehension

Coherence threshold

From O'Brien and Cook (2016).

Resonance Integration Validation

Threshold Time

How does the RI-Val model compare with Kintsch's constructionintegration
model? The two models are broadly similar: the resonance and integration
states resemble the construction stage in Kintsch's model. However,
there are two important differences: (1)

(2) 

The RI-Val model explicitly identifies separate integration and
validation processes whereas validation is only implicitly incorporated
within the construction-integration model. In contrast to other models,
it is assumed within the RI-Val model that the validation process often
continues even after the readers (or listeners) have understood the
discourse (see Figure 10.14). As a consequence, they may detect an
inconsistency in what they are reading or hearing after reaching the
coherence threshold.

Cook and O'Brien (2014) obtained support for the above prediction.
Participants read a passage about Mary who had been a strict vegetarian
for many years. The crucial (target) sentence in the passage was either,
Mary decided to order a cheeseburger, or, Mary decided to order a tuna
salad. The pattern of eye movements indicated that participants rapidly
detected the inconsistency between Mary being a vegetarian and ordering
a cheeseburger. However, the inconsistency is less obvious when Mary
orders a tuna salad. With that inconsistency, it was only on the
sentence following the target one that the participants' eye movements
were disrupted. Williams et al. (2018) obtained similar findings.
Readers often detected that sentences such as, Moses brought two animals
of each kind on the ark, were incorrect when reading the sentence
following the incorrect one. In sum, it makes sense to divide Kintsch's
integration stage into somewhat separate integration and validation
stages. The prediction that detection of an inconsistency in discourse
can be delayed when it is not immediately obvious based on participants'
general knowledge has been reported (Cook & O'Brien, 2014; Williams et
al., 2018). What are the model's limitations? First, it does not
explicitly consider the effects of individual differences (e.g., in
working memory capacity) on

Language comprehension

507

the three major processes involved in language comprehension and on
setting the coherence threshold. Second, the model focuses too much on
passive or automatic processes and has very little to say about active
strategic processes (discussed later).

Event-indexing model and event-segmentation theory Kintsch's
construction-integration model is a leading example of a situation
model. As Zwaan (2016, p. 1028) pointed out, "The basic idea behind
situation models is that comprehension of a stretch of discourse
involves the construction of the state of affairs denoted by the text
rather than only a mental representation of the text itself." In this
section, we consider two more situation models representing developments
of Kintsch's approach. The theoretical discussed here both emphasise the
importance of events. According to Radvansky and Zacks (2011, p. 608),
"Events are fundamental to human experience. They \[are\] the elements
that constitute the stream of experience." One theoretical approach we
will discuss is the event-indexing model (Zwaan et al., 1995). The other
is event-segmentation theory (Zacks et al., 2007) which represents a
development and extension of the event-indexing model. They are both
situation models, but they differ from Kintsch's model in the nature of
the representations formed during discourse comprehension. He argued
that mental models consist of abstract propositions. In contrast, the
event-indexing and event-segmentation theories assume representations
are often grounded in perception and action (Zwaan, 2014). Zwaan (2016,
p. 1029) used the sentence "The egg is in the carton" to illustrate the
difference between these theoretical approaches. A concrete
representation of the sentence might include the shape of a whole egg
whereas an abstract representation would not. The event-indexing model
(Zwaan et al., 1995) focuses on comprehension processes when someone
reads a narrative text (e.g., a story or novel). Thus, its scope differs
from that of the construction-integration model where the emphasis is on
comprehension of expository texts designed to describe and/or inform.
However, there are some similarities (e.g., the emphasis on constructing
situation models during reading). As McNamara and Magliano (2009,
p. 321) pointed out, a fundamental assumption of the event-indexing
model is that "The cognitive system is more attuned to perceive dynamic
events (changes in states) rather than static information". According to
the event-indexing model, readers monitor five situational aspects to
decide whether their situation model requires updating: (1) (2) (3) (4)

protagonist: the central character or actor in the present event
compared to the previous one; temporality: the relationship between the
times at which the present and previous events occurred; causality: the
causal relationship of the current event to the previous one;
spatiality: the relationship between the spatial setting of the current
and previous events;

Interactive exercise: Construction-integration model

508

Language

(5) 

intentionality: the relationship between the character's goals and the
present event.

What happens to outdated information when we update a situation model?
There are two possibilities (Zwaan & Madden, 2004). First, such
information continues to influence the comprehension process (resonance
view). Second, outdated information is mostly or totally discarded in
favour of new information in the text (here-and-now view). According to
event-segmentation theory (Zacks et al., 2007), updating of a situation
model can take two main forms: (1) (2)

incremental updating of individual situational dimensions (the
"brickby-brick" approach emphasised with the event-indexing model);
global updating in which the current situational model is replaced by a
new one (the "from scratch" approach emphasised by eventsegmentation
theory); such updating is most likely to occur when we reach the
boundary between one event and the next.

When do readers engage in global updating? It is assumed we try to
predict the near future when reading a text or observing a scene. Such
predictions become harder to make as we approach the boundary between
one event and the next, which can trigger construction of a new model.

Findings According to the event-indexing model, updating is effortful
and incurs a processing load. As predicted, Swets and Kurby (2016) found
reading time (indexed by eye movements) was greater when updating was
required at the boundary between the end of one event and the start of
the next. If each aspect of the situation model is processed
independently or separately, we would predict updating time to be
greater when two aspects require updating rather than only one. Curiel
and Radvansky (2014) obtained the predicted finding. The probability of
updating occurring varies across the situational aspects. Readers
generally update information on intentionality, time and protagonist,
but are less likely to do so with spatial information (Smith & O'Brien,
2012). Most research has involved only short texts. McNerney et
al. (2011) studied reading times while participants read a novel. In
contrast to findings with short texts, reading times were reduced when
spatial or temporal information required updating. Perhaps readers'
engagement with the novel facilitated the task of updating such
information. As discussed earlier, the theoretical approach discussed
here assumes situation models often contain concrete perceptual and/or
motor information. As Kaup et al. (2007, p. 978) argued, "Comprehension
is tied to the creation of representations . . . similar in nature to
the representations created when directly experiencing or
re-experiencing the respective situations and events." Evidence
supporting the above theoretical assumption has been obtained using the
sentence-picture verification task. Zwaan et al. (2002)

Language comprehension

asked participants to read sentences such as the following: The ranger
saw an eagle in the sky or, The ranger saw an eagle in the nest. They
were then presented with a picture and decided rapidly whether the
object in the picture had been mentioned in the preceding sentence.
Verification times were faster when the object's shape in the picture
(e.g., an eagle with outstretched or folded wings) matched the shape
implied in the sentence indicating readers' use of perceptual
information. Zwaan and Pecher (2012) also used the sentence--picture
verification task in several experiments. Verification times were faster
to pictures matching the implied orientation, shape or colour of
sentence objects than to non-matching pictures. Moore and Schwitgebel
(2018) reported evidence consistent with the above assumptions and
research. Participants read various kinds of text (e.g., stage dialogue;
poems; descriptive text). When they heard a beep, they indicated whether
they had just been engaged in visual imagery. Across the different kinds
of text, readers reported visual imagery 70% of the time. Is it
cognitively demanding for readers to create detailed visual simulations
of objects referred to in texts? Gao and Jiang (2018) increased
processing demands by presenting text in a hard-to-read font. However,
this did not impair readers' ability to infer the physical shapes of
objects referred to in texts. The implication is that relatively little
processing capacity is required for readers to create visual simulations
while comprehending texts. Does outdated information disrupt current
text processing and formation of a situation model? Kendeou et
al. (2013) argued it would be disadvantageous if outdated information
was always disrupting. They discovered the provision of causal
explanations supporting the updating process eliminated disruption. One
story involved Mary, who had been a vegetarian for 10 years. This
sentence was presented late in the story: Mary ordered a cheeseburger
and fries. There was no disruption from outdated information for readers
giving a causal explanation why Mary was no longer vegetarian (she had
insufficient vitamins and so her doctor told her to eat meat). Is
situation-model updating incremental (as claimed within the
eventindexing model) or global (as claimed within event-segmentation
theory)? Kurby and Zacks (2012) asked readers to think aloud while
reading an extended narrative. They showed incremental updating by
increased mentions of the character, object, space, time and goal when
the relevant situational aspect changed. They also showed global
updating -- the presence of an event boundary was associated with
increased mentions of the character, cause, goal, and time. Huff et
al. (2018) found that updating was also incremental when listeners were
presented with an audio drama.

Evaluation The greatest strength of the event-indexing model and
event-segmentation theory is that they identify key aspects of situation
models that were de-emphasised within other theoretical approaches. For
example, they focus on gradual and global updating of situation models
in response to changes within and between events. The assumption that
situation models are not limited to abstract propositions (as assumed
within the

509

510

Language

construction-integration model) but can include perceptual and other
concrete types of information has received much empirical support. What
are the limitations of this theoretical approach? First, it is fully
applicable only to narrative texts describing event sequences and is of
little relevance to expository texts providing information and/or
explanations. Even with narrative texts, situation models are less
likely to be formed when the text is complicated. For example, most
readers failed to form a situation model when reading a complex account
of a murder scene (Zwaan & van Oostendorp, 1993). Second, the
theoretical approach de-emphasises important determinants of
comprehension (e.g., the reader's goals and reading skills; McNamara &
Magliano, 2009). Reasonable reading skills and adequate motivation for
successful monitoring the five different dimensions of protagonist,
temporality, causality, spatial relationships and intentionality. Third,
relatively little is known about the underlying mechanisms leading text
comprehension to produce representations containing perceptual and/or
motor information (Dijkstra & Post, 2015). We also lack a detailed
understanding of how such concrete information and the abstract
propositional information emphasised by Kintsch are combined during text
comprehension. Fourth, most research has involved relatively short
texts. However, preliminary evidence suggests some comprehension
processes may differ between long and short texts (McNerney et al.,
2011).

CHAPTER SUMMARY •

Parsing: overview. Listeners often make use of prosodic cues (e.g.
pauses) provided by the speaker to interpret sentences (especially
ambiguous ones). There is much evidence readers use their "inner voice"
to produce implicit prosody that closely resembles the prosody found in
spoken sentences. Readers' use of implicit prosody is greatly aided by
the presence of commas in text.

•

Theoretical approaches: parsing and prediction. The gardenpath model is
a two-stage model where only syntactic information is used at the first
stage. In fact, various kinds of non-syntactic information are sometimes
used earlier in sentence processing than the model predicts. The model
erroneously predicts that most readers will ultimately generate a
correct syntactic structure even for complex sentences. According to the
constraint-based model, all sources of information (e.g., context) are
available immediately to someone processing a sentence. Competing
sentence analyses are activated in parallel, with several language
characteristics (e.g., verb bias) being used to resolve ambiguities.
There is much support for this model. However, its predictions are
sometimes imprecise. According to the unrestricted race model, all
information sources are used to identify a single syntactic structure
for a

Language comprehension

sentence. If this structure is disconfirmed, there is extensive
re-analysis. This model de-emphasises the importance of task demands in
influencing parsing. According to the good-enough language processing
account, we often process sentences rather superficially using various
heuristics and so are prone to error. It is not clear how readers decide
a proposed sentence structure is good enough. ERP studies indicate
several sources of information (including word meanings and context)
influence sentence processing at an early stage. Top-down processes
generate predictions as to what will be read next. •

Pragmatics. Pragmatics is concerned with intended rather than literal
meanings. Understanding figurative language (e.g., metaphor; irony) is
often relatively complex because it involves simultaneous processing of
metaphorical and literal meanings. Understanding metaphors involves
selecting predicate features relevant to the argument and inhibiting
irrelevant predicate features. There are processing differences between
different types of metaphors and between novel and familiar metaphors.
Listeners generally understand better what speakers are saying if they
make use of the common ground (shared knowledge and beliefs). When it is
effortful to use the common ground, listeners often rely on the
egocentric heuristic. Sometimes listeners make simultaneous use of an
egocentric perspective and common ground.

•

Individual differences: working memory capacity. Individuals high in
working memory capacity outperform low-capacity individuals with respect
to language comprehension. This superiority depends on both specific
individual differences (e.g., verbal working memory) and more general
ones. It has generally been assumed theoretically that there is a direct
relationship between working memory capacity and reading comprehension.
However, there is increasing evidence that the relationship is indirect
and depends on factors such as vocabulary size, language experience and
general reasoning ability.

•

Discourse processing: inferences. Readers typically make logical and
bridging inferences (e.g., anaphor resolution) but the extent to which
they make elaborative inferences is variable. Inference drawing depends
on two types of processes: (1) passive or "automatic" processes; (2)
effortful reader-initiated processes. Reader-initiated processes are
most likely to be used when required for readers to attain adequate
comprehension and coherence while reading a text. Anaphor resolution is
a very common form of bridging inference. It involves multiple
constraints operating interactively in parallel. Most research focuses
on

511

512

Language

whether inferences are drawn rather than which inferences are drawn.
However, there is evidence that anxious individuals are more likely than
non-anxious ones to draw threatening predictive inferences. •

Discourse comprehension: theoretical approaches. According to schema
theory, schemas or organised packets of knowledge influence our
comprehension of (and memory for) discourse in a top-down fashion. The
theory lacks explanatory power, and comprehension and memory are less
error-prone than assumed theoretically. According to Kintsch's
construction-integration model, three levels of text representation are
constructed. It is assumed bottom-up processes (construction stage) are
followed by top-down processes (integration stage). However, top-down
processes occur earlier than assumed theoretically. The model is less
applicable when texts are easily processed. According to the RI-Val
model (a development of the construction-integration model), a
long-lasting validation process can detect inconsistencies in a text
even after readers believe they have adequate text comprehension. The
event-indexing model and event-segmentation theory focus on how readers
update their situation models in response to changes within and between
events. This general approach works well with simple narrative texts but
is less applicable to complex and/or expository texts. The approach
de-emphasises the role played by the reader's goals and reading skills.

FURTHER READING Carreiras, M., Armstrong, B.C. & Duñabeitia, J.A.
(2018). Reading. In S.L. Thompson-Schill (ed.), Stevens' Handbook of
Experimental Psychology and Cognitive Neuroscience, Vol. 3: Language and
Thought (4th edn; pp. 207--244). New York: Wiley. Manuel Carreiras and
colleagues provide a thorough account of comprehension processes in
reading. Cook, A.E. & O'Brien, E.J. (2017). Fundamentals of inferencing
during reading. Language and Linguistics Compass, 11 (Article e12246).
This article evaluates several major theoretical approaches to inference
drawing while comprehending text. Garnham, A. (2018). Pragmatics and
inference. In S.-A. Rueschemeyer and M.G. Gaskell (eds), The Oxford
Handbook of Psycholinguistics (2nd edn). Oxford: Oxford University
Press. Alan Garnham provides a thorough review of theory and research on
pragmatics. Karimi, H. & Ferreira, F. (2016). Good-enough linguistic
representations and online cognitive equilibrium in language processing.
Quarterly Journal of Experimental Psychology, 69, 1013--1040. Hossein
Karimi and Fernanda Ferreira propose an interesting theoretical model of
language comprehension based on the good-enough processing approach.
Kim, A.E. (2018). Sentence processing. In S.L. Thompson-Schill (ed.),
Stevens' Handbook of Experimental Psychology and Cognitive Neuroscience,
Vol. 3:

Language comprehension Language and Thought (4th edn; pp. 111--148). New
York: Wiley. The many processes involved in understanding sentences are
discussed in detail in this chapter. Peng, P., Barnes, M., Wang, C.,
Wang, W., Li, S., Swanson, H.L. et al. (2018). A meta-analysis on the
relation between reading and working memory. Psychological Bulletin,
144, 48--76. This article provides a detailed account of how reading
performance is related to individual differences in working memory.
Pickering, M.J. & Gambi, C. (2018). Predicting while comprehending
language. Psychological Bulletin, 144, 1002--1044. Martin Pickering and
Chiara Gambi discuss how listeners' and readers' language comprehension
is enhanced by predictive processes. Zwaan, R.A. (2016). Situation
models, mental simulations, and abstract concepts in discourse
comprehension. Psychonomic Bulletin and Review, 23, 1028--1034. Rolf
Zwaan discusses key theoretical issues relating to approaches to
language comprehension based on situation models (e.g., Kintsch's
constructionintegration model; event-indexing model; event-segmentation
theory).

513

Chapter

11

Language production INTRODUCTION We know much more about language
comprehension than language production. Why is this? We can easily
control material to be comprehended, but it is harder to constrain an
individual's language production. In addition, to account for language
production, we need more than simply a theory of language. Language
production is basically a goal-directed activity having communication as
its main goal. People speak and write to impart information, to be
friendly and so on. Thus, motivational and social factors must be
considered in addition to purely linguistic ones. This chapter focuses
on speech production and writing (including the effects of brain damage
on these language processes). More is known about speech production than
about writing and nearly everyone spends more time talking than writing.
Thus, it is more important to understand the processes involved in
talking. Nevertheless, writing is an important skill. How similar are
the processes involved in spoken and written language? Both have as
their central function the communication of information about the writer
or speaker, other people and the world. In addition, both depend on the
same knowledge base. However, children (and nearly all adults) find
writing much harder than speaking which suggests there are important
differences between them. The main similarities and differences are
discussed below.

Similarities The view that speaking and writing are similar receives
support from theoretical approaches to these language activities. For
example, it is assumed both start with planning, in order to decide on
the overall meaning to be communicated (e.g., Dell et al., 1997, on
speech production; Hayes, 2012, on writing). At this stage, the actual
words to be spoken or written are not considered. The planning stage is
followed by language production (often on a clause-by-clause basis).
Miozzo et al. (2018) identified several other similarities. First,
children typically only learn how to write after they have developed
good spoken-language skills. Second, the teaching of writing often
focuses on

Language production

knowledge of spoken language (e.g., emphasising speech--print
correspondences). Third, adults' word spellings are influenced to some
extent by word pronunciation. Some forms of written communication
closely resemble spoken forms. For example, consider instant messaging
involving a rapid exchange of typed messages. Choe (2018) studied five
Korean friends exchanging instant messages. The messages were mostly
typed in a spontaneous and informal fashion resembling casual speech.
Those receiving these messages often replied with simplified messages
(e.g. yeah) or indicated their involvement by responding with
"machine-gun" questions (produced very rapidly without hesitation). In
sum, the exchanges of typed messages were very similar to spoken
conversation.

Differences There are several important differences between speaking and
writing. Written language typically uses longer and more complex
constructions as well as longer words and a larger vocabulary. Writers
make more use than speakers of words or phrases signalling what comes
next (e.g., but; on the other hand). This helps to compensate for the
fact that there is a relative lack of prosody (rhythm; intonation, and
so on; discussed shortly) in writing compared to speech. Here are five
major differences between speaking and writing (Crystal, 2005): (1) (2)
(3) (4) (5)

Speech is time-bound and transient whereas writing is space-bound and
permanent. Speakers typically have much less time available for planning
than writers and so spoken sentences are typically shorter. Speakers
mostly receive immediate verbal and non-verbal feedback (e.g.,
expressions of bewilderment) from their listeners. Speech is well suited
to social functions (e.g., casual chatting), whereas writing is well
suited to communicating facts and ideas. Writers have direct access to
what they have produced so far whereas speakers do not.

What are the consequences of the above differences? Speech is often
informal and simple in structure whereas writing is more formal and
complex. Writers need to write clearly because they do not receive
immediate feedback. Some brain-damaged patients have largely intact
writing skills despite an almost total inability to speak and a lack of
inner speech (e.g., EB, studied by Levine et al., 1982). Other
brain-damaged patients can speak fluently but find writing very hard
(Ellis & Young, 1988). Rapp et al. (2015) studied patients following a
left-hemisphere stroke. Aspects of grammar were impaired in writing but
not speech for some patients whereas others showed the opposite pattern.
These findings suggest partial independence of the processes underlying
writing and speech. However, the higher-level processes of language
production (e.g., planning; use of knowledge) are probably very similar
in speech and writing.

515

516

Language

We must not exaggerate the differences between speech and writing. As
Crystal (2005, p. 8) noted, "There are few . . . absolute differences
between speech and writing, and there is no single parameter of
linguistic variation which can distinguish all spoken from all written
genres." For example, emails often contain features associated with
speech (e.g., informality; rapid feedback).

BASIC ASPECTS OF SPEECH PRODUCTION We start by introducing broad issues
of direct relevance to speech production. First, there is the important
(but complex) issue of the extent to which speech production utilises
processes involved in speech comprehension. Second, we argue speech
production is much harder than it may appear subjectively. Strategies
used by speakers to cope with the complexities of speech production are
discussed. Third, we provide a preliminary account of the notion that
speech production involves a series of processing stages.

Speech production vs speech comprehension We saw in Chapter 9 that
speech perception (especially under difficult listening conditions)
often involves brain regions associated with speech production (e.g.,
Adank, 2012). In similar fashion, it is increasingly argued that speech
production often involves processes and brain regions associated with
speech perception. For example, Chater et al. (2016, p. 244) argued that
"Language comprehension and production are facets of a unitary skill".
They discussed their computational model (the ChunkBased Learner) which
simulates aspects of children's language acquisition and is equally
applicable to production and comprehension (see discussion later).
Strong evidence that speech production involves processes overlapping
with those used in speech perception was reported by Silbert et al.
(2014). They identified the brain areas activated as speakers produced a
15-minute narrative, and also those activated as listeners comprehended
the same narrative. They argued there are two possible reasons why a
given brain area is activated during both speech comprehension and
production: (1) (2)

The same processes are occurring in both cases. Different processes
occur in comprehension and production within the same brain area.

In their analyses, they assumed (1) was the case only when there were
similar patterns over time during comprehension and production: they
called this comprehension-production coupling. Silbert et al.'s (2014)
findings are shown in Figure 11.1. Several brain areas exhibited
comprehension-production coupling (in blue). Thus, speech production
shares several processes with speech comprehension. Unsurprisingly,
other brain areas were specifically associated with speech comprehension
or speech production. In approximate terms, the findings

Language production

Schematic summary SPM PM IFG

IPS

IPS

MC

TPJ

STG

AG

PM

rpPFC

precu neus PCC

TPJ

IFG

AG

RS

STG

MTG

MTG IT

Cau dala s mu Putarnen

IT

TP

Thals

TP

MC

Left hemisphere

Medial

Right hemisphere

Production

Overlap without coupling

Comprehension

Comprehension-production coupling (CPC)

overall suggested high-level language processing is more likely than
lowlevel processing to be shared between comprehension and production.
Pickering and Gambi (2018, p. 1002) focused on the use of
speechproduction processes in speech comprehension: "\[Comprehenders\]
covertly imitate the linguistic form of the speaker's utterance and
construct a representation of the underlying communicative intention . .
. \[they\] run this intention through their own production system to
prepare the predicted utterance." This hypothesis has much support (see
Chapter 10). For example, the average gap between turns during a
conversation between two individuals is only 250 ms (Stivers et al.,
2009) even though it takes about 600 ms to produce a single word
(Pickering & Gambi, 2018).

How easy is speech production? On the face of it (by the sound of it?),
speech production seems straightforward. Indeed, it seems almost
effortless when we chat with friends and acquaintances. We typically
speak at 2--3 words per second or about 150 words a minute and this
rapid speech rate suggests that speaking requires relatively few
processing resources. The reality of speech production is very different
from what is implied above. Consider Christiansen and Chater's (2016)
theoretical approach (discussed in Chapter 10 and in more detail later,
p. 535). According to this approach, our short-term memory has very
limited capacity and new information rapidly eliminates old information.
As a result, "Once detailed \[language\] production information has been
assembled, it must be executed straight away, before it is obliterated
by the on-coming stream of later low-level decisions" (Christiansen &
Chater, 2016, p. 5). Evidence speech production is often more
cognitively demanding than speech comprehension was reported by Boiteau
et al. (2014). Participants tracked a moving target while engaged in
speech production or comprehension. Speech production (especially speech
planning) was associated with a greater impairment of tracking
performance than speech comprehension. These findings suggest speech
production is more attentionally demanding than comprehension.

517 Figure 11.1 Areas activated (and coupled) during speech
comprehension and production are in blue (STG = superior temporal gyrus;
MTG = medial temporal gyrus; AG = angular gyrus; RPJ = temporal-parietal
junction; IFG = inferior frontal gyrus); areas activated (not coupled)
during comprehension and production are in orange; areas activated only
during production are in red; areas activated only during comprehension
are in yellow. From Silbert et al. (2014).

518

Language

KEY TERMS

How do speakers cope with the cognitive demands of producing speech? One
way is by re-using aspects of what they have just heard. An important
example is syntactic priming in which speakers re-use a given syntactic
structure. If, for example, you have just heard a passive sentence
(e.g., "The man was bitten by the dog"), this increases the probability
you will produce a passive sentence. Convincing evidence for syntactic
priming was reported in a meta-analysis (see Glossary) by Mahowald et
al. (2016). This priming effect was especially strong when speakers used
the same (or similar) words to those they had heard. Another way
speakers reduce processing demands is via preformulation, which involves
producing phrases used before. Approximately 70% of our speech consists
of word combinations we use repeatedly (Altenberg, 1990; Liu, 2014).
Horseracing commentators (who speak very rapidly) make extensive use of
preformulations (e.g., "They are off and racing now"). Another strategy
used to facilitate speech production is underspecification, which
involves using simplified expressions where the full meaning is not
explicit. Underspecification and preformulation often go together. "Or
something" and "and things like that" are examples.

Syntactic priming The tendency for a speaker's utterances to have the
same syntactic structure as those they have heard shortly beforehand.
Preformulation The production by speakers of phrases used frequently
before; it reduces the demands of speech production Underspecification A
strategy used to reduce processing costs in speech production by using
simplified expressions.

IN THE REAL WORLD: MILD COGNITIVE IMPAIRMENT It is cognitively demanding
to produce coherent spontaneous speech. Unsurprisingly, patients with
Alzheimer's disease exhibit clear signs of impaired spontaneous speech.
Alzheimer's disease is often preceded by mild cognitive impairment, a
condition involving minor problems with memory and thinking. Here we
consider which aspects of speech production are impaired in individuals
with mild cognitive impairment. Berisha et al. (2015) compared the press
conferences of two American presidents: Ronald Reagan and George Herbert
Walker Bush. Reagan was diagnosed with Alzheimer's disease six years
after leaving office. He showed a substantial reduction in the use of
unique words during his time as president, coupled with a large increase
in conversational fillers (e.g., "well"; "um"; "ah") and non-specific
nouns (e.g., "something"; "anything"). Thus, his speech became simpler
and less informative due to mild cognitive impairment. In contrast,
President Bush showed no systematic changes in vocabulary use over time.
Mueller et al. (2018) studied individuals with early mild cognitive
impairment (subtle cognitive deficits not meeting the criteria for mild
cognitive impairment). Over a two-year period, these individuals showed
greater decline than cognitively healthy controls in two aspects of
speech: (1) fluency (e.g., few filled pauses; few false starts); (2)
semantic content (proportion of words providing meaningful content).
These findings resemble those found with President Reagan. In sum,
reductions in speech-production quality are found even during the early
stages of mild cognitive impairment, suggesting that "normal" quality of
speech production requires intact cognitive processes. Such findings
also suggest that speech-production deficits may serve as an "early
warning" of future, more severe, cognitive impairment. Of relevance,
Berisha et al. (2017) found professional American football players had
lower spoken language complexity (e.g., low ratio of content words
(e.g., nouns; verbs) to total words spoken) than controls. In addition,
those football players who had been tackled the most had the lowest
spoken language complexity. It might be a useful precaution to carry out
more detailed cognitive testing on those American football players with
the least spoken language complexity.

Language production

519

Stages in speech production

KEY TERMS

Speech production involves several general stages or processes. Dell
(1986), in his spreading-activation theory (discussed later,
pp. 526--530), argued speech production consists of four levels:

Alzheimer's disease A disease in which general deterioration of the
brain leads to progressive mental deterioration.

●

●

● ●

semantic level: the meaning of what is to be said (or the message to be
communicated); this is the planning level; syntactic level: the
grammatical structure of the words in the planned utterance;
morphological level: the morphemes (basic units of meaning);
phonological level: the phonemes (basic units of sound).

It makes sense to assume the above four levels or stages occur in the
order described. Thus, we engage in planning, followed by working out
the grammatical structure of the sentence and the basic units of
meaning, and finally work out the sounds to be produced. In fact, speech
production is much less neat and tidy: "later" processes can occur at
the same time as (or even ahead of) "earlier" processes.

SPEECH PLANNING We typically plan what we are going to say before
speaking (the first stage in speech production). In other words, we
engage our brain before speaking. Is speech planning influenced by the
syntactic structure of planned utterances? Supporting evidence was
reported by Lee et al. (2013). Consider the following sentence: The
student of the teacher who is raising her hand. This sentence is
ambiguous. Is the person raising their hand the teacher (simpler
syntactic structure) or the student (more complex structure). The time
to initiate speech was longer when speakers produced the more complex
syntactic structure indicating that speech planning included aspects of
syntactic structure. What is the scope of speakers' planning? Planning
might occur at the level of the clause (a part of a sentence containing
a subject and a verb). Alternatively, it might occur at the level of the
phrase (a group of words expressing a single idea). In the sentence
"Failing the exam was a major disappointment to him", the first three
words form a phrase. Holmes (1988) found speakers talking spontaneously
about various topics had hesitations and pauses immediately before the
start of a clause. This suggests they were planning the forthcoming
clause. Martin et al. (2004) found speakers describing moving pictures
took longer to initiate speech when the initial phrase was complex
rather than simple. This suggests they planned the initial phrase before
speaking. The extent of advance speech planning often differs at the
semantic, syntactic and phonological levels. Garrett (1980) analysed
various types of speech errors (discussed further later, pp. 521--523).
Word-exchange errors (e.g., "My chair seems empty without my room")
often involved

Morphemes The basic units of meaning; words consist of one or more
morphemes. Clause A group of words within a sentence that contains a
subject and a verb. Phrase A group of words within a sentence expressing
a single idea.

520

Language

words belonging to the same syntactic or grammatical category and
generally spanned different phrases. These errors occur during
grammatical encoding. In contrast, sound-exchange errors (e.g., burst of
beaden instead of beast of burden) typically involved nearby elements
within a phrase. These errors occur during phonological encoding.
Garrett concluded that grammatical or syntactic planning occurs over
greater distances within a sentence than does phonological planning.
Recent research reveals a more complex picture. In a review, Klaus et
al. (2017) concluded planning at the syntactic and phonological levels
can both extend "beyond the initial phrase and may even span over a
whole simple sentence" (p. 813). In their own research, Klaus et
al. found advance planning was comparable at the syntactic and
phonological levels when speakers performed a visuo-spatial task at the
same time. However, performing a verbal task (remembering digits) at the
same time only reduced the extent of phonological planning, suggesting
the verbal task and phonological planning required the same processing
resources. More generally, the findings suggest that the scope of
planning at any given level (e.g., syntactic; phonological) depends on
the precise demands of any nontask processing occurring at the same
time.

Flexibility How can we account for the variable findings discussed
above? Speakers generally want to start communicating rapidly (implying
little forward planning). However, they also want to talk fluently
(implying much forward planning). Speakers resolve conflict flexibly
depending on their immediate goals and the situational demands. Ferreira
and Swets (2002) reported evidence that speakers' planning varies
flexibly. Speakers answered mathematical problems. When there was no
time pressure, speakers planned their responses before starting to speak
and so the time taken to start speaking was influenced by task
difficulty. When there was time pressure, speakers engaged in limited
planning before starting to speak, with additional planning occurring
during speaking. Thus, they did as much forward planning as was feasible
before speaking. Wagner et al. (2010) agreed speech planning is flexible
and identified several factors influencing advance planning. First,
individuals speaking slowly engaged in more planning than fast speakers.
Second, there was more planning before speakers produced simple rather
than complex sentences. Third, speakers showed more planning when under
low (rather than high) cognitive load. How can we explain speakers'
flexible advance planning? As mentioned earlier, they face a trade-off
between communicating effectively and avoiding errors on the one hand
and cognitive demands on the other hand. If they focus on avoiding
errors, the cognitive demands are substantial. However, if they try to
minimise cognitive demands, their speech will contain many errors. In
practice, speakers mostly engage in extensive planning only when it is
relatively undemanding. In sum, "Speech planning processes flexibly
adapt to external task goals" (Swets et al., 2013, p. 23).

Language production

There is a final important point. Since speakers' advance planning is
generally limited in scope, it would seem that they must often engage in
incremental planning. In other words, speakers plan only part of the
next sentence or utterance and gradually extend and change their plan
over time. Brown-Schmidt and Konopka (2015) obtained evidence of
incremental planning when participants were required to add new
information to their spoken utterance after they had started to speak.
Brown-Schmidt and Konopka also found that speakers' fluency was not
impaired by adding new information, suggesting that their initial plan
was so flexible it could easily accommodate message revisions.

SPEECH ERRORS Our speech is generally accurate and coherent. However, we
all make occasional speech errors. There are several kinds of speech
errors which can occur at any stage of speech production. Human
limitations in processing capacity (e.g., short-term memory) might
suggest speech errors would be frequent (Christiansen & Chater, 2016).
However, the average person makes a speech error only once every 500
sentences. In spite of their rarity, speech errors are important because
they provide insights into the mechanisms underlying speech production.
This would not be so if speech errors were random and thus
unpredictable. In fact, speech errors are predominantly systematic. The
speech errors even of brain-damaged patients are generally similar to
the correct words (Dell et al., 2014). As Dell et al. concluded, "Slips
\[speech errors\] are more right than wrong." Historically, speech
errors were typically written down by researchers immediately after
being heard. This is limited because many speech errors are undetected
(Ferber, 1995). More recently, research has focused on speech errors
produced deliberately under laboratory conditions.

Error types There are several types of error additional to those
mentioned earlier. One example is the spoonerism which occurs when the
initial letter(s) of two words are switched. It was named after the
Reverend William Spooner who is credited with several memorable examples
(e.g., "You have hissed all my mystery lectures"). Alas, most of his
gems resulted from painstaking effort. The Freudian slip is a famous
type of error allegedly revealing the speaker's true sexual desires. In
a study by Motley (1980), male participants said out loud pairs of items
such as goxi furl and bine foddy. For some participants, the
experimenter was a female who was "attractive, personable, very
provocatively attired, and seductive in behaviour" (Motley, 1980,
p. 140). More spoonerisms (e.g., goxi furl turning into foxy girl) were
produced when the participants' passions were inflamed by this female
experimenter. Semantic substitution errors occur when the correct word
is replaced by one of similar meaning (e.g., "Where is my tennis bat?"
instead of "Where is my tennis racquet?"). In 99% of cases, the
substituted and correct words belong to the same part of speech (e.g.,
nouns), suggesting speakers plan

521

KEY TERMS Spoonerism A speech error in which the initial letter or
letters of two words (typically close together) are switched to form two
different words. Freudian slip A speech error that reveals the speaker's
(often unconscious) sexual desires.

522

Language

the grammatical structure of their next utterance before finding the
precise words to insert into it. Morpheme-exchange errors involve
inflections or suffixes (e.g., -ed) being attached to the wrong word
(e.g., "He has already trunked two packs"). Such errors imply that the
positioning of inflections is dealt with by a different process from the
one responsible for positioning word stems (e.g., trunk; pack). The word
stems are worked out before the inflections are added because the spoken
inflections or suffixes are generally altered to fit with the new word
stems. For example, the "s" sound in "the forks of a prong" is
pronounced in a way appropriate within the word forks but not the
original word prongs. Finally, we consider subject-verb agreement
errors, in which singular verbs are mistakenly used with plural subjects
or vice versa (e.g., "The government have made a mess of things"). Why
do we make such errors? McDonald (2008) argued that considerable
processing resources are required to avoid subject-verb agreement
errors. As predicted, speakers made more such errors when there was an
externally imposed load on working memory. Other factors associated with
use of singular or plural verbs have been identified. When speakers had
recently encountered phrases (e.g., a trio of violinists) paired with
plural verbs, they were more likely to produce plural verbs with other,
similar phrases (e.g., a class of children) (Haskell et al., 2010).
Mirković and MacDonald (2013) found semantic factors are important.
Participants received verbs plus phrases (in Serbian) such as the
following: (1) (2)

Many wolves . . . (to jump) Several wolves . . . (to jump)

In each case, they had to decide whether to say jump or jumps (both
grammatically acceptable in Serbian). Mirković and MacDonald argued that
many is more suggestive than several of a single mass or collection. As
predicted, speakers used plural verbs less often following phrases
containing many rather than several. It has generally been assumed most
speech errors involve sound substitutions. Goldrick et al. (2016) showed
the limitations of this assumption. Speakers said tongue twisters
repeatedly. The sounds associated with speech errors varied considerably
-- some resembled direct substitutions but most did not. This
variability occurred because speech errors were due to a combination of
two factors: (1) planning processes relating to the targets of
articulation; and (2) articulatory processes specifying the motor
movements required to execute this plan. This study is important because
it indicates speech errors are multiply determined and so require more
complex explanations than those proposed in the past. In sum, speakers
make several types of speech errors. We will shortly discuss other types
of speech errors within the context of Dell's (1986)
spreading-activation theory, which provides an explanation of most types
of speech errors. Before turning to that theory, however, we discuss two
prominent theories of how speakers monitor their own speech to prevent
(or correct) speech errors. These theories have general importance
because

Language production

they identify mechanisms that serve to minimise the number of errors
made by speakers and thus enhance communication (Nozari & Novick, 2017).

Perceptual loop theory Speakers often detect and rapidly correct their
own speech errors. Levelt (1983) proposed a perceptual loop theory to
explain such error detection. According to this theory, speakers detect
their own speech errors by monitoring their utterances and discovering
that what they say sometimes differs from what they intended. Of
importance, this monitoring occurs at two levels: inner speech and overt
speech. With overt speech, speakers make use of auditory feedback. In
essence, speakers use the comprehension system to detect their own
speech errors in ways resembling those used to detect errors in other
people's speech. Monitoring of inner speech should typically occur
faster than monitoring of overt speech. Strong evidence that monitoring
for speech errors occurs at the two stages of inner and overt speech was
reported by Nooteboom and Quené (2017). Speakers were given a task
designed to produce errors. For example, the word pair BIN DOG was
presented visually and had to be spoken aloud. When they had previously
been presented with word pairs such as DOVE BALL; DEER BACK; and DIM
BOMB, they sometimes incorrectly said DIN BOG. Nooteboom and Quené
recorded two measures: (1) error-to-cut-off times (time between an error
and the speaker stopping speaking); and (2) error-to-repair times (time
between an error and the speaker correcting it). What did Nooteboom and
Quené (2017) find? First, the error-to-cutoff times showed two peaks
(139 ms and 637 ms). The fast times reflect monitoring of inner speech
whereas the slow times reflect monitoring of overt speech. Second, the
error-to-repair times also showed two peaks (253 ms and 970 ms):
repairing or correcting an error was more time-consuming when detected
in overt speech rather than inner speech. It is assumed within
perceptual loop theory that speakers often use auditory feedback to
monitor their own speech for errors. This assumption has been supported
by research showing speakers are worse at detecting errors when auditory
masking is used to prevent them from hearing themselves speak. However,
Nooteboom and Quené (2017) discovered that loud masking noise had no
effect on the detection of speech errors. Auditory feedback is probably
more important in monitoring when speakers produce fairly long and
complex utterances than when they simply produce two words as in
Nooteboom and Quené's study.

Conflict-based monitoring theory Nozari et al. (2011) proposed a
conflict-based monitoring theory. They argued error detection depends on
information generated by the speechproduction system rather than the
comprehension system. Their theory assumes speakers engage in conflict
monitoring during competition among various possible words at the time
of response selection. Cognitive control mechanisms are used to resolve
conflicts between response options.

523

524

Language

The two theories make different predictions. First, the perceptual loop
theory predicts speakers' success at detecting their own speech errors
depends mostly on their comprehension ability. In contrast, Nozari et
al.'s (2011) conflict-based account predicts speakers' ability to detect
their speech errors depends on the quality of their speech-production
system. Second, speakers should detect errors rapidly if error detection
depends on detecting conflict prior to producing an error (the
conflict-based account). According to the perceptual loop theory, in
contrast, error detection can be fast or slow depending on whether it is
based on monitoring inner or overt speech.

Figure 11.2 Correlations between aphasic patients' speech-production
abilities and their ability to detect their own speechproduction errors.
Top row: ability to avoid semantic errors when speaking (s weight) was
positively correlated with ability to detect their own semantic errors
(left) but not with ability to detect their own phonological errors.
Bottom row: ability to avoid phonological errors when speaking (p
weight) was not positively correlated with ability to detect their own
semantic errors (left) but was positively correlated with ability to
detect their own phonological errors (right). From Nozari et al. (2011).
Reprinted with permission from Elsevier.

Language production

Findings Nozari et al. (2011) tested patients with aphasia (various
language problems; see Glossary) to decide whether their ability to
detect their own speech errors depends more on their comprehension or
their speech-production ability. There was practically no correlation
between comprehension ability and error-detection performance. However,
speech-production ability predicted error detection (see Figure 11.2).
Patients making many semantic speech errors were much worse than other
patients at detecting their own semantic errors (r = --.59). Those
making many phonological speech errors were poorer at detecting their
own phonological errors (r = --.43). Blackmer and Mitton (1991) assessed
speed of error detection among callers to a radio chat show. Many errors
were detected very rapidly (e.g., 19% of overt corrections of what a
caller had just said occurred immediately). For example, one caller said
"willfiddily" and without any pause added "fully". In the study by
Noteboom and Quené (2017) discussed earlier, 72% of the error-to-cut-off
times were fast, which is consistent with conflict-based monitoring
theory. Gauvin et al. (2016) studied the brain regions associated with
error detection in speech production and speech perception. Error
detection in speech production generally involved brain regions mostly
independent of speech-perception systems. In addition, detection of
speech-production errors involved a cognitive control mechanism
resolving conflict centred on the anterior cingulate cortex.

Overall evaluation There is support for the assumption of perceptual
loop theory that speakers monitor inner and overt speech. Its further
assumption that monitoring of overt speech is based on auditory feedback
has also received some support. However, auditory feedback is used less
often than implied by the theory. Finally, the assumption that speech
monitoring involves comprehension-like processes appears mostly
incorrect. Several findings support conflict-based monitoring theory.
First, the success of brain-damaged patients in detecting their own
speech errors depends largely on their speech-production ability.
Second, the finding that speakers often detect speech errors very
rapidly suggests speech monitoring occurs within the speech-production
system. Third, the brain regions associated with the detection of speech
errors are closer to those predicted by this theory than by perceptual
loop theory (Gauvin et al., 2016). However, the theory is limited
because it de-emphasises the role sometimes played by speech-perception
mechanisms in detecting speech-production errors.

THEORIES OF SPEECH PRODUCTION Earlier we mentioned four levels or stages
of processing involved in speech production: semantic; syntactic;
morphological; and phonological. There is controversy concerning the
relationships between these levels or stages of processing in speech
production. Two highly influential theories of speech production are
Dell's (1986) spreading-activation theory and Levelt et al.'s

525

526

Language

KEY TERMS

(1999) WEAVER++ model (discussed in detail shortly, pp. 530--534). Below
       we provide a brief preview of key differences between them.
       According to Dell's (1986, 2013) spreading-activation theory,
       processing can occur in parallel (at the same time) at different
       levels (e.g., semantic; syntactic). More specifically, it is
       assumed theoretically that processing is interactive. That means
       there can be cascade processing (see Glossary) with the
       initiation of later processing stages occurring prior to the
       completion of processing at earlier stages. It also means
       processing can involve bottom-up feedback in addition to the
       top-down processing characteristic of speech production. In
       contrast, Levelt et al. (1999) argued serial processing (one
       process at a time) plays a major role in speech production. They
       also assumed within their WEAVER++ model that speech production
       involves a feedforward system with processing occurring in a
       strictly forward direction (i.e., from meaning to sound). That
       assumption seems reasonable -- it is plausible that speakers
       decide the meaning they want to communicate before deciding on
       the appropriate sounds to articulate. In sum, the main
       assumptions of spreading-activation theory imply
       speech-production processes are (if not chaotic) then at least
       very flexible. In contrast, the main assumptions of WEAVER++
       imply the processes involved in speech production are regimented
       and structured. However, the actual theoretical differences are
       less extreme. Dell (1986) accepted processing at any given point
       in time is generally more advanced at some levels (e.g.,
       semantic) than others (e.g., phonological). Thus, the notions
       that initial processing is mainly at the semantic and
       phonological levels whereas later processing is mostly at the
       morphological and phonological levels are common to both
       theories. We will make two final preliminary points about the two
       theories. First, Goldrick (2006) proposed the compromise position
       that there is "limited interaction" in speech production. This
       makes sense -- too much interaction would lead to numerous speech
       errors whereas too little interaction would inhibit speakers'
       ability to produce interesting new sentences and new ideas.
       Second, spreading-activation theory was initially based largely
       on evidence from speech errors. In contrast, WEAVER++ was based
       mostly on laboratory studies of the time taken to speak words
       accurately in different contexts. It is arguable (Goldrick, 2006)
       that interactive effects are more prevalent in speech-error data
       than response-time data. Speculatively, the speech-production
       system may be most efficient when there is minimal distraction
       and interference and so it operates approximately in line with
       the assumptions of WEAVER++. Finally, speech production does not
       depend only on language-specific processes. Some more general
       processes (e.g., attention; short-term memory) are also
       important. We discuss relevant theory and research based on this
       approach at the end of this section (see pp. 535--536).

Spreading activation Activation of a node (corresponding to a word or
concept) in the brain causes some activation to spread to several
related nodes or words.

Spreading-activation theory Unsurprisingly, the notion of spreading
activation is central to Dell's (1986) spreading-activation theory. It
is assumed the nodes within a

Language production

network (nodes correspond to words or concepts) vary in activation or
energy. When a node or word is activated, activation or energy spreads
from it to other related nodes or words. For example, strong activation
of the node corresponding to "tree" may cause some activation of the
node corresponding to "plant". According to the theory, spreading
activation occurs for sounds as well as words. The theory assumes there
are categorical rules at the semantic, syntactic, morphological and
phonological levels of speech production. These rules impose constraints
on acceptable categories of items and combinations of categories. The
rules define categories appropriate at each level. For example, the
categorical rules at the syntactic level specify the syntactic
categories of items within a sentence. There is also a lexicon
(dictionary) in the form of a connectionist network. It contains nodes
for concepts, words, morphemes and phonemes. When a node is activated,
it sends activated to all the nodes connected to it (see Chapter 1).
Insertion rules select items for inclusion in the representation of the
to-be-spoken sentence according to the following criterion: the most
activated node belonging to the appropriate category is selected. For
example, if the categorical rules at the syntactic level dictate a verb
is required at a given point in the sentence, then the verb whose node
is most activated will be selected. After selection, the node's
activation level immediately reduces to zero to prevent it from being
selected repeatedly. Dell et al. (2008) focused on why we replace a noun
with a noun and a verb with a verb when making speech errors. They
argued we possess a "syntactic traffic cop" that monitors what we intend
to say and inhibits words outside the appropriate syntactical category.
According to the spreading-activation theory, speech errors occur
because an incorrect item is sometimes more activated than the correct
one. The existence of spreading activation means several nodes are
activated at the same time, which increases the likelihood of speech
errors. Dell et al. (2014) discuss the processes responsible for the
occurrence of several major speech errors (e.g., anticipatory errors;
exchange errors).

Findings What errors are predicted by spreading-activation theory?
First, and of special importance, there is the mixed-error effect, which
occurs when an incorrect spoken word is semantically and phonemically
related to the correct word. The existence of this effect suggests
semantic and phonological factors can both influence word selection at
the same time -- this is consistent with the notion the various levels
of processing interact flexibly. Alternatively, a monitoring system may
inhibit the production of words phonologically dissimilar to the
intended word (Levelt et al., 1999). Convincing evidence for the
mixed-error effect was provided by Ferreira and Griffin (2003).
Participants read incomplete sentences (e.g., "I thought that there
would still be some cookies left, but there were . . .") followed by
picture naming (e.g., of a priest). In this example, participants tended
to produce the wrong word none due to the semantic similarity between
priest and nun combining with the phonological identity of nun and none.

527

KEY TERMS Mixed-error effect A form of speech error in which the
incorrect word spoken is related to the correct one in terms of both
meaning and sound.

528

Language

KEY TERM

Second, speech errors typically consist of actual words rather than
nonwords (the lexical bias effect). According to the theory, this effect
occurs because it is easier for words than non-words to become activated
because they have representations in the lexicon (see Glossary).
Alternatively, speakers may monitor their inner speech and edit out
non-words (monitoring of inner speech was discussed earlier). There is
support for both explanations (Dell et al., 2014). Nooteboom and Quené
(2008) found evidence for self-monitoring -- speakers often corrected
themselves just before producing an incorrect word (e.g., SAYING D . . .
BARN DOOR when seeing BARN-DOOR). Corley et al. (2011) asked people to
say tongue twisters rapidly. In one condition, all the stimuli were real
words compared to only half in the second condition. There was the
typical lexical bias effect in the all-word condition, but the effect
disappeared in the second condition. How can we explain these findings?
Since half the stimuli in the second condition were non-words, speakers
did not edit out non-words before speaking. Third, spreading-activation
theory predicts speakers should make anticipatory errors in which a
speech sound is made too early (e.g., "a Tanadian from Toronto" instead
of "a Canadian from Toronto"). This prediction has been confirmed (e.g.,
Nooteboom & Quené, 2013). Anticipatory errors occur because many
sentence words become activated during speech planning and sometimes a
later word is more activated than the one that should be spoken. Fourth,
many errors should be exchange errors in which two words within a
sentence are swapped (e.g., "I must send a wife to my email"). That is,
indeed, the case (Nooteboom & Quené, 2013). Remember the activation
level of a selected word immediately reduces to zero. If "wife" is
selected too early, it is unlikely to be selected in its correct place
in the sentence. This allows a previously unselected but highly
activated word such as "email" to be spoken in the wrong place. Fifth,
anticipation and exchange errors generally involve words moving only a
relatively short distance within the sentence. Those words relevant to
the part of the sentence under current consideration are generally more
activated than those relevant to more distant parts of the sentence.
Thus, the findings accord with the predictions of spreading-activation
theory.

Lexical bias effect The tendency for speech errors to form words rather
than non-words. Lexicon An individual's internal dictionary containing
information about word meanings.

Evaluation Spreading-activation theory has several strengths: (1) (2)
(3)

(4) 

The mixed-error and lexical bias effects indicate processing during
speech production can be highly interactive as predicted theoretically.
The theory can also explain several other speech errors (e.g., exchange
errors; anticipatory errors). The theory's emphasis on spreading
activation provides links between speech production and other cognitive
activities (e.g., word recognition: McClelland & Rumelhart, 1981). Our
ability to produce novel sentences may depend in part on the flexibility
resulting from widespread activation between processing levels assume by
the theory.

Language production

(5) 

Dell's (1986) original theory was vulnerable to the charge that it
predicted too many speech errors. However, Nozari et al. (2011;
discussed earlier, pp. 523--525) improved the theory by adding
mechanisms for monitoring and editing out errors early in processing.

What are the theory's limitations? (1)

(2) 
(3) 
(4) 

It de-emphasises processes involved in the construction of a message
(including its intended meaning). It also fails to consider audience
design (how speakers respond to the needs of their audience; discussed
later, pp. 544--547). It does not predict the time taken to produce
correct and incorrect spoken words. The interactive processes emphasised
by the theory are less apparent in error-free than speech-error data
(Goldrick, 2006). For example, the processes involved in correct versus
incorrect picture naming differ. Principe et al. (2017) found brain
activity within large regions of the parietal and temporal cortex
differed between correct and incorrect naming within approximately 100
ms of picture presentation. There is insufficient emphasis in the theory
on factors influencing the extent of interactive processes in speech
production. There is less interactive processing when overall processing
demands are high than when they are low (Mädebach et al., 2011;
discussed shortly, p. 533).

Anticipatory and perseveration errors Dell et al. (1997) developed
spreading-activation theory. They argued most speech errors belong to
two categories: (1)

(2) 

Anticipatory: as discussed earlier, sounds or words spoken ahead of
their time (e.g., "caff of coffee" instead of "cup of coffee"). These
errors mainly reflect inexpert planning. Perseveratory: sounds of words
are spoken later than they should have been (e.g., "beef needle" instead
of "beef noodle"). These errors reflect planning failure or a failure to
monitor what one is about to say.

Suppose we compare speakers engaging in much forward planning with those
doing much less forward planning. According to Dell et al. (1997), those
planning ahead should make more anticipatory errors. They focused on the
anticipatory proportion (the proportion of total errors \[anticipation +
perseveration\] that is anticipatory) and argued this should correlate
positively with speakers' tendency to plan ahead.

Findings Dell et al. (1997) gave speakers extensive practice at saying
tongue twisters (e.g., five frantic fat frogs; thirty-three throbbing
thumbs). They argued practice would lead to more forward planning and so
increase the anticipatory proportion. As predicted, the anticipatory
proportion increased from .37 early in practice to .59 at the end of
practice.

529

530

Language

KEY TERM

Dell et al. (1997) also argued that requiring participants to speak more
rapidly would reduce forward planning and so decrease the anticipatory
proportion. This prediction was supported by Vousden and Maylor (2006)
in a study in which children and young adults said tongue twisters
slowly or fast. Wutzler et al. (2013) assessed the anticipatory
proportion in elderly individuals. Those with cognitive impairment had a
significantly lower anticipatory proportion than those without,
presumably because they were less able to plan their utterances. Fossett
et al. (2016) asked speakers to say tongue twisters at three different
rates: typical; fast; or faster. The anticipatory proportion was
smallest at the typical speaking rate -- this is opposite to theoretical
prediction. How can we explain the above unexpected finding? Dell et
al. (1997) argued the anticipatory proportion will be greatest at a slow
speaking rate because it permits much forward planning. This prediction
involves the assumption that words later in the sentence remain
activated long enough to produce anticipatory errors. If word activation
decays rapidly, then the findings of Fossett et al. (2016) can be
explained.

Lemmas Abstract words possessing syntactic and semantic features but not
phonological ones.

Levelt's theoretical approach and WEAVER++ Levelt et al. (1999) put
forward a computational model called WEAVER++ (WEAVER stands for
Word-form Encoding by Activation and VERification). The model focuses on
the processes involved in producing individual spoken words and makes
the following assumptions: ●

●

●

●

●

There is a feedforward activation-spreading network meaning that
activation proceeds forwards through the network but not backwards. Of
particular importance, processing proceeds from meaning to sound. There
are three main levels within the network: (i) At the highest level are
nodes representing lexical concepts. (ii) At the second level are nodes
representing lemmas from the mental lexicon. Lemmas are word
representations that "are specified syntactically and semantically but
not phonologically" (Harley, 2013). Thus, if you know the meaning of a
word you are about to say and that is a noun, but you do not know its
pronunciation, you have accessed its lemma. (iii) At the lowest level
are nodes representing word forms in terms of morphemes (basic units of
meaning) and their phonemic segments. Lexical (word) selection depends
on a competitive process based on the number of lexical units activated.
Speech production following lexical selection involves various
processing states following each other in serial fashion (one at a
time). Speech errors are avoided by means of a checking mechanism based
on the speaker monitoring what they say (discussed earlier, see
pp. 523--525).

It is easy to get lost in the model's complexities (agreed?). In
essence, however, the model shows how word production proceeds from
meaning (lexical concepts and lemmas) to sound (e.g., phonological
words). There is

Language production

a stage of lexical selection at which a lemma (representing word
meaning + syntax) is selected. A given lemma is generally selected
because it is more activated than other lemmas. Then there is
morphological encoding during which the basic word form of the selected
lemma is activated. This is followed by phonological encoding -- the
word's syllables are computed. What happens is known as lexicalisation,
"the process in speech production whereby we turn the thoughts
underlying words into sounds" (Harley, 2013). The most important
development of Levelt et al.'s (1999) approach involved identifying the
brain regions associated with the various processes within the model
(Indefrey & Levelt, 2004). This development means neuroimaging
techniques can be used to test the model's predictions. In sum, WEAVER++
is a discrete, feedforward model. Processing is discrete (separate),
because the speech-production system identifies the correct lemma or
abstract word before starting to work out the sound of the selected
word. It is feedforward, because processing proceeds in a strictly
forward (from meaning to sound) direction.

Findings According to the model, speakers process syntactic (e.g., a
noun's gender) and phonological information sequentially. Bürki et
al. (2016) tested this assumption using event-related potentials (ERPs;
see Glossary). As predicted, the evidence from ERPs suggested syntactic
and phonological processing occurred at different times. Van Turennout
et al. (1998) used ERPs with Dutch participants and found syntactic
information about a noun's gender was available 40 ms before its initial
phoneme. This is consistent with Levelt's theoretical approach. Indefrey
(2011) carried out a meta-analysis of studies using ERPs and other
techniques to assess brain activation during speech production. The
right column of Figure 11.3 provides approximate timings for major
speech-production processes. Conceptual preparation takes about 200 ms.
After that, lemma retrieval takes 75 ms, and phonological code retrieval
takes 20 ms per phoneme and 50--55 ms per syllable. Finally, phonetic
encoding with articulation typically starts about 600 ms after the
initiation of processing. The left-hand side of Figure 11.3 is colour
coded to indicate the various brain regions in the left hemisphere
associated with each process. There are limitations with Indefrey's
(2011) meta-analysis. First, most research involved picture naming
meaning the focus of the meta-analysis is narrow. Second, the timings
are with respect to stimulus presentation. Since speech production is
more concerned with action than perception, it would be preferable to
focus on how long a given process occurs prior to speech onset. Third,
the neat-and-tidy impression created by Figure 11.3 is misleading (see
below, p. 532). Recent cognitive neuroscience research relevant to
Dell's and Levelt's theoretical approaches is discussed in the next
section. We can see the distinction between a lemma and the word itself
in the tip-of-the-tongue state. The tip-of-the-tongue state occurs when
we have a concept or idea in mind (i.e., we have activated the correct
lemma or abstract word) but cannot find the appropriate word (i.e.,
phonological

531

KEY TERMS Lexicalisation The process of translating a word's meaning
into its sound representation during speech production.
Tip-of-the-tongue state The frustrating experience of being unable to
find the correct word to describe a given concept or idea.

532

Language

Figure 11.3 The right side of the figure indicates the sequence of
processes (and their timings) for picture naming. Identical colours on
the left side of the figure indicate the brain regions associated with
each process (the numbers within regions are the median peak activation
times in msec after picture onset). From Indefrey (2011).

processing is unsuccessful). Harley and Bown (1998) found the
tip-of-thetongue state was especially frequent for words sounding unlike
nearly all other words (e.g., apron; vineyard ) -- their unusual
phonological forms make them hard to retrieve. Levelt et al. (1999)
claimed the lemma includes syntactic as well as semantic information.
Accordingly, individuals in the tip-of-the-tongue state should have
access to syntactic information. In many languages (e.g., Italian;
German), grammatical gender (e.g., masculine; feminine) is part of the
syntactic information relating to nouns. As predicted, Italian
participants in the tip-of-the-tongue state for nouns guessed the
grammatical gender correctly 85% of the time (Vigliocco et al., 1997).
Biedermann et al. (2008) reported less supportive findings. German
speakers guessed the grammatical gender and initial phoneme of nouns
when in a tip-of-the-tongue state. Theoretically, access to grammatical
gender precedes access to phonological information and so participants
should have guessed the first phoneme more often when they had access to
accurate gender information. However, that was not the case. Resnik et
al. (2014) used magneto-encephalography (MEG; see Glossary) while
individuals were in the tip-of-the-tongue state when trying

Language production

533

to identify pictures of celebrities. They predicted brain areas
associated with semantic and syntactic processing (i.e., lemma
selection) should be activated shortly after picture presentation. In
contrast, brain areas associated with motor programming and articulation
should be activated shortly before the correct word was produced. The
predicted brain areas were activated. However, semantic and motor areas
were activated during both time periods suggesting processing was more
interactive than assumed within the model. According to WEAVER++,
abstract word or lemma selection is completed before phonological
information about the word is accessed. In contrast, Dell's
spreading-activation theory assumes phonological processing can start
before lemma or word selection is completed. Most evidence is
inconsistent with WEAVER++'s prediction. Meyer and Damian (2007)
required participants to name target pictures while ignoring distractor
pictures. According to WEAVER++, the phonological features of distractor
names should not have been activated. However, target pictures were
named more slowly when accompanied by phonological related distractors
(e.g., wall when ball was the target). In similar fashion, Roux and
Bonin (2016) found naming times for a coloured target object (e.g.,
banana) slowed when a distractor was phonologically related to the
target's colour (e.g., yellow). Mädebach et al. (2011) found picture
naming was slowed in the presence of a phonologically similar distractor
word only when the overall processing demands were relatively low. What
do these findings mean? Serial processing (as predicted by Levelt)
occurred when processing demands were high. In contrast, processing was
more interactive (as predicted by Dell) when processing demands were
low.

Evaluation WEAVER++ has various successes to its credit. First, the
assumption word production involves a series of stages moving from
lexical selection to morphological encoding to phonological encoding is
reasonably accurate (Indefrey, 2011; however, see next section,
pp. 534--535). Second, Levelt's theoretical approach was important in
shifting the balance of research away from speech errors (which are
relatively rare) towards precise timing of accurate word-production
processes. Third, WEAVER++ is a simple and elegant model making many
testable predictions. It is arguably easier to test WEAVER++ than more
interactive theories such as Dell's spreadingactivation theory. Fourth,
lexical or word selection often involves a competitive process as
assumed theoretically. What are the limitations with WEAVER++? (1)

(2) 

It focuses narrowly on processes involved in the production of single
words and so several processes involved in planning and producing
sentences are de-emphasised. There are many more interactions between
different processing levels than assumed within WEAVER++ (see next
section, pp. 534--535). As Melinger et al. (2014, p. 676) argued, "It is
a plausible hypothesis that the language production system is
fundamentally parallel in its operation."

Interactive exercise: WEAVER++

534

Language

(3) 
(4) 

The evidence from speech errors (e.g., the mixed-error effect, the
lexical bias effect, word-exchange errors, and sound-exchange errors)
indicates more parallel processing than predicted by WEAVER++. As Harley
(2013) pointed out, "The need for lemmas is \[not\] strongly motivated
by the data. Most of the evidence really only demands a distinction
between the semantic and the phonological levels."

Cognitive neuroscience Earlier we discussed Indefrey's (2011)
meta-analysis of ERP and other studies that provided strong support for
WEAVER++. Munding et al. (2016) reported a similar meta-analysis to
Indefrey (2011) based on simple speech-production tasks (e.g., picture
naming; reading aloud). However, they included only studies using
magneto-encephalography (whereas Indefrey (2011) focused mostly on ERP
studies. This is important because MEG has superior spatial resolution.
Munding et al.'s (2016) findings are shown in Figure 11.4. First, Levelt
et al.'s (1999) assumption that cognitive functions near the top of the
figure occur earlier than those further down was supported. Second, as
Munding et al. concluded, "There is a great deal of overlap in diverse
functions' active periods, and substantial numbers of reports of
theoretically 'late' functions being implicated early" (p. 452). For
example, several studies found evidence of articulatory processing
approximately 300--500 ms before the appropriate response is produced.
Dubarry et al. (2017) assessed brain activity during a picture naming
task. They replicated Munding et al.'s (2016) findings when using the
typical procedure of averaging data across trials. However, they argued
the averaging approach can provide "a blurred view of the underlying
processes" (p. 415). When they focused at the level of single trials,
there was much less evidence of parallel processing. Thus, findings
based on averaged data may exaggerate the extent of parallel processing
in speech production. In sum, evidence obtained using the techniques of
cognitive neuroscience provides a complex picture. What conclusions can
we draw? First,

From Munding et al. 2016.

7

Conceptual prep.

6

Lemma sel.

5 4

Phon. code ret'l

3 Syllabiﬁcation 2 Articulation

1

Self monitoring

0 0

200

400

600 Time (ms)

500

Number of activations

Figure 11.4 The timing of activation associated with different cognitive
functions (colour indicates the number of studies reporting activity
related to a given function).

Cognitive function

Vis. Processing

Language production

as Riès (2016, p. 476) noted, "Areas associated with lemma selection are
generally active before those involved in phonological code retrieval,
which are themselves generally active before those associated with
articulation." Such findings support Levelt et al.'s (1999) theoretical
approach. Second, brain areas associated with supposedly "late"
processes (e.g., phonological processes) are often active much earlier
than predicted by Levelt et al. Perhaps top-down processes anticipate or
predict the processes necessary later in speech production.

Speech production: general cognitive processes Fifty years ago, it was
often assumed humans possessed "language genes" and that language
involves processes very different from those used in other cognitive
tasks. Those assumptions have been increasingly rejected. It is now
recognised that general processes (e.g., short-term memory; attention;
cognitive control) play an important role in language processing
(including speech production). Here we will briefly consider some
relevant research. As mentioned earlier, Christiansen and Chater (2016)
argued the very limited capacity of short-term memory means speakers
(and listeners to speech) have to deal with a "now-or-never" bottleneck:
"If linguistic information is not processed rapidly, that information is
lost for good" (p. 3). How do speakers cope with this bottleneck?
According to Christiansen and Chater (2016), children learn to form
chunks (see Glossary) in which frequently encountered words are grouped
together in long-term memory. As a result, an ever-increasing number of
chunks is stored in a "chunkatory". This reduces processing demands by
allowing speakers to focus on retrieving entire phrases (rather than
single words) from long-term memory. MacDonald (2016) argued that there
are important similarities between utterance planning (transient memory
of what is to be spoken) and verbal memory (e.g., immediate serial
recall of a word list). Here are some examples: (1) words close to each
other are most likely to be exchanged; (2) similar words interfere with
each other; (3) there are more errors in long lists/sentences than short
ones. These findings suggest the processes involved in speech planning
closely resemble those involved in verbal short-term memory. Proficient
bilinguals rarely allow words from their unintended language to intrude
into their speech. Top-down inhibitory processes play an important role
in this achievement (Kroll & Navarro-Torres, 2018). For example,
consider a Friulian-Italian bilingual patient (LI) with damage to the
frontal cortex and anterior cingulate (brain areas associated with
top-down control). He switched into Italian 40% of the time when he was
meant to be speaking Friulian and into Friulian 43% of the time when
Italian was required (Fabbro et al., 2000). On the picture naming task,
participants show interference when a word distractor is presented
together with each picture. Inhibitory processes are required to
minimise such interference. Patients with damage to the lateral
prefrontal cortex (involved in inhibition) have larger interference
effects than healthy controls (Piai et al., 2016). Jongman et al. (2017)
studied the relationship between sustained attention and picture naming.
Individuals with superior levels of sustained

535

536

Language

KEY TERMS

attention had better picture naming performance than those with low
levels. McClain and Goldrick (2018) discussed other research indicating
the importance of attentional processes in speech production. In sum,
general processes (e.g., attention; short-term memory; inhibition),
de-emphasised in spreading-activation theory and WEAVER++, strongly
influence speech production. For example, speakers' use of inhibitory
and other general processes may explain why the interactive processes
emphasised within spreading-activation theory do not lead to numerous
speech errors. In future, it will be important to develop theories
indicating how general and language-specific processes combine in speech
production.

Aphasia Severe problems in the comprehension and/or production of
language caused by brain damage. Wernicke's aphasia A form of aphasia
involving fluent speech with many content words missing and impaired
comprehension. Broca's aphasia A form of aphasia involving non-fluent
speech and grammatical errors.

COGNITIVE NEUROPSYCHOLOGY: SPEECH PRODUCTION The cognitive
neuropsychological approach to language started in the nineteenth
century. Its focus was on brain-damaged patients with aphasia, a
condition involving severe impairments in language comprehension and/or
production. Early researchers distinguished between Broca's and
Wernicke's aphasia. Patients with Broca's aphasia have slow, non-fluent
speech. They also have a poor ability to produce syntactically correct
sentences, but their sentence comprehension is relatively intact.
Broca's aphasia is generally assumed to involve BA44 and BA45 in the
inferior frontal gyrus (see Figure 11.5). In contrast, patients with
Wernicke's aphasia have fluent and apparently grammatical speech that
often lacks meaning. They also have severe problems with speech
comprehension. Wernicke's aphasia is generally assumed to involve the
posterior part of BA22 in the superior temporal gyrus (see Figure 11.5).
In sum, the traditional approach assumed impaired language production
was of central importance in Broca's aphasia whereas impaired language
comprehension was central to Wernicke's aphasia. Dronkers et al. (2017)
reviewed the relevant evidence and reported very limited support for the
traditional approach. That approach was much

Figure 11.5 Language-related regions and their connections in the left
hemisphere. PMC, premotor cortex; STC, superior temporal cortex; p,
posterior. Berwick et al. (2013). Reprinted with permission from
Elsevier.

Language production

oversimplified in several ways. First, there is no consensus concerning
the scope of Broca's area or Wernicke's area! Tremblay and Dick (2016)
found the most popular definition of Wernicke's area by experts was "the
posterior part of the superior temporal gyrus and including part of the
supramarginal gyrus" (p. 63) endorsed by 26% of respondents. The other
respondents endorsed smaller or larger areas. The most popular
definition of Broca's area (endorsed by 50%) was that it consisted of
the pars triangularis and pars opercularis with the remaining 50%
identifying a smaller or larger area. Second, most aphasic patients have
extensive brain damage (Flinker & Knight, 2018). As a result, the role
played by Wernicke's area of Broca's area (however defined) is hard to
establish. However, Flinker et al. (2015) found, by using precisely
targeted electrical stimulation of the cortex, that Broca's area
supports articulatory planning but is not directly involved in
production of spoken words. Third, "The areas of the brain that support
language are far more extensive than Broca or Wernicke could ever have
imagined" (Dronkers et al., 2017, p. 750). As we saw earlier, speech
production involves general processes (e.g., attention; cognitive
control) as well as language-specific processes (McClain & Goldrick,
2018). Language comprehension also involves similar general processes
within a "multiple demand" network including several prefrontal areas
(Blank & Fedorenko, 2017). Fourth, the finding that Broca's patients
find it much harder than Wernicke's patients to speak grammatically is
more common in Englishspeaking than German- or Italian-speaking
patients. English is less inflected than German or Italian (with
inflected languages, grammatical changes to nouns and verbs are
indicated by changes to the words themselves). As a result, the
grammatical limitations of English-speaking patients with Wernicke's
aphasia are less obvious (Dick et al., 2001). Fifth, aphasic patients
may have general problems relating to attention and memory in addition
to specific language impairments (McNeil et al., 2010). For example,
healthy individuals naming pictures rapidly make errors resembling those
of stroke aphasics with semantic impairments (Hodgson & Lambon Ralph,
2008). Thus, picture naming errors by aphasics may partly reflect
reduced processing resources or semantic control. In sum, the
traditional approach is very limited. Accordingly, the emphasis has
shifted towards systematic attempts to understand relatively specific
cognitive impairments (see below).

Anomia Nearly all aphasics (regardless of the type of aphasia) suffer
from anomia (an impaired ability to name objects). Within Levelt et
al.'s (1999) WEAVER++ model, there are two reasons aphasics might have
problems with lexicalisation (translating a word's meaning into its
sound): (1)

(2) 

There could be problems at the semantic level (i.e., selecting the
appropriate lemma or abstract word). In that case, naming errors would
resemble the correct word in meaning. There could be problems at the
phonological level, in which case patients would be unable to find the
appropriate form of the word.

537

KEY TERM Anomia A condition caused by brain damage in which there is an
impaired ability to name objects.

538

Language

KEY TERM

Findings

Phonological output lexicon It contains information about the spoken
form of words (e.g., number of syllables) and is used in object naming
and reading aloud.

Laganaro et al. (2009) divided aphasic patients into semantic and
phonological groups based on their main cognitive impairment on various
tasks. Both groups were then given a picture naming task and
event-related potentials were recorded to assess the time course of
processing. The semantic group had ERP abnormalities early (100--250 ms
after picture onset). In contrast, the phonological group only had later
abnormalities (300--450 ms after picture onset). Thus, anomia can result
from an early semantic stage (finding the correct word) or a later
phonological stage (generating the word's phonological form). Patients
with anomia having problems at the phonological (but not the semantic)
level often resemble healthy individuals in a tip-of-the-tongue state
(discussed earlier, see pp. 531--532). As a result, we might expect such
patients to experience the tip-of-the-tongue state very frequently.
Patients fitting this pattern (and having particular problems in
producing lowfrequency names) have been identified (Funnell et al.,
1996). Gvion and Friedmann (2016) clarified the mechanisms involved in
patients with anomia who have phonological problems. They focused on the
phonological output lexicon, which contains the representation of a
word's spoken form (e.g., number of syllables; consonants; vowels). It
is organised by word frequency so high-frequency words are more
accessible than low-frequency ones. Gvion and Friedmann found several
patients with anomia had an impaired phonological output lexicon.
However, these patients performed well on a word-comprehension task
suggesting their semantic processing was reasonably intact. Nardo et
al. (2018) studied 18 aphasic patients whose comprehension of spoken
words was good. They used a treatment programme focusing on patients'
phonological problems: on a picture naming task, phonemic cues (e.g.,
initial phoneme of the word) were presented. This treatment produced
short-term and long-term improvements in naming ability. Discovering
anomia can result from difficulties at the semantic and/ or phonological
levels is consistent with serial models (e.g., Levelt et al.'s
WEAVER++). However, it does not rule out interactive models (e.g.,
Dell's spreading-activation theory). Soni et al. (2009) compared these
models using a picture naming task in three conditions differing in the
cues accompanying each picture: (1) correct cues (e.g., lion + the cue l
); (2) incorrect cues (e.g., lion + the cue t which misleadingly
suggests tiger): (3) no cue. According to Levelt's model, speakers
determine the lemma (abstract word) appropriate to the object before
using phonological information generated by the cues. Thus, an incorrect
phonological cue should not impair performance. Interactive models make
the opposite prediction. Word selection can be influenced by
phonological activation and this can enhance (or impair) performance
depending on whether the cue is correct or incorrect. The findings
supported interactive models over serial ones. Soni et al. (2011)
extended their research. Aphasics viewed pictures accompanied by a sound
and named the picture. There were four conditions determined by the
relationship between picture and sound. Suppose the picture showed a
candle. The sound could be l (related category -- suggests lamp), w
(associate word -- suggests wax), or neutral (g). Naming

Language production

performance was worse in these conditions than when the sound was k
(suggesting the correct answer). These findings suggest (contrary to
Levelt et al., 1999) that semantic processing is not necessarily
complete before phonological processing starts.

Evaluation Much research on anomia is consistent with Levelt et al.'s
(1999) notion that problems with word retrieval can occur at two
different stages: (1) abstract word (lemma) selection; and (2) accessing
the phonological form of the word. However, there is a potential problem
with that explanation. There is suggestive evidence (Soni et al., 2009,
2011) for more interaction between semantic and phonological processing
than assumed by Levelt et al. (1999).

Agrammatism It is often assumed (e.g., Dell, 1986) that speaking
involves separate stages of working out the syntax or grammatical
structure of utterances and then producing content words to fit that
grammatical structure. Patients who apparently can find the appropriate
words but not order them grammatically suffer from agrammatism
(literally "without grammar"). Such patients produce short sentences
containing content words (e.g., nouns; verbs) but lacking function words
(e.g., the, in, and) and inflections (see Glossary). These omissions are
important. For example, function words play a key role in producing a
grammatical structure for sentences. As we will see, the agrammatic
patients' problems with syntactic processing often extend to language
comprehension as well as speech. Use of the term "agrammatism" implies
it forms a syndrome with all agrammatic patients having the same
symptoms and with the same brain areas involved in most (or all) cases.
It is the case that most agrammatic patients have damage to Broca's area
(BA44/45; see Figure 11.5) (Cappa, 2012). However, agrammatism is not a
syndrome -- many patients possess only some symptoms typical of
agrammatism (Harley, 2013).

Findings Engel et al. (2018) studied language comprehension in patients
with agrammatic aphasia presented with sentences such as: (1) (2)

The grandma said that the baker cleaned herself with a clean washcloth.
The grandma said that the baker cleaned her with a clean washcloth.

The above sentences differ only in that the pronoun in (1) is reflexive
(i.e., herself ) whereas the pronoun in (2) (i.e., her) is not. Healthy
controls had accurate comprehension of both types of sentences on over
90% of trials. In contrast, agrammatic patients performed much worse on
sentences such as (2) (63% vs 90%, respectively). What do the above
findings mean? Sentences such as (2) are slightly more complex
grammatically. Agrammatic patients were considerably

539

KEY TERM Agrammatism Literally, "without grammar"; a condition in which
speech production lacks grammatical structure and many function words
and word endings are omitted; there are often also problems with
language comprehension.

540

Language

more affected by this increased complexity than healthy controls, which
may reflect reduced computational resources in agrammatic individuals.
Faroqui-Shah and Friedman (2015) considered verb tense impairment. It
involves a failure to change the forms of verbs to reflect whether the
reference is to the past, the present, or the future (e.g., omitting -ed
when using a verb in the past tense). Agrammatic individuals had greater
verb tense impairment when the task was more demanding (e.g., picture
description) than when it was less demanding (e.g., grammaticality
judgement). They argued that these findings suggest that agrammatic
individuals have reduced computational resources. Beeke et al. (2007)
studied an agrammatic patient in the laboratory (using artificial tasks)
and while conversing at home. His speech was more grammatical in the
latter situation. Rhys et al. (2013) studied an agrammatic patient who
used prosodic cues (e.g., stress; intonation) to communicate meanings
and grammatical structures despite very limited speech. Christiansen et
al. (2010) also considered whether the deficits of agrammatic patients
are specific to language or whether they are more general. They found
agrammatic patients with damage to Broca's area (BA44/45) showed
impaired sequence learning as well as grammaticality, indicating their
deficits extend beyond language. How can we explain these findings? It
seems reasonable that a deficit in sequence learning could lead to the
production of ungrammatical sentences given the great dependence of
grammaticality on appropriate word order. Uddén et al. (2017) produced
further evidence for the role of Broca's area in sequence learning.
Transcranial magnetic stimulation (TMS; see Glossary) applied to that
area indicated it plays a causal role in sequence learning. Griffiths et
al. (2013) shed light on brain pathways involved in syntactic
processing. They studied patients with damage to a dorsal pathway
connecting part of Broca's area (BA44) with part of Wernicke's area
(middle temporal gyrus) and/or a ventral pathway connecting another part
of Broca's area (BA45) with Wernicke's area. Participants listened to
sentences (e.g., "The woman is hugged by the man") and then selected a
drawing: (1)

Figure 11.6 Semantic errors (left) and syntactic (right) errors made by:
healthy controls and patients with no damage to the dorsal (D) or
ventral (V) pathway, damage to the ventral pathway only, damage to the
dorsal pathway only and damage to both pathways. From Griffiths et
al. (2013). By permission of Oxford University Press.

Language production

the correct one; (2) a syntactic distractor (e.g., a woman hugging a
man); or (3) a semantic distractor (e.g., a man painting a woman). What
did Griffiths et al. (2013) find? Patients with damage to either or both
pathways made many more syntactic errors than controls or patients with
damage to neither pathway (see Figure 11.6). However, very few semantic
errors were made by any of the patient groups and the same was true on
other semantic comprehension tasks.

Evaluation Research on agrammatism can be related to Dell's (1986)
identification of four levels (semantic; syntactic; morphological; and
phonological) of speech production. More specifically, agrammatics
primarily have problems at the syntactic level at which the grammatical
structure of a sentence is formed (Dell, 1986). Of theoretical
importance, there is accumulating evidence that agrammatic individuals
have general deficits as well as language-specific ones. For example,
they have impaired sequence learning and reduced processing or
computational resources. What are the limitations of research on
agrammatism? First, the symptoms of agrammatic patients are too diverse
for it to form a syndrome. Second, agrammatic patients may possess more
grammatical competence than generally assumed. Third, more research is
required to establish the extent to which agrammatism involves
language-specific deficits versus more general ones.

Jargon aphasia Jargon aphasia "is an extreme form of fluent aphasia in
which syntax is primarily intact, but speech is marked by gross
word-finding difficulties" (Harley, 2013). This pattern is superficially
the opposite to that of patients with agrammatism, who can find the
correct content words but cannot produce grammatically correct
sentences. Jargon aphasics often produce jargon (including neologisms,
which are made-up words, and real words unrelated phonologically to the
target word). Finally, jargon aphasics have deficient self-monitoring --
they are generally unaware their speech contains numerous errors and
become irritated when others fail to understand them. Here is how a
jargon aphasic described a picture (Sampson & FaroquiShah, 2011):

It's not a large house, it's small, unless an awful lot of it goes back
behind the hose. They are whiking what they are doing in the front part
which must be peeving . . . leeling . . . weeding . . . there is a
nicoverit spotole for the changer.

Findings How grammatical is the speech of jargon aphasics? If they
engage in syntactic processing, their neologisms or made-up words might
possess appropriate prefixes or suffixes to fit the structure of the
sentences in which they

541

KEY TERMS Jargon aphasia A brain-damaged condition in which speech is
reasonably correct grammatically but there are severe problems in
accessing the appropriate words. Neologisms Made-up words produced by
patients suffering from jargon aphasia.

542

Language

appear. Jargon aphasics generally modify their neologisms in this way
(Butterworth, 1985). What factors determine the specific form of jargon
aphasics' neologisms? First, and of most importance, they exhibit a
failure of phoneme selection even when the appropriate target word is
initially selected. For example, Olson et al. (2015) studied three
jargon aphasic patients who performed naming, repetition, and reading
tasks. More specifically, the phonemes from target words were often only
weakly activated and so were outcompeted by non-target phonemes. These
non-target phonemes were often phonologically related to target phonemes
or were phonemes used recently. Pilkington et al. (2017) analysed the
neologisms produced by 25 patients with jargon aphasia. Those produced
by 23 of these patients were related phonologically to the target
(intended) word. These findings also indicate a major role for deficient
phonological encoding in the production of neologisms. If impaired
phoneme selection is responsible for patients' impaired speech
production, therapy designed to enhance phonemic processing might prove
beneficial. Bose (2013) found that therapy focused on generating and
analysing phonological features of words reduced the number of
neologisms produced by FF, a man with jargon aphasia. Second, deficient
self-monitoring plays a major role in jargon aphasia. Sampson and
Faroqui-Shah (2008) obtained a negative correlation between
self-monitoring and the production of jargon in jargon aphasics. Eaton
et al. (2011) studied a male jargon aphasic (TK) over a 21-month period.
His improved word naming performance over time correlated highly with
increased self-monitoring suggesting inadequate self-monitoring played a
role in TK's initially poor performance. Third, the production of jargon
by jargon aphasics is sometimes influenced by impaired general cognitive
abilities. For example, Robinson et al. (2015) studied a male jargon
aphasic (JA) who produced almost meaningless sentences. He had impaired
cognitive control and so he had no "brake" inhibiting production of
meaningless phrases.

Evaluation Several factors responsible for jargon aphasics' production
of neologisms and other jargon have been identified. Impaired phoneme
selection is typically of most importance. Some evidence indicates that
jargon aphasics often have impaired cognitive or inhibitory control
(linked to deficient self-monitoring) as well as more language-specific
deficits. A limitation of much research is that insufficient attention
has been paid to possible semantic deficits in addition to problems with
phoneme selection (Harley, 2013). More research is also needed to assess
more precisely the grammaticality (or otherwise) of jargon aphasics'
spoken utterances.

Conclusions Most theories of speech production are based on the
assumption, "There are independent levels of representation/processing
that encode word meaning

Language production

(semantics), word form (phonology), and grammatical structure (syntax)"
(McClain & Goldrick, 2018, p. 398). The evidence based on brain-damaged
patients provides support for this overarching assumption. In this
section, we have focused on the patterns of language impairment in
patients categorised as suffering from anomia, agrammatism or jargon
aphasia. Such categorisations mistakenly imply all patients assigned to
a given category have very similar language impairments. Mirman et al.
(2015) avoided the use of categories. They used several tasks to assess
various aspects of word recognition and production in 99 aphasic
patients and also assessed the brain areas damaged in those patients.
Mirman et al. (2015) used a statistical technique known as factor
analysis to identify the major components underlying patients' patterns
of impaired language performance. There was a major division between
semantic and phonological processing and each form of processing was
subdivided into language perception and language production. In future,
this approach could potentially allow us to move away from an
overreliance on categories or syndromes to a focus on similarities and
differences among aphasic. Another general conclusion is that the
speech-production problems of many aphasics (e.g., agrammatic
individuals; jargon aphasics) depend in part on general cognitive
processes as well as on language-specific ones. Evidence that general
cognitive processes are important in the speech production of healthy
individuals was reported by Zhang et al. (2018) using a picture naming
task. Their key finding was that successfully coping with increased task
difficulty involved additional activation in language-specific brain
areas and general cognitive control (e.g., inhibition) areas. The role
of general processes in language processing is discussed further in the
introductory section entitled Part III: Language.

SPEECH AS COMMUNICATION Most theories and research discussed so far
focus on monologue. In the real world, however, our speech nearly always
occurs as conversation in a social context. Dialogue involves various
complexities: "Both interlocutors \[individuals involved in a
conversation\] must simultaneously produce their own contributions and
comprehend the other's contribution" (Pickering & Garrod, 2013, p. 330).
Thus, as discussed earlier, speech production and speech comprehension
are interwoven (Meyer et al., 2016). Grice (e.g., 1975) considered the
requirements of successful communication in his cooperative principle:
"Make your conversational contribution such as is required . . . by the
accepted purpose or direction of the talk exchange in which you are
engaged" (Grice, 1989, p. 88). Grice's use of the term "cooperation" was
narrower than its common usage (Davies, 2007). It should be seen in the
context of his four maxims speakers should heed: ●

● ●

Maxim of relevance: the speaker should say things relevant to the
situation. Maxim of quantity: the speaker should be as informative as
necessary. Maxim of quality: the speaker should be truthful.

543

544

Language

Figure 11.7 A sample array with six different garments coloured blue or
green. From Tarenskeen et al. (2015).

●

Maxim of manner: the speaker should make their contribution easy to
understand.

There are two issues with Grice's approach. First, is unclear we need
four maxims -- the other three maxims are implied by the maxim of
relevance. Second, in the real world, many individuals (e.g., secondhand
car salespersons; politicians) ignore one or more of the maxims out of
self-interest. For example, an analysis of Donald Trump's statements
during 2015 revealed that he lied (failed to adhere to the maxim of
quality) 76% of the time (Holan, 2015). Speakers (even when not guided
by self-interest) often fail to adhere to Grice's four maxims. Suppose a
speaker tries to provide enough information so a listener can identify
the target item of clothing from an array (see Figure 11.7). Speakers
included colour in their statements on 79% of trials even though it was
unnecessary and so represented overspecification not adhering to the
maxim of quantity (Tarenskeen et al., 2015). Tarenskeen et al. (2015)
carried out another experiment that included many trials where it was
necessary for speakers to include colour, pattern or size in their
statements. As a result, each attribute was included in their statements
on 70% or more of trials when it was not necessary. This widespread
overspecification was probably due to the speakers' desire to be
consistent in their statements. In sum, speakers often fail to adhere to
Grice's maxims. However, overspecification (unlike underspecification)
typically has no negative effects on listeners' comprehension and so is
essentially harmless.

Audience design KEY TERM Audience design This involves speakers
tailoring what they say to the specific needs and knowledge of their
audience.

There has been a dramatic increase in research focusing on what speakers
say and how they say it when addressing one or more listeners. Much of
this research focuses on audience design, which "refers to the situation
in which speakers fashion their utterances so as to cater to the needs
of their addressees" (Ferreira, 2019). For example, communication can be
facilitated by establishing and extending common ground (see Chapter 9).

Language production

Common ground consists of "knowledge that is shared with a communication
partner, and that the communication partners know each other know"
(Brown-Schmidt & Duff, 2016, pp. 722--723). Common ground can include
several kinds of information (e.g., objects or events visible to both
partners; shared cultural values; shared experiences). Ferreira (2019)
identified two broad forms of audience design. First, there is a simple
form based on general characteristics of the listener. For example, a
speaker will typically plan shorter and simpler sentences when talking
to a child rather than an adult: this is child-directed speech (see
Glossary). This form of audience design typically makes modest demands
on processing effort. Second, there is a more complex form based on
idiosyncratic characteristics of the listener and/or the context. This
can involve considerable processing effort (e.g., taking full account of
common ground) and alterations to planned utterances (e.g., you are
talking to someone and they start looking at their mobile phone).

Theories Horton and Keysar (1996) proposed their monitoring and
adjustment model to account for speakers' successful (and unsuccessful)
use of common ground. Speakers initially plan their utterances using
information available to them without considering the listener's
perspective or knowledge. These plans are then monitored and corrected
to incorporate common ground. However, it is often computationally hard
for speakers to focus on the listener's perspective while planning what
to say. Accordingly, they often egocentrically focus on their own
perspective and ignore the common ground. Ferreira (2019) developed the
above ideas in his forward modelling approach (see Figure 11.8).
Speakers use their communicative intention (i.e., what they want to say)
to generate utterances (left-hand side of the figure). They also often
produce a forward model (including a model of audience comprehension) to
predict the likely effect on the audience of generating those
utterances. Of crucial importance, if the predictive communicative
effect mismatches the speaker's intent, their message is changed to
reduce the mismatch. This entire process is typically cognitively
demanding and so speakers sometimes lack sufficient resources to produce
a forward model plus a model of audience comprehension. Memory plays an
important role in audience design. For example, Horton and Gerrig (2016)
argued that memory limitations mean speakers sometimes assume less
common ground than is actually the case. Suppose you have told very few
friends about a recent event. As a result, you mistakenly assume the
friend you are talking to does not share that common ground. The
opposite can also happen: you have told nearly all your friends about an
event and mistakenly assume the one with whom you are currently talking
was among them.

Findings Effective use of common ground occurs most often when the
listener's knowledge and needs are readily accessible. Achim et
al. (2017) asked

545

546 Figure 11.8 Architecture of the forward modelling approach to
explaining audience design effects (blue rectangles = representations;
orange ovals = processes).

Language

Communicative intention

Evaluator

Message encoding Executive control

From Ferreira (2019). Message

Forward model Grammatical encoding

Words, structures

Phonetic encoding

Communicatively relevant linguistic features

Predicted communicative eﬀect

Model of audience comprehension Representations

Pre-articulatory utterance

Processes

speakers to introduce and subsequently reintroduce movie characters
likely (e.g., Harry Potter) or unlikely (Martin Riggs) to be known to
the listener. Speakers used each character's name much more often when
introducing and reintroducing known characters. They thus made effective
use of common ground because it was easy. Craycraft and Brown-Schmidt
(2018) tested the hypothesis that speakers only assume they have formed
common ground with listeners when those listeners appear to be
attentive. As predicted, speakers who had communicated information to an
inattentive listener (e.g., glancing repeatedly around the room; pulling
out their mobile phone) did not subsequently assume they shared common
ground with their listener. Thus, speakers are often responsive to the
listener's attentional state. In contrast, Fukumura and van Gompel
(2012) found speakers often ignored listeners' knowledge. Speakers
typically use a noun phrase (e.g., "the red desk") the first time an
object is mentioned but a pronoun (e.g., "it") in the next sentence.
However, it is only appropriate to use a pronoun in the second sentence
provided the listener has heard the previous sentence. In fact, speakers
generally used a pronoun in the second sentence even when the listener
had not heard the previous sentence, thus ignoring audience design.
According to the monitoring and adjustment model and Ferreira's (2019)
forward modelling approach, it is often cognitively demanding to take
account of the listener's perspective. Accordingly, we might expect
speakers with superior cognitive abilities to make more use of common
ground. As predicted, Long et al. (2018) found that speakers high in the
executive functions of inhibition and switching (see Chapter 6) used
common ground more often than low scorers.

Language production

Further evidence that cognitive demands are important in determining
whether speakers take account of the common ground they share with their
listener was reported by Horton and Keysar (1996). Speakers took less
account of common ground when they spoke under time pressure than when
they had as much time available as they wanted. According to Horton and
Gerrig (2016; mentioned earlier, p. 545), speakers' memory failures
often cause errors in the use of common ground. Empirical support was
obtained previously by Horton and Gerrig (2005), who analysed numerous
spontaneous telephone conversations. Here is an example of a speaker
assuming too little common ground: A: B:

This one guy with- who was like a a fresh br- breeze blown through the
factory uh uh uh twenty-four twenty-five-year-old guy Oh, yeah you
mentioned him. \[p. 19\]

Here is an example of a speaker assuming too much common ground: A: B:

Yeah okay. I told you about the shampoo did I tell you? What shampoo no.
\[p. 19\]

This example is especially interesting because it suggests the speaker
was monitoring the accuracy of their memory and begins to doubt its
accuracy. Rubin et al. (2011) obtained strong evidence of the importance
of memory. Amnesic patients with severely impaired episodic memory (see
Glossary) made far less use of information about common ground than
healthy controls. However, amnesic patients made reasonably effective
use of common ground when the relevant information was readily
available. Further evidence that amnesic speakers can often communicate
effectively despite their memory problems was reported by Yoon et
al. (2017). Amnesic speakers provided shorter descriptions of objects to
listeners to whom they had previously described those objects than to
new listeners. Thus, they were sensitive to the presence or absence of
common ground with their listener. This happened because the amnesic
speakers could identify the listener as new or old. Finally, speakers
use various simple and relatively effortless strategies to facilitate
communication. One example is syntactic priming (copying a previously
heard syntactic structure; see p. 518). Jaeger and Snider (2013) found
speakers were most likely to show syntactic priming when the last
sentence they heard contained an unexpected syntactic structure.
Speakers strive to "get on the same wavelength" as the person with whom
they are speaking and this helps to achieve that goal.

Gesture Most speakers use gestures. It is generally assumed they do this
because they believe it increases their ability to communicate with
their listener(s). This belief is correct (see Chapter 9). Human
communication probably depended on gestures in our ancestral past and it
was only much later that vocalisation emerged. The fact

547

548

Language

that primate gestures resemble human language much more closely than do
primate vocalisations supports that viewpoint (Cartmill et al., 2012).
It seems reasonable to assume speakers use gestures more often when they
can see the person to whom they are speaking. Surprisingly, this finding
has been obtained in only 50% of studies (Bavelas & Healing, 2013). Why
do speakers use gestures that cannot be seen by their listeners?
Gestures make it easier for speakers to communicate effectively.
FrickHorbury and Guttentag (1998) presented participants with the
definitions of relatively uncommon words (e.g., tambourine) and asked
them to say the word defined. When it was hard to use gestures, speakers
produced 21% fewer words than when they were free to use gestures.
Gerwing and Allison (2011) asked speakers to describe an elaborate dress
to a visible or non-visible listener. The number of gestures was
comparable in both conditions. However, speakers' gestures were much
more informative in the face-to-face situation. In that situation, 74%
of the information communicated was via gestures and only 26% via
speech. In contrast, only 27% of the information communicated in the
telephone situation was gestural. Gestures are often modified to take
account of the common ground between speakers and listeners. Hilliard
and Cook (2016) used a task where speakers communicated information
about how to solve a complex problem. When the common ground between
speakers and listeners was limited, speakers used more informative
gestures than when the common ground was more extensive. However,
speakers' spoken language was not influenced by the extent of common
ground. Gesture and speech provide a unified system for communication
and so either gesture or speech can be modified to take account of
common ground. How responsive are speakers to listeners' feedback?
Holler and Wilkin (2011) compared speakers' gestures before and after
listener feedback. There were two main findings: (1) (2)

The number of gestures reduced when the listener indicated understanding
of what had been said. Feedback encouraging clarification, elaboration
or correction was followed by more precise, larger or more visually
prominent gestures.

In sum, gestures are an important accompaniment to speech. Speakers use
gestures because they make it easier to work out what they want to say,
In addition, the fact that speakers are responsive to listeners' needs
(including the feedback they provide) means gestures facilitate
communication (see Chapter 9).

Prosodic cues Some information communicated by speakers to listeners
does not depend directly on the words themselves but rather on how those
words are uttered. This is prosody, which describes "systematic
modifications to the way that speakers utter words in order to specify
or disambiguate the meaning of an utterance" (Cvejic et al., 2012,
p. 442).

Language production

Prosodic cues include rhythm, stress and intonation. For example, in the
ambiguous sentence, "The old men and women sat on the bench", the women
may be or may not be old. If the women are not old, the spoken duration
of the word "men" should be relatively long and the stressed syllable in
"women" will have a steep rise in pitch contour. Neither prosodic
feature will be present if the sentence means the women are old.
Evidence that listeners' comprehension of speech is enhanced by prosodic
cues is discussed in Chapter 9. Gueliaï et al. (2014) found gestures
accompanying speech carry prosodic information. When listeners heard
ambiguous sentences with a mismatch between the prosodic cues in the
speech and the gestures, listeners more often understood these sentences
in line with the gestural information.

Discourse markers Speakers can also enhance listener comprehension by
using discourse markers. Discourse markers are words or phrases
assisting communication even though they are only indirectly relevant to
the speaker's message. Among the ways they do this are by expressing the
speaker's attitude and facilitating turn-taking in conversations (Hata,
2016). Speakers use the discourse marker you know, for example, to check
whether listeners understand them and to connect with them. We are often
unaware of the reasons why we use various discourse markers. For
example, what determines whether you say oh or so when moving on to a
new conversational topic? Bolden (2006) found oh was used 98.5% of the
time when the new topic directly concerned the speaker. In contrast, so
was used 96% of the time when the new topic was of most relevance to the
listener. In sum, discourse markers often make it easier for listeners
to understand speakers' intended meanings. However, we can also consider
discourse markers in the context of disfluencies (e.g., pauses;
repetitions). Crible (2017) analysed 15 hours of speech containing a
total of 161,700 words and found frequent clusters including
disfluencies and discourse markers. She concluded that discourse markers
are often simply disfluencies.

WRITING: THE MAIN PROCESSES Writing is an important topic in its own
right (no pun intended!). However, it is not separate from other
cognitive activities. As Kellogg and Whiteford (2012, p. 111) pointed
out, Composing extended texts is . . . a severe test of memory,
language, and thinking ability. It depends on the rapid retrieval of
domainspecific knowledge about the topic from long-term memory. It
depends on a high degree of verbal ability . . . It depends on the
ability to think clearly. Unsurprisingly, writing ability is positively
correlated with several aspects of cognitive ability (e.g., fluid
reasoning ability) (Cormier et al., 2016).

549

KEY TERMS Prosodic cues Features of spoken language such as stress,
intonation, pauses and duration making it easier for listeners to work
out grammatical structure and meaning; similar cues are often present in
texts (e.g., commas; semi-colons). Discourse markers Spoken words and
phrases that do not contribute directly to the content of what is being
said but still serve various functions (e.g., clarifying the speaker's
intentions).

Research activity: Discourse markers

550

Language

IN THE REAL WORLD: EFFECTS OF ALZHEIMER'S DISEASE ON NOVEL WRITING We
saw earlier that mild cognitive impairment (often a precursor to
Alzheimer's disease -- see Glossary) is associated with various problems
in speech production. In view of the cognitive complexities of effective
writing, it seems probable mild cognitive impairment would also impair
writing performance. Research has been carried out on Iris Murdoch
(1919--1999), the renowned Irish novelist who was diagnosed with
Alzheimer's disease. Garrard et al. (2005) compared her first published
work, a novel written during her prime, and her final novel. Iris
Murdoch's vocabulary became less sophisticated (e.g., smaller
vocabulary; more common words) across these three works but changes in
syntax were less clear- Iris Murdoch, the Irish novelist. cut.
Subsequent research by Pakhomov et al. Ulf Andersen/Getty Images. (2011)
showed the syntactic complexity of Iris Murdoch's writing decreased over
time. Thus, aspects of Iris Murdoch's writing were adversely affected
several years before she was diagnosed with Alzheimer's disease during a
period in which she probably had mild cognitive impairment. Le et
al. (2011) carried out a detailed longitudinal analysis of the writings
of Iris Murdoch, Agatha Christie (suspected of having Alzheimer's
disease towards the end of her life) and P.D. James (a novelist with no
signs of cognitive impairment or Alzheimer's disease). They confirmed
previous findings that there were signs of impairment in Iris Murdoch's
writing a considerable time before she was diagnosed with Alzheimer's
disease. Le et al. (2011) claimed Agatha Christie's last novels
indicated she probably suffered the onset of Alzheimer's disease. The
writing impairments of Agatha Christie and Iris Murdoch both involved
vocabulary much more than syntax. More specifically, they both showed a
sharp decrease in vocabulary size, increased repetition of phrases, and
irrelevant filler words or phrases. Van Velzen et al. (2014) reported a
detailed comparison of the writings of Iris Murdoch and Agatha Christie
focusing on their lexical diversity (richness of vocabulary). Iris
Murdoch had a much earlier and more sudden reduction in lexical
diversity than Agatha Christie. They concluded Agatha Christie did not
have Alzheimer's disease but rather some other neurodegenerative
condition. In contrast, P.D. James showed only marginal writing
impairments in old age due to normal ageing. In sum, there are
detectable impairments in the writing of novelists probably suffering
from mild cognitive impairment. These impairments can provide an early
indication of Alzheimer's disease (or other neurodegenerative diseases),
and probably reflect in part the cognitive complexity of writing.
However, even the onset of Alzheimer's disease has only modest effects
on syntax. Thus, cognitive impairment affects the content of what is
written more than its grammatical structure.

Language production

Key processes Writing extended texts involves several processes. In
spite of minor disagreements about the number and nature of these
processes, most theorists agree with Hayes and Flower (1986) that
writing involves the following three processes: (1) (2) (3)

A planning process which involves producing ideas and organising them to
satisfy the writer's goals. A sentence-generation process which involves
turning the writing plan into the actual production of sentences. A
revision process which involves evaluating what has been written or word
processed so far and changing it when necessary.

Chenoweth and Hayes (2003) developed the above approach. Their model
identifies four processes: (1) (2) (3) (4)

Proposer: it proposes ideas for expression and is engaged in
higher-level planning processes. Translator: it converts the message
formed by the proposer into word strings (e.g., sentences). Transcriber:
it converts the word strings into written or word processed text.
Evaluator/reviser: it monitors and evaluates what has been produced and
engages in revision of deficiencies.

The main difference between the two approaches described above is that
Chenoweth and Hayes (2003) added a transcriber. Why did they do that?
Hayes and Flower assumed transcribing (writing sentences already
composed) requires minimal processing resources and so had no impact on
other writing processes. However, that assumption is incorrect. Hayes
and Chenoweth (2006) asked participants to transcribe or copy texts from
one computer window to another. They transcribed more slowly when
performing a very simple task (saying tap repeatedly) at the same time.
Tindle and Longstaff (2016) found the task of writing down heard words
utilised working-memory resources. The latest version of the above
writing model (Hayes, 2012; shown in Figure 11.9) incorporates the four
writing processes identified by Chenoweth and Hayes (2003). However, it
is more comprehensive because the process level has been expanded to
include the task environment and there are additional control and
resource levels. Of importance, the current version includes motivation
as a factor. Writing effectively is so demanding (as the authors of this
book know to their cost!) that high motivation is required to engage in
prolonged evaluation and revision of what has been written. There is a
final point. The "natural" sequence of the four main writing processes
is as follows: proposer; translator; transcriber; and evaluator. As we
will see, however, writers surprisingly often deviate from this
sequence, switching rapidly between processes.

551

552

Language

Figure 11.9 Hayes' (2012) writing model. It consists of three levels:
(1) control level (including motivation and goal setting); (2) writing
process level (including proposer, evaluator, translator and
transcriber); and (3) resource level (including working memory,
attention and long-term memory). From Hayes (2012). Reprinted by
permission of SAGE Publications.

Findings

KEY TERM Directed retrospection A technique in which individuals (e.g.,
writers) categorise their immediately preceding thoughts.

Pauses account for over half of writing time. Medimorec and Risko (2017)
analysed the pause data of students writing narrative essays (about a
memorable day) and argumentative essays (about mobile-phone use in
schools). Pauses occurred most often at paragraph boundaries, followed
by sentence boundaries, suggesting they often indicate planning
processes. Limpo and Alves (2018) studied key aspects of writing
dynamics using the triple-task technique. Participants engaged in
writing an argumentative text (about controversial university initiation
rites) were asked to respond as rapidly as possible to occasional
auditory beeps. After they had responded, they indicated which writing
process they had just been using: planning, translating or revising.
This is known as directed retrospection. What did Limpo and Alves (2018)
find? First, time spent on planning reduced during the course of writing
(see Figure 11.10). Second, the time spent on the revising process
increased over time. Third, all three writing processes (i.e., planning,
translating and revising) occurred during all phases of the writing
process. Fourth, reaction times to the occasional beeps were slowed most
during revising and least during translating. These findings indicate
that revising was the most cognitively demanding process, followed by
planning and translating in that order. Beauvais et al. (2011) found
writers switched rapidly between different processes: 8 times a minute
with narrative texts (telling a story) and 6 times a minute with
argumentative texts (discussing ideas). Each episode of translating
lasted on average 16 seconds (narrative text) or 17 seconds
(argumentative text), planning 8 seconds (narrative text) or 12 seconds
(argumentative text), and revision (4 seconds for both texts). Thus, as
Levy and Ransdell (1995) found, episodes of planning and revising were
shorter than translating or text generation.

Language production

Figure 11.10 The frequency of three major writing processes (planning,
translating and revising) across the three phases (thirds) of writing.

No planning

9

Number of occurrences

8 7 6 5

Planning

4

Translating

3

Revising

2 1 Phase 1

Phase 2

553

Phase 3

Writing phase

How do writers make decisions about switching processes? Hayes and
Flower (1980) argued writers have a monitor (closely resembling the
central executive component of the working memory model: see Chapter 6)
controlling their processing activities. Two functions of the central
executive are to switch attention between tasks and to inhibit unwanted
responses. If the monitor requires working memory resources, it should
be less likely to trigger a switch in the current task when current
processing demands are high. Quinlan et al. (2012) tested this
assumption. Writers chose whether to complete a sentence before
correcting an error or to interrupt sentence composing to focus on the
error. Nearly all participants completed the sentence first (especially
when total processing demands were high).

Evaluation Processes such as planning, sentence generation and revision
are all crucial in writing. However, they cannot be neatly separated
because writers typically move rapidly between them. Writers probably
possess a monitor initiating processing shifts when overall processing
demands are relatively low. What are the limitations of research in this
area? First, the factors determining when writers shift processes are
mostly unknown. Second, the social aspect of writing (i.e., taking
account of the intended readership of written texts) is often
de-emphasised (see below). Third, the ways writing processes interact
are not specified with precision. For example, Hayes (2012; Figure 11.8)
failed to indicate how the four resources relate to writing processes.

Individual differences in writing: development of expertise Why are some
writers more skilful than others? As with any complex cognitive skill,
extensive deliberate practice is essential (see Chapter 12). In the next
section, we will see the working memory system (see Chapter 6)

From Limpo and Alves (2018). Reprinted with permission of Elsevier.

554

Figure 11.11 Kellogg's three-stage theory of the development of writing
skill. From Kellogg (2008). Reprinted with permission of the Journal of
Writing Research www.jowr. org.

Language

is very important. All its components have limited capacity. However,
the demands of writing on these components decrease with practice, which
provides experienced writers with spare processing capacity to enhance
their writing quality. Writing expertise often depends on reading
ability. Berninger and Abbott (2010) assessed the four main language
skills in children. Overall, writing performance was predicted best by
reading comprehension, followed by speech production and then speech
comprehension. Kent and Wanzek (2016) conducted a meta-analysis, also
finding reading comprehension predicted writing quality better than did
speech-production ability. How can we explain the above findings?
Reading allows writers to learn much about the structure and style of
good writing; it also enhances their vocabulary and knowledge. However,
most evidence is correlational and so does not prove writing ability is
caused by reading comprehension. For example, writing expertise may
enhance reading comprehension skills. Bereiter and Scardamalia (1987)
identified two major strategies writers use. First, there is the
knowledge-telling strategy: writers simply write down all they know
about a topic with minimal planning. Second, the more complex
knowledge-transforming strategy involves working out how to achieve the
writing goals and how to decide on the specific information to write
down. Optimal use of this strategy involves moving backwards and
forwards between these two aims. Kellogg and Whiteford (2012) developed
the above approach (see Figure 11.11). They argued that really expert
writers move beyond the knowledge-transforming strategy by using a
knowledge-crafting strategy.

Language production

With this strategy "The writer shapes what to say and how to say it with
the potential reader fully in mind. The writer tries to anticipate
different ways that the reader might interpret the text and takes these
into account in revising it" (Kellogg & Whiteford, 2012, p. 116). One
reason why knowledge crafting is important is because of the knowledge
effect -- writers often assume other people share the knowledge they
possess. Hayes and Bajzek (2008) found individuals familiar with
technical terms greatly overestimated other people's knowledge of these
terms (are the authors of this book guilty of this?).

555

KEY TERM Knowledge effect The tendency to assume others possess the same
knowledge as us.

Findings The knowledge-transforming strategy is effective for various
reasons. Writers using this strategy produce more high-level main points
capturing important themes (Bereiter et al., 1988) and show more
extensive interactions between planning, language generation and
reviewing. This strategy is used more effectively if writers enhance
their relevant knowledge prior to writing an essay (Chuy et al., 2012).
The resultant essays were more coherent and easier to read. Expert
writers spend more time revising than non-expert ones. Levy and Ransdell
(1995) found writers producing the best essays spent 40% more time
reviewing and revising their essays than those producing the worst
essays. In addition, expert writers detect many more problems in a text
than non-experts (Hayes et al., 1985). Evidence that knowledge-crafting
skills are important was reported by Karlen (2017). Students were
required to write an academic paper. Those possessing the most knowledge
about how to craft texts made greatest use of knowledge-crafting
strategies while writing and this in turn enhanced the quality of their
writing. Knowledge-crafting skills can be trained. For example,
responsiveness to the reader's needs can be improved by providing
writers with feedback from readers about comprehension problems they had
experienced (Sato & Matshushima, 2006). Wischgoll (2016) found students
developing their knowledge-crafting skills by a meta-cognitive strategy
(e.g., "Can I comprehend my text if I read it from the reader's
perspective?", p. 7) showed greater enhancement of their writing skills
than those using other strategies. Finally, the requirements of expert
writing depend on the type of text (e.g., an advanced textbook vs a
children's story). Beauvais et al. (2011) found moderately expert
writers engaged in more knowledge-telling when producing narrative
rather than argumentative texts. However, the opposite was the case for
knowledge-transforming. In other words, the writers tailored their
writing behaviour to the requirements of the type of text they were
producing.

Working memory Most people find writing difficult and effortful because
it involves several different cognitive processes (e.g., attention;
thinking; memory). Several theorists have argued writers make extensive
use of working memory to deal with these complexities. This argument was
supported by Tindle and

Research activity: Knowledge telling

556

Language

Case study: Working memory components

Longstaff (2015). They found writing made more demands on working memory
than reading or listening. Working memory is used when a task requires
temporary storage of some information while other information is
processed (see Chapter 6). That is clearly the case with writing --
writers have to remember what they have just written while planning what
they are going to write next. The key component of the working memory
system is the central executive (see Glossary), an attention-like
process involved in organising and coordinating cognitive activities.
Other components of the working memory system are the visuo-spatial
sketchpad (involved in visual and spatial processing) and the
phonological loop (involved in verbal rehearsal). All these components
have limited capacity. This can easily cause problems with the writing
process, which is often very cognitively demanding. All components of
working memory are involved in writing. Kellogg (2001) linked these
components to five processes involved in writing (see Table 11.1). These
processes overlap with those identified by Chenoweth and Hayes (2003;
described earlier, pp. 551--552). Planning corresponds to the proposer,
translating to the translator, programming is part of the transcriber,
and reading and editing together relate to the evaluator/reviser
(reading involves going back over what has been written so far). Kellogg
et al. (2013) reconsidered the information contained in Table 11.1 and
decided the phonological loop is actually involved in the editing
process. Research by Hayes and Chenoweth (2006; discussed earlier,
p. 551) showed error correction while copying text was slowed down when
the phonological loop was required for another task.

Findings As you can see in Table 11.1, Kellogg (2001) assumed writing
performance depends more on the central executive than any other working
memory component. We can assess its involvement by measuring reaction
times to auditory beeps presented in isolation (control condition) or
while people are engaged in writing. If writing uses much of the central
executive's capacity, reaction times should be longer during writing. In
a study discussed earlier (Limpo & Alves, 2018), planning, translating
and revising all slowed reaction times (especially planning).

TABLE 11.1 INVOLVEMENT OF WORKING MEMORY COMPONENTS IN VARIOUS WRITING
PROCESSES Process

Visuo-spatial sketchpad

Central executive

Phonological loop

Planning

yes

yes

--

Translating

--

yes

yes

Programming

--

yes

--

Reading

--

yes

yes

Editing

yes

--

--

Source: Based on Kellogg (2001).

Language production

The role of the central executive can also be assessed using an
individual differences approach. Vanderberg and Swanson (2007) adopted
this approach. Students wrote stories and their performance was divided
into general skills (e.g., planning, translating, revision) and specific
skills (e.g., grammar, punctuation). Individuals having the most
effective central executive functioning exhibited the greatest general
and specific skills. In contrast, individual differences in the
functioning of the visuo-spatial sketchpad and phonological loop did not
influence performance. Guan et al. (2014) studied the effects of
individual differences in working memory capacity (an approximate
measure of central executive functioning; see Glossary). Essay-writing
quality was predicted by working memory capacity. In similar fashion,
Van der Steen et al. (2017) found students high in working memory
capacity produced more complex essays than low-capacity individuals.
Another approach is to study brain-damaged individuals with impaired
central executive functioning suffering from dysexecutive syndrome (see
Glossary; and Chapter 6). Many patients with dysexecutive syndrome have
difficulties planning and organising their ideas on writing tasks and in
maintaining attention (Ardila & Surloff, 2006). Ardila and Surloff
coined the term dysexecutive agraphia to refer to such patients. Sitek
et al. (2014) studied four patients with dysexecutive agraphia who had
dementia causing severe cognitive impairment. Progressive deterioration
in their writing skills was closely linked to more general cognitive
impairment. What role does the phonological loop play in writing? We can
address this question using an articulatory suppression task (e.g.,
saying the the the repeatedly) while individuals are engaged in a
writing task. Articulatory suppression tasks use the resources of the
phonological loop and so impair performance on other concurrent tasks
requiring the phonological loop. Articulation suppression causes writers
to produce shorter sequences of words (suggesting it suppresses their
"inner voice"; Chenoweth & Hayes, 2003); it also slows down transcribing
or copying texts (Hayes & Chenoweth, 2006). Finally, Colombo et
al. (2009) found articulatory suppression impaired writers' ability to
produce the component parts of multi-syllable words in the correct
serial order. The above findings strongly suggest the phonological loop
is often used during writing. However, we must not exaggerate its
importance. Some patients with a severely damaged phonological loop
nevertheless have essentially intact written language (Gathercole &
Baddeley, 1993). What role does the visuo-spatial sketchpad play in
writing? Relevant research was reviewed by Olive and Passerault (2012).
Bourke et al. (2014) found individual differences in visuo-spatial
working memory predicted children's spelling and writing ability.
Kellogg et al. (2007) asked students to write descriptions of concrete
(e.g., house) and abstract (e.g., freedom) nouns while detecting visual
stimuli. The writing task slowed detection times only when concrete
words were being described, indicating the visuo-spatial sketchpad is
more involved when writers think about concrete objects. Somewhat
separate visual and spatial processes occur within the visuo-spatial
sketchpad (see Chapter 6). Are both processes involved in writing? Olive
et al. (2008) asked students to write a text while performing a visual
or spatial task and discovered the answer is "Yes".

557

KEY TERM Dysexecutive agraphia Severely impaired writing abilities in
individuals with damage to the frontal lobes whose central executive
functioning is generally impaired.

558

Language

Evaluation The main writing processes are very demanding and effortful
and impose substantial demands on working memory (see Olive, 2012, for a
review). Individuals with high working memory capacity have good general
and specific writing skills. The central executive is heavily involved
in most writing processes. There is also convincing evidence the
visuo-spatial sketchpad and phonological loop are both involved in the
writing process. The visuospatial sketchpad is involved in planning and
editing, and the phonological loop seems to be of relevance to various
writing processes. What are the limitations of theory and research on
working memory in writing? First, we do not know precisely why planning,
sentence generation and revising are so demanding of processing
resources. Second, there is little understanding of the role of working
memory in influencing when and why writers shift from one writing
process to another. However, switching of processes may be less likely
when total working memory demands are high (Quinlan et al., 2012).
Third, working memory (and other) processes are used flexibly and in
parallel (i.e., at the same time) in writing (Olive, 2014). However, the
factors determining when and how these processes are used in parallel
(and how they interact with each other) remain unclear. Fourth, most
research has been based on Baddeley's working memory model with other
approaches (e.g., theories based on working memory capacity; see Chapter
6) receiving little attention. These other approaches could potentially
enhance our understanding of the processes underlying writing
performance.

Word processing Goldberg et al. (2003) carried out meta-analyses to
compare writing performance when students used word processors or wrote
in longhand. They concluded as follows: "Students who use computers when
learning to write are not only more engaged in their writing but they
produce work that is of greater length and higher quality" (Goldberg et
al., 2003, p. 1). Van der Steen et al. (2017) found students wrote
faster and produced essays of higher quality when using word processing
rather than writing by hand. Why was this? Students spent more time
pausing in the word processing condition, and pausing was associated
with more revision and thinking. Are there any disadvantages associated
with word processing? Kellogg and Mueller (1993) found word processing
involves more effortful planning and revision (but not sentence
generation) than writing in longhand. Those using word processors were
much less likely to make notes (12% vs 69%, respectively), which may
explain the findings.

SPELLING Spelling is an important aspect of writing. Brain areas
involved in spelling were identified by Planton et al. (2013; see Figure
11.12) in a meta-analytic review. Three main areas were consistently
activated during handwriting tasks:

Language production

559

Figure 11.12 Brain areas activated during handwriting tasks, controlling
for verbal or linguistic input (red) or motor output (green). The areas
in yellow are controlled for both and so provide an indication of
handwriting-specific brain regions. IPS, intraparietal sulcus; SPL,
superior parietal lobe; SFS, superior frontal sulcus; post CB, posterior
cerebellum. From Planton et al. (2013). Reprinted with permission from
Elsevier.

(1) 
(2) 
(3) 

Intraparietal sulcus and superior parietal lobule in the left
hemisphere: this area is involved in the selection and/or representation
of letter shapes. Superior frontal sulcus in the left hemisphere: this
area seems to be the interface between abstract letter combinations and
the generation of motor commands. Posterior cerebellum in the right
hemisphere: this area is probably most involved in motor activity.

Planton et al. (2017) discovered most of these areas were also activated
when participants drew shapes or spelled out object names orally. Thus,
they are not specialised for writing.

Dual-route theory Several theorists (e.g., Hepner et al., 2017) have
proposed versions of the dual-route theory for understanding the
processes involved in spelling (see Figure 11.13(b)): ●

●

●

The most important assumption is that there are two main routes between
hearing a word and spelling it: (1) the lexical route (left-hand side of
the figure); (2) the non-lexical route (right-hand side of the figure).
The lexical route involves accessing word sounds in phonological
long-term memory followed by accessing word meanings in the lexical
semantic system and word spellings in orthographic long-term memory. It
is the main route we use with familiar words regardless of whether the
relationship between sounds (phonemes) and spellings (orthography) is
regular (e.g., cat) or irregular (e.g., yacht). The non-lexical route
does not involve gaining access to detailed information about the sound,
meaning and spelling of heard words. Instead, it uses rules to convert
sounds or phonemes into groups of

Case study: Differences in spelling ability

Language

Figure 11.13 The cognitive architectures for (a) reading and (b)
spelling.

(a) 
(b) 

Letter identification processes Orthographic working memory

From Hepner et al., 2017).

Lexical route

Spelling-to-sound conversion system

Phonological longterm memory

Phonological working memory

Phonological longterm memory Lexical semantic system Orthographic
longterm memory

Orthographic working memory

Graphic motor plan selection

●

KEY TERMS Orthographic working memory (also known as the graphemic
buffer) A store in which information about the individual letters in a
word (and their ordering) is held immediately prior to spelling the
word. Graphemic buffer (also known as the Orthographic working memory) A
store in which graphemic information about the individual letters in a
word is held immediately prior to spelling the word. Phonological
dysgraphia A condition caused by brain damage in which familiar words
can be spelled reasonably well but unfamiliar words and non-words
cannot.

●

Sound-to-spelling conversion system

Sublexical route

Lexical semantic system

Sublexical route

Orthographic longterm memory

Auditory/speech processing Phonological working memory

Lexical route

560

Letter name selection

letters or words. This route is used when spelling unfamiliar words or
non-words. It produces correct spellings when the relationship between
sounds and spellings is regular or common but spelling errors when the
relationship is irregular or uncommon. Both routes converge on
orthographic working memory (also known as the graphemic buffer). This
briefly holds information about the letters within a word and the
ordering of those letters before they are written or typed. The
processes and structures involved in spelling (Figure 11.13(b)) are very
similar to those involved in reading (Figure 11.13(a)), but are used in
the opposite direction. Spelling goes from hearing a word to writing it
whereas reading goes from the written word to saying it.

Findings What would happen if brain-damaged patients could not use the
non-lexical route but the lexical route was essentially intact? They
would spell familiar words accurately (whether they were regular or
irregular) because the spellings would be available in orthographic
long-term memory. However, they would have great problems with
unfamiliar words and non-words having no relevant information stored in
long-term memory. Such patients have phonological dysgraphia. Shelton
and Weinrich (1997) studied a male patient (EA) with phonological
dysgraphia. He spelled 50% of regular words and 45% of irregular words
correctly to dictation but 0% of non-words. Sotiropoulos and Hanley
(2017) found phonological dysgraphics had normal performance when
spelling regular and irregular words. It seems likely phonological
dysgraphics have severe problems with phonological processing
(processing involving word sounds). Accordingly,

Language production

they should perform poorly on any task requiring phonological
processing. As predicted, Cholewa et al. (2010) found children with
phonological dysgraphia performed poorly on various tests of
phonological processing (e.g., deciding whether two spoken non-words
sounded the same) as well as spelling non-words. What would happen if
patients had damage to the lexical route and so relied mostly on the
non-lexical route (converting sounds into groups of letters)? Such
patients would be more accurate at spelling regular or consistent words
and non-words (because the spelling can be worked out from the sound)
than irregular or inconsistent words. Such patients suffer from surface
dysgraphia. Macoir and Bernier (2002) studied a patient, MK, who spelled
92% of regular words correctly but only 52% of irregular words. Cholewa
et al. (2010) in a study discussed earlier (pp. 560--561) found children
with surface dysgraphia spelled 56% of irregular words incorrectly but
only 19% of nonwords. According to the dual-route theory, surface
dysgraphics should not have severe problems with phonological
processing. Cholewa et al. obtained partial support for this prediction
-- surface dysgraphics had impaired on some phonological tasks but on
fewer tasks than phonological dysgraphics. Some research findings
indicate the dual-route theory is oversimplified. First, Treiman and
Kessler (2016) asked participants to spell monosyllabic non-words.
Whether a final /f/ sound in these non-words was spelt f or ff did not
depend solely on sound-to-spelling rules as predicted by the theory.
Spellings were also influenced by context -- the spelling ff was more
likely to be used when the preceding vowel in the non-word was spelt
with one letter rather than two. Second, Rapp et al. (2002) found
greater interaction between the lexical and non-lexical routes during
word spelling than assumed by the theory. They studied LAT, a patient
with Alzheimer's disease. He spelled bouquet as BOUKET and knowledge as
KNOLIGE. These spellings suggest some use of the non-lexical route. In
addition, however, he could only have known that bouquet ends in t and
that knowledge starts with k by using information in orthographic
long-term memory. Third, according to the theory, the spelling of
non-words should involve only the non-lexical route. Suppose you heard
the non-word /vi:m/ and wrote it down. Would you write VEAM or VEME?
Most spellers write VEAM if dream has just been presented auditorily but
VEME if preceded by theme (Martin & Barry, 2012). This shows an
influence of the lexical route on non-word spellings.

Evaluation Evidence from phonological dysgraphics and surface
dysgraphics provides reasonable evidence spelling can involve a lexical
or non-lexical route. There is also evidence for interactions between
the two routes. What are the limitations of the two-route theory? (1)

The theory assumes phonological dysgraphics have a specific problem
turning sounds into groups of letters. In fact, they often have a more
general problem with phonological processing.

561

KEY TERM Surface dysgraphia A condition caused by brain damage in which
there is impaired spelling of irregular words but reasonably accurate
spelling of regular words and non-words.

562

Language

KEY TERMS

(2) 

Orthographic lexicon Part of long-term memory in which learned word
spellings are stored. Dyslexia Impaired ability to read not attributable
to low intelligence. Dysgraphia Impaired ability to write (including
spelling).

(3) 

There are more interactions between the two spelling routes than assumed
by the theory. This has been found with respect to the spelling of words
and non-words. The theory is oversimplified because we use more sources
of information in spelling than identified theoretically. As Treiman
(2017, p. 84) pointed out, "English spelling includes more regularities
than is often thought." For example, double consonants are common before
a final (e.g., haddock; paddock) but uncommon before a final (e.g.,
tannic vs panic, magic, tragic). Treiman discussed research showing we
use such information to increase the accuracy of our word spellings.

One or two orthographic lexicons? Look back to Figure 11.13 and you will
see many similarities between reading and spelling. Of most relevance
here, knowledge of word spellings (orthography) is important in reading
and writing. The simplest (and most plausible) assumption is that there
is a single orthographic lexicon within orthographic long-term memory
used for reading and spelling. Alternatively, an input orthographic
lexicon is used in reading and a separate output orthographic lexicon is
used in spelling.

Findings Relevant evidence has come from studies on brain-damaged
patients. Patients with a reading impairment (dyslexia) generally also
have impaired writing and spelling (dysgraphia). In many cases, such
patients have problems with the same specific words in reading and
writing. The above findings suggest there is a single orthographical
lexicon. However, some brain-damaged patients have greater problems with
reading than spelling, or vice versa. Such evidence suggests there are
two orthographic lexicons. However, those with greater reading problems
generally have damage to brain areas associated with visual perception
(e.g., BA17/18), whereas those with greater spelling problems have
damage to premotor areas (e.g., BA6) (Rapp & Lipka, 2011). These
findings reflect the greater role of perception in reading and of motor
processes in spelling and so they do not indicate whether there are two
orthographic lexicons. Hepner et al. (2017) studied PJT (an 8-year-old
boy with dysgraphia) and obtained the following findings: "We found no
evidence of any reading impairment . . . indicating a striking
dissociation between impaired spelling and superior reading." Hanley and
Sotiropoulos (2018) obtained similar findings with NR. He had no
problems in reading words with atypical sound--letter associations but
performed very poorly when required to spell such words. The above
findings may suggest there are two orthographic lexicons, with the one
associated with spelling being severely impaired in PJT and NR. However,
this interpretation is implausible. It is more likely PJT has one
orthographic lexicon but finds it hard to access the information in it
via phonological long-term memory (as is required during spelling).

Language production

Precentral gyrus Superior temporal/ supramarginal gyri

Middle frontal gyrus

563 Figure 11.14 Brain areas in the left hemisphere associated with
reading, letter perception and writing. From James (2017).

Fusiform gyrus

Inferior frontal gyrus

Left hemisphere

Reading system Letter perception system Writing system

James (2017) reviewed findings consistent with the dual-route theory and
the notion there is a single orthographic lexicon. In essence, she found
that the brain areas associated with writing correspond closely to those
involved in reading and in letter perception (see Figure 11.14). Purcell
et al. (2017) assessed activation in areas associated with orthographic
processing (the ventral occipito-temporal cortex and inferior frontal
gyrus) while participants read visually presented words or spelled
spoken words. These areas were involved in both reading and spelling.
When the same word was read on one trial and then spelled on the next
trial (or vice versa), there was reduced activation in brain areas
involved in orthographic processing These findings provide strong
evidence there is a single orthographic lexicon used on reading and
spelling tasks.

Evaluation The issue of one vs two orthographic lexicons has not been
fully resolved. However, most evidence from brain-damaged patients and
from neuroimaging studies on healthy individuals favours the notion of a
single orthographic lexicon. What are the limitations of research in
this area? First, much evidence is inconclusive. For example,
individuals such as PJT and NR have severely impaired spelling ability.
This may occur because they have a deficient orthographic lexicon for
spelling or because they have problems accessing the orthographic
lexicon when presented with word sounds. Second, the fact that children
are often taught reading and spelling as separate skills suggests some
caution before rejecting the notion of two orthographic lexicons.

Interactive feature: Primal Pictures' 3D atlas of the brain

564

Language

CHAPTER SUMMARY •

Introduction. Speaking and writing rely on the same knowledge base and
involve similar planning skills. However, spoken language is simpler and
less formal than written language because speakers have less time for
planning than writers, and because speech fulfils a social function.

•

Basic aspects of speech production. Speech production involves several
brain areas (and cognitive processes) overlapping with those involved in
speech perception. The finding that individuals with mild cognitive
impairment have poor speech quality indicates that speech production is
demanding. It is demanding in part because limited short-term memory
means speakers have to make rapid decisions while planning and producing
utterances. Speech production involves four stages: semantic; syntactic;
morphological; and phonological.

•

Speech planning. Speech planning can extend over a phrase or over a
clause. The extent of advance speech planning often differs at the
semantic, syntactic and phonological levels. Forward planning is
generally more extensive when speakers have no time pressure, when they
speak slowly and when they are under low cognitive load. Overall,
speakers can choose flexibly whether to focus on effective and
error-free communication or on minimising cognitive demands.

•

Speech errors. The study of speech errors can provide insights into the
processes (e.g., planning) underlying speech production. Speech errors
including spoonerisms, Freudian slips, semantic substitutions, exchange
errors and subject-verb agreement errors. Perceptual loop theory argues
that speakers use the comprehension system to monitor their inner and
overt speech for errors. In contrast, conflict-based monitoring theory
argues that error detection depends primarily on the speechproduction
system combined with cognitive control processes. Speakers monitor their
inner and overt speech. Most such monitoring probably involves the
speech-production system and cognitive control processes rather than the
comprehension system.

•

Theories of speech production. According to Dell's spreadingactivation
theory, the processing associated with speech production is parallel and
interactive. The theory accounts for most speech errors but may
exaggerate processing interactivity. WEAVER++ is a discrete, feedforward
model based on the assumption of serial processing. Patterns of brain
activation provide some support for this model, as does some research on
the tip-of-the-tongue state. However, speech production often involves
more interactive and parallel processing than assumed

Language production

within WEAVER++. In addition, the model exaggerates the role of
comprehension processes in the detection of one's own speech errors.
Various theorists (e.g., Christiansen & Chater, 2016) argue (with
supporting evidence) that general cognitive processes (e.g., short-term
memory; cognitive control) play a major role in speech production. These
general processes are de-emphasised within spreading-activation theory
and WEAVER++. •

Cognitive neuropsychology: speech production. There is a traditional
distinction between Broca's aphasia (slow, ungrammatical and non-fluent
speech) and Wernicke's aphasia (fluent speech often lacking meaning)
involving damage to different brain areas. The anatomical definitions of
Broca's and Wernicke's areas are unclear, and numerous other brain areas
are also crucial in language processing. Anomia (impaired naming
ability) can involve semantic impairments or phonological impairments,
but interactions are sometimes found between semantic and phonological
processing. Patients with agrammatism produce sentences lacking
grammatical structure and with few function words. They have impaired
processing resources, and general problems with sequence learning. The
speech of jargon aphasics is reasonably grammatical. However, they
produce many neologisms mostly due to deficient phonological processing.
Jargon aphasics' production of jargon occurs in part because they have
deficient self-monitoring of their own speech. We can avoid an
overreliance on categories such as anomia, agrammatism and jargon
aphasia by focusing on empirical similarities and differences in
patterns of language impairments among aphasic patients.

•

Speech as communication. The key purpose of speech is communication, and
speakers are often sensitive to the needs of their listener. They also
often make use of the common ground shared with the listener, but its
use is subject to speakers' memory limitations as well as their
processing limitations. Speakers use gestures in flexible ways that are
generally responsive to the listener. However, speakers make gestures
even when the listener cannot see those gestures, because the use of
gestures facilitates speakers when planning what to say. Other ways
speakers facilitate communication are by using prosodic cues (e.g.,
rhythm; stress) and discourse markers (words or phrases indirectly
assisting the listener's comprehension).

•

Writing: the main processes. Writing involves proposing or planning,
translating, transcribing, and evaluating and revising the text that has
been produced. Shifts from one writing process to another depend on a
monitor or control system. Good writers use a knowledge-transforming
rather than knowledge-telling strategy and devote more time to revision.
Expert writers attain

565

566

Language

a knowledge-crafting stage emphasising the reader's needs. The working
memory system (especially the central executive) is heavily involved in
the writing process. Word processing often enhances writing quality,
probably by encouraging revision and thinking processes. •

Spelling. According to the two-route theory, there are separate lexical
and non-lexical routes in spelling, with the former used to spell
familiar words and the latter unfamiliar words and nonwords.
Phonological dysgraphics have damage to the lexical route whereas
surface dysgraphics have damage to the non-lexical route. The theory is
oversimplified: phonological dysgraphics often have general problems
with phonological processing and the two routes often interact. Reading
and spelling probably both involve a single orthographic lexicon.
However, the evidence is complex and hard to interpret.

FURTHER READING Chater, N., McCauley, S.M. & Christiansen, M.H. (2016).
Language as skill: Intertwining comprehension and production. Journal of
Memory and Language, 89, 244--254. Nick Chater and colleagues stress the
strong links between speech production and comprehension and emphasise
the role played by general processes (e.g., short-term memory; basic
learning) in their development. Dronkers, N.F., Ivanova, M.V. & Baldo,
J.V. (2017). What do language disorders reveal about brain-language
relationships? From classic models to network approaches. Journal of the
International Neuropsychological Society, 23, 741--754. This article by
Nina Dronkers and colleagues contains a historical account showing how
cognitive neuropsychology has enhanced our understanding of the
processes underlying language comprehension and production. Ferreira,
V.S. (2019). A mechanistic framework for explaining audience design in
language production. Annual Review of Psychology, 70, 29--51. Victor
Ferreira discusses the processes used by speakers when attempting to be
responsive to listeners' needs. Hepner, C., McCloskey, M. & Rapp, B.
(2017). Do reading and spelling share orthographic representations?
Evidence from developmental dysgraphia. Cognitive Neuropsychology, 34,
119--143. Christopher Hepner and colleagues discuss a recent version of
the influential two-route theory of spelling. Kellogg, R.T., Turner,
C.E., Whiteford, A.P. & Mertens, A. (2016). The role of working memory
in planning and generating written sentences. Journal of Writing
Research, 7, 397--416. Ronald Kellogg and his colleagues provide a
comprehensive account of the various ways working memory contributes to
the writing process. McClain, R. & Goldrick, M. (2018). The
neurocognitive mechanisms of speech production. In S.L. Thompson-Schill
(ed.), Stevens' Handbook of Experimental Psychology and Cognitive
Neuroscience, Vol. 3: Language and Thought (4th edn; pp. 319--356). New
York: Wiley. The major processes (including attention) that are involved
in speech production are discussed in this chapter.

Language production Nozari, N. & Novick, J. (2017). Monitoring and
control in language production. Current Directions in Psychological
Science, 26, 403--410. This article provides an overview of the
mechanisms used by speakers to avoid or correct production errors.

567

569

Our ability to reflect in complex ways on our lives (e.g., to plan and
solve our daily problems) is the bedrock of thinking behaviour. The ways
we think (and reason and make decisions) are very varied. They range
from solving newspaper crossword puzzles, to troubleshooting (or not!)
if our car breaks down, to developing a new theory of the universe.
Below we consider two examples of the activities to which we apply the
term "thinking". First, a fragment of Molly Bloom's sleeping thoughts in
James Joyce's Ulysses (1922/1960, pp. 871--872): God help the world if
all women in the world were her sort down on bathingsuits and lownecks
of course nobody wanted her to wear I suppose she was pious because no
man would look at her twice I hope I'll never be like her a wonder she
didn't want us to cover our faces but she was a well educated woman
certainly and her gabby talk about Mr Riordan here and Mr Riordan there
I suppose he was glad to get shut of her. Second, here is the first
author struggling to use PowerPoint: Why has the Artwork put the title
in the wrong part of the slide? Suppose I try to put a frame around it
so I can drag it up to where I want it? Ah ha, now if I just summon up
the arrows I can move the top bit up, and then I do the same with the
bottom bit. If I move the bottom bit up more than the top bit, then the
title will fit in okay. These two examples illustrate several general
aspects of thinking. First, they both involve individuals being
conscious of their thoughts. Thinking typically involves conscious
awareness. There is an ongoing controversy concerning the extent to
which higher-level cognitive processes such as thinking can be
unconscious (see Chapter 16). Hassin (2013) claimed unconscious
processes can perform all the functions of conscious processes. However,
the evidence suggests unconscious processes are much more

PART IV

Thinking and reasoning

570570

Thinking and reasoning

limited than conscious ones (especially with respect to thinking and
reasoning) when stringent criteria are used to identify processes as
"unconscious" (Hesselmann & Moors, 2015). Note also that we tend to be
aware of the products of thinking rather than processes themselves (see
Chapter 16). Furthermore, even when we can introspect on our thoughts,
our recollections of them are often inaccurate. Joyce reconstructs well
the nature of idle, associative thought in Molly Bloom's internal
monologue. However, if we asked her to tell us her thoughts from the
previous five minutes, she would probably recall very little of it.
Second, thinking varies in the extent to which it is directed and
controlled. It can be relatively undirected as in the case of Molly
Bloom letting one thought slide into another as she is on the point of
slipping into a dream. In the other example, the goal is much clearer
and better defined. Third, the amount and nature of the knowledge used
in different thinking tasks vary enormously. The knowledge required in
the PowerPoint example is relatively limited (even though it took the
first author much time to acquire it!). In contrast, Molly Bloom is
making use of her vast knowledge of people and of life. The next three
chapters (Chapters 12--14) are concerned with the higherlevel cognitive
processes involved in thinking and reasoning (see the Box, Forms of
thinking, on the facing page). Of importance, we use the same cognitive
system to deal with all these types of thinking and reasoning. As a
result, many distinctions between different forms of thinking and
reasoning are somewhat arbitrary and camouflage similarities in
underlying cognitive processes. From the above viewpoint, it is
unsurprising that similar brain areas are typically involved in most
problem-solving and reasoning tasks (see Chapter 14). It is also worth
mentioning there has recently been a major shift in research from
deductive reasoning to informal reasoning because the latter is of
considerably more relevance in everyday life. Informal reasoning is
closer than deductive reasoning to research on judgement and
decision-making because it makes much more use of an individual's
knowledge and experience. We will briefly describe the structure of this
section. Chapter 12 is concerned primarily with the processes involved
in problem solving. We discuss various types of problems (e.g., those
involving insight) and there is an emphasis on the reasons why most
people find it very difficult to solve certain problems. There is also
an emphasis on the factors involved in the development of expertise in
various areas (e.g., chess playing; medical expertise). Chapter 13 deals
with judgement and decision-making with an emphasis on the errors and
biases that are often involved. A central theme is that most people make
extensive use of heuristics (rules of thumb) that are simple to

Thinking and reasoning

use but prone to error. Complex decision-making is also considered, as
well as the role of emotional factors in decision-making. Chapter 14
deals with the major forms of reasoning (inductive, deductive and
informal) and the errors to which they are prone. There is also
discussion of the key (but very tricky!) question, "Are humans
rational?". As you might expect, many psychologists answer that question
"Yes and no", rather than a definite "Yes" or "No"!

FORMS OF THINKING Cognitive activity that involves moving from the
recognition that there is a problem through a series of steps to the
solution. Most other forms of thinking involve some problem solving.
Problem solving differs from decision-making in that individuals have to
generate their own solutions. Decision-making Selecting one out of a
number of presented options or possibilities, with the decision having
personal consequences (e.g., winning or losing money). Judgement A
component of decision-making that involves calculating the likelihood of
various possible events; the emphasis is on accuracy. Deductive
reasoning Deciding what conclusions necessarily follow provided various
statements are assumed to be true; most deductive-reasoning tasks are
based on formal logic; however, most individuals use informal reasoning
(see below) rather than logic with such tasks (see Evans et al., 2015).
Informal reasoning Evaluating the strength of arguments by taking
account of one's relevant knowledge and experience. Inductive reasoning
Deciding whether certain statements or hypotheses are true on the basis
of the available information. It is used by scientists and detectives
but is not guaranteed to produce valid conclusions. Problem solving

571

Chapter

Problem solving and expertise

INTRODUCTION Life presents us with many problems, although thankfully
most are fairly trivial. Here are three examples. First, you have an
urgent meeting in another city. However, the trains generally run late,
your car is old and unreliable, and the buses are slow. Second, you are
struggling to work out the correct sequence of operations on your
computer to perform a given task. You try to remember what you needed to
do with your previous computer. Third, you are an expert chess player
competing against a strong opponent. The time clock is ticking, and you
must rapidly decide on your move in a complicated position. The above
examples relate to the three main topics of this chapter. The first is
problem solving, which involves the following (Goel, 2010, p. 613): "(1)
there are two states of affairs; (2) the agent \[problem solver\] is in
one state and wants to be in the other state; (3) it is not apparent to
the agent how the gap between the two states is to be bridged; and (4)
bridging the gap is a consciously guided multi-step process." One reason
problem solving is very important is because it is "a crossroads, where
many different processes come together in the service of the needs and
goals of an individual" (Weisberg, 2018, p. 607). The second topic is
analogical problem solving. In our everyday lives, we constantly use
past experience and knowledge to assist us in our current task. Often we
detect (and make effective use of) analogies or similarities between a
current problem and ones solved in the past. The third topic is
expertise. Individuals possessing expertise have considerable specialist
knowledge in one area or domain. There is much overlap between expertise
and problem solving in that experts are very efficient at solving
numerous problems in their area of expertise. However, there are also
important differences. Knowledge is typically more important in research
on expertise than problem solving. In addition, there is more focus on
individual differences in expertise research. Indeed, a central issue in
expertise is to identify the main differences (e.g., in knowledge; in
strategic processing) between experts and novices.

12

574

Thinking and reasoning

KEY TERMS

PROBLEM SOLVING: INTRODUCTION

Well-defined problems Problems in which the initial state, the goal and
the methods available for solving them are clearly laid out.

There are three major aspects to problem solving:

Ill-defined problems Problems in which the problem is imprecisely
specified; for example, the initial state, the goal state and the
methods available to solve the problem may be unclear. Knowledge-rich
problems Problems that can only be solved by those having considerable
relevant background knowledge. Knowledge-lean problems Problems that can
be solved by individuals in the absence of specific relevant prior
knowledge.

(1) 
(2) 
(3) 

It is purposeful (i.e., goal-directed). It involves controlled processes
and is not totally reliant on "automatic" processes. A problem exists
when someone lacks the relevant knowledge to produce an immediate
solution. Thus, for example, a task involving mathematical calculation
may be a problem for most individuals but not a professional
mathematician.

The above three aspects are typically found during problem solving.
However, as we will see, problem solving sometimes depends on
nonconscious processes as well as (or instead of) the conscious
deliberate processes implied by aspects (1) and (2). There are major
differences among problems. Well-defined problems are ones where all
problem aspects are clearly specified, including the initial state or
situation, the range of possible moves or strategies, and the goal or
solution. The goal is well specified because it is clear when it has
been reached (e.g., the centre of a maze). Chess is a well-defined
problem: there is a standard initial state, the rules specify all
legitimate moves and the goal is to achieve checkmate. However, chess is
in some ways ill-defined -- the nature of the problem faced by a chess
player varies constantly during a game. Ill-defined problems are
underspecified. Suppose you set yourself the goal of becoming happier.
There are endless strategies you could adopt, and it is very hard to
anticipate which would be most effective. Since happiness varies over
time and is hard to define, how are you going to decide whether you have
solved the problem of becoming happier? Most everyday problems are
ill-defined. However, psychologists have focused mostly on well-defined
problems. Why is this? With well-defined problems, the researcher knows
the correct answer and often also knows the optimal strategy for their
solution. As a result, they can easily identify the errors and
deficiencies in problem solvers' strategies. Goel and Grafman (2000)
studied PF, a man with brain damage to the right prefrontal cortex. He
had a high IQ (128) and performed successfully on well-defined
laboratory tasks. However, he performed very poorly with everyday
ill-defined problems because he produced inadequate preliminary plans.
In similar fashion, Goel et al. (2013) found patients with damage to the
right prefrontal cortex made premature commitments when planning a trip
to Italy. In contrast, planning is more straightforward with most
well-defined problems. We can also distinguish between knowledge-rich
and knowledge-lean problems. Knowledge-rich problems (e.g., chess
problems) can only be solved by those having much relevant specific
knowledge. In contrast, knowledge-lean problems do not require such
knowledge because the information needed to solve the problem is
contained in the initial problem statement. Historically, most research
involved knowledge-lean problems because they minimise individual
differences in relevant knowledge.

575

Problem solving and expertise

IN THE REAL WORLD: MONTY HALL PROBLEM We can illustrate key issues in
problem solving by considering the notorious Monty Hall problem that
formed an important part of Monty Hall's show on American television:
Suppose you're on a game show and you're given the choice of three
doors. Behind one door is a car, behind the others, goats. You pick a
door, say, Number 1, and the host, who knows what's behind the doors,
opens another door, say Number 3, which has a goat. He then says to you,
"Do you want to switch to door Number 2?" Is it to your advantage to
switch your choice? If you stayed with your first choice, you are in
good company since approximately 85% of people make that decision.
Unfortunately, it is wrong! There is actually a two-thirds chance of
being correct if you switch. Monty Hall, the game-show host. Most people
(including you?) furiously dispute the above answer. Monty Hall. ZUMA
Press, Inc./Alamy. Let's work it through. There are only three possible
scenarios with the Monty Hall problem (Krauss & Wang, 2003; see Figure
12.1). With scenarios 1 and 2, your first choice is incorrect, and so
Monty Hall opens the only remaining door with a goat behind it. As a
result, switching is certain to succeed. With scenario 3, your first
choice is correct, and you would win by refusing to switch. Overall,
switching succeeds two-thirds of the time.

Figure 12.1 Explanation of the solution to the Monty Hall problem: in
two out of three possible car/ goat arrangements, the contestant would
win by switching; therefore she should switch. From Krauss and Wang
(2003). © 2003 American Psychological Association.

576

Thinking and reasoning

Human performance on the Monty Hall problem is very poor. Indeed,
Herbranson and Schroeder (2010) found it was much worse than that of
pigeons! After extensive practice, humans switched on 66% of trials (the
optimal response) whereas pigeons switched on 96% of trials. The pigeons
performed well because they simply maximised the reward they received
whereas humans used more complex strategies. Why do humans perform so
poorly on this problem? First, people typically use a heuristic (rule of
thumb) known as the equiprobability bias (assuming all available options
are equally likely even when they are not; Tubau et al., 2015). In
addition, people experience more regret when losing by switching than
when losing by staying (Tubau et al.). These two factors lead most
people to stay, mistakenly. Second, the problem places substantial
demands on the central executive (an attention-like system; see
Glossary). Performance on the Monty Hall problem was much worse if
participants performed a demanding task involving the central executive
at the same time (8% vs 22%; De Neys & Verschueren, 2006). Third, many
people mistakenly believe the host's actions are random. Burns and Wieth
(2004) made the causal structure of the problem clearer. There are three
boxers, one of whom is so good he is certain to win any bout. You select
one boxer and then the other two fight each other. The winner of this
bout then fights the boxer you selected initially. You win if you choose
the winner of this second bout. With this version of the problem, 51%
correctly decided to switch versus only 15% with the standard three-door
problem. This occurred because it is easy to see that the boxer who won
the first bout did so because of skill rather than any random factor.
Fourth, it is very hard to understand the problem. Saenen et al. (2015)
found 16% of university students produced the optimal answer (i.e.,
switching) but only half understood the underlying probabilities. For
example, the probabilities of winning-when-staying and
winning-when-switching must equal 1 but several participants produced
probabilities that did not sum to 1! Thus, it is possible to "solve" the
Monty Hall problem without full understanding. When participants are
provided with relevant information about the underlying probabilities,
over 80% of them decided to switch compared to only 40% when that
information was not provided (James et al., 2018).

Researchers have studied problem solving using literally thousands of
different problems. This raises the issue as to whether there is some
commonality in the processes used to solve these diverse problems.
Bartley et al. (2018) addressed this issue in a meta-analysis (see
Glossary) of neuroimaging studies involving mathematical, verbal and
visuo-spatial problems. Bartley et al. (2018) identified what they
called "a core problem solving network" (p. 318) that was common to all
three types of problem (see Figure 12.2(d)). More specifically, there
was a fronto-parietal network (e.g., the dorsolateral prefrontal cortex;
the cingulate gyrus involved in processes such as attention, monitoring
and working memory). In addition, there were brain areas specific to
mathematical, verbal and visuo-spatial problems (see Figure 12.2).

KEY TERM Heuristic Rule of thumb that is cognitively undemanding and
often produces approximately accurate answers; see algorithm.

GESTALT APPROACH AND BEYOND: INSIGHT AND ROLE OF EXPERIENCE Early
research on problem solving was dominated by the gestaltists, German
psychologists flourishing between the 1920s and 1940s. They
distinguished between reproductive and productive thinking. Reproductive
thinking involves the systematic re-use of previous experiences (e.g.,
in

577

Problem solving and expertise

KEY TERM Insight The experience of suddenly realising how to solve a
problem; sometimes referred to as the "the Aha! experience".

Figure 12.2 Brain areas (a) involved in mathematical problem solving;
(b) verbal problem solving; (c) visuo-spatial problem solving; and (d)
areas common to all three problem types (conjunction). From Bartley et
al. (2018). Reprinted with permission of Elsevier.

mathematical problems) and is mostly required on well-defined problems.
Productive thinking involves novel problem restructuring and is mostly
required on ill-defined problems. In what follows, our main focus will
be on theorising and research influenced by the Gestalt approach with
only occasional mentions of the gestaltists' original research.

Insight The gestaltists argued problems requiring productive thinking
are often solved using insight. Insight involves a sudden problem
restructuring, often accompanied by an "Aha! experience". More
technically, insight is "any sudden comprehension, realisation, or
problem solution that involves a reorganisation of the elements of a
person's mental representation of a stimulus, situation, or event to
yield a non-obvious or non-dominant interpretation" (Kounios & Beeman,
2014, p. 74). The mutilated draughtboard (or chequerboard) problem (see
Figure 12.3) is an insight problem. The board is initially covered by 32
dominoes occupying two squares each. Then two squares are removed from
diagonally

Figure 12.3 The mutilated draughtboard problem.

578

KEY TERM Remote Associates Test This involves finding a word that is
related to three given words (e.g., opera, hand and dish are all related
to soap).

Thinking and reasoning

opposite corners. Can the remaining 62 squares be filled by 31 dominoes?
What is your answer? Nearly everyone starts by mentally covering squares
with dominoes. Alas, this strategy is ineffective because there are
758,148 possible permutations! You may well rapidly solve the problem
using insight if we tell you something you already know -- each domino
covers one white and one black square. If that does not work, note that
the two removed squares must have the same colour. Thus, the 31 dominoes
cannot cover the mutilated board. There is theoretical controversy
concerning insight. Some (including the gestaltists) claim it is very
different from other cognitive processes (the special-process
viewpoint). However, others claim very similar processes are used in
insight and non-insight problems (the business-as-usual viewpoint)
(Zander et al., 2016). Below we discuss this controversy.

Findings

Case study: Brain areas involved in insight

Researchers often use participants' reports of the Aha! experience to
indicate insight. Ideally, the Aha! experience should be reported
predominantly on "insight problems" rather than "non-insight problems"
and should be associated with correct solutions. The evidence partially
supports these predictions. Webb et al. (2016a) found Aha! experiences
were reported more often with insight than noninsight or problems.
However, insight problems were sometimes solved without any Aha!
experiences and the solution of non-insight problems was sometimes
accompanied by Aha! experiences. The gestaltists apparently assumed
insight always produces correct solutions. Danek and Wiley (2017)
reported contrary evidence using insight problems. Many incorrect
solutions (especially those produced rapidly) were associated with Aha!
experiences. Much research has considered whether insight is associated
with a specific pattern of brain activity (Kounios & Beeman, 2014). The
findings are variable. Bowden et al. (2005) used the Remote Associates
Test: three words were presented (e.g., fence; card; master) and
participants thought of a word (e.g., post) going with each one to form
compound words. The anterior superior temporal gyrus was activated only
when solutions involved insight. This is a brain area associated with
processing distant semantic relations between words as well as
reinterpretation and semantic integration. Other areas associated with
insight are the anterior cingulate cortex (involved in the detection of
cognitive conflict and the breaking of a mindset) and the prefrontal
cortex (involved in higher cognitive processes (Kounios & Beeman, 2014).
Metcalfe and Wiebe (1987) assessed participants' feelings of "warmth"
(closeness to solution) during insight and non-insight problems. Warmth
increased progressively during non-insight problems (as expected because
they involve several processes). With insight problems, warmth ratings
remained low until suddenly increasing dramatically just before problem
solution (consistent with the Aha! experience). Kizilirmak et al. (2018)
reported similar findings using the Remote Associates Test (discussed
above). Feelings of warmth increased much more abruptly for problems

579

Problem solving and expertise

whose solution was accompanied by an Aha! experience than those solved
with such experience. Subjectively, insight occurs suddenly and
unexpectedly. However, this is not necessarily true of the underlying
processes. Ellis et al. (2011) recorded eye movements while participants
solved four-letter anagrams (five letters were presented but one was a
distractor). On insight trials, participants reported suddenly finding
the solution to the problem. However, participants had decreasing
fixations on the distractor letter ahead of the solution indicating they
were gradually, but unconsciously, accumulating relevant knowledge. In
sum, insight is a process differing from other, more controlled
processes. However, there are issues with respect to the measurement of
insight. For example, Laukkonen and Tangen (2018) found problem solvers
often report the Aha! experience in the absence of a sudden increase in
warmth ratings and vice versa. The Aha! experience is a preferable
measure of insight because it is more consistently associated with
various objective measures (e.g., problem-solving strategies;
performance accuracy on insight problems) (see Laukkonen & Tangen). Of
relevance, the Aha! experience is associated with increased autonomic
arousal (Shen et al., 2018) indicating an emotional reaction to
insightful problem solving.

Representational change theory Ohlsson (1992, 2011) developed the
gestaltist approach in his representational change theory. According to
this theory, the initial stage of problem solving involves forming a
mental representation of the problem. After that, we access various
mental operators that might be applied to this representation, only one
of which is selected and used at any given time. More specifically, the
current mental representation causes activation to spread to mental
operators related to it in meaning via an unconscious process and the
mental operator most strongly activated is retrieved. We often encounter
an impasse (feeling blocked and unsure how to proceed) when solving a
problem because our mental representation of it is incorrect.
Theoretically, we must change (or restructure) the problem
representation for insight to occur. This can happen in three ways: (1)
(2) (3)

Constraint relaxation: inhibitions on what is regarded as permissible
are removed. Re-encoding: some aspect of the problem representation is
reinterpreted. Elaboration: new problem information is added to the
representation.

Őllinger et al. (2014) developed representational change theory (see
Figure 12.4). What is new is the assumption that a search process may be
necessary even after an impasse has been overcome by insight. For
example, consider the nine-dot problem which requires four straight
lines that go through all nine dots (see Figure 12.5). Most people
initially assume the line must remain within the confines of the square
formed by the dots. Even when this constraint is relaxed by explicitly
instructing participants that they can draw lines outside the square,
performance is still poor.

KEY TERM Impasse The experience of being blocked and not knowing how to
proceed when engaged in problem solving.

580

Thinking and reasoning

Figure 12.4 Flow chart of insight problem solving. Initially, a problem
representation is established using prior knowledge and perceptual
processes. The problem representation is searched by heuristics (rules
of thumb). If this proves unsuccessful, an impasse is encountered. This
leads to a change in the problem representation and this new
representation is also searched by heuristics. This process is continued
until a solution is found or the problem is abandoned.

Thus, the processes involved can be more complex than envisaged within
representational change theory.

Findings Earlier we discussed the mutilated chessboard problem on which
nearly everyone starts with an incorrect problem representation. Solving
it requires representing each domino Figure 12.5 as an object covering
one white and one black (a) The nine-dot problem and (b) its solution.
square (re-encoding) and representing the chessboard as having lost two
black (or white) squares (elaboration). Knoblich et al. (1999) showed
the importance of constraint relaxation using matchstick problems
involving Roman numerals (see Figure 12.6). The solution to each problem
requiring moving a single stick to produce a true statement to replace
the initial false one. Some problems (Type A) only required changing two
values in the equation (e.g., VI = VII + I \[6 = 7 + 1\] becomes VII =
VI + I \[7 = 6 + 1\]). In contrast, Type B problems involved a less
obvious change in the representation of the equation (e.g., IV = III --
I \[4 = 3 -- 1\] becomes IV -- III = I \[4 -- 3 = 1\]). According to
Knoblich et al. (1999), we have learned that many operations change the
values (numbers) in an equation (as in Type A problems). In contrast,
relatively few operations change the operators (i.e., +, -- and =) as
required in Type B problems. As predicted, participants found it much
harder to relax the normal constraints of arithmetic (and so show
insight) with Type B problems. Knoblich et al. (2001) reported further
evidence that participants' initial representation is based on the
assumption that values must be changed. Participants initially spent
much more time fixating the values than the operators with both types of
problems.

581

Problem solving and expertise

Figure 12.6 Two of the matchstick problems used by Knoblich et
al. (1999) and the cumulative solution rates produced for these types of
problems in their study. © American Psychological Association.

Reverberi et al. (2005) argued that processing constraints on insight
problems involve the lateral prefrontal cortex. Patients with damage to
that area should not impose artificial constraints when solving insight
problems and so might perform better than healthy controls. As
predicted, brain-damaged patients solved 82% of the hardest matchstick
arithmetic problems compared to only 43% of controls. According to
representational change theory, solution hints should be most useful
when individuals have just reached an impasse or block. At that point,
they have formed an incorrect problem representation but have not become
excessively fixated on it. Moss et al. (2011) obtained findings
consistent with this prediction. Fleck and Weisberg (2013) asked
participants to think aloud while solving insight problems. There were
large individual differences in their strategies. Evidence of impasse
and restructuring (of crucial importance according to representational
change theory) was obtained on only 25% of problem attempts. Other
successful strategies included direct applications of knowledge with no
representational change and use of simple heuristics or rules of thumb
(e.g., hill climbing, see Glossary). Overall, there was much less
evidence of impasse and restructuring when solutions were produced
rapidly rather than slowly. Fedor et al. (2015) reported various
findings inconsistent with representational change theory in a study on
solving an insight problem. First, less than 50% of problem solvers
followed the theoretically predicted sequence of constrained search,
impasse, insight, extended search and solution. Most used more complex
processing sequences with search and impasse occurring several times.
Second, Fedor et al. compared reported experiences of impasse with
behaviourally defined measures (i.e., repetitious behaviour;
inactivity). Problem solvers were no more likely to report experiencing
an impasse during a behaviourally defined impasse than at other stages
of processing. In sum representational change theory provides a more
explicit and testable account than the original Gestalt theory. However,
it is increasingly clear that problem solving on insight problems is
significantly more flexible and variable than assumed by that theory.

582

Thinking and reasoning

IN THE REAL WORLD: MAGIC TRICKS Many magic tricks persuade spectators to
focus on a strong (but incorrect) problem representation (Danek et al.,
2014). For example, a magician pours water from a glass into an empty
mug. He then turns the mug upside down and a large ice cube drops out
(see YouTube: http://www.youtube.com/watch?v=3B6ZxNROuNw). Figure 12.7
This trick works because most people assume the mug The multiplying
billiard balls trick. (a) This is the is empty. In fact, there is a
white napkin glued to the end of the trick when the initial one ball has
bottom of the mug and the ice cube. The water is fully become four
balls; (b) the secret of this trick is absorbed by the napkin and so
only the ice cube falls that the initial ball is an empty semi-spherical
out. Participants given a verbal cue to relax the incor- shell that can
contain another ball. rect assumption that the mug was empty had
improved From Ekroll et al. (2017). performance. Spectators often cannot
change their initial incorrect problem representation into the correct
one. Our perceptual system rapidly and unconsciously extrapolates from
the visible parts of objects to complete them (the Gestalt law of
closure shown in Figure 3.4) (Ekroll et al., 2017). For example,
consider the Chinese linking rings trick in which solid metal rings
appear to link and unlink by passing through each other. One ring has a
small gap in it, but spectators assume all the rings are complete. The
multiplying billiard balls trick also depends on visual completion (see
Figure 12.7). The conjuror starts with a single ball and then
progressively adds balls until they have four: the initial ball is a
hollow shell initially having a complete ball hidden in it. When that
second ball is revealed, the conjuror inserts another complete ball in
the hollow shell and so on. When observers viewed a hollow shell
balanced on the tip of their finger, they perceived a complete ball
despite strong evidence it was hollow (Ekroll et al., 2016). They even
perceived their own finger as shorter than usual! These findings are
directly relevant to representational change theory -- observers often
cannot correct their incorrect problem representation because their
assumption the initial ball is complete is based on powerful perceptual
processes.

Evaluation Representational change theory extended the Gestalt approach
by specifying the mechanisms underlying restructuring and insight. More
generally, it involves a fruitful combination of Gestalt ideas with
cognitive psychology. Öllinger et al.'s (2014) extension of this theory
has improved it by emphasising that efficient search processes are often
needed after as well as before an impasse leading to insight. What are
the theory's limitations? First, the theory provides an idealised
account of the processes involved in insight problems. There are
substantial individual differences in problem processing, and processing
sequences are often more complex and flexible than assumed
theoretically. Second, we often cannot predict when (or why) problem
solvers change a problem's representation. Third, there is often
surprisingly little evidence of restructuring or impasse when
individuals solve insight problems. Fourth, the strategies used to solve
insight problems include some (e.g., direct application of knowledge;
heuristics) not included within the theory. Fifth, the original

583

Problem solving and expertise

theory mistakenly implied that constraint relaxation is typically
sufficient to solve insight problems (Őllinger et al., 2014).

Facilitating insight: hints and incubation We can facilitate insight by
providing subtle hints. Consider Maier's (1931) pendulum problem.
Participants enter a room containing various objects (e.g., poles,
pliers, extension cords) plus two hanging strings (see Figure 12.8). The
task involves tying the strings together, but they are too far apart for
participants to reach one string while holding the other. The solution
involves tying the pliers to one string and swinging it like a pendulum.
Thomas and Lleras (2009) used the pendulum problem with occasional
exercise breaks in which participants swung or stretched their arms.
Those moving their arms in a solution-relevant way (i.e., swinging) were
more likely to solve the problem even though unaware of the relationship
between their arm movements and the task. Wallas (1926) claimed problem
solving can benefit from incubation, which "arises when the solution . .
. comes to mind after a temporary shift of attention to another domain"
(Sio & Ormerod, 2015, p. 113). Research typically involves comparing an
experimental group having an incubation period away from an unsolved
problem with a control group working continuously. Sio and Ormerod
(2009) reported three findings in a meta-analysis: (1) (2)

Incubation effects (generally fairly small) were reported in 73% of the
studies. Incubation effects were stronger with creative problems having
multiple solutions than linguistic and verbal problems having a single

KEY TERM Incubation A stage of problem solving in which the problem is
put to one side for some time; it is claimed to facilitate problem
solving.

Figure 12.8 The two-string problem in which it is not possible to reach
one string while holding the other.

584

Thinking and reasoning

KEY TERM Mental set The tendency to use a familiar problem-solving
strategy that has proved successful in the past even when it is no
longer appropriate; also known as Einstellung.

(3) 

solution. Incubation often widens the search for knowledge, which may be
more useful with multiple-solution problems. The effects were larger
when there was a fairly long preparation time prior to incubation. This
may have occurred because an impasse or block in thinking is more likely
to develop when preparation time is long.

Why is incubation beneficial? Simon (1966) argued control information
relating to the strategies used by problem solvers is forgotten during
incubation. This forgetting facilitates problem solvers adopting a new
approach after the incubation period. Penaloza and Calvillo (2012) found
solving insight problems was only facilitated by a 2-minute break when
this allowed misleading information to be forgotten. Gilhooly (2018)
focused on "unconscious work": "Incubation effects involve active
although unconscious processing of the problem materials." His approach
is supported by research on insight problems using two conditions: (1)
the task instructions immediately precede each problem; (2) a totally
irrelevant task is performed between instructions and the problem.
Performance is typically better in condition (2) than condition (1).
This can be explained by unconscious work but not forgetting previously
used strategies or information.

Past experience: mental set Past experience generally increases our
ability to solve problems. However, the gestaltists argued persuasively
we sometimes fail to solve problems because we are misled by our past
experience. For example, mental set (Einstellung in German) involves
continuing to use a previously successful problem-solving strategy even
when inappropriate or suboptimal. However, mental set is often useful --
it allows successive problems of the same type to be solved rapidly,
with few processing demands. Luchins (1942) investigated mental set
using problems that involved three water jars of varying capacity. Here
is a sample problem. Jar A can hold 28 quarts of water, Jar B 76 quarts
and Jar C 3 quarts. You must end up with exactly 25 quarts in one of the
jars. The solution is easy: Jar A is filled, and then Jar C is filled
from it, leaving 25 quarts in Jar A. Of participants previously given
similar problems, 95% solved it. Other participants had previously been
trained on problems all having the same complex three-jar solution (fill
Jar B and use the contents to fill Jar C twice and Jar A once). Of these
participants, only 36% solved the easy final problem! Vallée-Tourangeau
et al. (2011) found the damaging effects of mental set on Luchins'
water-jar problems were reduced when actual water jars were used rather
than presenting the problems on paper (as in the original research).
According to Vallee-Tourangeau et al., the actual water jars provided a
"rich and dynamic . . . perceptual input" (p. 1894). Thomas and
Didierjean (2016) showed some powerful effects of mental set.
Participants saw a central card surrounded by six cards (all face down).
A magician asked them to select one of the six cards, which was then
revealed to match the central card. Participants were asked to identify
the trick's secret (all the cards are the same). When the magician did
not

585

Problem solving and expertise

suggest a solution, 83% of participants solved the trick. However, when
he claimed he could influence participants' choice by a specific hand
move, only 13% of participants solved the trick! Thus, mental set is so
strong that a single exposure to an implausible solution can inhibit
finding the actual (and more obvious) solution. We might assume experts
given a problem in their area of expertise would be relatively
unaffected by mental set. Bilalić et al. (2008a) tested this assumption
with chess experts. Most failed to identify the shortest way to win a
chess game, using instead a longer solution based on a familiar
strategy. However, the most skilful players were least likely to be
impaired by mental set. Why are chess experts susceptible to the
damaging effects of mental set? Bilalić et al. (2008b) studied chess
experts who had found the familiar solution but were seeking a better
one. They still fixated features of the chessboard position related to
the familiar solution. Thus, their attention was still partly controlled
by processes producing the initial familiar solution even though they
were unaware this was the case. In sum, mental set often impairs problem
solving. Gobet (2016) argued that its negative effects are very
widespread. For example, mental set can lead scientists to ignore
findings inconsistent with their favourite theory (see Chapter 14). It
is also relevant to myside bias (see Glossary) which involves people
disregarding arguments disproving their beliefs (see Chapter 14).

KEY TERM Functional fixedness The inflexible focus on the usual
function(s) of an object in problem solving.

Past experience: functional fixedness We turn now to a specific form of
mental set: functional fixedness. Functional fixedness occurs when we
mistakenly assume any given object has only a limited number of familiar
uses. Duncker (1945) carried out a classic study on functional
fixedness. Participants were given a candle, a book of matches, tacks in
a box and several other objects (see Figure 12.9). Their task was to
attach the candle to a wall by the table, so that it did not drip onto
the table below. Most participants tried to nail the candle directly to
the wall or glue it to the wall by melting it. Only a few produced the
correct answer -- use the inside of the tack box as a candle holder and
then nail it to the wall with tacks. According to Duncker (1945), his
participants "fixated" on the tack box's function as a container rather
than a platform. More correct solutions were produced when the box
containing the tacks was empty at the start of the experiment because it
appeared less like a container. More direct evidence that past
experience can produce functional fixedness was reported by Ye et
al. (2009). Participants decided whether objects could be used for a
Figure 12.9 specific function (e.g., packable with -- usable Some of the
materials provided for participants instructed as packing material to
pack an egg in a box). to mount a candle on a vertical wall in the study
by Duncker Immediately afterwards, they decided whether (1945).

586

Thinking and reasoning

the same objects could be used for a different function (e.g., play
catch with, over a distance of 15 feet). Some objects (e.g., ski cap;
pillow) could be used for both functions. Deciding an object possessed
the first function reduced the probability of detecting it also
possessed the second function: this is functional fixedness. It is often
assumed we are inflexible in our perceived uses of objects. Wagman et
al. (2016) disputed this assumption. Rods with several added plastic
pieces were regarded as more suitable for striking than poking an
object. However, such rods were not regarded as suitable for striking
with precision although they were suitable for striking with power. How
can we overcome functional fixedness? Challoner (2009) studied 1,001
important inventions and solutions to insight problems. Two steps were
typically involved: (1) (2)

Focus on an infrequently noticed or new feature. Form a solution based
on that obscure feature.

McCaffrey (2012) argued crucial obscure features are ignored because
people focus on the typical functions of objects based on their shape,
size, material they were made of, and so on. This functional fixedness
can be reduced by the generic-parts technique: (1) generate
function-free descriptions of all object parts; (2) decide whether each
description implies a use. McCaffrey gave some participants training in
the generic-parts technique. These participants solved 83% of insight
problems (e.g., Duncker's candle problem) compared to only 49% in the
control group.

Cognitive control: its role in insight, functional fixedness and mental
set Cognitive control refers to "the ability to limit attention to
goal-relevant information and inhibit, or suppress, irrelevant
distraction" (Amer et al., 2016b, p. 905). It is greater in individuals
high in working memory capacity (which is related to attentional
control; see Glossary). We might expect a high level of cognitive
control to be advantageous on tasks involving insight, functional
fixedness or mental set. However, that is not always the case. Cognitive
control is associated with a narrow focus of attention on goal-relevant
information and specific task strategies coupled with an inhibition of
processing of other information sources (Amer et al., 2016b). Thus, high
cognitive control can impair performance when a broad focus of attention
would be beneficial.

Findings Pope et al. (2015) compared the ability to break a mental set
in human adults, children and baboons. The original task was as follows:
(1) presentation of two red squares followed by participants touching
the locations previously occupied by those red squares: (2) if this was
done correctly, a blue triangle was presented and had to be touched for
reward. After participants had established a mental set, the task
changed slightly -- the blue triangle was present throughout. All
participants needed to do was touch the

587

Problem solving and expertise

blue triangle for reward (thus breaking the mental set) although they
could keep using the original strategy. Pope et al. (2015) found 100% of
baboons successfully broke the mental set, as did 45% of children but
only 12% of adults! Thus, the ability to break the mental set was
inversely related to intelligence (and cognitive control). Baboons
probably broke the mental set because that involved much less processing
capacity than the original strategy. Human adults did not break the set
because they found it hard to believe the task could be as easy as
simply touching the blue triangle. DeCaro et al. (2016) compared the
performance of individuals who were high and low in working memory
capacity (resembling attentional control) on Knoblich et al.'s (1999)
matchstick arithmetic problems. Some required insight (e.g., the Type B
problem shown in Figure 12.6) whereas others did not (e.g., the Type A
problem shown in Figure 12.6). Participants high in working memory
capacity performed better than those low in working memory capacity
scorers on problems not requiring insight (see Figure 12.10). However,
the opposite was the case with insight problems. How can we explain the
above findings? Individuals high in working memory capacity tend to
consider complex problem solutions even when simple ones are required
(DeCaro et al., 2016, 2017). This disadvantages high-capacity
individuals on many insight problems. However, highcapacity individuals
are often better than low-capacity ones at forming an initial problem
representation and this facilitates their performance of many
non-insight problems. Jarosz et al. (2012) considered the effects of
alcohol intoxication on an insight task (Remote Associates Test; see
Glossary). Intoxicated participants solved 58% of the problems compared
to only 42% for sober participants. Alcohol intoxication broadened
participants' attentional focus beyond strong (but incorrect) associates
of the three words presented on each trial.

100%

Problem success (probability)

90% 80% 70% 60% Incremental Insight

50% 40% 30% 30% 10% 0% Low (--1 SD)

High (+1 SD)

Working memory capacity

Figure 12.10 Mean percentages of correct solutions as a function of
problem type (incremental, not requiring insight, vs insight) and
working memory capacity (low vs high). From DeCaro et al. (2016).

588

KEY TERM Problem space An abstract description of all the possible
states that can occur within a given problem.

Thinking and reasoning

Chrysikou et al. (2013) assessed the role of cognitive control in
functional fixedness when participants generated common or uncommon uses
for objects. When transcranial magnetic stimulation (TMS; see Glossary)
was applied to the left prefrontal cortex to reduce cognitive control,
this facilitated performance when uncommon uses for objects had to be
produced.

Conclusions High cognitive control can impair performance on certain
tasks, especially those "that are aided by the use of previously
irrelevant information, or on tasks that generally benefit from drawing
on diverse bits of information from various sources" (Amer et al.,
2016b, p. 906). However, high cognitive control is advantageous on tasks
requiring working memory and/or selective attention, and when
distracting stimuli must be ignored. It remains for the future to
establish precisely which tasks benefit from (or are impaired by) high
cognitive control and to obtain a detailed understanding of the
underlying mechanisms.

PROBLEM-SOLVING STRATEGIES Major landmarks in problem-solving research
were an article by Newell et al. (1958) followed in 1972 by Newell and
Simon's book, Human Problem Solving. Their central insight was that the
strategies we use when tackling complex problems reflect our limited
ability to process and store information. More specifically, we have
very limited short-term memory capacity and so complex information
processing is typically serial (one process at a time). These
assumptions were included in their General Problem Solver (a computer
program designed to solve well-defined problems). Gobet and Lane (2015)
evaluated this theoretical approach. On the positive side, the General
Problem Solver was one of the first problem-solving programs and led to
Newell and Simon being identified as "the founding fathers of artificial
intelligence" (Gobet & Lane, 2015, p. 141). In addition, Newell and
Simon (1972) identified several important problem-solving strategies
(discussed below). Limitations include exaggerating the role of serial
processing in problem solving and the reliance on rather abstract and
artificial problems. Newell and Simon (1972) used various well-defined,
knowledge-lean problems (e.g., the Tower of Hanoi; see Figure 12.11).
The initial problem state consists of up to five discs piled in
decreasing size on the first of three pegs. When they are on placed in
the same order on the last peg, the problem has been solved. Only one
disc can be moved at a time and a larger disc cannot be placed on top of
a smaller one. Newell and Simon (1972) identified a problem space for
each problem. A problem space consists of the initial problem state, the
goal state, all possible mental operators (e.g., moves) that can be
applied to any state to Figure 12.11 change it into a different state,
and all the interThe initial state of the five-disc version of the Tower
of Hanoi problem. mediate problem states.

589

Problem solving and expertise

How do we solve well-defined problems with our limited processing
capacity? According to Newell and Simon (1972), we rely heavily on
heuristics (see Glossary) -- rules of thumb that are easy to use and
often produce reasonably accurate answers. Heuristics can be contrasted
with algorithms (computational methods guaranteed to produce a problem
solution). Algorithms are often too complex to be used by most people.
In this section, we consider some heuristics identified by Newell and
Simon (1972). We also discuss other heuristics and strategies for
problem solving.

Hill climbing Newell and Simon (1972) identified the hill-climbing
heuristic. Hill climbing is a very simple strategy which involves
changing the present problem state into one closer to the goal. It is
mostly used when the problem solver has no clear understanding of the
problem structure and so focuses on very shortterm goals. Use of hill
climbing resembles a climber who tried to reach the highest mountain
peak in the area by using the strategy of always moving upwards. This
may work. However, the climber will probably find himself/ herself
trapped on a hill several valleys away from the highest peak.

Means--ends analysis According to Newell and Simon (1972), the most
important heuristic method is means--ends analysis. It resembles hill
climbing but the problem solver has greater awareness of how to break
the problem down into sub-problems. Here is the essence of means--ends
analysis: ● ●

●

Note the difference between the current problem state and the goal
state. Form a subgoal to reduce the difference between the current and
goal states. Select a mental operator (e.g., move or moves) that permits
attainment of the subgoal.

Means--ends analysis typically assists problem solution. However,
Sweller and Levine (1982) found it can severely impair performance.
Participants tried to solve an apparently simple maze, most of which was
not visible. Some participants could see the goal state
(goal-information group) whereas others could not. Use of means--ends
analysis requires knowledge of goal location and so only the
goal-information group could use that heuristic. However, the problem
was designed so that means--ends analysis would not be useful -- every
correct move involved turning away from the goal. Only 10% of
participants in this group solved the problem in 298 moves whereas those
in the other group solved the problem in an average 38 moves.

Meta-reasoning Ackerman and Thompson (2017) emphasised the importance of
metareasoning (processes that monitor our progress during problem
solving

KEY TERMS Algorithm A computational procedure providing a specified set
of steps to problem solution; see heuristic. Hill climbing A simple
heuristic used by problem solvers in which they focus on making moves
that will apparently put them closer to the goal. Means--ends analysis A
heuristic method for solving problems based on creating a subgoal to
reduce the difference between the current state and the goal state.
Meta-reasoning Monitoring processes that influence the time, effort and
strategies used during reasoning and problem solving.

590

Thinking and reasoning

and reasoning and influence the strategies we adopt). One example is
progress monitoring. Problem solvers assess their rate of progress
towards the goal. If progress is too slow to solve the problem within
the maximum number of moves allowed, they change their strategy.
MacGregor et al. (2001) gave participants the nine-dot problem (see
Figure 12.5) with one line of the solution to help them. Performance was
worse when participants had the illusion of making progress (and so were
slow to switch strategies). Payne and Duggan (2011) also studied
progress monitoring. Participants received an unsolvable water-jar
problem with a small or large number of possible problem states. When
the problem had a small number of problem states, participants more
rapidly abandoned the problem because it was easier to perceive progress
towards a solution was impossible. Ackerman and Thompson (2017)
discussed other aspects of metacognition related to progress monitoring.
These include judgements of solvability, and feelings of rightness or
error when problem solvers produce an answer to any given problem, all
of which influence the decision as to whether to remain engaged in
problem solving.

Planning It is generally assumed individuals presented with a complex
problem engage in preliminary planning and that this planning involves
prefrontal areas associated with planning. Supportive evidence comes
from patients with damage to prefrontal areas, who typically have
impaired planning and problem solving (Szczepanski & Knight, 2014). Goel
and Grafman (1995) found patients with prefrontal damage performed worse
than healthy controls on the Tower of Hanoi task (see Figure 12.11). The
patients were especially disadvantaged on a difficult move involving
moving away from the goal because they found it harder to plan ahead.
Colvin et al. (2001) reported similar findings using water-jar problems.
Patients with prefrontal damage and healthy controls used the
hill-climbing strategy. However, the patients performed worse because
their deficient planning made it harder for them to make moves
conflicting with that strategy. As discussed earlier, prefrontal damage
can produce planning problems in everyday life. For example, Goel et
al. (2013) found patients with right prefrontal damage performed poorly
on a real-world travel planning task because their planning was too
Figure 12.12 piecemeal and insufficiently comprehensive. Tower of London
task (two-move and five-move problems). Dagher et al. (1999) used the
Tower of The balls in the bottom half must be rearranged to match the
arrangement in the top half. London task in which coloured discs must
From Dagher et al. (1999). By permission of Oxford University Press. be
moved one by one from an initial state to

Problem solving and expertise

match the goal state (see Figure 12.12). There was increased activation
of the dorsolateral prefrontal cortex when participants solved complex
versions of this task. In sum, the prefrontal cortex is important in
planning on many problem-solving tasks. However, many other brain areas
are also involved (Szczepanski & Knight, 2014).

Sequential processing stages Tasks such as the Tower of Hanoi and Tower
of London require planning a sequence of moves. However, we can
distinguish between plan production and plan execution. With complex
tasks, only some moves are typically planned, so executing the initial
plan is followed by generating a further plan and then its execution.
Crescentini et al. (2012) supported the distinction between plan
production and plan execution using simple versions of the Tower of
Hanoi task. The dorsolateral prefrontal cortex was more active during
initial planning than plan execution. In contrast, posterior temporal
areas, inferior frontal regions and dorsolateral premotor cortex were
more activated during plan execution. Nitschke et al. (2012) obtained
support for the assumption that Tower of London problems require
participants to engage in problem representation followed by planning.
On problems placing high demands on forming a problem representation,
participants alternated their gaze more often between the start and goal
state. On problems imposing high demands on planning, in contrast, the
last fixation of the start state was unusually prolonged.

How much planning? Newell and Simon (1972) assumed problem solvers
typically engage in limited planning because of the constraints of
short-term memory capacity. Patsenko and Altmann (2010) obtained strong
support using Tower of Hanoi problems. Sometimes they added, deleted or
moved discs during participants' eye movements so they were not directly
aware of the change. These changes only minimally disrupted performance,
strongly suggesting that the participants' next move was triggered by
the current state of the problem rather than a preformed plan. There are
substantial individual differences in planning for problem-solving
tasks. Koppenol-Gonzalez et al. (2010) found with the Tower of London
task that some participants engaged in efficient planning (considerable
preplanning of moves and high performance). In contrast, other
participants showed very little evidence of effective planning (short
period of preplanning and numerous errors). Most individual differences
in performance on this task can be explained by the single factor of
planning ability (Debelak et al., 2016). The amount of planning is very
flexible. Delaney et al. (2004) found little evidence of planning on
water-jar problems when participants chose their preferred strategy.
However, instructions to generate the complete solution before making
any moves led to detailed planning and

591

592

KEY TERMS Cognitive miser Someone who is economical with their time and
effort when performing a thinking task. Cognitive Reflection Test A test
assessing individuals' tendencies to override intuitive (but incorrect)
answers to problems.

Thinking and reasoning

faster problem solution. Morgan and Patrick (2013) argued that
increasing the cost of accessing important task-relevant information
(the goal state) on the Tower of Hanoi task would lead to more planning.
It produced increased planning and also led to problems being solved in
fewer moves. If planning involves deliberate processes, we would expect
problem solvers to be consciously aware of it. Evidence suggesting
important problem-solving processes occur below the level of conscious
awareness was reported by Paynter et al. (2010) using event-related
potentials (ERPs; see Glossary). They observed clear differences in the
ERPs associated with correct and incorrect moves early in the problem
when no behavioural evidence indicated participants were making
progress.

Cognitive miserliness Many theorists have proposed dual-process theories
to account for performance on cognitive tasks such as judgement,
decision-making and reasoning. Evans and Stanovich (2013; see Chapter
14) reviewed these theories and identified various commonalities among
them. Of particular importance, the theories distinguish two processes:
(1) Type 1 intuitive processes are fast and relatively effortless; and
(2) Type 2 reflective processes are slow and controlled. Most
dual-process theorists argue that many individuals are cognitive misers.
A cognitive miser is someone typically economical with their time and
effort on tasks requiring thinking. Cognitive misers would often respond
rapidly (but sometimes incorrectly) to problems using Type 1 processes
without checking their answer using Type 2 processes. The Cognitive
Reflection Test (Frederick, 2005), which assesses the extent to which
people are cognitive misers, involves a conflict between Type 1 and Type
2 processes. Why don't you take this very short test and then see how
many of your answers are correct?

IN THE REAL WORLD: COGNITIVE REFLECTION TEST (1) (2) (3)

A bat and a ball cost \$1.10 in total. The bat costs \$1.00 more than
the ball. How much does the ball cost? \_\_\_ cents. If it takes 5
machines 5 minutes to make 5 widgets, how long would it take 100
machines to make 100 widgets? \_\_\_ minutes. In a lake, there is a
patch of lily pads. Every day, the patch doubles in size. If it takes 48
days for the patch to cover the entire lake, how long would it take for
the patch to cover half the lake? \_\_\_ days.

The correct answers are 5 cents (problem 1), 5 minutes (problem 2) and
47 days (problem 3). Do not worry if you did not get them all right --
only about 25% of highly intelligent individuals answer all the items
correctly. Most incorrect answers (10 cents; 100 minutes; and 24 days)
are intuitive responses produced rapidly by individuals using Type 1
processes.

593

Problem solving and expertise

However, individuals producing incorrect answers often experience a
feeling of error (Gangemi et al., 2015), suggesting some awareness of
conflict. Low scorers on the Cognitive Reflection Test also perform
relatively poorly on many other judgement and reasoning tasks (Toplak et
al., 2014). This occurs in part because performance on the Cognitive
Reflection Test correlates positively with intelligence. However, scores
on the Cognitive Reflection Test predicted performance on several other
tasks after the effects of intelligence were removed statistically. This
finding suggests cognitive miserliness is found on many tasks. Travers
et al. (2016) found participants ultimately giving the incorrect
intuitive answer were not drawn to the correct answer at any point. This
suggests they did not use Type 2 reflective processes. In contrast,
participants ultimately producing the correct answer were nevertheless
initially drawn to the incorrect intuitive answer suggesting they
inhibited the incorrect intuitive answer. There is overlap between the
notion of cognitive miser and Newell and Simon's (1972) focus on problem
solvers' use of heuristics (discussed earlier, p. 589). In both cases,
individuals resort to simple (and often inaccurate) strategies. However,
Newell and Simon assumed our limited processing capacity forces us to
use heuristics. In contrast, cognitive misers use heuristics because
they are reluctant to engage in effortful processing rather than because
they cannot.

ANALOGICAL PROBLEM SOLVING AND REASONING Here we discuss analogical
problem solving. An analogy is "a comparison between two objects, or
systems of objects, that highlights respects in which they are thought
to be similar" (Stanford Encylopedia of Philosophy, 2013). Analogies are
very important -- we often cope successfully with novel situations by
relating them to situations encountered previously. Analogical
problem-solving performance correlates highly with IQ, leading Lovett
and Forbus (2017, p. 60) to argue "Analogy is perhaps the cornerstone of
human intelligence". More specifically, there are close links between
analogical problem solving and fluid intelligence, which "refers to the
ability to reason through and solve novel problems" (Shipstead et al.,
2016, p. 771). The most used test of fluid intelligence is Raven's
Progressive Matrices (Raven et al., 1998). It involves geometrical
analogies and requires analogical reasoning (see Figure 12.13).
Analogies have proved valuable in science. For example, the physicist
Ernest Rutherford argued electrons revolve around the nucleus as the
planets revolve around the sun. This analogy (like nearly all others)
has limitations -- planets in the solar system attract each other
through gravitational force whereas electrons repel each other.
Scientists working on the Mars Rover Mission used analogies when there
was high uncertainty about scientific issues. Why did they use
analogies? According to Chan et al. (2012, p. 1362), "Analogy supports
problem solving under uncertainty by narrowing the space of
possibilities to facilitate quick, approximate problem solving,
reasoning, and decision making."

KEY TERMS Analogy A comparison between two objects (or between a current
and previous problem) that emphasises similarities between them. Fluid
intelligence Non-verbal reasoning ability applied to novel problems.

594

Thinking and reasoning

Figure 12.13 A problem resembling those used on the Raven's Progressive
Matrices. The image from the bottom 8 images that best completes the top
3 x 3 matrix must be selected. From Lovett and Forbus (2017).

Analogical problem solving If we are to use a previous problem to solve
the present one, we must detect similarities between them. Chen (2002)
identified three main types of similarity between problems: (1) (2) (3)

Superficial similarity: solution-irrelevant details (e.g., specific
objects) are common to the two problems. Structural similarity: causal
relations between the main components are shared by both problems.
Procedural similarity: procedures (actions) for turning the solution
principle into concrete operations are common to both problems.

Chen (2002) gave participants a problem providing them with an analogy
having structural and procedural similarity with the target problem or
one having only structural similarity with it. Performance was
significantly better in the former condition because those participants
were more likely to find the correct procedures or actions to solve the
problem. With most analogical problems, participants must first retrieve
appropriate past experience or knowledge and then adapt it to make
explicit its relevance to the current problem. Gick and Holyoak (1980)
found retrieval failures often underlie people's inability to solve
analogical problems. They used a problem where a patient with a
malignant stomach tumour can only be saved by a special kind of ray
(Duncker, 1945). However, a ray strong enough to destroy the tumour will
also destroy the healthy tissue, whereas a ray that does not harm
healthy tissue will be too weak to destroy the tumour. Only 10% of
participants solved this problem when presented on its own. If you find
the above problem puzzling, here is an analogy. A general wants to
capture a fortress. However, the roads to it are mined, making it too
dangerous for the entire army to march along any one of them.

Problem solving and expertise

However, the mines were set so that small numbers of men could pass over
safely. The general had his army converge on the fortress at the same
time by walking along several different roads. Among participants who
had previously memorised the story about the general and the fortress,
80% of them solved the radiation problem when informed of its relevance.
However, only 40% of them solved it when not so informed. Why did so
many of Gick and Holyoak's (1980) participants fail to make spontaneous
use of the relevant, memorised story? Of relevance, there were no
superficial similarities between the story and problem. In contrast,
when the story was superficially similar to the problem (it involved a
surgeon using rays on a cancer), 88% of participants spontaneously
recalled it when given the radiation problem (Keane, 1987). Kubricht et
al. (2017) studied performance on Duncker's (1945) radiation problem as
a function of individual differences in fluid intelligence (see
Glossary) assessed by Raven's Progressive Matrices (discussed earlier,
p. 593). Individuals high in fluid intelligence performed much better
than low scorers when the radiation problem was preceded by a verbal
analogy (approximately 85% vs 40%, respectively). Thus, high
intelligence is a factor in facilitating effective use of analogies
(discussed further later, pp. 597--598). Gick and Holyoak (1980) used
the reception paradigm -- participants received detailed information
about a possible analogy before receiving a problem. However,
individuals in everyday life generally produce their own analogies: the
production paradigm. Blanchette and Dunbar (2000) confirmed that people
given the reception paradigm often selected analogies based on
superficial similarities. However, those given the production paradigm
mostly produced analogies sharing structural features with the current
problem. Experts (e.g., scientists) often use analogies because they
provide a major source of new concepts and ways of thinking about
problems. What kinds of analogies do experts use? Dunbar and Blanchette
(2001) studied laboratory discussions of leading molecular biologists
and immunologists. When they used analogies to fix experimental
problems, the previous problem was often superficially similar to the
current one. When they generated hypotheses, however, their analogies
involved fewer superficial similarities and considerably more structural
ones. Thus, the types of analogies used by scientists depend on their
current goal. Do experts mostly use distant analogies (i.e., those
linking different domains) or less distant within-domain ones? Dunbar
(1995) found that 98% of analogies were within-domain when experts
discussed issues with fellow experts. In contrast, more distant
analogies are used when scientific experts communicate with less expert
colleagues (Kretz & Krawczyk, 2014). This difference occurs because
within-domain analogies are generally more detailed and precise than
distant analogies.

Enhancing analogical problem solving How can we increase people's use of
analogies in analogical problem solving? There are two main approaches:
(1) increasing the encoding of the underlying structure of the current
problem; (2) increasing the use

595

596

Thinking and reasoning

of effective retrieval strategies. Minervino et al. (2017) adopted the
first approach. All participants were initially presented with the
fortress story. Some identified the similarities and differences between
Duncker's problem and another problem with a similar structure before
attempting Duncker's problem (experimental group). Others attempted
Duncker's radiation problem on its own (control group). Experimental
group participants were much more likely than control group participants
to solve the radiation problem (34% vs 9%, respectively). Their
performance was superior because they understood more clearly the
abstract or schematic structure of the radiation problem. Trench et
al. (2016) found simply instructing individuals to use analogies when
generating arguments to persuade a poor family to reduce its
indebtedness increased their use of analogies fourfold. Other
participants were instructed to use analogies drawn from areas not
directly related to economic issues (e.g., health; human relations).
This led to a substantial increase in arguments based on analogies
(especially structural analogies). In sum, most individuals rarely
produced analogies spontaneously but could easily do so when prompted.

Processes in analogical reasoning So far we have focused on analogical
problem solving. However, much research on analogies has involved
analogical reasoning. For example, consider four-term analogy problems
taking the form A:B::C:D (A is to B as C is to D; e.g.,
GLOVE:HAND::SOCK:FOOT). Participants decide whether the two-word pairs
express the same relationship (i.e., is it true that glove is to hand as
sock is to foot?). Alternatively, only the first three terms (i.e., A, B
and C) are provided with participants supplying the fourth term (i.e.,
D) themselves. Why are four-term analogy problems used so often in
research? They differ from analogical problem solving in that they are
tightly controlled -- all the necessary information is presented
explicitly and there is a single correct answer. These features
facilitate the task of understanding the underlying processes.

Sequential processing stages Analogical reasoning involves several
sequential processing stages. For example, Grossnickle et al. (2016)
identified four component processes: (1) (2) (3) (4)

Encoding: information concerning the problem stimuli is processed.
Inferring: identifying a relation (i.e., similarity) between two items.
Mapping: identifying the overall relational pattern or rule governing
the problem. Applying: using the outcome of the mapping process to
select the response completing the analogy.

Grossnickle et al. (2016) compared the performance of high and low
performers on tasks involving relational reasoning (including analogical

Conditional probabilities for each reasoning process

Problem solving and expertise

597 Figure 12.14 Probability of successful encoding P(E), successful
inferring given successful encoding P(I/E), successful mapping given
successful inferring P(M/I), and successful applying given successful
mapping for low and higher performers.

1 0.95 0.9 0.85 0.8 0.75 0.7

From Grossnickle et al. (2016). Reprinted with permission of Elsevier.

0.65 0.6 0.55 0.5 P(E) All participants

P(I\|E)

P(M\|I) Low performers

P(A\|M) High performers

reasoning). The probabilities of successfully completing each process
given the previous process had been successfully completed are shown in
Figure 12.14. The inference and mapping processes were the hardest
(especially for low performers). Vendetti et al. (2017) identified two
major strategies used by people solving four-term analogy problems.
According to project-first models, individuals first generate a rule
relating the A and B terms, then they map the A and C terms, and finally
they apply a rule generating D. According to alignment-mapping models,
individuals first align the A and C terms, and then align the B item
with the target (D item). Vendetti et al. (2017) used eye tracking to
identify which strategy was used. The strategy identified by
project-first models was used on 50% of trials. In contrast, the
strategy identified by alignment-mapping models was used on 34% of
trials. On average, reasoning performance was higher when the former
strategy was used.

Working memory Analogical reasoning is sufficiently complex for us to
predict it requires the central executive component of the working
memory system (see Glossary and Chapter 6). If so, problem-solving
performance should be impaired if a secondary task involving the central
executive is performed at the same time. That has been found with
four-term analogies (Morrison et al., 2001) and with Raven's Matrices
problems (Rao & Baddeley, 2013).

Individual differences We can increase our understanding of analogical
reasoning by studying individual differences in reasoning ability. Much
research has considered the relationship between analogical reasoning
and working memory capacity (the ability to process and store
information at the same time; see

598 Figure 12.15 Major processes involved in performance of numerous
cognitive tasks. From Shipstead et al. (2016).

Thinking and reasoning

Level 1 Executive attention/ goal state

Level 2 Active processing/ focal attention

Level 3 Physical environment

Top-down signal organises maintenance and disengagement around a goal.

Top-down executive signal

Maintenance

Disengagement

To-be-performed task

The emphasis of maintenance and disengagement in carrying out top-down
goals is partially determined by the nature of the to-beperformed task.
Task provides an environmental medium around which cognitive processes
are organised. Some tasks place a heavier burden on maintenance, others
on disengagement.

Glossary). Ackerman et al. (2005) found in a meta-analysis the average
correlation between measures of working memory capacity and performance
on Raven's Matrices (which requires analogical reasoning and involves
fluid intelligence) was +.49. Shipstead et al. (2016) identified key
processes associated with working memory capacity and fluid intelligence
(see Figure 12.15). Most cognitive tasks (Level 3) require top-down,
goal-focused executive attention (Level 1). Such tasks differ in the
extent to which they also require maintenance (keeping relevant
information accessible) and disengagement (removing or inhibiting
outdated information) (Level 2). In essence, fluid intelligence involves
executive attention + disengagement whereas working memory capacity
involves executive attention + maintenance. Evidence that fluid
intelligence and working memory capacity both involve executive
attention was reported by Clark et al. (2017). Frontalparietal brain
areas associated with executive attention were activated when
participants performed tasks involving working memory or fluid
intelligence. Harrison et al. (2015) obtained findings consistent with
the above theoretical approach using Raven's Matrices problems. Some
problems involved a repeated-rule combination (i.e., the same rule
combination as a previous problem) whereas others involved a novel-rule
combination (i.e., a rule combination not previously used). Harrison et
al. (2015) argued that individuals high in working memory capacity are
better than those with low working memory capacity at maintaining
information in memory. Accordingly, they should perform especially well
on Raven's Matrices problems with a repeated rule relative to those with
a novel rule. That is exactly what they found. In contrast, individuals
high in fluid intelligence (assessed by tests other than Raven's
Matrices) performed much better than those low in fluid intelligence
regardless of whether problems involved a repeated or a novel rule.

Problem solving and expertise

599

According to Shipstead et al.'s (2016) theoretical model, the excellent
analogical reasoning of individuals high in fluid intelligence depends
in part on their ability to disengage. An important aspect of
disengagement is the ability to think flexibly. With Raven's Matrices
problems, that often involves a re-representation of problem structure
by making it more abstract (Lovett & Forbus, 2017). For example,
consider a problem with an upward-facing arrow followed by a
rightward-facing arrow and then a downward-facing arrow. Participants
who re-represent these figures as an arrow rotating clockwise perform
better than those who do not. Lovett and Forbus (2017, p. 83) attach
great importance to re-representation: Re-representation is critical
because analogies are slaves to their symbolic representation. If two
cases happen to be represented with different relational structure, they
will fail to align, and the only way to complete the analogy will be to
change the structure. In sum, successful performance on Raven's Matrices
problems requires a high level of goal-focused executive attention. In
addition, it requires disengagement to inhibit task-irrelevant
information. Key aspects of the disengagement process are flexibility
and re-representation.

Brain mechanisms Krawczyk (2012) reviewed research on brain-damaged
patients and neuroimaging studies to identify brain areas involved in
analogical reasoning (see Figure 12.16): (1)

(2) 
(3) 
(4) 

Occipital and parietal areas are associated with visual and spatial
processing, followed by extensive involvement of the prefrontal cortex.
Left rostrolateral prefrontal cortex (centred on BA10) integrates
information within analogical problems. The dorsolateral prefrontal
cortex and inferior frontal gyrus are involved in inhibitory processes
to prevent distraction and interference. The temporal lobes are involved
because information about concept meanings (semantic memory) is stored
there.

Suppose you are given the following problem:
sandwich:lunchbox::hammer:\_\_\_\_

Figure 12.16 Summary of key brain regions and their associated functions
in relational reasoning based on patient and neuroimaging studies.
RLPFC, rostolateral prefrontal cortex; DLPFC, dorsolateral prefrontal
cortex; LIFG, left inferior frontal gyrus; Ctx, cortex. From Krawczyk
(2012). Reprinted with permission from Elsevier.

600

KEY TERM Expertise The high level of knowledge and performance in a
given domain that an expert has achieved through years of systematic
practice.

Thinking and reasoning

Possible answers are toolbox (correct), nail (a semantic distractor),
gavel (auctioneer's hammer, a perceptual distractor) and ribbon (an
irrelevant distractor). Krawczyk et al. (2008) argued inhibitory
processes involving the prefrontal cortex (brain area 3 above) are
required on such problems to avoid incorrect answers involving relevant
semantic or perceptual distractors. As predicted, patients with damage
to the prefrontal cortex were more likely than those with damage to the
temporal area to select semantic or perceptual distractors. The left
rostrolateral prefrontal cortex is of central importance in analogical
reasoning. Hobeika et al. (2016) conducted a meta-analysis of
neuroimaging studies (mostly using visuo-spatial analogies based on the
Raven's Progressive Matrices or verbal four-word analogy problems --
discussed earlier, pp. 596--597). The left rostrolateral prefrontal
cortex was consistently activated with both visuo-spatial and verbal
analogies, probably because of its involvement in mapping or relational
integration. Urbanski et al. (2016) studied analogical reasoning
performance in patients with frontal-lobe damage. Damage to the left
rostrolateral prefrontal cortex (including BA10 and 47) was more
consistently associated with impaired analogical reasoning than other
frontal damage. These findings fit well with those of Hobeika et
al. (2016). Other findings provide more direct support for the notion
that the left rostrolateral prefrontal cortex is involved in mapping or
relational integration. Green (2016) discussed his own research using
verbal four-term analogies (discussed earlier) varying in the difficulty
of mapping or relational integration. Activity within left rostrolateral
prefrontal cortex increased progressively as the demands on mapping
increased. In sum, research on brain mechanisms has identified the brain
areas associated with the major processes involved in analogical
reasoning. The consistent finding that the left rostrolateral prefrontal
cortex is strongly involved when individuals solve several different
analogical reasoning tasks implies (but not does prove) that these tasks
involve similar cognitive processes.

EXPERTISE So far we have mostly discussed studies where the time
available for learning was short, the tasks were relatively limited, and
prior specific knowledge was not required. In the real world, however,
people often spend many years acquiring knowledge and skills in a given
area (e.g., psychology; law; medicine; journalism). The end point of
such long-term learning is expertise. Expertise is "elite, peak, or
exceptionally high levels of performance on a particular task or within
a given domain . . . An expert's field of expertise can be almost
anything from craftsmanship, through sports and music, to science or
mathematics" (Bourne et al., 2015, p. 211). The development of expertise
resembles problem solving in that experts are extremely efficient at
solving numerous problems in their area or domain of expertise. However,
most traditional research on problem solving involved "knowledge-lean"
problems, requiring no special knowledge or training. In contrast,
studies on expertise typically use "knowledgerich" problems requiring
much knowledge beyond that contained in the

601

Problem solving and expertise

problem; this knowledge has typically been acquired through prolonged
practice and study. In what follows, we first consider chess expertise.
There are various advantages to studying chess. First, the ELO ranking
system (named after the chess master Arpad Elo) assesses chess players'
level of expertise. Second, expert chess players develop cognitive
skills (e.g., pattern recognition; selective search) of general
usefulness. Sala et al. (2017) discussed a meta-analytic review showing
chess instruction improves achievement in mathematics and overall
cognitive ability. Third, there are clear similarities between the
remarkable memory for chess positions shown by chess experts and the
vast knowledge experts in other domains have stored in long-term memory.
We then discuss medical expertise (especially medical diagnosis),
followed by a comparison of these two forms of expertise. After that, we
consider the role of brain plasticity in expertise. Finally, we evaluate
the hypothesis that deliberate practice is the main requirement for the
development of expertise and also consider alternative theoretical
approaches.

KEY TERM Template As applied to chess, an abstract schematic structure
consisting of a mixture of fixed and variable information about chess
pieces and positions.

CHESS-PLAYING EXPERTISE As already indicated, there are various reasons
why it is valuable to study chess-playing expertise. For example, we can
measure chess players' levels of skill precisely based on their results
against other players. In addition, the existence of permanent records
of chess players' tournament records over their entire career means
detailed longitudinal data are available for analysis. The most obvious
reason why some individuals are much better than others at playing chess
is that they have devoted far more time to practice -- it takes about
10,000 hours on average to become a grandmaster. Of special importance,
expert chess players have much more detailed information about chess
positions stored in long-term memory than non-experts. In classic
research, De Groot (1965) presented chess players with brief
presentations of board positions from actual games. After removing the
board, they reconstructed the positions. Chess masters recalled the
positions much more accurately than less expert players (91% vs 43%,
respectively). This does not reflect differences in memory ability --
there were no group differences when remembering random board positions.

Template theory What is the nature of the vast amount of chess-related
information experts have stored in long-term memory? Gobet (e.g., Gobet
& Waters, 2003) provided an influential answer in his template theory. A
template is an abstract, schematic structure more general than an actual
board position. Each template consists of a core (fixed information)
plus slots (containing variable information about pieces and locations).
Each template typically stores information relating to about ten pieces
although it can be larger. Templates' possession of slots makes them
adaptable and flexible in use. Templates are built up out of small
memory structures known as chunks (see Glossary).

Case study: Eye movements of expert chess players

602

Thinking and reasoning

Here are the main predictions of template theory: (1) (2)

(3) 
(4) 

Chess positions are stored in three templates, some of which are large.
Outstanding chess players owe their excellence more to their superior
template-based knowledge of chess than slow, strategy-based processes.
This knowledge can be accessed rapidly and permits expert players to
narrow down the possible moves they consider. Expert chess players store
away the precise board locations of pieces after studying a board
position. Chess pieces close together are most likely to be found in the
same template (Gobet & Simon, 2000). Expert players have superior recall
than non-experts of random chess positions. The reason is they are
better at recognising small chunks occurring by chance even in random
positions. However, the memory superiority of experts should be greater
with structured positions because experts can use their greater template
knowledge as well as their greater chunk knowledge.

Findings

Fernand Gobet. Courtesy Fernand Gobet.

Gobet and Clarkson (2004) reported support for the first prediction.
Expert players recalled chessboard positions much better than novices.
However, the number of templates (averaging out at about 2) did not vary
as a function of playing strength. The maximum template size was 13--15
for masters compared to only about 6 for novices. Evidence relating to
the second prediction is less consistent. Charness et al. (2001)
reported supportive evidence. Expert players were significantly more
likely than intermediate players to fixate tactically relevant pieces
very rapidly (within about 1 second). Sheridan and Reingold (2017a)
presented four chess positions at the same time and asked chess players
to find the one allowing the knight to reach a target square in three
moves. Expert players' eye movements indicated they were much faster
than novices to fixate the target board. Further support was reported by
Burns (2004), who focused on blitz chess (the entire game must be
completed in 5 minutes). He assumed performance in blitz chess must
depend mainly on players' template-based knowledge because there is
insufficient time to engage in slow searching through possible moves. As
predicted, performance in blitz chess correlated highly (+.78 to +.90)
with performance in standard chess. Evidence less supportive of the
second prediction was reported by van Harreveld et al. (2007) and Chang
and Lane (2016). Skill differences between players were less predictive
of game outcome as the time available decreased suggesting slow
processes are more important for strong than weak players. Chang and
Lane studied speed chess (longer than blitz chess but much shorter than
standard chess). Players (especially stronger ones) often spent a
considerable amount of time on a few moves indicating they were using
strategy-based processes.

Problem solving and expertise

Moxley et al. (2012) asked experts and tournament players to think aloud
while selecting the best possible moves with several problems. Their
final move was generally much stronger than the first move considered
for both groups (see Figure 12.17). Thus, slow, strategy-based processes
play a key role in chess. We turn now to the third prediction. Chess
players typically recall the precise squares occupied by given pieces
within a template when asked to memorise board positions. However,
actual chess playing focuses much more on evaluating board positions.
McGregor and Howes (2002) asked expert players to evaluate various chess
positions. These players subsequently had much better memory for
attack/defence relations than precise board locations of the pieces.
Linhares et al. (2012) found grandmasters outperformed masters, more
with respect to memory for abstract features (e.g., strategically
significant attacks or defences) than superficial features (e.g.,
specific board positions). The fourth prediction is that expert players
will have better recall than nonexperts of random chess positions.
Supporting evidence was reported by Sala and Gobet (2017) in a
meta-analysis. As predicted, the beneficial effects of expertise on
recall of random chess positions were smaller than those obtained
previously in structured chess positions.

Figure 12.17 Mean strength of the first-mentioned chess move and the
move chosen as a function of problem difficulty by experts (top panel)
and by tournament players (bottom panel). From Moxley et al. (2012).
With permission from Elsevier.

Evaluation Template theory has several successes to its credit. First,
much of the information experts store from board positions consists of a
few large templates. Second, outstanding chess players possess much more
knowledge about chess positions than experts, which gives them a
substantial advantage when playing chess. Third, the tendency of experts
to win at blitz chess is due mainly to their superior template-based
knowledge (Burns, 2004). Fourth, experts have better recall of random
board positions than non-experts (Sala & Gobet, 2017). What are the
limitations of template theory? First, slow search processes are more
important to expert players than assumed by the theory (Moxley et al.,
2012; van Harreveld et al., 2007). This is even the case with speed
chess (Chang & Lane, 2016). Second, the most expert players often use
strategies allowing them to go beyond stored knowledge of chess
positions. Bilalić et al. (2008a)

603

604

Thinking and reasoning

presented chess players with a problem solvable in five moves using a
familiar strategy but in only three moves using a less familiar
solution. International Masters were far more likely than Candidate
Masters to find the shorter solution (50% vs 0%) because they were
better at avoiding the familiar, template-based solution. Third, the
precise nature of the information stored in long-term memory remains
controversial. Template theory assumes the precise locations of pieces
are typically stored. However, it is likely attack/defence relations are
more important (Linhares et al., 2012; McGregor & Howes, 2002).
According to the theory, chess players have stored information in the
form of chunks and templates. However, it is often hard to identify
their respective roles. Fourth, template theory de-emphasises the
importance of cognitive ability. Grabner et al. (2007) found all chess
masters they studied had above-average intelligence. In addition,
intelligence correlated significantly with the players' rated skill
level. Burgoyne et al. (2016) found in a metaanalytic review that chess
skill correlated positively with several aspects of cognitive ability
(e.g., processing speed; fluid reasoning, which involves understanding
novel relationships).

MEDICAL EXPERTISE The processes involved in chess-playing expertise may
(or may not) resemble those involved in other forms of expertise.
Accordingly we will now consider medical expertise, specifically the
ability of medical experts to make rapid and accurate diagnoses. This
ability can literally be a matter of life-or-death. We will focus mostly
on the search for abnormalities in medical images (e.g., X-rays; brain
scans). Various methods have been used including eye-tracking and the
think-aloud technique (Gegenfurtner et al., 2017). Eye-tracking can
provide useful information about visual attention and subconscious
processes, and think-aloud data can shed light on individuals' eye
fixations and decision-making. How do medical experts' strategies differ
from those of non-experts? One approach assumes there are three main
reasons why abnormalities in medical images fail to be detected (see
Figure 12.18): (1) (2) (3)

There are detection errors when the crucial area within the image is not
fixated. There are recognition errors when the crucial area is fixated
briefly but the doctor fails to appreciate its significance. There are
judgemental errors when the crucial area is fixated for some time
(indicating it raised some concern) but its significance is not fully
appreciated.

The most obvious prediction is that experts will have fewer errors of
all three types than non-experts. Figure 12.18 indicates three processes
of relevance to the various error types. First, there is global or
holistic perception of the image; if that is incomplete or ineffective,
detection errors will occur. Second, there is focal or selective
processing, involving deeper processing of only certain specific visual
elements; failure of such processing leads to recognition errors.

Problem solving and expertise

Global perception of the scene for identifying areas of value

Insuﬃcient searching skills detection error Missing cues

Selectivity for deeper processing

Insuﬃcient perceptual processing time recognition error

Pattern matching

Insuﬃcient analysis skills judgemental error

Decision-making

Decisional error

Figure 12.18 A theoretical framework of the main cognitive processes and
potential errors in medical decision-making. From Al-Moteri et
al. (2017). Reprinted with permission of Elsevier.

Third, there is pattern matching, which involves finding a match between
the visual medical image and patterns stored in long-term memory;
failure of such processing leads to judgemental errors. There is an
important distinction between explicit and implicit reasoning (Engel,
2008). Explicit reasoning is slow, deliberate and is associated with
conscious awareness. In contrast, implicit reasoning is fast,
"automatic" and not associated with conscious awareness. It involves the
global processing identified by Al-Moteri et al. (2017; see Figure
12.18). Dual-process theories of judgement (see Chapter 13) and
reasoning (see Chapter 14) are based on a similar distinction. The
crucial assumption is that medical experts engage mainly in implicit
reasoning whereas novices rely mostly on explicit (analytic) reasoning.
This assumption makes sense given that experts have substantially more
relevant visual and other knowledge stored in long-term memory. As a
result, they can often rapidly engage in pattern matching (i.e.,
relating a given medical image to stored knowledge). We will consider
evidence relevant to the above explicit--implicit distinction with
respect to visual specialities (e.g., pathology; radiology). Note that
experts generally cross-check their diagnoses with slow, deliberate
processes even if they start with fast, "automatic" ones (McLaughlin et
al., 2008).

Findings Sheridan and Reingold (2017b) reviewed research testing the
hypothesis that experts engage in holistic or global processing. One
prediction based

605

606

Figure 12.19 Eye fixations of a pathologist given the same biopsy
whole-slide image starting in year 1 (a) and ending in year 4 (d).
Larger circles indicate longer fixation times. From Krupinski et
al. (2013). Reprinted with permission from Elsevier.

Thinking and reasoning

on this hypothesis is that experts can extract useful information from
rapidly presented images. Kundel and Nodine (1975) found expert
radiologists detected abnormalities very rapidly. Chest radiographs were
presented for only 200 milliseconds but were correctly interpreted 70%
of the time. Another prediction is that medical experts should be better
able than non-experts to make use of information presented in peripheral
vision. Several studies support this prediction. Krupinski et al. (2013)
carried out a longitudinal study of pathologists viewing breast biopsies
at the start of their first, second, third and fourth years of
residency. Over time, there was a substantial reduction in fixations per
slide and less examination of non-diagnostic regions (see Figure 12.19).
Thus, training produced enhanced attentional focus. Kundel et al. (2007)
showed doctors experienced in mammography difficult mammograms showing
or not showing cancer. The mean time taken by experts to fixate a cancer
was typically under 1 second. Time of first fixation on the cancer
correlated --0.9 with performance (i.e., accurately detected breast
cancer). Thus, fast fixation was an excellent predictor of performance.
The rapid detection of abnormalities by experts suggests they engage in
pattern matching (matching medical images to images stored in longterm
memory). Of relevance, Jaarsma et al. (2014) considered how experts and
non-experts explained their diagnoses after viewing medical images.

Problem solving and expertise

Experts were much more likely to use terms such as "typical", "regular"
and "increase of" suggesting their diagnoses were based on comparisons
between presented and stored images. Nodine and Mello-Thoms (2010)
argued that experts use a detect-thensearch process, starting with rapid
detection of diagnostically relevant information followed by a brief
search to check there is no other relevant information. In contrast,
novices use a search-then-detect process, involving extensive visual
search and including much irrelevant information, followed by eventual
detection of diagnostically relevant information. Brunyé et al. (2014)
found novices were more likely than experts to fixate salient visual
areas (e.g., brightly coloured ones) lacking diagnostic relevance.
According to the theoretical framework shown in Figure 12.18, many
detection failures occur even though the crucial area is fixated.
Manning et al. (2006) studied nodule detection in chest radiology.
Correct negative decisions (i.e., no nodule) were made faster than
incorrect negative decisions. In the latter case, participants often
fixated the nodule and were suspicious of it but failed to recognise it
as a nodule. Rubin et al. (2015) studied the detection of very small
lung nodules by experienced radiologists. The best performer detected
82% of fixated nodules whereas the worst performer detected only 47%.
According to Al-Moteri et al. (2017), failures to detect abnormalities
in medical images can occur because of judgemental errors. They
discussed several studies in which medical experts sometimes fixated an
abnormality for more than 1 second but failed to report it. Such
findings are suggestive of judgemental errors. Are the effects of
expertise on eye movements similar across different domains or areas?
Gegenfurtner et al. (2011) reported a meta-analytic review involving
domains including medicine, sport and transportation. Several
differences between experts and non-experts were common across domains:
(1) shorter fixations; (2) faster first fixations on task-relevant
information; (3) more fixations on task-relevant information; (4) fewer
fixations on task-irrelevant areas; and (5) longer saccades (rapid eye
movements). We turn now to the roles of implicit and explicit (analytic)
reasoning. Melo et al. (2012) argued medical experts use similar
implicit or relatively "automatic" processes to those we all use when
perceiving visual scenes. They found comparably fast times to diagnose
abnormalities in chest X-ray images and to name animals (1.33 vs 1.23
seconds, respectively). Of most importance, diagnosing abnormalities and
naming animals involved activation in very similar brain regions (see
Figure 12.20). However, diagnosing abnormalities was associated with
greater activation in the frontal sulcus and posterior cingulate cortex,
suggesting diagnosis is more cognitively demanding than naming animals.
Naming letters involved similar brain regions to diagnosing
abnormalities and naming animals but with less activation. How can we
explain the above findings? Melo et al. (2012) suggested medical experts
engage in rapid pattern recognition: each slide is compared against
stored patterns from the past. In other words, they use a predominantly
visual strategy. Kulatunga-Moruzi et al. (2004) asked three groups
varying in expertise to diagnose skin diseases from photographs. Some
participants made their decisions from the photographs alone whereas
others were also given a

607

608

Thinking and reasoning

Figure 12.20 Brain activation while diagnosing lesions in X-rays, naming
animals and naming letters. The first column provides a right view, the
middle column a left view and the last column a posterior view. From
Melo et al. (2012).

comprehensive verbal description before each photograph. The least
expert group performed best when given the verbal descriptions plus the
photographs. In contrast, the more expert groups performed better
without the verbal descriptions. They used a rapid visual strategy and
the verbal descriptions interfered with their ability to use that
strategy effectively. In spite of the above evidence, experts typically
make some use of slow, explicit or analytic processes. Mamede et
al. (2010a) compared the performance of medical experts and non-experts
providing diagnoses immediately or after some analytic thinking.
Analytic thinking enhanced the diagnostic performance of experts with
complex cases but not simple ones. In contrast, non-experts derived no
benefit from engaging in analytic thinking.

Evaluation The diagnostic strategies used by medical experts and
non-experts often differ considerably. Experts use fast holistic
processes more than nonexperts. In addition, experts are more proficient
than non-experts at using

609

Problem solving and expertise

slow, explicit or analytic processes. More generally, incorrect
diagnoses can result from detection, recognition or judgemental errors.
What are the limitations of theory and research? First, there are very
few longitudinal studies (apart from Krupinski et al., 2013). Such
studies are essential to understand the learning processes involved in
the development of expertise. Second, we need more research on the ways
fast and analytic processes are combined. For example, Kulatunga-Moruzi
et al. (2011) found nonexperts benefited from this combination when fast
processes preceded analytic ones but not when analytic processes came
first. Third, relatively little research has compared different training
programmes designed to enhance diagnostic accuracy. Such research could
clarify the advantages and disadvantages of different diagnostic
strategies.

Chess expertise vs medical expertise Chess and medical expertise have
several similarities. First, intensive training is required to attain
genuine expertise. Second, this training leads to the acquisition of
huge amounts of relevant stored knowledge. Third, experts in both areas
are superior to non-experts at using rapid (apparently "automatic")
processes. Fourth, experts in both areas use analytic or strategy-based
processes effectively when necessary. What are the differences between
chess and medical expertise? First, while much of the knowledge
possessed by chess experts consists of fairly abstract templates,
medical experts are more likely to possess knowledge that is less
abstract and more visual. Second, chess experts must relate a current
chess position to their stored knowledge and then consider their
potential next move and that of their opponent. In contrast, medical
experts focus more narrowly on relating information about a specific
case to their stored knowledge.

BRAIN PLASTICITY The development of expertise involves acquiring huge
amounts of knowledge and specialised cognitive processes. Does the
development of expertise also cause modifications within the brain? The
key concept here is plasticity: "changes in structure and function of
the brain that affect behaviour and are related to experience or
training" (Herholz & Zatorre, 2012, p. 486). It is often assumed
structural changes resulting from plasticity facilitate further learning
and the development of expertise. Before discussing research on
expertise, we will mention compelling evidence for plasticity in
individuals becoming blind at an early age. They exhibit high levels of
activity in occipital cortex (typically involved in visual processing)
when performing many non-visual tasks (e.g., reading Braille; localising
sound) (Heimler et al., 2014). This is known as cross-modal plasticity.

Taxi drivers Important research was carried out on London taxi or cab
drivers, who have to acquire "The Knowledge". This consists of detailed
knowledge

KEY TERM Plasticity Changes within the brain occurring as a result of
brain damage or experience.

610

Thinking and reasoning

of the 25,000 streets within 6 miles of Charing Cross and the locations
of thousands of hospitals, tube stations and so on. Unsurprisingly, it
takes three years to acquire all this information. How do cab drivers
develop this extraordinary knowledge and expertise? The hippocampus (an
area within the medial temporal lobes) is of major importance, as might
be expected given its central role in long-term memory (see Chapter 6).
Hippocampal damage is also associated with impaired spatial navigation
skills (McCormick et al., 2018). Unsurprisingly, a taxi driver who had
recently suffered extensive hippocampal damage had severely impaired
navigation skills (Maguire et al., 2006). Acquisition of "The Knowledge"
probably has a direct effect on the hippocampus. Experienced London cab
drivers have a greater volume of grey matter in the posterior
hippocampus than novice drivers (Woollett et al., 2009). However, cab
drivers have a smaller volume of grey matter than other people in the
anterior hippocampus. This is an area used in processing novel stimuli,
imagining events and recalling events (Zeidman & Maguire, 2016). The
finding that cab drivers perform poorly on tasks requiring them to learn
and remember new object-place associations may reflect their reduced
grey matter in the anterior hippocampus (Woollett & Maguire, 2009).

Causality The findings discussed so far are correlational and so cannot
show acquiring "The Knowledge" causes hippocampal changes. Somewhat more
direct evidence was reported by Woollett and Maguire (2011). Among
adults who had spent several years acquiring "The Knowledge", only those
who succeeded in becoming London taxi drivers had a selective increase
in grey matter in their posterior hippocampus. Hyde et al. (2009)
studied 6-year-old children who received 15 months of instrumental
musical training. They showed significant changes in voxel size (a voxel
is a small cube of brain tissue) in the primary motor area (see Figure
12.21) and the primary auditory area (see Figure 12.22). In addition,
children having the greatest brain changes showed the greatest
improvement in musical skills. More evidence that training can alter
brain structure was reported by de Manzano and Ullén (2018). They
studied monozygotic (identical) twins where one twin had received at
least 1,000 hours of piano practice more than the other, thus
controlling for genetic factors. The brains of the more musically
trained twins differed in various ways from the less trained ones (e.g.,
they had greater cortical thickness within the auditory-motor network).
Herholz et al. (2016) carried out a longitudinal study in which adults
received six weeks of training in playing the piano. There was evidence
for plasticity: training enhanced activity in brain areas (e.g.,
premotor and posterior parietal regions) involved in motor preparation
and sensorimotor integration. Other brain areas (e.g., parts of the
primary auditory cortex; premotor cortex) predicted individuals'
learning rates during piano training. These brain areas reflected
individual differences in predisposition (potential for learning musical
skills). In sum, these findings emphasise the value of considering
individual differences in pre-training brain activity (predisposition).

Problem solving and expertise

611

Figure 12.21 The brain image shows areas in the primary motor cortex
with differences in relative voxel size (a voxel is a small cube of
brain tissue) between children receiving 15 months of instrumental music
training and non-trained controls: (a) changes in relative voxel size
over time in trained and non-trained groups (a value of 1.00 indicates
no change); (b) correlation between amount of improvement in motor-test
performance and change in relative voxel size for all participants. From
Hyde et al. (2009). Reprinted with permission of The Society for
Neuroscience. Permission conveyed through Copyright Clearance Center,
Inc.

Evaluation Numerous studies have shown predictable differences in brain
structure and function between individuals with varying amounts of
training in a given domain (Zatorre, 2013). Support for the hypothesis
that developing expertise can cause changes in brain structure has come
from longitudinal studies where brain structure was assessed before,
during and after training and from de Manzano and Ullén's (2018) study
on monozygotic twins. Progress has been made in identifying brain areas
associated with predisposition (potential for learning) and
training-related plasticity during learning (e.g., Herholz et al.,
2016). What are the limitations of research on plasticity and expertise?
First, it is hard to show definitively that practice has caused changes
in brain structure of relevance to performance improvement. Second, most
research has focused on musical training. This is reasonable given that
musical training influences auditory perception and several aspects of
higher-level cognition. However, it means the relevant database is
relatively narrow.

612

Thinking and reasoning

Right Heschl's gyrus

Figure 12.22 Brain image showing areas in the primary auditory area with
differences in relative voxel size between trained children and
non-trained controls: (a) changes in relative voxel size over time; (b)
correlation between improvement in melodyrhythm test and change in
relative voxel size From Hyde et al. (2009). Republished with permission
of The Society for Neuroscience. Permission conveyed through Copyright
Clearance Center, Inc.

KEY TERMS Deliberate practice This is an effective form of practice
provided that learns are given a task of moderate difficulty repeatedly,
and have informative feedback so they can correct their errors.

Third, many complex effects of practice on neural plasticity have been
reported in the literature. For example, Vaquero et al. (2016) found
expert pianists had greater grey matter volume than controls in the
putamen (involved in motor control and reinforcement learning). However,
these experts had smaller grey matter volume than controls in other
brain areas (e.g., superior temporal gyrus) involved in auditory
processing and sensorimotor control. We lack a coherent theoretical
understanding of such complexities.

DELIBERATE PRACTICE AND BEYOND We have seen deliberate practice over a
period of many years is essential to become an expert in a given domain.
That is obvious. Less obvious are the answers to two related issues.
First, what determines the effectiveness of prolonged practice? Second,
what factors other than prolonged practice are required to become an
expert?

Problem solving and expertise

613

Ericsson (e.g., 2017) argued that the answer to the first question is
deliberate practice. More specifically, he claimed that ten years
(10,000 hours) of deliberate practice is required to achieve expertise.
Controversially, he claimed such practice is the most important factor
required to develop expertise and that innate talent or ability is of
little or no relevance. Deliberate practice has four aspects: (1) (2)
(3) (4)

The task is at an appropriate level of difficulty (not too easy or
hard). The learner is given informative feedback about their
performance. The learner has adequate chances to repeat the task. The
learner has the opportunity to correct their errors.

What happens as a result of prolonged deliberate practice? According to
Ericsson and Kintsch (1995), experts can reduce the negative effects of
having limited working memory capacity. They put forward the notion of
long-term working memory. The crucial notion is that "fast . . .
transfer to LTM \[long-term memory\] becomes possible with expertise via
knowledge structures, which enables LTM \[long-term memory\] to be used
during WM \[working memory\] tasks, thus giving the appearance of
expanding individuals' WM capacity" (Guida et al., 2013, p. 1). Suppose
expert and novice chess players learn the positions of chess pieces on a
board. Novices rely largely on working memory (a limitedcapacity system
that processes and stores information briefly; see Chapter 6). In
contrast, experts use their huge relevant knowledge to store much of the
information directly in long-term memory and thus enhance their recall
of the board position. In other words, experts use long-term working
memory, but novices do not.

IN REAL LIFE: MAGNUS CARLSEN, WORLD CHESS CHAMPION The Norwegian Magnus
Carlsen was born on 30 November 1990. He became a chess grandmaster at
the amazingly young age of 13 and the world chess champion in November
2013 (aged 22). In 2014, he was rated the strongest player in chess
history. The difference between him and the second-best player (Levon
Aronian) was almost as great as that between the 2nd and 14th best
players. One of his greatest strengths is his "nettlesomeness" --
meaning he is a vexatious individual who is superb at making moves that
pressurise opponents into Magnus Carlsen, who became world chess
champion in 2013. making mistakes. dpa Picture-Alliance/Alamy Stock
Photo. Magnus Carlsen disproves the main assumptions of Ericsson's
deliberate practice theory. First, he became a grandmaster after only
five years of deliberate practice although Ericsson claimed ten years of
deliberate practice are required to achieve outstanding levels of
performance.

614

Thinking and reasoning

Second, according to Ericsson's theory, we would expect Magnus Carlsen
to have accumulated more years of deliberate practice than other top
chess players. However, when he became world champion, he had devoted 6½
years fewer to deliberate practice than the average of the next 10 best
players in the world (Gobet & Ereku, 2014). Across the top 11 players in
the world, the association between rating and number of years of
practice was modestly negative. According to Ericsson's theory, it
should have been strongly positive. In sum, Magnus Carlsen's career
shows that talent and deliberate practice are both essential for the
development of outstanding expertise. Indeed, Carlsen's extraordinary
talent has led to him being called "the Mozart of chess".

KEY TERM

Findings: positive

Long-term working memory Used by experts to store relevant information
rapidly in long-term memory and to access it through retrieval cues in
working memory (see Glossary).

Ericsson and Chase (1982) demonstrated the powerful effects of
deliberate practice. A student, SF, received extensive practice (one
hour a day for two years) on the digit-span task (random digits are
recalled immediately in the correct order). He increased his digit span
from 7 digits to 80 (10 times the average performance level). SF made
use of his great knowledge of running times (e.g., "3594" was
Bannister's world-record time for the mile and so he stored these digits
as a single unit or chunk). After that, he organised chunks into a
hierarchical retrieval structure. Thus, SF made very effective use of
long-term working memory. Another student (Dario Donatelli) increased
his digit span from 8 to 104 digits following 800 hours of practice
(Yoon et al., 2018). Guida et al. (2012) reviewed neuroimaging studies
comparing novices and experts performing working memory tasks. There
were two main findings. First, experts and novices both showed
activation in prefrontal and parietal areas associated with working
memory processes. Second, only experts showed activation in medial
temporal regions strongly associated with long-term memory. This finding
suggests experts make more use than novices of long-term memory
processes during task performance. To what extent can individuals' level
of expertise be accounted for by individual differences in deliberate
practice? Campitelli and Gobet (2011) found across many studies on
chess-playing expertise that the correlation between total practice
hours and chess skill exceeded +.50. However, such correlational
evidence cannot prove that the former directly caused the latter.

Research activity: Skill acquisition

Findings: negative We turn now to findings indicating that expertise
does not depend mainly on deliberate practice. Macnamara et al. (2014)
found in a meta-analytic review that the average correlation between
deliberate practice and performance was +.35, which suggests deliberate
practice explains 12% of the variance in performance. However, the
percentage of the variance explained differed considerably across
domains: it was 26% for games, 21% for music, 18% for sports, but only
4% for education and \<1% for the professions.

Problem solving and expertise

Macnamara et al. (2016b) confirmed in a further meta-analytic review
that deliberate practice accounted for 18% of the variance in sports
performance. However, when they focused on elite samples, deliberate
practice explained only 1% of the variance in sports performance. How
can we explain this last finding? Nearly all elite individuals have
benefited from excellent environmental conditions (e.g., prolonged
deliberate practice; top-class coaching) and so individual differences
in expertise probably reflect genetic rather than environmental factors.
More direct evidence was reported by Güllich (2017). Those sports people
who had won medals at Olympic and/or world championships accumulated
fewer hours of deliberate practice across their careers than
non-medallists. Campitelli and Gobet (2011) identified three predictions
from deliberate practice theory: (1) (2) (3)

All individuals engaging in massive distributed practice should achieve
very high skill levels. The variability across individuals in the number
of hours required to achieve high expertise should be small. Everyone's
skill level should benefit comparably from any given amount of
distributed practice.

Campitelli and Gobet (2011) considered the above three predictions with
reference to chess. None was supported. So far as the first prediction
is concerned, there are several chess players who have devoted over
20,000 hours to practice without becoming masters. With respect to the
second prediction, the practice hours required to achieve master level
varied between 3,000 and 23,600 hours. Evidence against the third
prediction was reported by Howard (2009). He studied candidates (elite
players who have competed for the right to challenge the world
champion); non-candidate grandmasters (elite players but less expert
than candidates); and non-grandmasters. Their skill ratings as a
function of games played are shown in Figure 12.23. There are two points
of interest. First, these three groups showed clear performance
differences early on which increased over games. Second, players in all
groups showed no improvement after playing about 750 games. Howard
(2009) found additional evidence of a performance ceiling among five
players who had played over 2,300 games (representing more than 8,000
hours' playing time!). These players showed no improvement over the last
1,000(+) games they played. Thus, the beneficial effects of deliberate
practice are limited. The above findings suggest it is possible early in
their careers to identify those who will eventually become outstanding
chess players, suggesting they have very high natural talent. The same
is true in sports such as tennis and golf (think of Federer, the
Williams sisters and Woods). The findings also suggest there is a
ceiling on the performance level any individual can attain based on
their natural talent. The finding that deliberate practice typically
correlates positively with expert performance does not necessarily mean
the former causes the latter. For example, individuals with much innate
talent are likely to enjoy early

615

616

Thinking and reasoning

Figure 12.23 Mean chess ratings of candidates, non-candidate
grandmasters (GMs) and all non-grandmasters as a function of number of
games played. From Howard (2009). With kind permission from Springer
Science+Business Media.

success, which may motivate them to devote more time to deliberate
practice than those with less talent. Thus, performance level can
influence the amount of practice. Dramatic evidence supporting the above
point of view was reported by Mosing et al. (2014) in a twin study on
music practice and music ability. Genetic factors accounted for 40%--70%
of individual differences in hours of music practice -- this probably
occurred because individuals with more innate talent practised more. Of
importance, there was no difference in music ability between monozygotic
(identical) twins even when they differed in the amount of music
practice. Thus, the relationship between music practice and music
ability depended mostly on genetic factors.

Evaluation Memory in a domain of expertise can be developed via the use
of long-term working memory and this can reduce limitations on
processing capacity. However, enhanced storage of domain-relevant
information forms only part of what is required to develop expertise.
Unsurprisingly, nearly all the evidence supports the contention that
prolonged deliberate practice is necessary to achieve outstanding levels
of expertise. What are the theory's limitations? First, it is hard to
test because of vague definitions. For example, "deliberate practice"
sometimes refers to teacher- or coach-designed activities and sometimes
to solitary practice (Hambrick et al., 2018), and several definitions of
"expert" have been used (Macnamara et al., 2016a). Second, Ericsson's
research is narrow in scope. Most factors influencing expertise could
not be identified because of their focus on deliberate practice (see
below, pp. 617--619). Even with such narrow research, individual
differences in deliberate practice are only moderately related to
performance (e.g., Macnamara et al., 2014, 2016b). Third, Ericsson
emphasised the role of long-term working memory (see Glossary) in
expertise. Experts use stored structures in long-term memory

617

Problem solving and expertise

to enhance working memory performance. However, it is not necessary to
hypothesise the existence of a brand new form of working memory
(Baddeley, 2012). Fourth, it is assumed deliberate practice causes
expertise. This begs the question of why individual differences in
distributed practice exist. The evidence suggests naturally talented
individuals are more motivated to devote substantial time to deliberate
practice than less talented individuals. Fifth, deliberate practice
theory provides an extreme environmentalist approach to understanding
the development of expertise. As such, it ignores several factors (e.g.,
intelligence; gene-environment interactions) of demonstrable importance
to expertise (Ullén et al., 2016; see below). Sixth, the importance of
deliberate practice depends on the domain (or area) of expertise
(Macnamara et al., 2014). Deliberate practice influences the development
of expertise more in relatively specific domains (e.g., increasing digit
span) than in much broader and more complex ones (e.g., succeeding in
the professions) (Gottfredson, 1997; discussed below). Seventh, the
theory is very oversimplified. Its assumption that deliberate practice
is sufficient (as well as necessary) for the development of expertise is
wrong.

Beyond deliberate practice: multifactorial gene-environment interaction
model As we have seen, deliberate practice is not the only important
factor determining the development of expertise. Ullén et al. (2016)
used findings such as those discussed above to develop their
impressive-sounding multifactorial gene-environment interaction model
(see Figure 12.24).

Neural mechanisms

Abilities General IQ Narrow abilities

LTM-WM Sensorimotor skills

Personality Grit/conscientiousness Openness Impulsivity

Interests Motivation

Genes

Expertise Deliberate practice

Physical properties Muscle strength Height Size of body and extremities

G-E covariation

Environment

Figure 12.24 The main factors (genetic and environmental) influencing
the development of expertise. Many of these factors interact with each
other. From Ullén et al. (2016).

618

Thinking and reasoning

What are the main assumptions of this model?

KEY TERMS Gene-environment interaction Individuals differing in their
genetic make-up respond in different ways to environmental variation.

(1) 

Gene-environment correlation Genetic differences between individuals
partly determine the different environments they experience.

(3) 
(4) 
(5) 
(6) 
(7) 

Hambrick et al. (2018, p. 291) pointed out, "At the core of MGIM
\[multifactorial gene-environment interaction model\] is the assumption
that expertise is multiply determined." The development of expertise
depends on both domain-specific knowledge and skills (fostered by
deliberate practice) and domain-general abilities (e.g., intelligence;
personality). There is gene-environment interaction (the magnitude of
genetic influences on performance varies as a function of the nature of
environmental experiences). There is gene-environment correlation
(individuals experience different environments as a function of their
genetic make-up). Deliberate practice increases expertise in part by
modifying neural mechanisms (e.g., brain plasticity). Individual
differences in deliberate practice are determined in part by genetic
factors relating to personality, abilities and motivation.

Findings There is considerable evidence supporting the second assumption
above. Hambrick et al. (2019) reviewed research indicating that
expertise in many areas depends on the domain-general ability of
intelligence or cognitive ability. As we saw earlier, intelligence is
positively correlated with chess expertise (Burgoyne et al., 2016).
Evidence indicating that intelligence or IQ influences the development
of expertise was reviewed by Gottfredson (1997). The correlation between
IQ and work performance was +.58 for high-complexity jobs (e.g.,
biologist; city circulation manager). In addition, the mean IQ of those
in very complex jobs (e.g., accountants; lawyers; doctors) was about
120--130 (much higher than the population mean of 100). However,
intelligence is much less relevant for relatively specific skills. For
example, Ceci and Liker (1986) found experts at calculating the odds in
harness racing had IQs ranged from 81 to 128 and there was no
relationship between performance and IQ. Hambrick and Tucker-Drob (2015)
reported findings supporting the model's third and fourth assumptions in
a study on music practice and accomplishment in twins. There was
evidence for gene-environment interaction: genetic influences on music
accomplishment were greater among participants who engaged in music
practice. There was also evidence for gene-environment correlation:
there were genetic effects on the amount of music practice. Indeed,
these effects were greater than genetic effects on music accomplishment.
Research relevant to the fifth assumption was discussed earlier. In
spite of problems with establishing that deliberate practice has causal
influences on neural mechanisms, the evidence overall supports this
assumption (e.g., de Manzano & Ullén, 2018). Evidence that personality
plays a role in determining individual differences in deliberate
practice was discussed by Ullén et al. (2016). High levels of grit or
conscientiousness are associated with high levels of deliberate practice
whereas high impulsivity is associated with low levels of practice.

Problem solving and expertise

619

There is also evidence that motivation influences the amount of
deliberate practice. For example, individuals' vocational interests
influence what they choose to focus on and how much time and effort they
expend pursuing those interests (Ackerman, 2014).

Evaluation The multifactorial gene-environment interaction model is
considerably more ambitious in scope than Ericsson's approach based on
deliberate practice. There is compelling evidence that all the factors
identified by the model influence the development of expertise. There is
also evidence that these factors interact in complex ways largely
consistent with the predictions of the model. In sum, this model is
currently the most comprehensive model we have of the development of
expertise. What are the model's limitations? First, much more research
is required to test some of the complex predictions made by the model.
Second, we need to move beyond predicting gene-environment interactions
and correlations to identify the specific genes responsible for these
effects. Third, the model predicts that interactions among the factors
influencing the development of expertise will vary over time. As yet,
there has been a dearth of longitudinal studies testing such
predictions.

CHAPTER SUMMARY •

Introduction. This chapter is devoted to problem solving, analogical
problem solving and reasoning, and expertise. Most research on problem
solving focuses on problems requiring no special knowledge. In contrast,
research on expertise typically involves problems requiring considerable
background knowledge. Analogical problem solving focuses on the use of
previous knowledge and experience on a current problem, whereas
expertise research is concerned with what differentiates experts from
novices in a given area.

•

Gestalt approach and beyond: insight and role of experience. Much
research supports the notion of insight. However, insight is hard to
measure, and "insight" problems are often solved with no evidence of
insight. Incubation often benefits problem solving because misleading
information or ineffective strategies are forgotten. Representational
change theory claims correctly that solving insight problems often
requires constraint relaxation and/or re-encoding of the problem
representation. However, it underestimates the range of strategies used
on insight problems. The phenomena of functional fixedness and mental
set show past experience can impair problem solving. High cognitive
control sometimes impairs performance on tasks involving insight,
functional fixedness or mental set.

Research activity: Cognitive reflection test

620

Thinking and reasoning

•

Problem-solving strategies. Problem solvers use heuristics (e.g., hill
climbing; means--ends analysis). They also use metacognitive processes
to determine their problem-solving strategies. Much problem solving
involves successive stages of problem representation, planning and plan
execution. The prefrontal cortex is heavily involved in planning and
problem solving generally. There is more planning when it is costly to
access task-relevant information. Cognitive misers fail to solve some
problems because of a reluctance to engage in effortful processing.

•

Analogical problem solving and reasoning. Analogical problem solving
depends on three kinds of similarity: superficial, structural and
procedural. Failures to use analogies often occur through failures to
retrieve relevant information from memory. Such failures can be reduced
if problem solvers identify the underlying structure of the current
problem. Four-term analogy problems involve four component processes:
encoding, inferring, mapping and applying, of which inference and
mapping are typically the hardest. Individuals high in fluid
intelligence have excellent analogical reasoning due to their superior
top-down executive attention, ability to disengage (e.g., inhibit
irrelevant information) and think flexibly. The left rostrolateral
prefrontal cortex is the brain area of greatest relevance to analogical
reasoning (especially mapping).

•

Chess-playing expertise. Expertise is typically assessed by using
knowledge-rich problems. Expert chess players differ from nonexpert ones
in having greater cognitive ability and possessing far more
template-based and chunk-based knowledge. This knowledge permits expert
players to identify good moves rapidly. However, the precise information
contained in templates remains unclear. The template approach
de-emphasises experts' use of slow search processes and complex
strategies.

•

Medical expertise. Medical experts (e.g., radiologists) often rely more
than non-experts on fast, automatic processes in diagnosis: they rapidly
fixate relevant information and ignore task-irrelevant information.
Slow, analytic processes enhance diagnostic performance (especially for
experts). Diagnostic errors can be due to failures in detection,
recognition or judgement. Medical expertise involves more visual and
less abstract knowledge than chess expertise. It is also more narrowly
focused.

•

Brain plasticity. There are differences in brain structure between
experts and non-experts (e.g., taxi drivers). Training studies
(especially in music) have shown that these changes in brain structure
are often caused by experience and reflect brain plasticity. The
structural changes associated with brain plasticity probably provide
experts with an additional benefit compared to non-experts.

Problem solving and expertise

•

Deliberate practice and beyond. According to Ericsson, the development
of expertise depends only on deliberate practice (involving informative
feedback and the opportunity to correct errors). In fact, deliberate
practice is necessary (but not sufficient) for developing expertise. The
importance of innate talent is suggested by the variability in the
amount of practice required to achieve high expertise and individual
differences in the benefits of a given amount of practice. As predicted
by the multifactorial gene-environment interaction model, innate ability
is especially important in broad domains (e.g., career success). The
model also accurately predicts that genetic factors strongly influence
the amount of deliberate practice. More generally, individual
differences in expertise depend heavily on gene-environment interactions
and gene-environment correlations.

FURTHER READING Al-Moteri, M.O., Symmons, M., Plummer, V. & Cooper, S.
(2017). Eye tracking to investigate cue processing in medical
decision-making: A scoping review. Computers in Human Behavior, 66,
52--66. Modi Owied Al-Moteri and colleagues provide a theoretical
framework indicating the main processes involved in medical
decision-making. Gobet, F. (2016). Understanding Expertise: A
Multi-Disciplinary Approach. London: Palgrave. Fernand Gobet shows how
expertise can be understood by integrating ideas and research from
several scientific disciplines. Hambrick, D.Z., Burgoyne, A.P.,
Macnamara, B.N. & Ullén, F. (2018). Toward a multifactorial model of
expertise: Beyond born versus made. Annals of the New York Academy of
Sciences, 1423 (SI), 284--295. David Hambrick and colleagues discuss
limitations with the notion that expertise depends almost totally on
deliberate practice and discuss their multifactorial gene-environment
interaction model in detail. Lovett, A. & Forbus, K. (2017). Modelling
visual problem solving as analogical reasoning. Psychological Bulletin,
124, 60--90. This article provides interesting theoretical insights into
the processes underlying analogical reasoning. Robertson, S.I. (2017).
Problem Solving: Perspectives from Cognition and Neuroscience (2nd edn).
London: Routledge. This book provides a useful and readable introduction
to problem solving and expertise. Ward, P., Schragen, J.M., Gore, J. &
Roth, E. (eds.) (2019). Oxford Handbook of Expertise: Research and
Application. Oxford: Oxford University Press. This edited book contains
chapters by leading experts on expertise. Weisberg, R.W. (2018). Problem
solving. In L.J. Ball & V.A. Thompson (eds), Routledge International
Handbook of Thinking and Reasoning (pp. 607--623). Abingdon, Oxon.:
Routledge. Robert Weisberg reviews contemporary theories and research on
problem solving. Zuk, J. & Gaab, N. (2018). Evaluating predisposition
and training in shaping the musician's brain: The need for a
developmental perspective. Annals of the New York Academy of Sciences,
1423, 4--60. Jennifer Zuk and Nadine Gaab discuss a theoretical model
accounting for the role of brain plasticity in the development of
musical expertise (the "musician brain").

621

Chapter

13

Judgement and decision-making

INTRODUCTION

KEY TERMS Judgement An assessment of the probability of a given event
occurred based on incomplete information. Decision-making Making a
selection from various options; if full information is unavailable,
judgement is required.

In this chapter, our focus is on the overlapping areas of judgement and
decision-making. Judgement involves deciding on the likelihood of
various events using incomplete information. For example, you might use
information about your previous examination performance to judge the
probability you will succeed in your next examination. What matters in
judgement is accuracy. Decision-making involves selecting one option
from several possibilities. For example, you may have had to decide
which college or university to attend, which courses to study and so on.
The factors involved in decision-making depend on the importance of the
decision -- the processes involved in deciding on a career path are much
more complex and time-consuming than deciding whether to drink a Coke or
a Pepsi! Problem solving (discussed in Chapter 12) differs from
decision-making in that individuals must generate their own solutions
rather than choosing from presented options. We typically assess
decision quality in terms of consequences -- are we happy with our
choice of university or course? This can be unfair. There is the story
of a surgeon saying "The operation was a success. Unfortunately, the
patient died". This sounds like a sick joke in every sense. In fact,
however, a decision can be good given the information available at the
time even if its consequences are poor. Judgement typically forms an
important initial part of the decisionmaking process. For example,
someone deciding which car to buy might make judgements about how much
various cars would cost to run, how reliable they would be and how much
he/she would enjoy owing one. What does research on judgement and
decision-making tell us about human rationality? That issue is part of a
broader one concerning human rationality and logicality in general. That
issue (including consideration of research on judgement and
decision-making) is discussed in Chapter 14.

623

Judgement and decision-making

JUDGEMENT RESEARCH Our subjective assessment of the probability of
something is often changed by new information. Suppose you are 90% sure
someone has lied to you. However, their version of events is later
confirmed by someone else, leading you to believe there is only a 60%
chance you have been lied to. In everyday life, new information often
increases or decreases the strength of our beliefs. The Rev. Thomas
Bayes provided a precise way of thinking about such cases
(unsurprisingly, his approach is known as Bayesian inference). He
focused on situations where there are two possible subjective beliefs or
hypotheses (e.g., X is lying vs X is not lying) and showed how new data
or information changes the subjective probabilities of each hypothesis
being correct. According to Bayes' theorem, we need to evaluate beliefs
concerning the relative probabilities of the two hypotheses before the
data are obtained (prior odds or beliefs). We also need to calculate the
relative probabilities of obtaining the observed data under each
hypothesis (likelihood ratio). Bayesian methods evaluate the probability
of observing the data, D, if hypothesis A is correct, written p(D/HA),
and if hypothesis B is correct, written p(D/HB). Bayes' theorem is
expressed as an odds ratio:

KEY TERM Bayesian inference A form of statistical inference in which
initial beliefs (prior probabilities) are modified by evidence or
experience to produce posterior probabilities.

p(HA/D) p(HA) p(D/HA) ---------------- = ------------ × ----------------
p(HB/D) p(HB) p(D/HB) The above formula may look intimidating, but it is
not really (honestly!). On the left side of the equation are the
relative probabilities of hypotheses A and B in the light of the new
data. These are the probabilities we want to work out. On the right side
of the equation, we have the prior odds of each hypothesis being correct
before the data were collected multiplied by the likelihood ratio based
on the probability of the data given each hypothesis. We can apply
Bayes' theorem to Kahneman and Tversky's (1972) taxicab problem. A cab
was involved in an accident one night. Of the city's cabs, 85% belonged
to the Green company and 15% to the Blue company. An eyewitness
identified the cab as a Blue cab. However, when her ability to identify
cabs under similar visibility conditions was tested, she was wrong 20%
of the time. What is the probability the cab was Blue? The hypothesis
the cab was Blue is HA and the hypothesis it was Green is HB. The prior
probability for HA is .15 and for HB it is .85 because 15% of the cabs
are blue and 85% are green. The probability of the eyewitness
identifying the cab as Blue when it was Blue, p(D/HA) is .80. Finally,
the probability the eyewitness identifies the cab as Blue when it was
Green, p(D/HB) is .20. According to the formula: 0.15 0.80 0.12 --------
× -------- = -------- 0.85 0.20 0.17 Thus, the odds ratio is 12:17 and
there is a 41% (12/29) the taxi cab was Blue. Alas, this is not the most
popular answer.

Interactive exercise: Taxi-cab problem

624

Thinking and reasoning

KEY TERMS

Neglecting base rates

Base-rate information The relative frequency of an event within a given
population.

According to Bayes' theorem, individuals making judgements should take
account of the base-rate information (the relative frequency of an event
within a given population). However, such information is often ignored
or de-emphasised. With the taxi-cab problem, most people ignore the
baserate information about the relative numbers of Green and Blue cabs.
They consider only the evidence of the witness and so conclude wrongly
there is an 80% probability the taxi was Blue rather than Green.
Kahneman and Tversky (1973) provided another example of people ignoring
base-rate information. Participants were given the lawyer-engineer
problem:

Heuristics: representativeness heuristic The assumption that an object
or individual belongs to a specified category because it is
representative (typical) of that category. Conjunction fallacy The
mistaken assumption that the probability of a conjunction of two events
is greater than the probability of one of them.

Case study: The base rate fallacy reconsidered

Jack is a 45-year-old man. He is married and has four children. He is
generally conservative, careful and ambitious. He shows no interest in
political and social issues and spends most of his free time on his many
hobbies which include home carpentry, sailing and numerical puzzles. The
participants were told the description had been selected at random from
100 descriptions. Half were told 70 descriptions were of engineers and
30 of lawyers, whereas the others were told 70 were of lawyers and 30 of
engineers. On average, the participants decided there was a .90
probability Jack was an engineer regardless of whether most of the 100
descriptions were of lawyers or engineers. Thus, participants ignored
the base-rate information (i.e., the 70:30 split in the 100
descriptions).

Heuristics Tversky and Kahneman (e.g., 1974) argued most people given
judgement tasks use rules of thumb or heuristics. Heuristics are
"strategies that ignore part of the information, with the goal of making
decisions more quickly, frugally and/or accurately than more complex
methods" (Gigerenzer & Gaissmaier, 2011, p. 454). Heuristics often
greatly reduce the effort associated with cognitive tasks.

Representativeness heuristic Our use of heuristics can lead us to ignore
base-rate information. More specifically, we use the representativeness
heuristic, which involves deciding an object or person belongs to a
given category because it appears typical or representative of that
category. For example, Jack's description (see above) seems that of a
typical engineer. Tversky and Kahneman (1983) studied the conjunction
fallacy, the mistaken belief that the conjunction or combination of two
events (A and B) is more likely than one event (A or B) on its own.
Consider the following description: Linda is 31 years old, single,
outspoken and very bright. She majored in philosophy. As a student, she
was deeply concerned with issues of discrimination and social justice,
and also participated in anti-nuclear demonstrations.

Judgement and decision-making

Is it more likely Linda is a bank teller or a bank teller active in the
feminist movement? Most people (including you?) argue it is more likely
she is a feminist bank teller. They seem to rely on the
representativeness heuristic -- the description sounds more like that of
a feminist bank teller than of a bank teller. This is the conjunction
fallacy: all feminist bank tellers belong to the larger category of bank
tellers! Many people misinterpret the statement "Linda is a bank
teller", as implying she is not active in the feminist movement.
However, the conjunction fallacy is still found when almost everything
is done to ensure people interpret the problem correctly (Sides et al.,
2002). Standard explanations of the conjunction fallacy (including those
based on the representativeness heuristic) assume it occurs because of
the high perceived probability of the additional information (i.e.,
Linda is a feminist activist) given the description. Tentori et
al. (2013) argued for a subtly different explanation: the hypothesis
that Linda is a feminist activist is strongly supported by her
description. Tentori et al. (2013) contrasted these explanations by
considering a further additional scenario: "Linda is a bank teller and
owns a pair of black shoes." It is more probable Linda owns a pair of
black shoes than that she is an activist feminist. However, the
information she owns a pair of black shoes is hardly supported by her
description. Thus, standard explanations would predict Linda owning a
pair of black shoes would be rated as likelier than her being a feminist
activist whereas the hypothesis explanation predicts the opposite.
Tentori et al.'s findings supported the hypothesis explanation.

IN THE REAL WORLD: HEURISTICS IN MEDICAL DIAGNOSIS The importance of the
representativeness heuristic would be increased if experts in real life
sometimes mistakenly used it. Supporting evidence was discussed by
Groopman (2007). Evan McKinley (a pseudonym) was a forest ranger in his
early forties. He was slim and very fit. While hiking, he experienced
severe discomfort in his chest so that it hurt every time he took a
breath. Accordingly, he went to see a doctor (Pat Croskerry). Croskerry
ascertained McKinley had never smoked, was not under stress, his blood
pressure was normal, and no problems were revealed by electrocardiogram
and chest X-ray. Dr Croskerry concluded, "I'm not at all worried about
your chest pain. You probably overexerted yourself in the field and
strained a muscle. My suspicion that this is coming from your heart is
about zero." Shortly afterwards, McKinley had a heart attack. This led
Croskerry to admit, "I missed it because my thinking was overly
influenced by how

Dr Pat Croskerry. Courtesy Pat Croskerry.

625

626

Thinking and reasoning

healthy this man looked, and the absence of risk factors." In other
words, McKinley seemed very representative of healthy people with an
extremely low risk of having a heart attack. Crupi et al. (2018)
investigated the double conjunction fallacy: a conjunction of two
statements (A + B) is judged to be more probable than statement (A) and
then statement (B) when considered on their own. Medical experts were
provided with a scenario in which a man has chronic anaemia. Crupi et
al. found 49% of the medical experts committed the double conjunction
fallacy -- they judged it more likely that the man suffered from
alcoholism and thalassemia trait (a blood disorder) than that he
suffered from alcoholism or from thalassemia trait. However, this cannot
be the case. Why did almost half of the medical experts exhibit this
bias? Some of the clinical evidence presented in the scenario was very
consistent with the hypothesis that the man had both alcoholism and
thalassemia. Thus, the findings are consistent with Tentori et al.'s
(2013) hypothesis explanation. Saposnik et al. (2016) and Croskerry
(2018) reviewed studies on cognitive biases associated with medical
decisions. Common cognitive biases were anchoring (relying excessively
on the first symptom identified), omission bias (preferring inaction
over action) and overconfidence (excessive confidence in the correctness
of one's judgement). The reviewed evidence suggested cognitive biases
were associated with diagnostic inaccuracies in between 36% and 77% of
cases. However, the prevalence of cognitive biases in actual medical
practice is currently unknown.

Heeding base rates In spite of the findings discussed so far, people
often make some use of base-rate information. Bialek (2017) used the
engineer-lawyer problem discussed earlier (p. 624). The mean estimated
probability that a description drawn randomly from a sample of 1,000 was
an engineer was .84 when 997 of the sample were engineers compared to
.53 when only 3 were engineers. More strikingly, Bialek found with
similar problems that many participants made use of base-rate
information irrelevant to the judgement task. Krynski and Tenenbaum
(2007) argued that we possess valuable causal knowledge allowing us to
make accurate judgements using base-rate information in our everyday
lives. However, laboratory judgement problems generally fail to provide
such knowledge. Krynski and Tenenbaum (2007) gave some participants the
following judgement task (the false positive scenario): The following
statistics are known about women at age 60 who participate in a routine
mammogram screening, an X-ray of the breast tissue that detects tumours:
●

KEY TERM Double conjunction fallacy A stronger form of the conjunction
fallacy in which a conjunction of two statements is judged more likely
than each of the statements judged separately.

●

2% of women have breast cancer at the time of screening. Most of them
will receive a positive result on the mammogram. There is a 6% chance
that a woman without breast cancer will receive a positive result on the
mammogram.

Suppose a woman at age 60 gets a positive result during a routine
mammogram screening. Without knowing any other symptoms, what are the
chances she has breast cancer? The base rate of cancer in the population
was often neglected by participants given this task. This may have
happened because breast cancer is the only cause of positive mammograms
explicitly mentioned. Suppose the

Judgement and decision-making

627

problem is reworded slightly to indicate an alternative cause of
positive mammograms. Krynski and Tenenbaum (2007) did this by changing
the wording of the third paragraph: ●

There is a 6% chance that a woman without breast cancer will have a
dense but harmless cyst that looks like a cancerous tumour and causes a
positive result on the mammogram.

Participants given the benign cyst scenario were far more likely to take
full account of the base-rate information than those given the standard
false positive scenario (see Figure 13.1). Krynski and Tenenbaum (2007)
argued the reasonably full causal knowledge available to participants
with the benign cyst scenario allowed them to solve the problem. It also
corresponds to real life. In Kahneman and Tversky's (1972) taxi-cab
problem (discussed earlier, pp. 623--624), most participants ignored the
base-rate information about the numbers of Green and Blue cabs. Krynski
and Tenenbaum (2007) argued that this happened because it was hard for
participants to see the causal structure. Accordingly, they devised a
version providing a reason why the witness might have made a mistake.
Here is the crucial addition to the problem: When testing a sample of
cabs, only 80% of the Blue Co. cabs appeared blue in colour, and only
80% of the Green Co. cabs appeared green in colour. Due to faded paint,
20% of Blue Co. cabs appeared green in colour, and 20% of Green Co. cabs
appeared blue in colour. Only 8% of participants showed base-rate
neglect with the faded paint version compared to 43% with the standard
version. Correct answers increased from 8% with the standard version to
46% with the faded paint version. Thus, many people use base-rate
information when they understand the underlying causal factors. People
also use base-rate information when strongly motivated to do so. Suppose
you were asked to put some saliva on a strip of paper. If it turned
blue, that would mean you had an enzyme deficiency indicating a health
problem. However, there is a 1/10 probability the test was misleading.
Unfortunately, the paper turned blue.

Figure 13.1 Percentages of correct responses and various incorrect
responses (based on base-rate neglect, odds form, base-rate overuse, and
other) with the falsepositive and benign cyst scenarios. From Krynski
and Tenenbaum (2007). Copyright © 2007, American Psychological
Association. Reproduced with permission.

628

KEY TERMS Availability heuristic The rule of thumb that the frequencies
of events can be estimated accurately by the subjective ease with which
they can be retrieved. Affect heuristic Using one's emotional responses
to influence rapid judgements or decisions.

Figure 13.2 Percentage of correct predictions of the judged frequencies
of different causes of death based on the affect heuristic (overall
dread score), affect heuristic (single dread item),
availability-by-recall (direct experience) and
availabilityby-total-experience (TEX: direct experience + media). From
Pachur et al. (2012a). © American Psychological Association.

Thinking and reasoning

Ditto et al. (1998) gave participants the above task. Most used the
base-rate information (i.e., 1/10 probability of a misleading result) to
argue the test was inaccurate. In contrast, participants who were told
the paper turning blue meant they did not have a health problem
perceived the test as accurate -- they were not motivated to take
account of the base-rate information. Motivation also distorts informal
reasoning (see Chapter 14). For example, there is much evidence for
myside bias (the tendency to favour information consistent with one's
prior beliefs over information inconsistent with those beliefs).

Availability heuristic We turn now to the availability heuristic -- the
frequencies of events can be estimated by how easy or hard it is
subjectively to retrieve them from longterm memory. Lichtenstein et
al. (1978) asked people to judge the relative likelihood of different
causes of death. Those attracting much publicity (e.g., murder) were
judged more likely than those that do not (e.g., suicide) even when the
opposite was the case. Pachur et al. (2012a) argued that we can explain
people's judged frequencies of various causes of death in three ways.
First, they may use an availability heuristic based on their own direct
experience. Second, they may use an availability heuristic based on
media coverage of causes of death plus their own experience
(availability by total experience). Third, they may use the affect
heuristic: "Gauge your feeling of dread that Risk A and Risk B,
respectively, evoke and infer that risk to be more prevalent in the
population for which the dread is higher" (Pachur et al., 2012a,
p. 316). What did Pachur et al. (2012a) find? Availability based on
recall of direct experiences was the best predictor of the judged
frequencies of different causes of death (see Figure 13.2). Judged risks
were also predicted by the affect heuristic. Availability based on media
coverage was the least successful predictor. It should be emphasised
that affect influences numerous kinds of judgements and that the term
"affect heuristic" is used in various ways

Judgement and decision-making

629

(Rakow & Skylark, 2018). For example, Scherer et al. (2018) asked
participants to judge the benefits of medical tests (e.g., magnetic
resonance imaging scan for migraine headaches). Those receiving
information indicating that a given test might cause harm experienced
more negative affect and judged the benefits of the test as less than
those put into a negative mood. Fazio et al. (2015) found truth ratings
for false statements (e.g., "A date is a dried plum") were greater for
participants who had previously encountered them. Surprisingly, this was
so even for participants who knew the correct answer. Thus, individuals
often rely on readily available information even when they possess
knowledge indicating they should not. Oppenheimer (2004) found the
availability heuristic is sometimes overridden. Participants were
presented with pairs of names (one famous, one non-famous) and asked to
indicate which was more common. They would have chosen the famous names
if using the availability heuristic, but mostly selected the non-famous
ones. What happened was that the participants used deliberate thought to
override the availability heuristic. When the task was performed under
cognitive load to reduce deliberate thought, participants mistakenly
chose the famous name 80% of the time (Oppenheimer & Monin, 2009).

IN THE REAL WORLD: AVAILABILITY HEURISTIC IN MEDICAL DIAGNOSIS Groopman
(2007) discussed an example of poor medical decision-making triggered by
the availability heuristic. When Dr Harrison Alter was working at a
hospital in Arizona, he saw dozens of patients suffering from viral
pneumonia in a three-week period. One day, Blanche Begaye, a Navajo
woman, arrived complaining of having trouble breathing. She said she had
taken a few aspirin and was breathing at almost twice the normal rate.
Dr Alter diagnosed viral pneumonia even though she lacked the white
streaks in her lungs as well as lacking rhonchi (harsh sounds in the
lungs characteristic of that disease). However, her blood had become
slightly acidic, which can occur when someone has a major infection. A
few minutes later, an internist argued correctly Blanche Begaye had
aspirin toxicity, which occurs when patients overdose on that drug. Dr
Alter used the availability heuristic because he was overly influenced
by the numerous recent cases of viral pneumonia making that disease
spring to mind. Mamede et al. (2010b) confirmed the problems potentially
associated with the availability heuristic. Doctors faced with a case
resembling ones recently encountered tended mistakenly to make the
diagnosis appropriate only to the earlier cases. How can we reduce
cognitive biases (e.g., those based on the availability and
representativeness heuristics?). Lambe et al. (2016) reviewed studies
using cognitive interventions to enhance diagnostic accuracy. The most
effective intervention was guided reflection, which involved use of
guided, structured, reflective processes. Another effective intervention
involved considering possible alternative diagnoses. Of relevance, Dr
Alter learned from his misdiagnosis to "make sure even when I think I
have the answer to generate a short list of alternatives". A heuristic
that has proved useful is to focus on ruling out the worst-case scenario
(ROWS; Croskerry, 2018).

630

Thinking and reasoning

KEY TERM

Overall evaluation

Anchoring-andadjustment heuristic When someone makes an initial estimate
(the anchor) and then adjusts it to produce a final estimate, the
adjustment is generally insufficient.

Kahneman and Tversky identified numerous general heuristics or rules of
thumb underlying judgements in many different contexts. Only a few of
these heuristics (e.g., representativeness heuristic; availability
heuristic) have been discussed here. Another important heuristic
discovered by Kahneman and Tversky is the anchoring-and-adjustment
heuristic: judges use an initial estimate (the anchor) and then adjust
it to produce a final estimate; however, the adjustment is typically
insufficient. For example, judgements of the number of African countries
in the United Nations are systematically biased by initial numbers
produced randomly by a roulette wheel (Fiedler & von Sydow, 2015).
Kahneman and Tversky established the field of judgement research and
their emphasis on the role of heuristics has spread to several other
research areas including decision-making (this chapter, pp. 640--663),
and reasoning (Chapter 14). Their ideas have also been hugely
influential outside psychology (e.g., in economics and philosophy).
There is plentiful evidence that most people frequently prefer to
minimise the cognitive demands on them by using heuristics (Fiedler &
von Sydow, 2015). There are several limitations with the heuristics and
biases approach. First, the heuristics are defined vaguely. As Fiedler
and von Sydow (2015, p. 150) pointed out, "One-word labels like
'representativeness' are theory surrogates \[substitutes\] that fail to
place any testable constraints on the cognitive decision process."
Second, theorising based on the heuristics-and-biases approach has been
limited (but see later discussion, pp. 634--637). According to Fiedler
and von Sydow (2015, p. 154), "What is disillusioning and disappointing
. . . is how little precision, refinement, and progress has been
obtained at the theoretical level." For example, there is little
evidence that the anchoring-and-adjustment heuristic depends on an
incomplete adjustment process rather than a simpler process (e.g., the
initial numerical value triggers or primes values similar to it). In
addition, the precise conditions that elicited the various heuristics
and the relationships between different heuristics remain unspecified.
Third, inaccurate judgements are not necessarily due to biased
processing. Instead, inaccurate judgements often occur because
individuals have been exposed to a small and biased sample of
information (an environmental factor). For example, most people judge
skin cancer to be a more common cause of death than cancer of the mouth
and throat although the opposite is actually the case (Hertwig et al.,
2005). Such findings have been attributed to an internal cause (the
availability heuristic). In fact, they are due primarily to the much
greater media coverage of skin cancer (an external cause). Fourth,
emotional and motivational factors influence our judgements in the real
world but were rarely studied in the laboratory until relatively
recently (see Chapter 15). For example, the judged risk from
formaldehyde (a toxic chemical compound) was greater when individuals
were in a sad rather than neutral mood (Lench & Darbor, 2014). Fifth, it
has often been argued that the cognitive biases (e.g., failure to take
account of the underlying base rate) observed in much research are

Judgement and decision-making

due in part to the artificiality of much laboratory research (McDowell &
Jacobs, 2017). Reasons why our judgements might be more accurate under
more naturalistic conditions are discussed next.

Natural frequency hypothesis We are rarely presented with summary
statistics providing base-rate information in our everyday lives
although this is common in laboratory research. Instead, what is common
in our everyday experience is natural sampling -- "the process of
encountering instances in a population sequentially" (McDowell & Jacobs,
2017, p. 425). According to Gigerenzer and Hoffrage (1995), our
evolutionary history makes it easy for us to calculate the frequencies
of different kinds of events. In contrast, we are ill-equipped to deal
with fractions and percentages: this helps to explain why we often
perform so poorly on judgement problems involving base rates. The
central prediction is that performance on such problems would be greatly
enhanced if natural frequencies were used. This theoretical approach
poses some problems. First, we encounter only a sample of events in the
real world, and the frequencies of such events may differ substantially
from "natural" samples. For example, the frequencies of highly
intelligent and less intelligent people encountered by university
students differ from those in the general population. Second, we must
distinguish between natural frequencies and the word problems actually
used in research. With most word problems, participants receive
frequency information and so bypass the complexities of natural
sampling.

Findings Gigerenzer and Hoffrage (1995) presented a judgement task
closely resembling the mammogram problem used by Krynski and Tenenbaum
(2007; discussed earlier, pp. 626--627). When the problem was presented
in probabilities, only 16% of participants produced the correct answer.
In contrast, 46% of participants were correct when frequencies were
used. McDowell and Jacobs (2017) reported a meta-analysis (see Glossary)
of studies comparing performance on judgement tasks using probabilities
or natural frequencies. Overall, there was a clear-cut advantage when
natural frequencies were presented. Performance on tasks presented using
probabilities was improved when the task was made easier by presenting a
limited amount of information or by using visual aids. However, these
manipulations also improved performance on tasks using natural
frequencies. Even individuals with much relevant knowledge benefit from
frequency information. Hoffrage et al. (2015) used four realistic
diagnostic tasks requiring use of base-rate information in probability
or natural frequency versions with advanced medical students. These
tasks varied in complexity (e.g., the number of relevant cues; more than
two possible hypotheses). Correct judgements on each task were far more
common with the natural frequency than the probability version (see
Figure 13.3). Overall, 45% of natural frequency problems were solved
correctly compared to only 7% of probability problems.

631

632

Thinking and reasoning

Figure 13.3 Percentage of correct inferences on tasks presented in
probability of natural frequency versions. The simplest task (Task 3)
has one hypothesis and two cue values; Task 1 has one hypothesis and
three cue values; Task 2 has three hypothesis and two cue values each;
Task 4 has one hypothesis with three cues.

Percentage of correct inferences

100

From Hoffrage et al. (2015).

Probabilities

90

Natural frequencies

80 70

59%

60

46%

50

38%

38%

40 30 16%

20 10 0

6%

6%

1%

Task 1 Three cue values

Task 2 Three hypotheses

Task 3 Two cues

Task 4 Three cues

Fiedler et al. (2000) used a problem where there was an 80% chance a
woman with breast cancer would have a positive mammogram compared to
9.6% for a woman without breast cancer. The base rate of breast cancer
in women is 1%. Participants engaged in frequency sampling cards from
files organised into the categories of women with and without breast
cancer to decide the probability that a woman has breast cancer if she
has a positive mammogram. Participants' sampling was heavily biased
towards women with breast cancer because they mistakenly believed that
category was more informative. This led them to produce an average
estimate of 63% a woman has breast cancer given a positive mammogram
(the correct answer is 7.8%). The participants performed poorly because
they engaged in biased frequency sampling.

Evaluation The natural frequency hypothesis has two major apparent
strengths. First, we often use information based on natural sampling
when making judgements in everyday life. Second, judgements are often
more accurate when based on natural frequency rather than probability
information. What are the limitations of the hypothesis? (1)

(2) 

Enhanced performance with frequency versions may be due to its
"computational simplicity" (Amitani, 2015) rather than because evolution
has equipped us to process frequency information efficiently. So far
research has not resolved this theoretical controversy (McDowell &
Jacobs, 2017). It is generally assumed participants make accurate
judgements because they use Bayes theorem (discussed earlier, p. 623).
However, Domurat et al. (2015) found that, using a natural sampling
approach, participants sometimes produced accurate judgements by using a
simpler

633

Judgement and decision-making

(3) 
(4) 

strategy. More generally, research has rarely identified with precision
the strategies actually used on judgement tasks. There is often a
yawning chasm between people's actual sampling behaviour and the
neat-and-tidy frequency data provided in laboratory experiments. This
can occur because their sampling behaviour is biased due to inaccurate
hypotheses (e.g., Fiedler et al., 2000) or because readily accessible
information is biased. People sometimes find it harder to think in
frequencies than percentages. Keeping track of frequency information in
the real world can impose considerable demands on memory (Amitani,
2015).

THEORIES OF JUDGEMENT Several theories of judgement have been proposed.
Below we discuss those theories that have contributed the most to our
understanding of the processes underlying judgement and its biases.

Support theory Tversky and Koehler (1994) proposed their support theory
based partly on the availability heuristic (discussed earlier,
pp. 628--629). Their key assumption was that an event appears more or
less likely depending on how it is described. Thus, we must distinguish
between events and descriptions of those events. You will almost
certainly assume the probability you will die on your next summer
holiday is extremely low. However, it might seem more likely if you were
asked "What is the probability you will die on your next summer holiday
from a disease, a car accident, a plane crash, contaminated food, or any
other cause?". Why is the subjective probability of death on holiday
greater in the second case? According to support theory, there are two
main reasons: (1) (2)

An explicit description draws attention to aspects of the event less
obvious in the non-explicit description. Memory limitations may prevent
people remembering all the relevant information if it is not supplied.

More generally, the subadditivity effect follows from the theory. The
subadditivity effect is "the tendency to judge the probability of the
whole set of outcomes to be less than the total probabilities of its
parts" (Riege & Teigen, 2017, p. 96).

Findings We might assume experts' probability estimates would not be
influenced by the explicitness of descriptions because they can readily
provide missing details from their extensive knowledge. However,
Redelmeier et al. (1995) disconfirmed this assumption. Expert doctors
received the description of a woman with abdominal pain. Half assessed
the probabilities of two specified diagnoses (gastroenteritis and
ectopic pregnancy) and a residual category

KEY TERM Subadditivity effect The judged probability of the whole is
less than the combined probabilities of its parts.

634

Thinking and reasoning

(everything else). The other half assigned probabilities to five
specified diagnoses (including gastroenteritis and ectopic pregnancy)
and everything else. The key comparison was the subjective probability
of all diagnoses other than gastroenteritis and ectopic pregnancy. It
was .50 with the non-explicit description but .69 with the explicit
(more detailed) one. Thus, subjective probabilities were higher for
explicit descriptions even with experts. Riege and Teigen (2017)
obtained strong evidence for the subadditivity effect. Participants were
given the names and descriptions of the five actors nominated for the
best actor award at the 2014 Oscars and indicated the probability of
each one winning. The sum of the five probabilities came to 156% (the
correct figure must be 100%). Sloman et al. (2004) found participants
estimated the probability an American person selected at random would
die of disease rather than some other cause was .55. The probability was
similar when three typical diseases (heart disease, cancer, stroke) were
explicitly mentioned. However, it was only .40 when three atypical
diseases (pneumonia, diabetes, cirrhosis) were mentioned. Thus, an
explicit description can reduce subjective probability (rather than
increase it as predicted theoretically) if it leads us to focus on
low-probability causes.

Limitations Support theory has various limitations. First, the theory
does not explain in detail why providing an explicit description
generally increases an event's subjective probability. However, Hilbert
(2012) argued the processes converting objective evidence into
subjective estimates are "noisy", leading us to overestimate the
probabilities of events having an objectively low probability. This
leads to subadditivity and also explains several other cognitive biases.
Second, the theory is oversimplified because it assumes the perceived
support for a given hypothesis provided by relevant evidence is
independent of the support for rival hypotheses. However, we often
compare hypotheses and so this independence assumption is incorrect
(Pleskac, 2012). Third, support theory cannot easily explain Sloman et
al.'s (2004) finding that superadditivity (the opposite of
subadditivity) is found when explicit descriptions focus on
low-probability causes. This probably happens because focusing
participants' attention on low-probability causes reduces their
awareness of high-probability ones.

Fast-and-frugal heuristics

Research activity: Smart heuristics

We have seen our judgements are often inaccurate because we rely on
various heuristics. In contrast, Gigerenzer and colleagues (e.g.,
Gigerenzer & Gaissmaier, 2011) argued heuristics are often very valuable
when judging probabilities and making decisions. Their central focus is
on fast-and-frugal heuristics involving rapid processing of limited
information. They assumed we possess an "adaptive toolbox" consisting of
several such heuristics which are often surprisingly accurate. The
take-the-best heuristic is a key fast-and-frugal heuristic based on
"take the best, ignore the rest". Suppose you must decide which of two

635

Judgement and decision-making

German cities (Cologne and Herne) has the larger population. You might
assume the most valid cue is that cities whose names you recognise have
larger populations than unrecognised cities. However, you recognise both
names. After that, you think of another valid cue to city size (e.g.,
cities with cathedrals tend to be larger than those without). Since you
know Cologne has a cathedral but are unsure about Herne, you say
Cologne. The take-the-best strategy has three components: (1) (2) (3)

search rule: search cues (e.g., name recognition; cathedral) in
decreasing order of validity; stopping rule: stop after finding a
discriminatory cue (i.e., the cue applies to only one option). decision
rule: choose outcome.

The recognition heuristic (selecting the recognised object rather than
the unrecognised object) is a much researched example of the
take-thebest strategy. In the example above, if you recognise the name
Cologne but not Herne, you guess (correctly) Cologne is the larger city.
Goldstein and Gigerenzer (2002) argued controversially that when
individuals recognise one object but not the other, no other information
influences their judgement. How do people decide which heuristic to use
on judgement or decision-making tasks? Kruglanski and Gigerenzer (2011)
argued there is a two-step process. First, the nature of the task and
individual memory limit the number of available heuristics. Second,
individuals select one heuristic based on the likely outcome of using it
and its processing demands.

Findings Evidence indicating the importance of the recognition heuristic
was reported by Goldstein and Gigerenzer (2002). American students were
presented with pairs of German cities and decided which was larger. When
only one city name was recognised, participants apparently used the
recognition heuristic 90% of the time. However, selecting the recognised
city does not necessarily mean the recognition heuristic was used -- it
could have been chosen for other reasons. In another study, Goldstein
and Gigerenzer (2002) told participants that German cities with football
teams tend to be larger than those without. When participants decided
whether a recognised city without a football team was larger or smaller
than an unrecognised city, participants apparently used the recognition
heuristic 92% of the time. Thus, as predicted theoretically, they mostly
ignored conflicting information about the absence of a football team.
Basehore and Anderson (2016) presented participants with pairs of
fictitious cities (having pre-exposed them to one in each pair) and
asked them to select the one with the larger population. This approach
has the advantage that recognition was manipulated experimentally so its
impact could be assessed unconfounded by any other differences between
the two cities. As predicted, selections consistent with the recognition
heuristic were made on 74% of trials.

KEY TERM Recognition heuristic Using the knowledge that only one out of
two objects is recognised as the basis for making a judgement.

636

Thinking and reasoning

The validity of the recognition heuristic depends on the precise task.
For example, suppose participants must decide which of two Italian
cities has the larger population or is higher above sea level.
Unsurprisingly, the recognition heuristic is more valid with the former
decision and is also used more often (Pohl et al., 2017). Most people
are sensitive to validity: Pachur et al. (2012b) obtained a correlation
of +.64 between usage of the recognition heuristic and its validity in a
meta-analysis. Controversially, it is assumed that use of the
recognition heuristic means no other knowledge is taken into account. In
contrast, it is assumed within the parallel constraint satisfaction
theory (e.g., Glöckner et al., 2014) that all available information is
integrated "automatically" in parallel. Heck and Erdfelder (2017)
compared predictions from the two theories with respect to decisions
with pairs of objects, one recognised and the other not. According to
the parallel constraint satisfaction theory, the more information
available, the faster the decision times. According to the recognition
heuristic account, in contrast, decision times should be slower when
influenced by additional information. Heck and Erdfelder (2017) carried
out a meta-analysis of decision times based on 19 data sets. Their
findings were striking: 87.5% of participants performed as predicted by
the parallel constraint satisfaction theory. In contrast, only 11.3%
conformed to predictions based on the recognition heuristic. More
evidence that people often utilise additional information, even when the
recognition heuristic could be used on its own, was reported by Richter
and Späth (2006). German students were asked to decide, which of two
American cities was larger. The recognised city was identified as larger
more often when they were told it had an international airport than when
told it did not: 98% vs 82%, respectively. Dummel et al. (2016) focused
on participants making decisions consistent with the take-the-best
strategy (i.e., based on the best cue). When the next-best cue
conflicted with the best cue, participants inhibited information about
that cue and made slower decisions than when the two cues did not
conflict. Thus, the next-best cue was processed even though
theoretically it should not have been. The take-the-best strategy is
used less often than predicted theoretically (Fiedler & von Sydow,
2015). For example, Newell et al. (2003) had participants choose between
the shares of two fictitious companies. Only 33% used all three
components of the take-the-best strategy. This strategy was least likely
to be used when the cost of obtaining information was low and cue
validities were unknown. In those circumstances, participants used more
complex processes than those associated with the take-the-best strategy.
Gigerenzer's theoretical approach is based on a toolbox metaphor:
different strategies (e.g., take-the-best) are chosen in different
situations. Söllner and Bröder (2016) contrasted that approach with one
based on an adjustable spanner metaphor: the same strategy is used in
different situations, but it is used flexibly. The amount of information
participants chose to acquire before making a decision was better
predicted by the adjustable spanner metaphor.

Judgement and decision-making

Evaluation Individuals often use fast-and-frugal heuristics (e.g., the
recognition heuristic; the take-the-best strategy). Such heuristics
involve more precisely spelled-out mechanisms than those emphasised by
Kahneman and Tversky (Fiedler & von Sydow, 2015). These heuristics can
be surprisingly effective despite their simplicity. Factors determining
strategy selection on judgement tasks have been identified. The
fast-and-frugal approach accounts for much applied decision-making
(discussed later in the chapter, p. 655). What are the limitations of
this theoretical approach? First, as Evans and Over (2010, p. 174)
pointed out, "The suggestion that we are always better off following
intuitions and 'gut feelings' is an extraordinary claim. Why would we
have the capacity for logical reasoning if it was of no value?" Second,
the assumption that the recognition heuristic is often used with
additional information being ignored is often wrong (e.g., Heck &
Erdfelder, 2017). Many findings are better explained by other theories
(e.g., parallel constraint satisfaction theory). It is also likely
people consider why they recognise an object before deciding whether to
use the recognition heuristic (Newell, 2011). Third, the take-the-best
strategy is used less often than suggested theoretically. Its use
requires us to organise the various cues hierarchically based on their
validity, but often we lack adequate knowledge of cue validities.
Lawrence et al. (2018) discovered that the precise cues used by
individuals depend on their accessibility in memory, a factor not
emphasised by Gigerenzer. Another issue is that people often use
information (e.g., about the next-best cue) that theoretically should be
ignored with the takethe-best strategy. Fourth, the approach
de-emphasises the importance of the decision. Decision-making may stop
after finding a single discriminatory cue when deciding which of two
cities is larger. However, most women want to consider all the relevant
evidence before deciding which of two men to marry!

Dual-process theory: Kahneman (2003) Most people rely heavily on
heuristics when making judgements because they can be used rapidly and
effortlessly. However, individuals sometimes use more complex cognitive
processes. As a result, some theorists (e.g., De Neys, 2012; Kahneman,
2003) have proposed dual-process models. Similar models have also been
applied to performance on reasoning problems (see Chapter 14). According
to Kahneman (2003), probability judgments depend on processing within
two systems: System 1: "The operations of System 1 are typically fast,
automatic, effortless, implicit (not open to introspection) and often
emotionally charged; they are also difficult to control or modify"
(Kahneman, 2003, p. 698).

637

638

Thinking and reasoning

System 2: "The operations of System 2 are slower, serial \[one at a
time\], effortful, more likely to be consciously monitored and
deliberately controlled; they are relatively flexible and potentially
rule-governed" (Kahneman, 2003, p. 698). How are these two systems
related? System 1 rapidly generates intuitive answers to judgement
problems (e.g., those based on the representativeness heuristic). These
answers are then monitored or evaluated by System 2, which may correct
them. Thus, judgement involves serial processing starting with System 1
and sometimes followed by System 2. Morewedge and Kahneman (2010)
subsequently modified the above aspect of the theory, arguing that
System 1 and System 2 processes "can operate in parallel" (p. 439). They
also argued that System 1 processes cause some information to become
strongly activated. This information is then often overweighed and leads
to biased judgements. Finally, they assumed that System 1 processing
often produces errors which may then be corrected by System 2
processing.

Findings De Neys (2006) obtained support for Kahneman's theory using the
Linda problem (discussed earlier, pp. 624--625). Those producing the
correct answer (and so presumably using System 2) took almost 40% longer
than those apparently using only System 1. This is consistent with the
assumption it takes longer to use System 2. There was a reduction in
correct solutions from 17% to 9.5% when participants performed a
cognitively demanding task at the same time. This is as predicted given
that System 2 requires cognitively demanding processes. De Neys et
al. (2011) found on standard base-rate problems that incorrect answers
neglecting base-rate information were obtained on 80% of trials. This
suggests participants often totally ignored base-rate information.
However, they were less confident about their responses when they
produced incorrect answers than when producing correct ones suggesting
there is some processing of base-rate information even when it does not
influence people's judgements. Earlier we discussed the lawyer-engineer
problem (p. 624; Kahneman & Tversky, 1973) on which base-rate
information is often ignored. Pennycook and Thompson (2012) used similar
problems such as the following: In a study 1,000 people were tested.
Among the participants there were 995 nurses and 5 doctors. Paul is a
randomly chosen participant of this study. Paul is 34 years old. He
lives in a beautiful home in a posh suburb. He is well spoken and very
interested in politics. He invests a lot of time in his career. What is
the probability that Paul is a nurse? (p. 528) There is a conflict
between the base-rate information (suggesting Paul is a nurse) and the
personality description (suggesting he is a doctor). Use of System 1
processing might lead participants to focus on the personality
description using the representativeness heuristic and decide Paul was

Judgement and decision-making

probably a doctor. The participants answered each problem twice:
initially with the first answer coming to mind and then with a more
deliberate answer. On Kahneman's theory, people must use System 2
processing for their answers to reflect base-rate information. As a
result, initial answers should rarely reflect base-rate information but
instead should be based on the representativeness heuristic. In
addition, base-rate information should be used much more often in
deliberate than in initial answers. Neither prediction was supported.
Half the initial answers were based primarily on base-rate information.
Of the participants changing their responses, 30% took more account of
base-rate information in their deliberate answer. However, nearly as
many (23%) took less account of base-rate information in their
deliberate answer which is inconsistent with Kahneman's theory. Newman
et al. (2017) obtained similar findings when instructing participants to
give an immediate answer ("Please provide us with the FIRST ANSWER that
comes to mind") and a more deliberate one. Base-rate information often
influenced their immediate answer. Newman et al. concluded the
distinction between System 1 and System 2 responses should be abandoned.
Perhaps responses differ primarily with respect to complexity: "more
complex responses . . . are more time-consuming and challenging to
produce" (pp. 1165--1166). Chun and Kruglanski (2006) also obtained
findings indicating the importance of complexity. They used various
versions of the lawyerengineer problem in which base-rate and
personality information was presented. Some information was easy to
process because it was presented briefly whereas the remainder was
complex (presented at length). Chun and Kruglanski (2006) assessed the
effect of cognitive load. According to dual-process theory, cognitive
load should reduce System 2 processing and use of base-rate information.
In fact, cognitive load led to increased use of easily processed
information regardless of whether it referred to base rate or
personality.

Evaluation There is support for the notion there are two different
processing systems, with System 2 being slower and more effortful than
System 1 processing. Similar dual-process theories have proved
reasonably successful in accounting for reasoning (Chapter 14). What are
the limitations of Kahneman's (2003) theory? First, and most
importantly, there is "the alignment problem" (Melnikoff & Bargh, 2018,
p. 281). In essence, it is assumed System 1 processes are unintentional,
uncontrollable, unconscious and efficient (i.e., they use minimal
processing capacity) whereas System 2 processes are intentional,
controllable, conscious and inefficient. These assumptions have rarely
been tested. However, the available evidence indicates strongly that
these attributes are much less highly correlated than assumed
theoretically (Melnikoff & Bargh). As a consequence, it is not possible
to define System 1 processes with precision. Second, and related to the
first point, the assumption that rapid judgement responses reflect the
use of System 1 whereas slow responses reflect the use of System 2 is
also oversimplified. In fact, rapid responses often

639

640

Thinking and reasoning

reflect System 2 processing and slow responses often reflect System 1
thinking (Newman et al., 2017; Pennycook & Thompson, 2012). Third, there
is relatively little support for Kahneman's (2003) original assumption
that System 1 and System 2 processes occur serially. How can we detect
rapidly that responses produced by System 1 are incorrect if System 2
has not been used up to that point? More generally, the theory fails to
provide an explicit account of the monitoring determining whether we
decide to use System 2 processes as well as System 1 processes. However,
as noted earlier, Morewedge and Kahneman (2010) argued that System 1 and
2 processes could occur in parallel. Fourth, Morewedge and Kahneman
(2010) committed the "good/ bad fallacy" (Melnikoff & Bargh, 2018,
p. 282). This fallacy involves the assumptions that System 1 processing
is often "bad" and error-prone whereas System 2 processing is "good" and
leads to rational judgements. Much of the evidence discussed above
illustrates the oversimplifications involved in these assumptions.

The way forward? Processing on judgement tasks is much more flexible
than implied by Kahneman's (2003) dual-process theory. It is also clear
different processes often operate in parallel rather than serially as
assumed theoretically. De Neys (2012, 2014) proposed a logical intuition
model (see Figure 14.4 on p. 685) to resolve some issues. He argued
there is rapid intuitive heuristic processing (System 1) and intuitive
logical processing (e.g., of base-rate information) in parallel. This
initial processing is sometimes followed by deliberate System 2
processing if the two types of intuitive processing generate different
responses. Support for the logical intuition model was reported by Bago
et al. (2018). They presented base-rate judgement problems involving
conflict between information in the problem and base-rate information.
Eventrelated potentials (ERPs; see Glossary) revealed sensitivity to
conflict within approximately 200 ms even on trials where participants
produced the wrong answer. It is improbable that System 2 processes
occurred so rapidly, and so this conflict sensitivity was probably due
to System 1 processes operating in parallel. This model has several
advantages over Kahneman's theory. First, heuristic and base-rate
information can both be accessed rapidly through intuitive processing.
This is consistent with the findings of Pennycook and Thompson (2012)
and Newman et al. (2017). Second, the finding that easily processed
base-rate information is often used under high cognitive load (Chun &
Kruglanski, 2006) is more consistent with De Neys' model. Third, the
model clarifies how conflicts between heuristic and base-rate
information are rapidly detected (e.g., De Neys et al., 2011) and
trigger System 2 processes.

DECISION-MAKING UNDER RISK Life is full of decisions. Would I prefer to
date Dick or Harry? Who will I share an apartment with next year? At one
time, it was assumed people

Judgement and decision-making

think rationally and so generally select the best option. This
assumption was built into normative theories, which focused more on how
people should make decisions rather than their actual decisions. Here we
will consider von Neumann and Morgenstern's (1944) expressed utility
theory. They argued we try to maximise utility (the subjective value we
attach to an outcome). When we choose between simple options, we assess
the expected utility or value of each one via the following formula:
Expected utility = (probability of a given outcome) × (utility of the
outcome). von Neumann and Morgenstern (1944) treated decisions as if
they were gambles. This approach was subsequently coupled with Savage's
(1954) mathematical approach based on using information from people's
preferences to combine subjective utilities and subjective
probabilities. This led to the development of subjective expected
utility theory. In the real world, various factors are generally
associated with each option. For example, one holiday option may be
preferable to another because it is in a more interesting area with
better weather. However, the first holiday is more expensive, and more
time would be spent travelling. In such circumstances, people allegedly
calculate the expected utility or disutility (cost) of each factor to
assess the overall expected value or utility of each option. In fact,
our choices are often decided by factors other than simply utility.
Decisions differ enormously in complexity (e.g., making life choices vs
meal choices). We start with relatively simple decision-making. The most
influential such theory (prospect theory) will be discussed, followed by
theories focusing more on emotional and/or social factors. After that,
we consider more complex decision-making.

Losses and gains It is reasonable to assume we make decisions to
maximise the chances of making a gain and minimise the chances of making
a loss. Suppose someone offered you \$200 if a tossed coin came up heads
but a loss of \$100 if it came up tails. You would jump at the chance
(wouldn't you?) because the bet provides an average expected gain of
\$50 per throw. Here are two more decisions. Would you prefer a sure
gain of \$800 or an 85% chance of gaining \$1,000 and a 15% probability
of gaining nothing? Since the expected value of the latter decision is
greater than that of the former (\$850 vs \$800, respectively), you
might well choose the latter option. Finally, would you prefer a sure
loss of \$800 or an 85% probability of losing \$1,000 with a 15%
probability of avoiding any loss? The average expected loss is \$800 for
the former choice and \$850 for the latter one, so you go with the
former choice, do you not? The first problem was from Tversky and Shafir
(1992) and the other two from Kahneman and Tversky (1984). In every
case, most participants failed to make what appears to be the best
choice. Two-thirds refused to bet on the coin toss and a majority
preferred the choices with the smaller expected gain and the larger
expected loss! Below we discuss attempts to understand such seemingly
irrational decision-making.

641

642

Thinking and reasoning

KEY TERMS

Prospect theory

Loss aversion The finding that losses have a greater subjective impact
on individuals than gains of the same magnitude.

Kahneman and Tversky (1979, 1984) developed prospect theory to explain
apparently paradoxical findings such as those above. Here are two key
assumptions:

Risk aversion A preference for certain gains over potentially larger
(but less certain) gains. Framing effect The finding that decisions can
be influenced by situational aspects (e.g., problem wording) irrelevant
to optimal decision-making.

(1) 
(2) 

Individuals identify a reference point representing their present state.
Individuals are much more sensitive to potential losses than potential
gains: loss aversion. This explains why most people are unwilling to
accept a 50:50 bet unless the amount they might win is about twice the
amount they might lose (Kahneman, 2003).

The above assumptions are represented in Figure 13.4. The reference
point is where the line labelled losses and gains intersects the line
labelled value. The positive value associated with gains increases
relatively slowly as gains become greater. Thus, winning £2,000 (2,200
euros) instead of £1,000 (1,100 euros) does not double the subjective
value of the money won. In contrast, the negative value associated with
losses increases relatively rapidly as losses become greater. How does
prospect theory account for the findings discussed earlier? If people
are much more sensitive to losses than gains, they should be unwilling
to accept bets involving potential losses even when the potential gains
outweigh the potential losses. They should also prefer a sure gain to a
risky (but potentially greater) gain; this is risk aversion. However,
the theory does not predict people will always avoid risky decisions. If
offered a chance to avoid a loss, most people will take it because they
are so concerned to avoid losses: this is risk seeking. Tversky and
Kahneman (1992) put forward cumulative prospect theory, which is more
comprehensive than prospect theory. However, it "retains the major
features of . . . prospect theory" (p. 317). Accordingly, we use the
term "prospect theory" to refer to both versions. It is assumed
theoretically that people overweigh low-probability events: rare events
receive more weight than they should given their actual probability of
occurrence. This helps to explain why people bet on the National Lottery
where the chances of winning the jackpot are 1 in 14 million.

Findings: framing effect Much research has considered the framing effect
in which decisions are influenced Figure 13.4 A hypothetical value
function. From Kahneman and Tversky (1984). © American Psychological
Association.

by irrelevant aspects of the situation. Tversky and Kahneman (1981) used
the Asian disease problem to study this effect. All participants were
given the following information:

Judgement and decision-making

Imagine that the US is preparing for the outbreak of an unusual Asian
disease, which is expected to kill 600 people. Two alternative
programmes to combat the disease have been proposed. Assume that the
exact scientific estimate of the consequences of the program are as
follows . . . In the gain-frame condition, participants chose between
the following prospects: ● ●

If programme A is adopted, 200 people will be saved. If programme B is
adopted, there is a 1 in 3 probability 600 people will be saved, and a 2
in 3 probability that no people will be saved.

In this condition, 72% chose the certain gain (programme A) even though
the two programmes (if implemented several times) would on average both
lead to the saving of 200 lives. In the loss-frame condition,
participants chose between the following prospects: ● ●

If programme C is adopted, 400 people will die. If programme D is
adopted, there is a 1 in 3 probability that nobody will die, and 2 in 3
probability that 600 people will die.

In this condition, 78% of participants chose programme B. This was the
case even though the two programmes would have the same effect if
implemented several times. Steiger and Kühberger (2018) carried out a
meta-analysis based on 81 experimental findings. There was much
variation across studies, but the overall framing effect was moderately
strong. According to prospect theory, the framing effect occurs because
people focus on potential gains in the gain-frame condition whereas they
are motivated by loss aversion in the loss-frame condition. Mandel
(2014) claimed the framing effect is trivial because it depends on
ambiguity about unstated information (e.g., programme A is interpreted
as meaning at least 200 people would be saved). However, Chick et
al. (2016) still obtained a robust framing effect when all ambiguities
were eliminated. Wang (1996) argued performance on the Asian disease
problem is influenced by social and moral factors de-emphasised by
prospect theory. Participants chose between definite survival of
two-thirds of the patients (deterministic option) versus a 1/3
probability of all patients surviving and a 2/3 probability of none
surviving (probabilistic option). The deterministic option leads, on
average, to the survival of twice as many patients. However, the
probabilistic option seems fairer because all patients share the same
fate. Participants strongly preferred the deterministic option when the
problem related to six unknown patients. However, they preferred the
probabilistic option when it related to six close relatives because
participants were especially concerned about fairness in that condition.

643

644

Thinking and reasoning

KEY TERM

Findings: sunk-cost effect

Sunk-cost effect Investing additional resources to justify a previous
commitment that has so far proved unsuccessful.

A phenomenon resembling loss aversion is the sunk-cost effect: "the bias
. . . to persist in a course of action because of the prior investments
in that option, and not because of the future consequences of pursuing
that option" (Magalhães & White, 2016, p. 339). This effect involves
"throwing good money after bad". The sunk-cost effect is found in
long-term relationships -- the more money and effort individuals have
invested in an unhappy relationship, the more likely they are to stay
(Rego et al., 2018). In one study, participants were told two people had
paid a \$100 non-refundable deposit for a weekend at a resort (Dawes,
1988). On the way there, they both became slightly unwell and felt they
would probably have a more pleasurable time at home. Many participants
argued the two people should drive on to avoid wasting the \$100 -- the
sunk-cost effect. This decision involves extra costs (money spent at the
resort) and is less preferred than being at home! One explanation for
the sunk-cost effect is that many people would find it embarrassing if
others knew they had wasted money or other resources on an abandoned
project (see study by Simonson and Staw, 1992, discussed later, p. 653).
Domeier et al. (2018) identified another reason. Individuals chose
whether to continue with an option in which they had already invested
time and money (sunk-cost option) or to switch to an alternative option
having a higher probability of being successful. Those choosing the
sunk-cost option did so because it satisfied their need to feel
competent more than the alternative option (see Figure 13.5).

Findings: Loss aversion Loss aversion (greater sensitivity to potential
losses than potential gains) is of central importance within prospect
theory. Much research involving large amounts of money supports the
notion of loss aversion (see also research on experts in the Box below,
pp. 645--646). However, this is much less the case with small amounts
(Yechiam, 2018). For example, consider the following choice:

Figure 13.5 Ratings of competence satisfaction for the sunkcost option
(SCO) and the alternative option (AO) for those selecting the sunk-cost
option and those selecting the alternative option. From Domeier et
al. (2018).

50% to win £1 (1.15 euro); 50% to lose £1 (1.15 euro) 50% to win £5
(5.75 euros); 50% to lose (5.75 euros)

Competence satisfaction

(1) 
(2) 

5 4.5 4 3.5 3 2.5 2 1.5 1

SCO-selectors AO-selectors

SCO

AO

Choice of option

645

Judgement and decision-making

According to prospect theory, people are loss averse and so should
choose (1) because it reduces potential losses. In fact, the typical
finding is loss neutrality -- individuals do not favour one option over
the other unless the stakes are high (Yechiam & Hochman, 2013). This
consistent finding is contrary to prospect theory. Pachur et al. (2018)
argued that attentional processes influence loss aversion. More
specifically, individuals who attend more to losses (relative to gains)
should exhibit greater loss aversion than those attending more to gains.
Pachur et al. manipulated participants' attention to losses and gains
and obtained their predicted findings. In similar fashion, the loss
neutrality with small stakes found by Yechiam and Hochman (2013) depends
in part because small potential losses do not attract much attention.

IN THE REAL WORLD: LOSS AVERSION AND RISK AVERSION IN EXPERTS Most
research on prospect theory is laboratory-based, raising doubts about
its real-world applicability. First, individuals taking risks to avoid
losses in the laboratory using hypothetical money may not do so in
everyday life. Second, most participants performing laboratory tasks
have limited relevant experience. In contrast, experts in the real world
might know how to prevent biases (e.g., loss aversion) from influencing
their behaviour and reducing their income.

Figure 13.6 Risk aversion for gains and risk seeking for losses on a
moneybased task by financial professionals and students. From Abdellaoui
et al. (2013). With kind permission from Springer Science+Business
Media.

646

Thinking and reasoning

For professional golfers, a birdie (one under par) on a hole is a gain
whereas a bogey (one over par) is a loss. Loss aversion would lead them
to be more cautious when putting for a birdie than for par. In the
latter case, failure to hole the putt would produce a bogey and thus a
loss. Pope and Schweitzer (2011) studied 2½ million putts by
professional golfers. Par putts were less likely than same-length birdie
putts to stop short of the hole (indicative of loss aversion). Loss
aversion was found in 94% of golfers (including Tiger Woods). McFall
(2016) reported additional evidence of loss aversion among professional
golfers playing par five holes. Golfers penalised for hitting their tee
shot out of bounds adopted a riskier approach to playing the rest of the
hole than those not penalised. This attempt to avoid loss (i.e., a bogey
or worse) was ineffective because it impaired their performance. Eil and
Lien (2014) studied very experienced poker players. In spite of their
expertise, they typically played more aggressively (i.e., betting and
raising more often) when losing (indicating loss aversion). In addition,
as predicted by prospect theory, they were risk averse when winning.
Abdellaoui et al. (2013) studied financial professionals handling an
average of £200 million (230 million euros) each. As prospect theory
predicts, they were risk averse for gains and risk seeking for losses on
a money-based task. Their risk aversion for gains was comparable to
students but they were less loss averse than students (see Figure 13.6).
In sum, experts in several different areas show clear evidence of loss
aversion when losing. They also exhibit risk aversion when winning.
Thus, prospect theory is applicable to the real world.

Findings: description-experience gap Most research on prospect theory
has used a description-based approach where outcomes and their
associated probabilities are presented explicitly. There is also an
experience-based approach where information about outcomes and
associated outcomes is acquired through sampling. Wulff et al. (2018)
carried out a meta-analysis of relevant research. Overall, there was a
robust description-experience gap: individuals are more likely to
overweigh the probability of rare events when exposed to descriptions
than when experiencing events. Since prospect theory predicts that rare
events should be overweighed, the description-based findings are
apparently more consistent with the theory than the experience-based
findings. How can we explain the description-experience gap? The single
most important factor is a sampling error when the experience-based
approach is used because participants making decisions from experience
often fail to encounter rare events. However, Wulff et al. (2018) found
there was still a description-experience gap (but much smaller) when
experienced frequencies of events closely resembled actual
probabilities. Glöckner et al. (2016) pointed out that nearly all
studies finding a description-experience gap had compared choices of a
certain option against a risky option. This could partially explain the
gap because certainty of outcome cannot be achieved in experience. When
Glöckner et al. avoided using certain options, they consistently
obtained a reversal of the description-experience gap (i.e., a reverse
description-experience gap, or a greater overweighting of rare events in
decisions made from experience than from descriptions). Thus, the
relationship between experience-based and description-based
decision-making is more complex than usually assumed. In sum,
description-experience gaps are of importance for various reasons.
First, most research has involved description-based decisions

Judgement and decision-making

647

IN THE REAL WORLD: NIK WALLENDA'S DECISION-MAKING Individuals differ
enormously in their willingness to take risky decisions. Consider Nik
Wallenda, the American tightrope walker known as "the King of the Wire"
(Newell, 2015). On 23 June 2013, he walked along a wire suspended 1,500
feet above the Grand Canyon without a safety harness or safety net. The
conditions were windy, and at one point Wallenda said "Winds are way
worse than I expected". However, he successfully reached the other side.
Most people would never consider making Nik Wallenda's life-threatening
decision. How can we explain his decision-making? He focused Nik
Wallenda at the Grand Canyon. very much on the gains: "I do this because
Tim Boyles/Getty images. I love what I do . . . Walking the wire to me
is life." Most importantly, his strong Christian faith allowed him to
minimise potential losses: "I know where I'm going to go when I die . .
. I'm not scared of dying." His friend Michael Mascitto said that
Wallenda had realised that "God is giving him a platform to use his
abilities for God's glory".

whereas experience-based decisions are common in everyday life. Second,
prospect theory cannot provide a coherent account of the different
description-experience gaps reported in the literature. Third,
descriptions have been used to test most aspects of prospect theory. We
need to assess experience-based decisions much more often to test the
generality of findings obtained based solely on descriptions.

Findings: individual differences Prospect theory de-emphasises
individual differences (see discussion above of Nik Wallenda). Consider
research on the show Deal or No Deal, a game of chance on which
contestants can win or lose large sums of money. As predicted by
prospect theory, most participants are risk averse, especially when the
stakes are high (Brooks et al., 2009). However, there are large
individual differences in willingness to take risks even with very high
stakes. Narcissism, a personality dimension involving excessive
self-regard, was studied by Foster et al. (2011). Individuals high in
narcissism engaged in riskier stock-market investing because they have
high sensitivity to reward but low sensitivity to punishment. According
to prospect theory, people should be risk averse for gains but risk
seeking to avoid losses. Contrary evidence was reported by Gigerenzer
and Garcia-Retamero (2017). Only 25% of participants showed the expected
pattern whereas 44% were consistently risk averse or risk seeking for
both gains and losses (21% risk averse and 23% risk seeking). How can

648

Thinking and reasoning

we explain these findings? Individuals especially motivated to avoid
regret are consistently risk averse whereas those attaching less concern
to possible regret are more likely to be consistently risk seeking.

Evaluation Prospect theory represents a substantial advance over
previous approaches (e.g., subjective expected utility theory). The
value function (especially the notion that losses loom larger than
gains) accounts for many phenomena (e.g., loss aversion; sunk-cost
effect; framing effect). The theory has wide applicability as has been
shown by the discovery that professional golfers, experienced poker
players and financiers all show loss aversion. More generally, prospect
theory was crucial in the development of behavioural economics -- using
a knowledge of psychological processes to understand economic
decision-making. What are prospect theory's limitations? First, "\[It\]
lacks any unifying principle that might explain why such preferences
\[e.g., loss aversion\] exist" (Houston et al., 2014, p. 502). Part of
the answer may lie in our evolutionary history (McDermott et al., 2008).
For example, engaging in risky behaviour may be optimal for someone
starving, whereas it makes evolutionary sense to minimise risk when
resources are abundant. However, this approach needs to consider whether
individuals' ability to predict likely future conditions influences
their tendency to engage in risky behaviour (Mallpress et al., 2015).
Second, the reference point is a cornerstone of prospect theory (see
Figure 13.4) because it determines whether any given outcome is
desirable or undesirable. Terzi et al. (2016) provided participants with
several possible reference points (e.g., the average payoff received by
other participants; the experimenter's prediction as to the individual
participant's likely payoff). Participants chose different reference
points. Lack of clarity about participants' reference points makes it
hard to test theoretical predictions. Third, prospect theory has little
to say about the cognitive processes underlying the various
decision-making biases. However, Pachur et al. (2018) found that
variations in loss aversion depended in part on participants' allocation
of attention, showing the value of considering cognitive processes.
Fourth, much research is artificial because participants receive summary
descriptions of the relevant probabilities and outcomes rather than
experiencing them directly as in real life. There is sometimes less
support for prospect theory with more naturalistic conditions (e.g.,
Wulff et al., 2018). Fifth, loss aversion occurs less often than
predicted by the theory (Yechiam, 2018). This is especially the case
when decision-making involves relatively small amounts of money. Sixth,
individual differences in the willingness to make risky decisions are
de-emphasised. For example, the theory does not predict that many people
are risk averse (or risk seeking) for both gains and losses. Seventh,
prospect theory also de-emphasises the impact of social and emotional
factors (Newell, 2015; see below, pp. 649--654). Of particular
importance, prospect theory has poor predictive power when the potential

Judgement and decision-making

losses associated with a decision are of great personal relevance (e.g.,
medical side effects; Suter et al., 2016 (discussed below)).

DECISION-MAKING: EMOTIONAL AND SOCIAL FACTORS Emotional factors are
important in decision-making because winning and losing both have
emotional consequences. The underlying processes involved are discussed
here. Social factors are also important. Laboratory decisions are rarely
taken in a social context. However, we often need to justify our
decisions to others in our everyday lives. Consider a contestant on Who
Wants to be a Millionaire? deciding whether to attempt a question when
there are two possible answers left. If they answer correctly, they gain
£75,000 (82,000 euros), but they lose £25,000 (27,300 euros) if they are
wrong. In strict financial terms, the balance of advantage lies with
answering the question. Suppose, however, the contestant's family is
poor, and their lives would be transformed by taking home the money
already won. In that case, the social context strongly indicates the
contestant should take the money. Social factors influencing
decision-making are discussed later.

Emotional factors The effects of emotion on decision-making are complex.
Giorgetta et al. (2013) studied gambling with the choices made by the
participant or a computer. When participants lost, they experienced
regret if they had made the decision, but disappointment if the computer
had. Regret was followed by riskier choices than disappointment. Wins
were experienced as rejoicing (personal choices) or elation (computer
choices), with elation being followed by riskier choices. Overall, the
findings were more consistent with prospect theory when participants had
a sense of personal agency (i.e., regret and rejoicing conditions).
According to Kahneman (2011, p. 287), "Humans described by prospect
theory are guided by the immediate emotional impact of gains and
losses." The details of what is involved are unclear in prospect theory.
However, here are two plausible predictions stemming from prospect
theory (Charpentier et al., 2016): (1)

(2) 

The theory assumes there is diminishing sensitivity to changes in value
as gains and losses increase (see Figure 13.4). It might be predicted
the same diminishing sensitivity would be found for feelings associated
with gains and losses. The theory assumes the subjective value of a
given loss is greater than the impact of an equivalent gain (see Figure
13.4) and this produces loss aversion. We might predict feelings would
be influenced more by a given loss than an equivalent gain.

Charpentier et al. (2016) tested the above predictions. They obtained
strong support for the first prediction with both expected (anticipated)
and experienced feelings associated with gains and losses. There was
also evidence for

649

650

KEY TERM Impact bias Overestimation of the intensity and duration of
negative emotional reactions to losses and positive emotional reactions
to gains.

Thinking and reasoning

impact bias -- the impact of given losses or gains was greater on
expected

feelings than on experienced feelings. Charpentier et al. (2016, p. 768)
surprisingly failed to support the second prediction: "When feelings
associated with losses and gains are evaluated separately . . . losses
are not experienced more intensely than gains." How, then, can we
explain loss aversion? Individuals often make loss-averse decisions
because they attend more to (and weigh more heavily) the negative
feelings anticipated from loss than the positive feelings anticipated
from gain. Note that we saw the impact of attentional processes on loss
aversion earlier in the chapter (Pachur et al., 2018). Suter et
al. (2016) distinguished between decision-making when the negative
prospects are affect-poor (e.g., monetary losses) and when they are
affect-rich (e.g., medical side effects). They investigated whether
prospect theory could explain findings from both affect-poor and
affect-rich problems. With affect-rich problems, participants imagined
they suffered from an unspecified illness requiring medication. They
chose between two medications each producing a given side effect with
some probability (e.g., medication A: insomnia with a probability of
15%; medication B: fever with a probability of 10%). With affect-poor
problems, participants chose between two monetary lotteries each leading
to a given amount of loss with some probability. The findings are shown
in Figure 13.7. First, the decisions made by over 90% of participants
with affect-poor problems conformed to expectations from prospect
theory, whereas the comparable figure was much less with affect-rich
problems. Second, many more participants used the minimax rule (ignoring
probabilities), which is inconsistent with prospect theory, and focusing
only on outcomes, i.e., unpleasantness of the possible side effects)
with affect-rich problems. In sum, prospect theory is much less
applicable to affect-rich choices than affect-poor ones.

(a) Aﬀect--poor

Aﬀect--rich without WTP

5% 29%

40%

31% 95% Figure 13.7 Percentages of participants adhering to cumulative
prospect theory (CPT), the minimax rule, or unclassified with
affect-poor and affect-rich problems (a) with or (b) without numerical
information concerning willingness to pay (WTP) for medication. From
Suter et al. (2016).

CPT Minimax Unclassiﬁed

(b) Aﬀect--poor

5%

Aﬀect--rich with WTP 2.5% 32.5%

92.5%

22.5%

45%

651

Judgement and decision-making

Omission bias and status quo bias

KEY TERMS

There is other evidence that emotional factors influence
decision-making. One example is omission bias, a preference for inaction
to action with risky decision-making. For example, British parents were
asked questions about having their children inoculated against various
diseases (Brown et al., 2010). They were willing to accept a greater
risk of their children having a disease than of their children suffering
adverse reactions to vaccination. Omission bias with respect to having
children vaccinated occurs because parents believe this would increase
their anticipated responsibility and regret (Wroe et al., 2005). Even
experts exhibit omission bias. Pulmonologists (experts in treating lung
disease) received scenarios involving an evaluation of pulmonary
embolism and treatment of septic shock (Aberegg et al., 2005). They were
significantly less likely to select the best management strategy when
they had the option of doing nothing. Feldman and Albarracin (2017)
found social norms (accepted standards of behaviour) influenced regret
following action and inaction. Perceived regret was greater for action
than inaction when social norms favoured inaction. However, this effect
was much reduced (or even reversed) when social norms favoured action.
Brewer et al. (2016) conducted a meta-analytic study focusing on action
vs inaction with respect to health behaviour and anticipated regret.
Anticipated regret strongly predicted whether individuals engaged in
action or inaction. Thus, action regret was associated with inaction and
inaction regret was associated with action. Overall, anticipated regret
predicted individuals' behaviour more strongly than did other negative
emotions (e.g., worry). Another example of decision avoidance caused by
emotional factors is status quo bias -- individuals often prefer to
accept the status quo (current state) rather than change their decision.
For example, many individuals maintain the same allocation of retirement
funds year after year even when no costs would be incurred by changing
(Samuelson & Zeckhauser, 1988). Nicolle et al. (2011) found mistaken
rejection of the status quo triggered stronger feelings of regret than
mistaken acceptance of the status quo. In addition, mistaken rejection
of the status quo was associated with greater activation in brain
regions (medial prefrontal cortex; insula) associated with regret.
Anderson (2003) proposed a rational-emotional model to account for
decision avoidance. Within the model, the omission and status quo biases
were both explained in terms of regret and fear. We have seen regret is
important. Fear is relevant because it reduces when someone decides to
defer making a decision. Anderson's (2003) model cannot explain why
individuals often experience more regret for inaction than errors of
action when asked a long time afterwards (Leach & Plaks, 2009). It also
fails to explain why status quo bias is more common when decision-makers
have numerous options rather than just a few (Dean et al., 2017).
Finally, status quo bias is found even with trivial decisions (e.g.,
deciding whether to switch television channels: Esteves-Sorenson &
Perrett, 2012). It is hard to believe regret or fear lie

Omission bias A biased preference for risking harm through inaction
compared to risking harm through action. Status quo bias A preference
for maintaining the status quo (present state) rather than acting to
change their decision.

652

Thinking and reasoning

KEY TERM

behind people's decision to remain on the same television channel rather
than switching!

Interoception Sensitivity to bodily stimuli (especially those relating
to emotion) at the conscious or nonconscious level.

Brain mechanisms We can obtain additional insights into the role of
emotion in risky decision-making by studying patients with damage to
brain areas associated with emotion. Shiv et al. (2005) used a gambling
task where the most profitable strategy was to gamble on every round.
Patients with damage to emotion regions (amygdala, ventromedial
prefrontal cortex and insula) gambled significantly more often than
other brain-damaged patients and healthy controls, and thus gained the
most money. Why was this? The other two groups were much less likely to
gamble immediately following a loss. In contrast, the patients with
damage to emotion areas were totally unaffected by the outcome of the
previous round. The above findings do not mean emotional involvement
necessarily impairs decision-making. Seo and Barrett (2007) studied
decision-making performance on a stock-investment simulation among
experienced stock investors. Those reporting more intense feelings
performed better than those with less intense feelings because they had
a good understanding of their emotions. Kandasamy et al. (2016) studied
individuals' sensitivity to their own bodily stimuli (interoception).
Financial traders working on a London trading floor showed superior
interoceptive ability by perceiving their own heartbeats more accurately
than controls. Interestingly, traders with the highest interoceptive
ability generated greater profits and survived longer in the financial
markets. These findings suggest "gut feeling" is important for
successful risk taking. Research has clarified the roles of specific
brain areas in risky decision-making. De Martino et al. (2010) studied
loss aversion in two women (SP and AP) with severe damage to the
amygdala (see Glossary; and Chapter 15). Neither had loss aversion,
suggesting the amygdala acts as a "cautionary brake". Sokol-Hessner et
al. (2013) studied risky financial decision-making. Participants
instructed to engage in emotion regulation (designed to reduce their
emotional involvement in the task) showed reduced loss aversion. Other
findings suggested this happened because emotion regulation decreased
amygdala responses to losses. Patients with damage to the ventromedial
prefrontal cortex display elevated risk-taking behaviour with respect to
potential gains and losses especially when the probability of success is
low (e.g., Weller et al., 2007). Studer et al. (2015) investigated the
impact of damage to the ventromedial prefrontal cortex using a task
assessing risk-sensitive decision-making. They distinguished between
risk appetite (overall level of betting) and risk adjustment (adjusting
bets to take account of the probability of winning). What did Studer et
al. (2015) find? The patients showed greater risk appetite than healthy
controls (especially when risk taking was disadvantageous) and poorer
risk adjustment. Unsurprisingly, their betting performance was poor.
Thus, the ventromedial prefrontal cortex plays a key role in processing
of risk and in successful decision-making under risk.

Judgement and decision-making

653

Social factors Tetlock (2002) emphasised the importance of social
factors in his social functionalist approach. He argued people often act
like intuitive politicians: "They are accountable to a variety of
constituencies . . . their long-term success at managing impressions
hinges on their skill at anticipating objections that others are likely
to raise to alternative courses of action" (p. 454). Simonson and Staw
(1992) studied the effects of accountability on decision-making in a
study on the sunk-cost effect (see Glossary; see p. 644). Some
participants were told their decisions would be shared with instructors
and other students (high-accountability condition) whereas others were
told their decisions would be confidential (low-accountability
condition). Highaccountability participants were more likely to continue
with their previously ineffective course of action. They showed a
stronger sunk-cost effect because they experienced a greater need to
justify their previous decisions. Tetlock and Boettger (1994) found that
accountability influenced performance when participants decided on the
acceptability of a new drug (Carozile) that was not yet on the market.
Participants were told it would probably save many lives but would also
probably cause many deaths. There was much more evidence of the status
quo bias (maintaining the present state but not accepting the drug) when
they felt accountable for their decision. Accountability pressures also
influence experts' decisions (see Box). Schwartz et al. (2004) asked
medical experts to choose treatment for a patient with osteoarthritis.
Their decision-making was more biased when they were made accountable
for their decision by writing an explanation for it and agreeing to be
contacted later to discuss it.

IN THE REAL WORLD: POLITICIANS' DECISION-MAKING It has sometimes been
argued (e.g., Axelrod, 2015) that many (or most) politicians are experts
at decision-making because they work in an environment requiring
numerous decisions. A counterargument is that politicians' decisions are
often open to public scrutiny (and thus accountability) which might
increase their tendency to make biased decisions. For example,
politicians in the United Kingdom (and elsewhere) often greatly increase
spending on failing projects: this is basically the sunk-cost effect.
Sheffer et al. (2018) presented participants with a sunk-cost decision
scenario involving a failing government scheme to provide loans to small
businesses. The participants consisted of politicians and population
samples from three countries. The proportions voting to extend the loan
programme are shown in Figure 13.8. Politicians showed more evidence of
the sunk-cost effect in all three countries. Sheffer et al. (2018) also
studied the status quo bias (see Glossary) in politicians and population
samples. Participants decided whether to whether to abandon the present
economy policy plan in favour of a different plan that would increase
economic growth but also increase the budget deficit. What findings
would we expect? Earlier we discussed findings indicating that high
accountability increases the probability that individuals will show the
status quo bias (Tetlock & Boettger, 1994). Suppose we assume
politicians experience greater feelings of accountability than
non-politicians

Figure 13.8 Proportion of politicians (circles) and population samples
(diamonds) in Belgium, Canada and Israel voting to extend a loan
programme (proportions above 0.5 indicate the sunkcost effect). From
Sheffer et al., 2018.

Thinking and reasoning

Proportion voting to extend (predicted probabilities)

654

1.0 0.9 0.8 0.7 0.6 0.5 0.4 0.3 All

Belgium

Canada

Israel

(especially with respect to being held accountable for the increase in
the budget deficit). That would lead us to predict politicians would
show more evidence of the status quo bias (i.e., sticking with the
present plan). Sheffer et al. (2018) obtained the predicted findings. In
sum, politicians are more prone to various decision-making biases
(sunk-cost effect; status quo effect) than other people. These findings
help to explain some of the poor decisions made by politicians and
suggest that accountability can distort the decision-making process.

The social functionalist approach could be developed to account for
cultural factors. Consider the distinction between individualistic
cultures (emphasising individual responsibility) and collectivistic
cultures (emphasising interpersonal relationships). Those living in
individualistic cultures are more sensitive to losses and so exhibit
more loss aversion than those in collectivistic cultures (Wang et al.,
2017; Xie et al., 2018). The above findings can be interpreted by the
cushion hypothesis, according to which the social support provided by
others in collectivistic cultures provides a "cushion" for potential
financial losses. What are the limitations with the social functionalist
approach? First, individual differences in the extent to which people
feel the need to justify themselves to others are de-emphasised. Second,
most research has involved laboratory tasks lacking real demands on
social responsibility. Third, we have a limited understanding of the
underlying mechanisms. For example, increased accountability often
changes decisions but the role of cognitive processes (e.g., attention;
deliberate or analytic thinking) remains largely unexplored.

APPLIED AND COMPLEX DECISION-MAKING There are two important differences
between decision-making in the laboratory and the real world. First,
decision-making has more serious

655

Judgement and decision-making

consequences in the real world. For example, medical experts make
lifeor-death diagnostic decisions (see Chapter 12). Some other decisions
are also both important and complex (e.g., "Should I marry John?";
"Should I move to Australia?"). Second, laboratory-based decision-makers
typically make a single decision. In contrast, in real life we often
make several decisions over time as we strive towards important goals
(e.g., establishing a career).

Fast-and-frugal heuristics: applied decision-making It seems reasonable
to assume effective real-world decision-making typically involves
complex strategies. In contrast, advocates of the fast-and-frugal
approach (e.g., Gigerenzer, 2014; discussed earlier, pp. 634--637),
assume simple heuristics or rules of thumb can be more effective than
complex strategies. The approach based on fast-and-frugal heuristics
explains some decisions in applied settings (see Hafenbrädl et al.,
2016). For example, the fast-and-frugal approach has been applied to
investment decision-making. DeMiguel et al. (2009) compared a simple
heuristic (1/N: allocate funds equally to each of N funds) against 14
other much more complex models including the mean-variance portfolio,
which won its creator (Harry Markowitz) the Nobel Prize in economics.
None of these complex models was consistently better than 1/N. How can
this be? Complex models are very sensitive to past data about stocks.
However, they are sensitive to "noise" in the data as well as its
underlying structure which leads to overly complex and distorted models.
How can doctors decide whether a patient with acute vestibular syndrome
(symptoms include vertigo, nausea and unsteady gait) has had a stroke?
They can use magnetic resonance imaging (MRI) but that is expensive. A
much cheaper (and easier) approach is to administer three short tests of
abnormalities in eye movements and then apply a simple tallying
heuristic -- a stroke is diagnosed if at least one test indicates
abnormality. Newman-Toker et al. (2013) found strokes were detected more
often using this heuristic than with MRI, both typically used within two
days of arrival at a medical centre. In sum, the approach based on
fast-and-frugal heuristics sometimes provides reasonable decisions in
complex situations. As discussed earlier, an issue with this approach is
whether it is really as simple as is generally assumed. For example,
there are unresolved problems relating to how we acquire the various
heuristics and how decision-makers select the most appropriate heuristic
for a given problem (Otworowska et al., 2018).

Complex decision-making In an ideal world, our decision-making would
involve strategies maximising utility (the subjective desirability of an
outcome). Such strategies "involve exhaustive computations based on
perfect knowledge of decision-relevant information, possible choices,
and their outcome probabilities and consequences" (Oh et al., 2016,
p. 1937).

KEY TERM Utility How rewarding or satisfying a given outcome is
perceived to be subjectively.

656

Thinking and reasoning

KEY TERM

Multi-attribute utility theory (see Dyer, 2016) is an approximation to
an ideal strategy involving the following stages:

Satisficing Simplifying the decisionmaking process by using heuristics
and ignoring some relevant information sources; the term represents a
blend of the words satisfactory and sufficing.

(1) 
(2) 
(3) 
(4) 
(5) 

Identify attributes relevant to the decision. Decide how to weigh those
attributes. List all options under consideration. Rate each option on
each attribute. Obtain a total utility (i.e., subjective desirability
for each option by summing its weighted attribute values) and select the
one with the highest weighted total.

We can see this theory's workings by considering someone deciding which
flat to rent. First, the relevant attributes (e.g., number of rooms;
rent per week) are identified. Second, the relative utility of each
attribute is calculated. Third, the flat with the highest total utility
is chosen. It has often been assumed that individuals rarely adopt this
optimal strategy. They typically possess incomplete knowledge of
decisionrelevant information and they are constrained by processing
limitations (e.g., small short-term memory capacity). However, some
evidence suggests that individuals can approximate to this optimal
strategy provided the decision-making task is only moderately complex.
For example, Brusovansky et al. (2018) asked participants acting as job
interviewers to choose one of two candidates based on the candidates'
attributes (3, 4 or 5 attributes) and the importance of those attributes
(weights of 1, 2, 3 or 4). Participants were required to make rapid
decisions (mean response time was 1.5 seconds). What did Brusovansky et
al. (2018) find? Mean overall accuracy was 86% in spite of the speed of
responding (varying between 90% for 3-attribute problems and 84% for
5-attribute problems). The key finding was that 59% of the participants
used a strategy approximating that assumed by multiattribute utility
theory. Since decisions were made rapidly, the processing of attributes
and their weights must have occurred fairly "automatically". In spite of
findings such as those of Brusovansky et al. (2018), our limited
processing ability means we cannot readily use the strategy described by
multi-attribute utility theory with more complex decision-making
problems. Instead, we often engage in satisficing (formed from the words
satisfactory and sufficing). Satisficing involves "fast but
'good-enough' heuristic decision-making that prioritises some sources of
information while ignoring others" (Oh et al., 2016, p. 1937). Schwartz
et al. (2002) emphasised the importance of individual differences. They
distinguished between satisficers (content with making reasonably good
decisions) and maximisers (perfectionists). Satisficers were happier and
more optimistic than maximisers and experienced less regret and
self-blame. According to Cheek and Schwartz's (2016) two-component
model, maximisers differ from satisficers in setting higher goals (i.e.,
choose the best) and in strategy (seek out numerous options and compare
them). In similar fashion, Luan and Li (2017) distinguished between goal
desirability and feasibility (the effort required to achieve the goal).
The main difference between maximisers and satisficers was that the
former were willing to put more effort into achieving desirable goals.
For example,

Judgement and decision-making

maximisers were willing to wait much longer than satisficers for a table
at a highly desirable restaurant (78 vs 51 minutes).

Elimination by aspects Tversky (1972) argued that we often use
relatively simple strategies. According to his elimination-by-aspects
theory, decision-makers eliminate options by considering one relevant
attribute or aspect after another. For example, someone buying a house
may initially consider geographical location, eliminating all houses
outside a given area. They may then consider the attribute of price,
eliminating all properties costing above a certain figure. This process
continues attribute by attribute until only one option remains.
Elimination by aspects has the advantage that it is relatively
undemanding cognitively. However, the option selected often varies as a
function of the order in which the attributes are considered. As a
result, the selected option may not be the best one. Kaplan et
al. (2011) proposed a modified version of Tversky's (1972) theory. In
their two-stage theory, the initial stage resembles elimination in that
only options fulfilling certain criteria are retained, which reduces the
options being considered to a manageable number. The second stage
involves detailed comparisons of the patterns of attributes of the
retained options and is only feasible when the number of options is
relatively small.

Findings Payne (1976) asked students to decide among flats based on
information about various attributes (e.g., rent; distance from campus).
When there were many flats to consider, the students typically started
with a simple strategy (e.g., satisficing; elimination-by-aspects). When
only a few flats remained, they often switched to a more complex
strategy corresponding to the assumptions of multi-attribute utility
theory. Kaplan et al. (2011) obtained support for their two-stage
theory. Student participants selected an apartment after having searched
through information relating to 600 apartments. In the first stage, the
three most popular criteria for retaining or eliminating apartments were
location, walking time to the university and rental price. In the second
stage, participants' calculations included complex interactions between
attributes. For example, the importance attached to a low rental price
depended on several other factors (e.g., price knowledge; frequency of
going to the university; experience of searching for apartments). More
specifically, low rent was most important when participants had little
price knowledge, went frequently to the university and had often
searched for apartments in recent years. Lenton and Stewart (2008)
obtained similar findings when single women made selections from a real
dating website with 4, 24 or 64 potential dates. Unsurprisingly, the
women shifted from complex to simple strategies with increased numbers
of potential dates. The weighted averaging strategy assumed by
multi-attribute utility theory was used by 81% with 4 potential dates
but only 41% choosing from 64. The respective figures for the
elimination-by-aspects strategy were 39% and 69%, respectively, and

657

658

KEY TERM Selective exposure A preference for information that
strengthens pre-existing views and avoidance of information conflicting
with those views.

Thinking and reasoning

for the satisficing strategy were 6% and 16% (the numbers exceed 100%
because many women used multiple strategies). Which attributes most
influence date choice depends on how easily they are assessed.
Speed-dating decisions at large events were determined mostly by easily
assessable attributes (e.g., age; height; weight) rather than those
harder to assess (e.g., occupation; academic achievements) (Lenton and
Francesconi, 2010). The opposite was the case at small events. These
findings probably reflect the increased cognitive load at large events.

Evaluation Elimination-by-aspects theory has proved reasonably
successful when individuals choose among numerous options. However,
individuals often adopt a more complex approach resembling that of
multi-attribute utility theory with relatively few options. Thus,
elimination by aspects is a useful filter at an early stage of
decision-making but is less valuable subsequently.
Elimination-by-aspects theory does not take account of our preference
for options sharing many attributes with other options. Adding this
preference to the elimination-by-aspects approach enhances its ability
to predict people's choices in decision making (Won, 2012).

Complicating factors: changing preferences and selective exposure Most
theories (including those discussed earlier) assume a given individual's
assessment of the utility or preference (desirability X importance) of
any given attribute remains constant. Simon et al. (2004) tested this
assumption. Participants decided between job offers from two department
stores using four attributes (e.g., salary; commuting time). They were
then told one job was in a much better location. This increased
preferences for desirable attributes of the chosen job and decreased
preferences for undesirable attributes of that job. These findings are
inconsistent with the notion that preferences remain constant. Decisions
can even cause individuals to misremember factual information used
during decision-making. Advanced nursing students prioritised a male or
female patient for surgery. Afterwards, their memory for the facts
(e.g., probability of surviving surgery) was distorted to increase the
apparent support for their decision. It may seem changing preferences is
irrational and likely to impair decision-making. However, changing
preferences can be entirely rational if individuals' initial preferences
are based on uncertain or "noisy" observations (Howes et al., 2016).
This viewpoint is supported by the finding that preference changing is
more common when time pressure decreases, suggesting preference changing
is based on deliberate or analytic thinking. Most theories discussed
earlier assumed decision-makers are provided with all the information
relevant to making a decision. However, an important factor in poor
decision-making is selective exposure -- the tendency to prefer
information consistent with one's beliefs over inconsistent information.
Fischer and Greitemeyer (2010) proposed a model predicting increased
selective exposure when individuals have high defence motivation

Judgement and decision-making

659 Figure 13.9 A model of selective exposure. Defence motivation (a
need to defend one's own position) increases the individual's selective
exposure to confirmatory information. Accuracy motivation reduces
selective exposure when it is triggered by the goal of making the
optimal decision but increases it when it is triggered during the search
for information. From Fischer and Greiemeyer (2010). Reprinted by
permission of SAGE Publications.

(i.e., a need to defend their personal position) (see Figure 13.9).
Increased selective exposure should also be found when decision-makers
have high accuracy motivation but restricted access to information.
Reduced selective exposure occurs when there is high accuracy motivation
produced by instructing decision-makers to make the best choice. All
these findings were reported in a meta-analysis (Hart et al., 2009).

Naturalistic decision-making The artificiality of much laboratory
research has led to an increasing interest in naturalistic
decision-making. For example, in the laboratory, individuals typically
make decisions from a clear set of options. In contrast, real-life
decision-making often occurs in relatively unstructured situations where
individuals must generate their own options. Galotti (2002) proposed a
theory of naturalistic decision-making in unstructured environments
involving five phases: setting goals; gathering information; structuring
the decision (i.e., listing options + criteria for deciding among them);
making a final choice; and evaluating the decision. Phase order is
flexible, with decision-makers often returning to previous phases when
struggling to make a decision (see Figure 13.10). A key phase in
Galotti's theory is decision structuring. Galotti (2007) discussed five
studies on important real-life decisions (e.g., students choosing a
college; students choosing their main subject). There were several
findings: (1)

Decision-makers constrained the amount of information they considered,
focusing on between two and five options (mean = four) at any given
time.

660

Thinking and reasoning

(2) The number of options considered decreased over time.
(3) The number of attributes considered at any given time was between
    three and nine (mean = six).
(4) The number of attributes did not decrease over time; sometimes it
    actually increased.
(5) Individuals of higher ability and/or more education considered more
    attributes.
(6) Most of the decisions were assessed as good. The most striking
    finding is that people consistently limited the amount of
    information (options + attributes) considered. This is consistent
    with Simon's (1957) notion of bounded rationality but not
    multi-attribute utility theory. In addition, the number of options
    considered decreased by 18% over Figure 13.10 several months. A
    reduction (though larger The five phases of decision-making
    according to Galotti's than this) is predicted by Tversky's (1972)
    theory. Note the flexibility in the ordering of the phases.
    elimination-by-aspects theory. From Galotti (2002). Galotti and
    Tinkelenberg (2009) obtained similar findings to Galotti (2007).
    Parents choosing a first-grade school focused on a restricted number
    of options (typically 3 out of the 8+ available) and typically
    considered only about 5 criteria or attributes at any given time.
    However, their decision-making was dynamic -- one-third of the
    options and over half the criteria changed on average over a
    six-month period.

Expert decision-making

KEY TERM Bounded rationality The notion that people are as rational as
the environment and their limited processing capacity permit.

We turn now to the processes involved in experts' naturalistic
decisionmaking focusing on Klein's (e.g., 1998, 2008) recognition-primed
decision-making model (see Figure 13.11). When the situation is familiar
or typical, experts match the situation to learned patterns of
information stored in long-term memory using pattern recognition. This
rapid automatic process typically leads to retrieval of a single option.
It is followed by mental simulation (i.e., imagining what would happen
if the expert acted on the retrieved option). If the imagined outcome is
satisfactory, that option rapidly determines his/her actions. There is
much support for the model. Klein (1998) found in an analysis of over
600 decisions that various kinds of experts (e.g., fireground
commanders; military commanders) generally considered only one option at
a time. Experts typically rapidly categorised even a novel situation as
an example of a familiar type of situation. After that, they simply
retrieved the appropriate decision from long-term memory. Klein et
al. (2010) obtained further support for the model based on retrospective
semi-structured interviews with fireground commanders.

Judgement and decision-making

661

Figure 13.11 Klein's recognition-primed decision model. Decision-making
is easy if the situation is typical: pattern recognition based on
information in long-term memory generates a decision that confirms
expectancies. Decision-making is more complex if the decision-maker's
expectancies are violated or if the situation is perceived as not
typical. In either case, there is a process of clarifying and diagnosing
the situation and collecting more data. From Patterson et al. (2009).
British Computer Society.

These commanders considered only one option at 80% of the decision
points encountered while firefighting. There is an interpretive issue
here. Did the fireground commanders consider only one option because it
was objectively the best one (to the extent this can be calculated) or
because there was insufficient time to consider other options? Another
issue is that it is generally assumed fireground commanders make rapid
decisions. However, as Launder and Perry (2014) pointed out, fireground
commanders often obtain relevant information (e.g., from the initial
radio contact) prior to arriving at the fire itself. There is general
agreement that pattern recognition plays a key role in experts'
responses to a crisis situation. However, Launder and Perry (2014)
argued the decision-making involved in urban fire settings is more
complex than assumed within the model. More specifically, they
identified five sequential stages: "Awareness of the situation, deciding
on a strategy to handle the situation, planning how to implement the
strategy, actually implementing the strategy, and reviewing how the
emergency is and/or was handled" (p. 145). The existence of these five
stages was supported by interviews with experienced firefighters.
Individual differences are de-emphasised within the model. Consistent
with the model, most individuals use an intuitive (or System 1) thinking
style when making decisions in areas involving relevant expertise
(Pachur & Spaar, 2015). However, Pachur and Spaar found some individuals
preferred a reflective (or System 2) thinking style even when they
possessed relevant expertise.

Evaluation The recognition-primed decision-making model explains
experts' ability to make rapid, accurate decisions under considerable
pressure, often while

662

Thinking and reasoning

considering only one option (see Schraagen, 2018). The model's emphasis
on their ability to use pattern recognition effectively is consistent
with experts' chess and medical decision-making (see Chapter 13). It
also offers a potential explanation for slower, more deliberate
decision-making in atypical or unfamiliar situations. What are the
model's limitations? First, the model provides a general outline of
expert decision-making but provides few details. For example, when a
crisis situation is perceived as unfamiliar it is assumed experts engage
in clarification and diagnosis. However, the precise information
processing involved depends substantially on the nature of the crisis
and the expert's relevant knowledge. Second, the fact that most evidence
has been obtained in real-life situations is a mixed blessing. One
problem is that the crisis situations investigated were generally so
complex it is hard to identify the key factors triggering experts'
decisions. In addition, there has (inevitably) been extensive reliance
on experts' fallible memories for their thought processes during crisis
situations.

Unconscious thought theory Dijksterhuis and Nordgren (2006) argued that
unconscious thinking is often more effective than conscious thinking
with complex decision-making. Conscious thinking is constrained by the
limited capacity of conscious awareness, and so unconscious thinking is
better than conscious thinking at integrating large amounts of
information. Dijksterhuis and Strick (2016) updated this theory, arguing
that unconscious thinking is most likely to be effective with inherently
interesting problems.

Findings Much research on unconscious thought theory has taken the
following form: (1) (2) (3)

Participants are presented with a problem providing several options;
Problem presentation is followed by a period of conscious deliberation
or distraction (designed to prevent conscious thought about the
problem); Finally, participants select one option.

Theoretically, the prediction is that decision-making performance will
be superior for participants in the distraction condition (who have used
only unconscious thought) than those in the conscious deliberation
condition. Strick et al. (2011) reported significant support for this
prediction in a meta-analysis. However, the magnitude of the effect
depended on several factors (e.g., problem complexity; duration of
distraction or deliberation). Nieuwenstein et al. (2015) also carried
out a thorough meta-analysis based on more studies than those considered
by Strick et al., and obtained weaker overall evidence for an
unconscious thought advantage. Nordgren et al. (2011) argued complex
decision-making should be best if it involved conscious and unconscious
thought. Performance was optimal

Judgement and decision-making

for 57% of participants using conscious thought followed by unconscious
thought, compared to 26% for those using only conscious thought, and 28%
for those using only unconscious thought.

Evaluation Unconscious thought theory has focused attention on the
strengths and limitations of conscious and unconscious thought.
Unconscious thought sometimes (but probably rarely) produces superior
decision-making to conscious thought. The theory may have relevance to
some cases where problem solving has benefited from incubation (putting
a problem to one side for some time; see Chapter 12). Decision-making
can be optimal when individuals combine conscious and unconscious
thought (Nordgren et al., 2011). What are the theory's limitations?
First, the main problem is that the relevant findings are weak and
inconsistent (Nieuwenstein et al., 2015). Second, participants assigned
to the distraction condition are assumed to rely heavily on unconscious,
intuitive processes in their decision-making. However, they often claim
to rely on conscious memory (Aczel et al., 2011).

CHAPTER SUMMARY •

Introduction. There are close links between judgement and
decision-making. However, decision-making covers all processes involved
in deciding on a course of action. In contrast, judgement focuses mainly
on aspects of decision-making concerning with estimating the probability
of various events. Judgements are evaluated in terms of their accuracy
whereas decisions are evaluated on their consequences.

•

Judgement research. Our estimates of the probability of something
happening change in the light of new evidence. When making such
estimates, people often fail to take full account of base-rate
information in part because of their reliance on the representativeness
heuristic. Base-rate information is used more often when people are
strongly motivated to use such information or when full causal knowledge
is available. Some judgement errors depend on use of the availability
heuristic. Errors based on use of the representativeness and
availability heuristics occur in everyday life and are even found in
experts. Medical misdiagnosis based on heuristics can be reduced by
training in guided, structured, reflective processes. According to the
natural frequency hypothesis, judgements are more accurate when based on
natural sampling and frequencies rather than probabilities. In fact, the
reasons for the superiority of frequency formats are varied and complex.

•

Theories of judgement. According to support theory, an event's
subjective probability increases as its description becomes

663

664

Thinking and reasoning

more explicit and detailed. However, the opposite finding has sometimes
been obtained (e.g., when the problem focuses people's attention on
low-probability causes). Fast-and-frugal heuristics (e.g., the
recognition and take-the-best heuristics) are clearly specified and are
often useful. However, judgements often involve making use of more
information sources than assumed by advocates of fast-and-frugal
heuristics. According to Kahneman's dual-process theory, initial
intuitive processing (System 1) is sometimes followed by more conscious
and controlled processing (System 2). This serial processing assumption
is oversimplified as is the notion that the processes used on judgement
tasks can be neatly divided into heuristic and controlled ones. •

Decision-making under risk. According to prospect theory, people are
more sensitive to potential losses than gains, and so are willing to
take risks to avoid losses. The theory is supported by research on
phenomena such as the framing and sunk-cost effects. There is also
evidence of loss aversion in professional golfers, experienced poker
players and financial experts. The theory has limited explanatory
principles and the crucial notion of a "reference point" is often vague.
There is sometimes less support for prospect theory when decisions are
based on experience rather than descriptions. According to prospect
theory, people should be risk averse for gains but risk seeking to avoid
losses. However, many individuals are risk averse (or risk seeking) for
both gains and losses.

•

Decision-making: emotional and social factors. A plausible prediction
from prospect theory is that losses are experienced more intensely than
gains. However, this is not the case when losses and gains are evaluated
separately. Prospect theory is less applicable to affect-rich problems
than affect-poor ones. The emotions of regret and fear often explain the
existence of the omission and status quo biases. Brain areas of
relevance to risky decision-making include the amygdala and ventromedial
prefrontal cortex. According to Tetlock's social functionalist approach,
people's need to justify their decisions to others accounts for some
biases in decision-making. This approach could be developed to explain
cultural differences in loss aversion.

•

Applied and complex decision-making. Decision-makers in the laboratory
and the real world often start by reducing the number of options
considered by eliminating aspects, followed by detailed comparisons of
the retained options. However, experts often consider a single option
and make rapid intuitive decisions especially when there is considerable
time pressure. Making a decision can cause decision-makers to
misremember relevant factual information to increase the apparent
support for that decision. According to Dijksterhuis's unconscious
thought theory,

Judgement and decision-making

unconscious thinking is more useful than conscious thinking, but this is
contradicted by most available research. However, decisionmaking is
sometimes best when conscious thought is followed by unconscious thought

FURTHER READING Hoffrage, U., Hafenbrädtl, S. & Marewski, J.N. (2018).
The fast-and-frugal heuristics programme. In L.J. Ball and V.A. Thompson
(eds), Routledge International Handbook of Thinking and Reasoning
(pp. 325--345). Abingdon, Oxon.: Routledge. The role of fast-and-frugal
heuristics in judgement and decision-making is discussed thoroughly by
Ulrich Hoffrage and his colleagues. Keren, G. & Wu, G. (eds) (2016). The
Wiley Blackwell Handbook of Judgment and Decision-Making (2 vols).
Hoboken: Wiley-Blackwell. This two-volume handbook contains chapters
covering all the main topics in judgement and decision-making research.
Rakow, T. & Skylark, W.J. (2018). Judgement heuristics. In L.J. Ball and
V.A. Thompson (eds), Routledge International Handbook of Thinking and
Reasoning (pp. 451--471). Abingdon, Oxon.: Routledge. The authors
evaluate prominent theoretical accounts of the heuristics or rules of
thumb used on judgement tasks. Schraagen, J.M. (2018). Naturalistic
decision-making. In L.J. Ball and V.A. Thompson (eds), Routledge
International Handbook of Thinking and Reasoning (pp. 487--501).
Abingdon, Oxon.: Routledge. This chapter focuses on what is known about
complex decision-making in the real world. Schulz, C. & Newell, B.R.
(2018). Decision-making under risk: An experience-based perspective. In
L.J. Ball and V.A. Thompson (eds), Routledge International Handbook of
Thinking and Reasoning (pp. 502--522). Abingdon, Oxon.: Routledge.
Christin Schulz and Ben Newell discuss theory and research on
decision-making with an emphasis on the roles played by learning and
experience.

665

Chapter

14

Reasoning and hypothesis testing

INTRODUCTION

KEY TERMS Inductive reasoning Forming generalisations (that may be
probable but are not certain) from examples or sample phenomena; see
deductive reasoning. Deductive reasoning Reasoning to a conclusion from
a set of premises or statements where that conclusion follows
necessarily from the assumption the premises are true; see inductive
reasoning.

For hundreds of years, philosophers have distinguished between two kinds
of reasoning. One is inductive reasoning, which involves drawing general
conclusions from premises (statements) referring to particular
instances. A key feature of inductive reasoning is that the conclusions
of inductively valid arguments are probably (but not necessarily) true.
The philosopher Bertrand Russell provided the following example. A
turkey might use inductive reasoning to draw the conclusion "Each day I
am fed", because that has always been the case in the past. However,
there is no certainty that the turkey will be fed tomorrow. Indeed, if
tomorrow is Christmas Eve, it is likely to be proven false. Scientists
very often use inductive reasoning similarly to Russell's hypothetical
turkey. A psychologist may find across numerous experiments that
reinforcement (reward) is needed for learning. This might lead them to
use inductive reasoning to propose the hypothesis that reinforcement is
essential for learning. This conclusion is not necessarily true because
future experiments may not replicate past ones. The other kind of
reasoning identified by philosophers is deductive reasoning. Deductive
reasoning allows us to draw conclusions that are definitely or certainly
valid provided other statements are assumed to be true. For example, the
conclusion Tom is taller than Harry is necessarily true if we assume Tom
is taller than Dick and Dick is taller than Harry. Deductive-reasoning
problems owe their origins to formal logic. An important issue is
whether the distinction between inductive and deductive reasoning is as
clear-cut in practice as it appears above. There is increasing evidence
that similar processes are involved in both cases. For example, Stephens
et al. (2018) asked participants to evaluate identical sets of arguments
after receiving inductive- or deductive-reasoning instructions. With the
former instructions, participants decided whether the conclusion was
plausible, strong or likely to be true. With the latter instructions,
they decided whether the conclusion was necessarily true.

667

Reasoning and hypothesis testing

Stephens et al. (2018) found participants used the same processes
whether instructed to reason inductively or deductively. The only major
difference was that greater argument strength was required to decide
that a conclusion was necessarily true (deductive condition) than to
decide it was strong or likely to be true. The wide chasm between the
artificial, logic-driven, deductive-reasoning tasks traditionally used
in the laboratory and everyday reasoning in the form of argumentation
has led to a rapid increase in research on informal reasoning. Informal
reasoning (discussed later, pp. 694--701) is based on our knowledge and
experience rather than logic. It is a form of inductive reasoning that
resembles our everyday reasoning. A major consequence of this shift in
research is that it is increasingly accepted that reasoning processes
often resemble those used in judgement and decision-making. For example,
the Bayesian approach, according to which our subjective probabilities
(i.e., that X is dishonest) are adjusted in the light of new
information, plays a prominent role in theorising about judgements (see
Chapter 13). In a similar fashion, the Bayesian approach is increasingly
applied to reasoning (Navarrete and Mandel, 2016).

HYPOTHESIS TESTING Karl Popper (1968) distinguished between confirmation
and falsification. Confirmation involves the attempt to obtain evidence
confirming or supporting one's hypothesis. In contrast, falsification
involves the attempt to falsify hypotheses by experimental tests. Popper
claimed we cannot achieve confirmation via hypothesis testing. Even if
all the available evidence supports a hypothesis, future evidence may
disprove it. He argued falsifiability (the potential for falsification)
separates scientific from unscientific activities such as religion or
pseudo-science (e.g., psychoanalysis). According to Popper, scientists
should focus on falsification. In fact, as discussed later, they often
seek confirmatory rather than disconfirmatory evidence when testing
their hypotheses. It has also been claimed the same excessive focus on
confirmatory evidence is found in laboratory studies on hypothesis
testing -- research to which we now turn.

Wason's 2-4-6 task Wason (1960) devised a much-researched
hypothesis-testing task (see Evans, 2016, for a review). Participants
were told three numbers 2-4-6 conformed to a simple relational rule.
Their task was to generate sets of three numbers and provide reasons for
generating each set. After each choice, the experimenter indicated
whether the set of numbers conformed to the experimenter's rule. Here is
the rule: "Three numbers in ascending order of magnitude." The
participants could announce what they believed to be the rule on any
trial and were told whether it was correct. The rule sounds (very)
simple. However, only 21% of university students were correct with their
first attempt (Wason, 1960). In spite of the emphasis in the literature
on the poor levels of performance with the 2-4-6 task, Wason found 72%
of participants eventually solved it.

KEY TERMS Informal reasoning A form of reasoning based on one's relevant
knowledge and experience rather than logic. Falsification Proposing
hypotheses and then trying to falsify them by experimental tests; the
logically correct means by which science should work, according to
Popper (1968).

668

Thinking and reasoning

KEY TERM

Why is performance so poor? One explanation focuses on confirmation bias
-- most people seek information confirming their hypothesis. For

Confirmation bias In hypothesis testing, seeking evidence that supports
one's beliefs.

example, participants whose original hypothesis or rule is that the
second number is twice the first, and the third number is three times
the first number often generate sets of numbers (test triples)
consistent with that hypothesis (e.g., 6-12-18; 50-100-150). Wason
assumed participants produced test triples conforming to their current
hypothesis. However, this is an oversimplification (Evans, 2016). It is
true that participants mostly produce positive or confirmatory tests
conforming to their hypothesis and expected to receive positive feedback
(conforms to the rule). However, participants sometimes produce negative
tests, not conforming to their hypothesis, where they expect to receive
negative feedback (does not conform to the rule). There are two types of
negative tests (Evans, 2016): (1) (2)

those (e.g., 12-8-4) where participants expect to receive the answer
"No" and which are therefore confirmatory; those (e.g., 1-4-9) where
participants expect to receive the answer "Yes" and which are therefore
disconfirmatory.

Findings Participants typically engage in very few falsification
attempts on the 2-4-6 task and have a low success rate. Tweney et
al. (1980) enhanced performance by telling participants the experimenter
had two rules in mind and they had to identify both. One rule generated
DAX triples and the other MED triples. They were also told 2-4-6 was a
DAX triple. After generating each test triple, participants were
informed whether the set fitted the DAX or MED rule. The DAX rule was
any three numbers in ascending order and the MED rule covered all other
sets of numbers. Over 50% of participants produced the correct answer on
their first attempt (much higher than with the standard problem). Of
importance, participants could identify the DAX rule by using positive
testing to confirm the MED rule, and so they did not have to try to
disconfirm the DAX rule. Gale and Ball (2012) carried out a study
resembling that of Tweney et al. (1980). They always used 2-4-6 as an
example of a DAX triple, but the example of a MED triple was 6-4-2 or
4-4-4. Success in identifying the DAX rule was much greater when the MED
example was 6-4-2 (75%) rather than 4-4-4 (23%). The greatest difference
between solvers and non-solvers of the DAX rule was the number of
descending triples they produced. This indicates the importance of
participants focusing on the ascending/descending dimension, which was
difficult to do when the MED example was 4-4-4. Cowley and Byrne (2005)
argued people show confirmation bias because they are loath to abandon
their initial hypothesis. They suggested people might be much better at
managing to falsify a given incorrect hypothesis if told it was someone
else's. As predicted, 62% of participants abandoned the other person's
hypothesis compared to only 25% who abandoned their

Reasoning and hypothesis testing

own hypothesis. Cowley (2015) extended these findings. Participants were
told the hypothesis "even numbers ascending in two" was theirs or that
of an imaginary participant Peter. They generated more negative
falsifying tests when the hypothesis was Peter's rather than their own
(32% vs 7%, respectively). In another experiment by Cowley (2015), all
participants were told Peter's hypothesis was "even numbers ascending in
twos". In two conditions, they were also told another participant,
James, had a different explicit hypothesis ("any ascending numbers") or
implicit hypothesis ("something else"). In the third, condition, there
was no mention of James. There were three key findings. First, there
were numerous falsifying test triples (positive + negative tests) in all
conditions (percentages between 43% and 54%; predominantly negative
falsifying tests). Second, Peter's incorrect hypothesis was rejected by
nearly 80% of participants. Third, the correct rule was discovered by
50% of participants given James' explicit hypothesis and 31% given his
implicit hypothesis. In sum, "Negative falsifying is possible more often
than the literature has ever shown . . . falsification is sufficient to
announce that a hypothesis is untrue, but an explicit alternative
hypothesis that explains the falsifying result is necessary for truth
discovery" (Cowley, 2015, pp. 32--33). Performance on the 2-4-6 task
involves separable processes of hypothesis generation and hypothesis
testing. Most research has focused on the latter, but Cherubini et
al. (2005) focused on hypothesis generation. They argued participants
try to preserve as much of the information contained in the example
triple (i.e., 2-4-6) as possible in their initial hypothesis, making
this hypothesis much more specific than the general rule. Cherubini et
al. (2005) presented participants with two initial triples exemplifying
the rule. When these triples inhibited the generation of a very specific
rule (e.g., 6-8-10; 9-14-15), participants generated more general
hypotheses than when the two triples were consistent with a specific
rule (e.g., 6-8-10; 16-18-20). The success rate was much higher in the
former condition (70% vs 30%).

Theoretical analysis Most hypotheses are sparse or narrow (applying to
under half the possible entities in any given domain: Navarro & Perfors,
2011). For example, Perfors and Navarro (2009) asked people to generate
all the rules and hypotheses applying to numbers in a given domain
(numbers 1 to 1,000). The key finding was that 83% of the rules (e.g.,
two-digit numbers; prime numbers) applied to fewer than 20% of the
numbers. With sparse hypotheses, positive testing is optimal "because
there are so many ways to be wrong and so few to be right". In such
circumstances, the learner will discover "the world has a bias towards
saying 'no', and asking for 'yes' is the best way to overcome it"
(Perfors & Navarro, 2009, p. 2746). Thus, positive testing is typically
successful. In contrast, the 2-4-6 task penalises positive testing
because the target rule is so general.

669

670

Thinking and reasoning

Evaluation Wason's 2-4-6 task has been "the classic test-bed reasoning
task for investigations of hypothesis falsification for over forty
years" (Cowley, 2015, p. 2), with research having clarified the
strengths and limitations of human inductive reasoning. The processes
involved in the 2-4-6 task are of relevance to understanding scientists'
hypothesis testing. What are the limitations of Wason's approach? First,
his task differs from real-life hypothesis testing. Participants given
the 2-4-6 task receive immediate accurate feedback but are not told why
the numbers they produced attracted a "yes" or "no" response. In the
real world (e.g., scientists testing hypotheses), the feedback is much
more informative, but is often delayed in time and sometimes inaccurate.
Second, the correct rule or hypothesis in the 2-4-6 task (three numbers
in ascending order of magnitude) is very general because it applies to a
fairly high proportion of sets of three numbers. In contrast, most rules
or hypotheses apply to only a smallish proportion of possible objects or
events. Positive testing works poorly on the 2-4-6 task but not with
most other forms of hypothesis testing. Third, Wason argued most people
show confirmation bias and find a falsification approach very hard to
use. However, there is much less confirmation bias but more evidence of
falsification when testing someone else's hypothesis (Cowley, 2015;
Cowley & Byrne, 2005). This is consistent with scientists' behaviour.
For example, at a conference in 1977 on the levels-of-processing
approach to memory (see Chapter 6), nearly all the research presented
identified limitations with that approach.

Hypothesis testing: simulated and real research environments According
to Popper (1968), a crucial feature of all truly scientific theories is
falsifiability. Scientists should focus on falsification rather than
confirmation because the latter cannot be achieved. His arguments
possess merit but are oversimplified (see below). Suppose a scientist
obtains findings apparently inconsistent with their hypothesis. The
findings may mean the hypothesis is incorrect. However, they may reflect
problems with the experimental design or the accuracy of the data. Of
relevance, a recent study (Open Science Collaboration, 2015; see
Chapter 1) found that attempts to replicate 100 findings in psychology
were successful only 36% of the time. Dunbar (1993) found evidence of
confirmation bias using a simulated research environment. Participants
had to explain how genes are controlled by other genes using a
computer-based molecular genetics laboratory. This problem is so
difficult that those solving it in real life (Jacques Monod and François
Jacob) received the Nobel prize! The participants were led to focus on
the hypothesis that the gene control was by activation whereas it was
actually by inhibition. Participants who simply sought data consistent
with their activation hypothesis failed to solve the problem. In
contrast, the 20% of participants solving the problem tried to explain
the discrepant findings. Most participants started with the general
hypothesis that activation was the key

Reasoning and hypothesis testing

671

IN THE REAL WORLD: HYPOTHESIS TESTING BY SCIENTISTS What actually
happens in real-life science? Uchino et al. (2010) analysed numerous
research articles in psychology. The great majority (77%) sought
confirmation by testing the hypothesis favoured by the researcher(s) and
91% supported an existing theory. Only 22% discussed other hypotheses.
These findings suggest, "Someone must be wrong: either scientists are
going about their business incorrectly or Popper was mistaken about how
science progresses" (Sanbonmatsu et al., 2015, p. 2). Sanbonmatsu et
al. (2015) proposed a solution based on a distinction between absolute
or universal hypotheses and non-absolute hypotheses. Absolute hypotheses
claim a given phenomenon always occurs, whereas non-absolute hypotheses
claim a phenomenon occurs only in some conditions. Popper (1968) assumed
scientific theories are absolute or universal. On that assumption, the
optimal approach involves falsification or disconfirmation -- a single
negative observation would disprove an absolute theory. In contrast, a
confirmatory approach is generally more informative than a
disconfirmatory one with non-absolute hypotheses. What do scientists
actually do? Sanbonmatsu et al. (2015) found 96% of researchers in
psychology indicated their research was mostly driven by non-absolute
hypotheses. Nearly all (96%) said they generally used a confirmatory
approach. With absolute hypotheses, 81% of researchers would use a
disconfirmatory approach. With non-absolute hypotheses, in contrast,
only 9% would use a disconfirmatory approach with 91% favouring a
confirmatory approach. Feist (2008) argued a useful heuristic in science
is "confirm early -- disconfirm late". Scientists should initially seek
confirmatory evidence for a theory; when they have such evidence, they
should focus more on disconfirming the theory and discovering its
breadth of application. Eighty-three percent of scientists were most
likely to use a confirmatory approach early in a research programme, and
87% were most likely to use a disconfirmatory approach subsequently
(Sanbonmatsu et al., 2015). In sum, Popper adopted an excessively
black-and-white approach. The reality is messy: research rarely provides
a definitive falsification of a theory. Instead, theories are modified
as their limitations become increasingly apparent (Lakatos, 1978).
Scientists' strategies when engaged in hypothesis testing approximate to
maximising the informativeness of the evidence obtained. Thus,
describing their typical approach as "confirmation bias" (see Glossary)
is misleading. Kane and Webster (2013) suggested using the term
"confirmation heuristic" to refer to appropriate focus on a confirmation
strategy, limiting the use of "confirmation bias" to situations where
scientists refuse to use the disconfirmatory strategy even when optimal.

controlling process, focusing on one gene after another as the potential
activator. Only after every activation hypothesis had been disconfirmed
did some participants focus on explaining data inconsistent with
activation hypotheses.

Confirmation bias: analysis and interpretation We have seen scientists
generally adopt a confirmatory approach during hypothesis testing. We
now focus on confirmation bias when scientists analyse and interpret
their findings (see Nuzzo, 2015, for a review). Fugelsang et al. (2004)
studied professional scientists working on issues in molecular biology
relating to how genes control and promote replication

672

Thinking and reasoning

in bacteria, parasites and viruses. Of 417 experimental results, over
half (223) were inconsistent with the scientists' predictions. They
responded to 88% of these inconsistent findings by blaming problems with
their methods. In only 12% of cases did the scientists modify their
theories. Thus, the scientists showed considerable reluctance to change
their original theoretical position. Approximately two-thirds of the
inconsistent findings were followed up, generally by changing the
methods used. In 55% of cases, the inconsistent findings were
replicated. The scientists' reactions were very different this time --
in 61% of cases, they changed their theoretical assumptions. How
defensible was the scientists' behaviour? Note that almost half the
inconsistent findings were not replicated when a second study was
carried out. Thus, it was reasonable for the scientists to avoid
prematurely accepting possibly spurious findings. Overall, these
findings suggest the scientists' exhibited only a modest tendency
towards confirmation bias. John et al. (2012) asked over 2,000
psychologists to provide anonymous information about their questionable
research practices. There was substantial evidence of such practices.
For example, John et al. estimated 78% of respondents had selectively
reported studies that "worked", 62% had excluded data (typically those
inconsistent with their hypotheses), and 36% had stopped data collection
after achieving the desired result. Here are two other examples of
confirmation bias. First, Bakker and Wicherts (2011) found in an
analysis of statistical analyses in research journals that over 10% of p
values were incorrect. In the great majority of cases where such errors
changed the statistical significance of the results, the change was from
non-significant to significant. Second, researchers often expect their
meta-analyses (see Glossary) to support their existing hypotheses. As
Watt and Kennedy (2017, p. 1) argued, "Decisions about studies to be
included \[in a meta-analysis\], statistical analyses, and moderating
factors are made after the analysts know the outcomes of the studies.
These retrospective decisions provide high potential for
\[confirmation\] bias." How can we reduce confirmation bias in the
analysis and interpretation of data? Several answers have been proposed
(Hamlin, 2017). First, more openness or transparency is required by
experimenters so other researchers can see precisely what has been done.
Second, there is blind analysis -- all relevant statistical analyses are
completed before the experimenter(s) is aware of the outcomes of such
analyses. Third, and most importantly, there is pre-registration --
experimenters announce the rationale, hypotheses, design and proposed
methods of data analysis before conducting a piece of research.

DEDUCTIVE REASONING In deductive reasoning, conclusions can be drawn
with certainty. In this section, we will mostly consider conditional and
syllogistic reasoning problems based on traditional logic. In the next
section, we consider general theories of deductive reasoning. As we will
see, theory and research increasingly focus on the non-logical
strategies and processes used when people solve deductive-reasoning
problems.

673

Reasoning and hypothesis testing

Conditional reasoning

KEY TERM

Conditional reasoning (basically, reasoning with "if") had its origins
in

Conditional reasoning A form of deductive reasoning based on if . . .
then propositions.

propositional logic, in which logical operators such as or, and, if . .
. then, if and only if are included in sentences or propositions. In
this system, symbols represent sentences and logical operators are
applied to them to reach conclusions. Thus, we might use P to stand for
the proposition "It is raining" and Q to stand for "Nancy gets wet", and
then use the logical operator if . . . then to relate these two
propositions: if P then Q. The meanings of words and propositions in
propositional logic differ from their natural language meanings. For
example, propositions can have only one of two truth values: true or
false. If P stands for "It is raining", then P is true (in which case it
is raining) or P is false (it is not raining). Propositional logic does
not admit any uncertainty about the truth of P, such as when it is so
misty you could almost call it raining. Many people produce incorrect
answers when given certain conditional-reasoning problems. Consider the
following (affirmation of the consequent): Premises If Nancy is angry,
then I am upset. I am upset. Conclusion Therefore, Nancy is angry. Many
people accept the above conclusion as valid. However, it is not valid
because I may be upset for some other reason (e.g., my football team has
lost). Here is another problem in conditional reasoning: Premises If it
is raining, then Nancy gets wet. It is raining. Conclusion Nancy gets
wet. This conclusion is valid. It illustrates the rule of inference
known as modus ponens: "If P, then Q" and also given "P", we can validly
infer Q. Another major rule of inference is modus tollens: from the
premise "If P, then Q" and the premise "Q is false", the conclusion "P
is false" necessarily follows. Here is an example: Premises If it is
raining, then Nancy gets wet. Nancy does not get wet. Conclusion It is
not raining.

Interactive exercise: Conditional reasoning

674

Thinking and reasoning

People consistently perform much better with modus ponens than modus
tollens: many people argue incorrectly that the conclusion to the above
problem is invalid. Another inference involves denial of the antecedent:
Premises If it is raining, then Nancy gets wet. It is not raining.
Conclusion Therefore, Nancy does not get wet. Many people argue the
above conclusion is valid although it is invalid. It does not have to be
raining for Nancy to get wet (e.g., she might have jumped into a
swimming pool). Traditionally, research on conditional reasoning was
limited in three ways. First, unlike everyday life, it focused on
disinterested reasoning (goals and preferences are irrelevant). For
example, denial of the antecedent is invalid in traditional logic. In
natural language, however, "If P, then Q" often means "If and only if P,
then Q". If someone says to you "If you mow the lawn, I will give you
five dollars", you are likely to interpret it to imply, "If you don't
mow the lawn, I won't give you five dollars." Second, traditional
research typically involved instructions indicating that background
knowledge was irrelevant. Nowadays, participants are generally not
instructed to disregard their relevant knowledge with
conditional-reasoning problems. Third, traditional research required
participants to draw definite conclusions (true or false). In contrast,
participants nowadays are often asked to assess the probability of the
conclusion being true. This change is desirable because we often assign
probabilities to conclusions in everyday life (Singmann et al., 2016).

Theories Here we briefly discuss theories of conditional reasoning. More
general theories of deductive reasoning are discussed later. Klauer et
al. (2010) proposed a dual-source model of conditional reasoning. There
is a knowledge-based process influenced by premise content where the
subjective probability of the conclusion depends on individuals'
relevant knowledge. There is also a form-based process influenced only
by the form of the premises. Verschueren et al. (2005) also proposed a
dual-process model (other more general dual-process models are discussed
later, pp. 683--690). They focused on individual differences in
conditional reasoning more than Klauer et al. (2010). Some reasoners use
a relatively complex counterexample strategy: a conclusion is considered
invalid if the reasoner can find a counterexample to it (this process is
discussed later in the section on mental models, pp. 681--683). The
other process is an intuitive statistical strategy based on
probabilistic reasoning triggered by relevant knowledge.

Reasoning and hypothesis testing

Findings Singmann et al. (2016) tested the dual-source model using many
conditional-reasoning problems. For each problem, participants rated the
likelihood of the conclusion being true on a probability scale running
from 0% to 100%. Knowledge-based processes were more important than
form-based ones. Overall, the model accounted very well for
participants' performance. De Neys et al. (2005) obtained evidence
relevant to Verschueren et al.'s (2005) dual-process model. On some
trials, participants were presented with few or many counterexamples
conflicting with valid conclusions (modus ponens and modus tollens).
According to classical logic, these counterexamples should have been
ignored. In fact, however, participants were more likely to decide
wrongly the conclusions were invalid when there were many
counterexamples. Markovits et al. (2013) tested the dual-process model
using problems involving affirmation of the consequent (where the
conclusion is invalid). Here are two examples: (1) (2)

If a rock is thrown at a window, then the window will break. A window is
broken. Therefore, a rock was thrown at the window. If a finger is cut,
then it will bleed. A finger is bleeding. Therefore, the finger was cut.

Reasoners using the statistical strategy were influenced by the fact
that the subjective probability that "If a finger is bleeding, it was
cut" is greater than the probability that "If a window is broken, it was
broken by a rock". As a result, such reasoners accepted the invalid
conclusion more often in problem (2) than (1). In contrast, reasoners
using the counterexample strategy accepted the conclusion if no
counterexample came to mind. They also accepted the invalid conclusion
more often in problem (2). This was because it was easier to find
counterexamples with respect to the conclusion of problem (1) (the
window might have been broken by several objects other than a rock) than
the conclusion of problem (2). According to the model, the
counterexample strategy is more cognitively demanding than the
statistical strategy. Accordingly, Markovits et al. (2013) predicted it
would be used less often when participants had limited time. This
prediction was supported: that strategy was used on 49% of trials with
unlimited time but only 1.7% of trials with limited time. Markovits et
al. (2017) gave their participants modus ponens inferences which are
always valid. Each problem was presented with additional information
indicating the relative strength of evidence supporting the inference
(50%; 75%; 99%; or 100%). Markovits et al. compared groups of
participants previously identified as using counterexample or
statistical strategies. Markovits et al. (2017) found clear differences
between the two groups (see Figure 14.1). Statistical reasoners were
strongly influenced by relative strength when deciding whether to accept
modus ponens inferences. In contrast, counterexample reasoners showed a
sharp reduction in acceptance when some evidence failed to support the
inference (e.g., the 99% and 75% conditions). These findings were as
predicted.

675

Figure 14.1 Mean number of MP (modus ponens) inferences accepted (out of
3) as a function of relative strength of the evidence and strategy. From
Markovits et al. (2017).

Thinking and reasoning

Mean number of MP inferences accepted

676

3 2.5 2 1.5

Counterexample

1

Statistical

0.5 0 100%

99%

75%

50%

Relative strength

Summary Research on conditional reasoning has become much more
realistic. For example, reasoners are encouraged to use their relevant
knowledge on reasoning tasks. They also assign probabilities to the
correctness of conclusions rather than simply deciding conclusions are
valid or invalid. Theoretically, it is assumed reasoners are influenced
by the form of the premises. More importantly, however, their relevant
knowledge and experience lead them to engage in probabilistic reasoning
(dual-source model) or to try to find counterexamples to the stated
conclusion (dual-process model).

Wason selection task The Wason selection task has been studied
intensively by researchers interested in deductive reasoning. However,
it is more accurately described as a task involving hypothesis testing
using a conditional rule. Research activity: In the standard version of
the task, four cards lie on a table (R, G, 2, 7; Deductive reasoning see
Figure 14.2). Each card has a letter on one side and a number on the
other, and there is a rule applying to the four cards (e.g., "If there
is an R on one side of the card, then there is a 2 on the other side of
the card"). The participants' task is to select only those cards needing
to be turned over to decide whether or not the rule is correct. What is
your solution? Most people select the R and 2 cards. If you did the
same, you are wrong! You need to see whether any cards fail to obey the
rule when turned over. From this perspective, the 2 card is irrelevant:
if there Figure 14.2 is an R on the other side, this indicates only The
Wason selection task. Rule: If there is an R on one side of the card,
then there is a 2 on the other. that the rule might be correct. If there
is any

677

Reasoning and hypothesis testing

other letter on the other side, we have discovered nothing about the
rule's validity. The correct answer is to select the R and 7 cards, an
answer given by only about 10% of university students. The 7 is
necessary because it would definitely disprove the rule if it had an R
on the other side. How can we explain performance on the Wason selection
task? Several factors are involved. First, performance is worse with
abstract versions of the task (as above) compared to concrete versions
referring to everyday events (e.g., "Every time I travel to Manchester,
I travel by train"). Ragni et al. (2018) found in a meta-analysis that
the percentage of correct answers increased from 7% with abstract
versions to 21% with concrete versions. Second, there is matching bias
(the tendency to select cards matching the items named in the rule).
Thompson et al. (2013a) obtained strong evidence for matching bias on
the selection task. In addition, cards named in the rule were selected
faster than other cards and produced greater feelings of rightness.
Third, the logical solution to the Wason selection task conflicts with
everyday life (Oaksford, 1997). According to formal logic, we should
test the rule "All swans are white" by searching for swans and non-white
birds. However, this would be extremely time-consuming because only a
few birds are swans and the overwhelming majority of birds are
non-white. It would be preferable to adopt a probabilistic approach
based on the likely probabilities of different kinds of events or
objects. The problem of testing the above rule resembles the Wason
selection task, which has the form "If p, then q". We should choose q
cards (e.g., 2) when the expected probability of q is low but not-q
cards when q's expected probability is high to maximise information
gain. As predicted, far more q cards were selected when the percentage
of q cards was low (17%) than when it was high (83%) (Oaksford et al.,
1997). Fourth, motivation is important. People are more likely to select
the potentially falsifying card (7 in the original version of the task)
if motivated to disprove the rule. Dawson et al. (2002) gave some
participants the rule that individuals high in emotionality lability
experience an early death. The four cards showed high emotional
lability, low emotional lability, early death and late death, with the
correct answer involving selecting the first and last cards. Of
participants led to believe they had high emotional lability (and so
motivated to disprove the rule), 38% solved the problem (versus 9% of
control participants). Motivation is also involved with deontic rules
(rules concerned with obligation or permission). Sperber and Girotto
(2002) used a deontic rule relating to cheating. Paolo must decide
whether he is being cheated when buying things through the internet: the
answer is to select the "item paid for" and "item not received" cards
(selected by 68% of participants). This unusually high level of
performance was achieved because the motivation to detect cheating led
participants to select the "item not received" card. In a meta-analysis,
Ragni et al. (2018) found the correct answer was selected by 61% of
participants with deontic versions but 7% using abstract versions.
Marrero et al. (2016) proposed a general motivational approach
accounting for the above findings. Individuals concerned about potential

KEY TERMS Matching bias The tendency on the Wason selection task to
select cards matching the items explicitly mentioned in the rule.
Deontic rules Rules relating to obligation and permissibility.

678

KEY TERMS Syllogism A type of problem used in deductive reasoning; there
are two statements or premises and a conclusion that may or may not
follow logically from the premises. Belief bias In syllogistic
reasoning, the tendency to accept invalid but believable conclusions and
reject valid but unbelievable ones.

Thinking and reasoning

costs focus on disconfirming evidence whereas those concerned about
potential benefits focus on confirming evidence. Fifth, Ragni et
al. (2018) evaluated 15 theories of relevance to Wason's selection task.
In a large-scale meta-analysis, they found Johnson-Laird's (1983) mental
model theory (discussed shortly, pp. 681--683) best predicted
performance. In essence, this theory assumes that selections on Wason's
selection task depend on two processes: (1) (2)

There is an intuitive process producing selections matching the
reasoners' hypothesis (e.g., selection of R in the version of the task
shown in Figure 14.2). There is a more deliberate process producing
selections of potential counterexamples to the hypothesis (e.g.,
selection of 7 in the same version).

The extent to which reasoners search for counterexamples depends on
factors discussed above including task content, instructions and so on.

Syllogistic reasoning Syllogistic reasoning has been studied for over
2,000 years. A syllogism consists of two premises or statements followed
by a conclusion. Here is an example: "All A are B; all B are C.
Therefore, all A are C". A syllogism contains three items (A, B and C),
with one (B) occurring in both premises. The premises and conclusion all
contain one of the following quantifiers: all; some; no; and some . . .
not. When presented with a syllogism, you must decide whether the
conclusion is valid assuming the premises are valid. The validity (or
otherwise) of the conclusion depends only on whether it follows
logically from the premises -- the conclusion's truth or falsity in the
real world is irrelevant. Consider the following example: Premises All
children are obedient. All girl guides are children. Conclusion
Therefore, all girl guides are obedient. The conclusion follows
logically from the premises. Thus, it is valid regardless of your views
about children's obedience.

Findings Various biases cause errors in syllogistic reasoning. Of
special importance is belief bias, the tendency to accept invalid
conclusions as valid if believable and to reject valid (but
unbelievable) conclusions as invalid (theoretical explanations are
discussed later). Klauer et al. (2000) investigated belief bias
thoroughly. The conclusions of half their syllogisms were believable
(e.g., "Some fish are not trout") whereas the others were unbelievable
(e.g., "Some trout are not fish"). Half the syllogisms were valid

Reasoning and hypothesis testing

and half invalid; however, some participants were told only one-sixth of
the syllogisms were valid whereas others were told fivesixths were. What
did Klauer et al. (2000) find? First, there was a base-rate effect:
syllogistic reasoning performance was influenced by the perceived
probability of syllogisms being valid (see Figure 14.3). Second, there
was strong evidence for belief bias. Third, there was a belief-by-logic
interaction. Performance on syllogisms with valid conclusions was better
when those conclusions were believable, whereas performance on
syllogisms with invalid conclusions was worse when those conclusions
were believable. In sum, reasoners' performance was influenced by
factors irrelevant to logic. Stupple and Ball (2008) found with
syllogistic reasoning that unbelievable premises were processed more
slowly than believable ones. This finding suggests people experienced
conflict between their beliefs and what they were asked to assume and
resolving this conflict was time-consuming. Some problems in syllogistic
reasoning occur because of differences in the meanings of expressions in
formal logic and everyday life. For example, we often assume "All As are
Bs" means "All Bs are As" and "Some As are not Bs" means "Some Bs are
not As". Ceraso and Provitera (1971) spelled out such premises
unambiguously (e.g., "All As are Bs, but some Bs are not As"). This
greatly enhanced reasoning performance. In similar fashion, "some" means
"some but not all" in everyday usage but "at least one and possibly
Figure 14.3 Percentage acceptance of conclusions as a function of all"
in formal logic. Schmidt and Thompson perceived base rate validity (low
vs. high), believability of (2008) found syllogistic reasoning improved
conclusions and validity of conclusions. when the meaning of "some" in
formal logic Based on data in Klauer et al. (2000). © American
Psychological Association. was made explicit. Finally, people's
syllogistic reasoning performance is influenced by whether the
conclusion matches the premises in surface or superficial features. Here
is an example of matching: no A are not B; no B are not C; therefore, no
C are not A; and an example of non-matching: all A are B; all B are C;
therefore no A are not C. In spite of the irrelevance of matching vs
non-matching to formal logic, people are more likely to accept
conclusions matching the premises (Stupple et al., 2013).

679

680

Thinking and reasoning

IN THE REAL WORLD: INVALID DEDUCTIVE REASONING So far we have focused on
laboratory-based examples of invalid deductive reasoning. However, such
reasoning is also very common in everyday life. Here are a few examples
starting with the politician's syllogism, which is along the following
lines: Premises We must do something to save the country. Our policy is
something. Conclusion Our policy will save the country. Invalid
conditional reasoning occurs frequently in everyday life. Earlier we
discussed the logical fallacy known as denial of the antecedent. Here is
a real-world example: Premises If you have got nothing to hide, you have
nothing to fear. You have nothing to hide. Conclusion You have nothing
to fear. The above argument is invalid because it implies that people
are only interested in privacy because they have something to hide. In
fact, of course, we all have a basic human right to privacy. Ironically,
the authorities who argue strongly in favour of greater surveillance of
the public are often notoriously reluctant to provide information about
their own activities! Finally, we consider an everyday example of the
logical fallacy known as affirmation of the consequent (discussed
earlier, p. 673). Premises If the Earth's climate altered throughout
pre-human history, this was due to natural climate change. The Earth's
climate is currently altering. Conclusion Natural climate change is
occurring currently. This is clearly an invalid argument. The fact that
past climate change was not due to humans does not necessarily mean that
current climate change is not due to human intervention. In sum, many
groups in society (e.g. politicians; climate change deniers) are
strongly motivated to persuade us of the rightness of their beliefs.
This often leads them to engage in invalid forms of reasoning. The
take-home message is that we all need to be sceptical and vigilant when
exposed to their arguments.

THEORIES OF "DEDUCTIVE" REASONING Here we will focus on two very
influential theoretical approaches to deductive reasoning. First, there
is Johnson-Laird's mental model theory, which represents a relatively
"traditional" approach. Second, we turn our

681

Reasoning and hypothesis testing

attention to the increasingly popular dual-process approach. The word
deductive in the title of this section has been put in quotation marks
to indicate that individuals presented with deductive-reasoning problems
often fail to use deductive processes when trying to solve them.

Mental models Johnson-Laird (e.g., 1983; Johnson-Laird et al., 2018)
argues that reasoning involves constructing mental models. What is a
mental model? According to Johnson-Laird et al. (2015, p. 202), a mental
model is "an iconic representation of a possibility that depicts only
those clauses in a compound assertion that are true. The mental models
of a disjunction, 'A or B but not both' accordingly represent two
possibilities: possibly (A) and possibly (B)". It is iconic because its
structure corresponds to what it represents. Here is a concrete example
of a mental model: Premises The lamp is on the right of the pad. The
book is on the left of the pad. The clock is in front of the book. The
vase is in front of the lamp. Conclusion The clock is to the left of the
vase. According to Johnson-Laird (1983), people use the information
contained in the premises to construct a mental model like this: book
clock

pad

lamp vase

The conclusion the clock is to the left of the vase clearly follows from
the mental model. The fact we cannot construct a mental model consistent

with the premises (but inconsistent with the conclusions) (i.e., we
cannot construct a counterexample) indicates the model is valid. Here
are the theory's main assumptions: ●

●

●

●

●

A mental model describing the given situation is constructed and the
conclusions that follow are generated. An attempt is made to construct
alternative models to falsify the conclusion by finding counterexamples
to the conclusion. If a counterexample model is not found, the
conclusion is deemed valid. The construction of mental models involves
the limited resources of working memory (see Chapter 6). Reasoning
problems requiring the construction of several mental models are harder
than those requiring only one mental model because the former impose
greater demands on working memory. The principle of truth: "Mental
models represent what is true, but not what is false" (Khemlani &
Johnson-Laird, 2017, p. 16). This minimises demands on working memory.

KEY TERMS Mental models An internal representation of some possible
situation or event in the world having the same structure as that
situation or event. Principle of truth The notion that assertions are
represented by forming mental models concerning what is true while
ignoring what is false.

682

Thinking and reasoning

Findings Several studies support the notion that working memory plays a
central role in the formation of mental models. Brunyé et al. (2008)
found the central executive (see Glossary) and visuo-spatial sketchpad
(see Glossary) components of the working memory system were heavily
involved in constructing mental models. Copeland and Radvansky (2004)
found working memory capacity (see Glossary) correlated +.42 with
syllogistic reasoning performance. Khemlani and Johnson-Laird (2017)
reviewed 20 studies testing the principle of truth. These studies used
various reasoning tasks, in all of which individuals failing to
represent what is false in their mental models would produce illusory
inferences. Numerous illusory inferences were drawn. In contrast,
performance was very good with similar problems where adherence to the
principle of truth was sufficient to produce the correct answer.
Consider the following problem: Only one of the following premises is
true about a particular hand of cards: There is a king in the hand or
there is an ace, or both. There is a queen in the hand or there is an
ace, or both. There is a jack in the hand or there is a 10, or both. Is
it possible there is an ace in the hand? What is your answer? Nearly
everyone says "Yes", but this is wrong! If there were an ace in the
hand, both the first two premises would be true. However, the problem
states that only one of the premises is true. Theoretically, individuals
make illusory inferences because they ignore what is false. As
predicted, people are less susceptible to such inferences if explicitly
instructed to falsify the premises of reasoning problems (Newsome &
Johnson-Laird, 2006). Khemlani and Johnson-Laird (2012) carried out a
meta-analysis of syllogistic reasoning studies to compare seven
theories. The mental model theory was best at predicting participants'
responses with a 95% success rate. However, it was relatively weak at
rejecting responses people do not produce. According to the theory,
people search for counterexamples after having constructed their initial
mental model and generated a conclusion. As a result, they may construct
several mental models and consider several conclusions. Newstead et
al. (1999) obtained no support for this conclusion: the average number
of conclusions considered with multiple- and single-model syllogisms was
very low (1.12. and 1.05, respectively). Khemlani et al. (2012) also
found that people generate relatively few counterexamples. Participants
were given this problem: They're not living adult males. So, who could
they be? There are seven possibilities (e.g., dead adult males; living
girls) but participants listed only four possibilities on average. The
theory struggles with ambiguous reasoning problems. Here is an example
(Ragni & Knauff, 2013):

Reasoning and hypothesis testing

The Porsche is to the right of the Ferrari. The Beetle is to the left of
the Porsche. The Dodge is in front of the Beetle. The Volvo is in front
of the Porsche. There is no definite answer to the question "Which
relation holds between the Beetle and the Ferrari?". Mental model theory
does not predict which answer will be given by most participants. Ragni
and Knauff (2013) argued that reasoners prefer easily constructed mental
models (e.g., the Beetle is to the left of the Ferrari in the above
problem). Their findings supported their theory over mental model
theory.

Evaluation The theory has several successes to its credit. First, the
theory compares well against other theories of reasoning (Khemlani &
Johnson-Laird, 2012; Johnson-Laird et al., 2018) and also performs well
when predicting performance on Wason's selection task (Ragni et al.,
2018). Second, as predicted, working memory is involved in the
construction of mental models. Third, there is substantial support for
the principle of truth. Fourth, as discussed later (pp. 704--705), the
theory has recently been developed to account for reasoning about
probabilities (Johnson-Laird et al., 2015). What are the theory's
limitations? First, most people find deductive reasoning very hard and
so resort to easier forms of processing (discussed shortly). Second,
most people do not typically search for counterexamples as predicted
theoretically. Third, the processes involved in forming mental models
are underspecified. It is assumed people use background knowledge when
forming mental models, but the theory does not spell how we decide which
information to include in a mental model. Fourth, mental model theory
often fails to predict people's answers with ambiguous reasoning
problems (e.g., Ragni & Knauff, 2013).

Dual-process theories Several theorists (e.g., Kahneman, 2003; see
Chapter 13 and Evans, 2018) have proposed dual-process (sometimes called
dual-system) theoretical accounts of human reasoning and other aspects
of higher-level cognition. While they differ from each other in various
ways, "dual-process theories should be viewed as a family whose members
share some features . . . it includes close relatives . . . as well as
distant cousins" (Evans, 2018, p. 151). Commonalities among dual-process
theories are discussed below. Evans and Stanovich (2013a,b) provided an
integrative account of dual-process theories based on a distinction
between Type 1 intuitive processing and Type 2 reflective processing.
One defining feature of Type 1 processing is autonomy (it is mandatory
or necessary when the appropriate triggering stimuli are encountered).
Its other defining feature is the lack of involvement of working memory
(see Glossary). Note there is substantial diversity among Type 1
processes. In contrast, a defining feature of Type 2 processing is that
it requires working memory. Its other defining feature

683

684

Thinking and reasoning

is cognitive decoupling or mental simulation -- hypothetical reasoning
not constrained by the immediate environment. Evans and Stanovich
(2013a,b) also identified several features often (but not invariably)
associated with the two types of processing. Features of Type 1
processing include the following: fast; high capacity; parallel;
non-conscious; automatic; and independent of cognitive ability. Features
of Type 2 processing include the following: slow; capacity-limited;
serial; conscious; controlled; and correlated with cognitive ability.
Evans and Stanovich (2013a,b) assumed that individuals trying to solve
reasoning problems initially use intuitive Type 1 processing to generate
a rapid heuristic answer which may be corrected by a subsequent more
deliberate answer produced via slow Type 2 processing. A key assumption
is that reasoning performance will generally (but not invariably) be
superior when it involves Type 2 processing in addition to Type 1
processing. This approach is often referred to as the
default-interventionist model. Why is it wrong to equate Type 1
processing with biased (and often incorrect) reasoning and Type 2
processing with correct reasoning? This question was addressed by Evans
(2018). He pointed out that we have all had the experience of using
effortful Type 2 processing when trying to solve a problem in
mathematics without producing the correct response. In addition, correct
reasoning does not always require Type 2 processing: "We often get
things right via habit or reliable intuition \[both involving Type 1
processing\], as all dual-process authors agree" (p. 163). We will start
by considering predictions made by early dual-process theories of
reasoning (e.g., Evans, 2006). According to these theories, various
factors increase reasoners' use of time-consuming and effortful analytic
or Type 2 processes: (1) (2) (3)

the reasoners are highly intelligent; sufficient time is available for
Type 2 processing; reasoners do not need to perform a secondary
demanding task at the same time.

Findings Much research to test the above predictions has focused on
belief bias (discussed earlier, pp. 678--679; see Ball & Thompson,
2018). This bias occurs in syllogistic reasoning when a logically valid
but unbelievable conclusion is rejected as invalid, or a logically
invalid but believable conclusion is accepted as valid. According to
dual-process theories, there will be less belief bias (and superior
performance) when Type 2 processes are used. Thus, reasoners' use of
Type 2 processes will generally reduce belief bias. There is much
support for the first prediction that more intelligent reasoners exhibit
less belief bias than less intelligent ones (e.g., Trippas et al.,
2013). More intelligent reasoners might show less belief bias because of
their high cognitive ability or because they choose to adopt an analytic
cognitive style. Trippas et al. (2015) found the willingness to engage
in analytic thinking was more important. These findings are consistent
with dualprocess theory because they emphasise the role played by Type 2
processes in reducing belief bias and enhancing reasoning performance.

Reasoning and hypothesis testing

685

There is also support for the second prediction that there should be
less belief bias with ample thinking time (e.g., Evans and
Curtis-Holmes, 2005) because restricting thinking time reduces
reasoners' ability to use Type 2 processes. In similar fashion, errors
in conditional reasoning occur more often when reasoners must respond
rapidly (Markovits et al., 2013; discussed earlier, p. 675). De Neys
(2006) tested the third prediction above by presenting reasoning
problems on their own or with a secondary task low or high in its
demands. As predicted, reasoners exhibited much more belief bias when
performing a demanding secondary task.

Theoretical differences and developments We have seen early dual-process
theories of reasoning generated many predictions supported by
experimental evidence. However, these theories were oversimplified. For
example, as we will see, the assumption that correct reasoning
performance reflects Type 2 processing whereas incorrect reasoning
performance reflects Type 1 processing is only partially correct.
Another oversimplification concerns the relationship between Type 1 and
2 processing during reasoning tasks. As we saw earlier, several
theorists (e.g., Evans & Stanovich, 2013a) proposed serial models for
reasoning in which Type 1 processing provides a rapid intuitive answer.
This is often followed by slow Type 2 processing which may lead to the
initial intuitive answer being corrected and replaced by a more
reflective answer. De Neys (2012) argued the above theoretical position
is too narrow and incomplete. He identified three models of how Type 1
and 2 processing combine (see Figure 14.4). (1)

The traditional theoretical approach described above (serial model)
involves serial processing with intuitive (or Type 1) processing being
followed by deliberate (or Type 2) processing. Figure 14.4 Three models
of the relationship between the intuitive and deliberate systems. (a)
Serial model: intuitive processing may or may not be followed by
deliberate processing. (b) Parallel model: intuitive and deliberate
processing are both involved from the outset. (c) Logical intuition
model: deliberate processing is triggered if there is a conflict between
initial intuitive heuristic and intuitive logical responses produced in
parallel. From De Neys (2012). Reprinted by permission of SAGE
Publications.

686

Thinking and reasoning

(2) 
(3) 

In the parallel model, intuitive (Type 1) and deliberate (Type 2)
processes occur at the same time. This model is wasteful of cognitive
resources because effortful processes are always used. According to the
logical intuition model (advocated by De Neys, 2012, 2014), two types of
intuitive responses (intuitive heuristic and intuitive logical) are
activated in parallel. If these two responses conflict, deliberate (Type
2) processes resolve matters. The notion of intuitive logical processing
sounds paradoxical. However, De Neys argued that traditional logical
principles can be activated fairly automatically.

Findings Evidence consistent with the logical intuition model was
reported by De Neys et al. (2010) using a syllogistic reasoning task
involving conflict (or no conflict) between the logical validity and
believability of the conclusions. There was strong belief bias --
accuracy was only 52% on conflict (belief bias) trials compared to 89%
on non-conflict trials. The very poor performance on conflict problems
(marginally greater than chance) suggests reasoners failed to detect
their logical structure. However, De Neys et al. (2010) found
participants had greater physiological arousal on conflict trials
suggesting conflict was registered within the processing system below
the conscious level. The implication is that some logical processing can
be intuitive rather than analytic. Further support for the logical
intuition model was reported by Trippas et al. (2016). Participants
simply decided how much they liked various sentences. Sentences
following logically from preceding sentences were rated more likeable
than those that did not. Since the task made no reference to logical
validity, this finding suggests participants had an implicit sensitivity
to logical structure based primarily involving Type 1 processes. Bago
and De Neys (2017) presented participants with various syllogistic
reasoning problems involving conflict between the believability and
validity of the conclusion. The participants provided two responses to
each problem: (1) a fast, intuitive response; and (2) a much slower and
more deliberate response. According to the default-interventionist model
(e.g., Evans & Stanovich, 2013a; discussed earlier, pp. 683--684), we
would predict low levels of accurate fast responses and substantially
more correct deliberate responses than intuitive ones. Neither
prediction was supported. On average, 44% of the fast responses were
accurate, and only 7% of initially inaccurate fast responses were
followed by accurate slow responses. In one of their experiments, Bago
and De Neys (2017) used the same syllogistic reasoning task described
above. However, there was an additional requirement on participants --
they performed a secondary demanding task at the same time to reduce
their engagement in Type 2 analytic processing. Nevertheless, 49% of
fast responses on conflict problems were correct. Overall, these
findings support the logical intuition model in that fast (and
presumably Type 1) processes often produce logically correct responses.
Similar findings to those of Bago and De Neys (2017) have been reported
in research on conditional reasoning (see Glossary; see pp. 673--676).
Newman et al. (2017) used conditional-reasoning problems

Reasoning and hypothesis testing

687

involving belief bias (see Glossary). Reasoners provided a fast and a
slow response to each problem. Contrary to the predictions of early
dualprocess theories, fast responses were often correct based on logical
validity and slow responses were often incorrect and exhibited belief
bias. These findings suggest a blurring of the distinction between Type
1 and Type 2 processes -- there was a mixture of logically correct and
belief-based responses regardless of whether Type 1 processes (fast
responses) or Type 2 processes (slow responses) were involved. Imagine
we presented reasoners with conditional-reasoning problems involving a
conflict between logical validity and believability (e.g., "If a child
is happy, then it cries; suppose a child laughs; does it follow that the
child is happy?"). According to logic, the correct answer is "No".
According to beliefs and our knowledge of the world, the answer is
"Yes". Trippas et al. (2017) used problems like that but with the novel
twist that reasoners were sometimes told to answer the question based on
their beliefs rather than logic. According to early dual-process
theories (e.g., the default-interventionist model), responding on the
basis of belief should involve Type 1 processing and so should be faster
than responding on the basis of logic (involving Type 2 processing). In
addition, the believability of the conclusion (accessed rapidly) should
interfere with logic-based responses (accessed slowly) but the reverse
should not be the case. Neither prediction was supported (Trippas et
al., 2017). Response times were comparable on belief-based and
logic-based trials, and the logical validity of the conclusion
interfered with belief-based responding. However, these findings are
entirely consistent with parallel-processing theories. Thompson et
al. (2018) carried out a similar study. Participants differing in
cognitive ability received incongruent reasoning problems involving a
conflict between belief and logic and had to respond on the basis of
belief or logic. There were two main findings (see Figure 14.5):

Incongruent 1.0 0.9

Proportion correct

0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 1st quartile

2nd quartile Logic

3rd quartile Belief

4th quartile

Figure 14.5 Proportion correct on incongruent syllogisms as a function
of instructions (respond on the basis of logic or belief) and cognitive
ability (1st quartile = lowest; 4th quartile = highest). From Thompson
et al. (2018).

688

KEY TERM Meta-reasoning Monitoring processes that influence the time,
effort and strategies used during reasoning and problem solving.

Thinking and reasoning

(1) 
(2) 

The more intelligent reasoners had greater difficulty resolving conflict
when providing belief-based responses rather than logic-based responses.
The less intelligent reasoners exhibited the opposite pattern.

These findings suggest more intelligent individuals generate logic-based
responses faster than belief-based ones, whereas less intelligent
individuals generate belief-based responses faster. What conclusions
should we draw? First, rather than arguing beliefbased responses involve
fast Type 1 processing whereas logic-based responses involve slow Type 2
processing, we need to consider individual differences. Second, "If
responses (belief- or logic-based) can be generated either quickly and
effortlessly or slowly and deliberately, perhaps these responses merely
differ on a single dimension, namely, complexity" (Newman et al., 2017,
p. 1165).

What causes Type 2 processing? What determines whether reasoners'
responses are based on analytic (Type 2) processing or whether they
reflect only intuitive (Type 1) processes? The theories discussed above
address this issue. Traditional serial models assume that Type 2
processes monitor the output of Type 1 processes and it is this
monitoring process that determines whether reasoning performance is
based on Type 2 processes. In similar fashion, many parallel models
assume Type 2 reasoning is triggered when conflict monitoring (involving
Type 2 processing) leads to conflict detection. What is puzzling about
all these theories is that, "They assume that Type 2 processing is
effectively caused by itself" (Pennycook et al., 2015, p. 36). Ackerman
and Thompson (2017, p. 607) provided a detailed account of
meta-reasoning: "The processes that monitor the progress of our
reasoning and problem-solving activities and regulate the time and
effort devoted to them" (see Figure 14.6). Monitoring processes assess
the probability of success before, during and after performing a
reasoning task. The most important monitoring feature is the feeling of
rightness: "the degree to which the first solution that comes to mind
feels right" (p. 608). Only when this feeling is weak do reasoners
engage in substantial Type 2 or analytic processing. Thompson et
al. (2011) studied the role of feeling-of-rightness ratings on the use
of Type 2 processes with syllogistic and conditional-reasoning tasks.
Participants provided an initial answer immediately after reading each
problem (intuitive, or Type 1, answer) followed by an assessment of that
answer's correctness (feeling of rightness). Participants then had
unlimited time to reconsider their initial answer and provide a final
analytic, or Type 2, answer. As predicted, participants spent longer
reconsidering their intuitive answer and were more likely to change it
when they had low feelings of rightness. What determines
feeling-of-rightness ratings? Thompson et al. (2013b) addressed this
issue in a study on syllogistic reasoning. Participants produced the
first response that came to mind, provided a feeling-of-rightness
rating, and then produced a slower, more deliberate response.
Feeling-of-rightness

Reasoning and hypothesis testing

Reasoning

Timeline

Meta-reasoning

Identiﬁy components and goal

Meta-cognitive monitoring

Meta-cognitive control

Assessment of knowledge and strategies

Think? Search memory? Change strategy? Stop?

Generate an initial, autonomous, response

Initial judgement of solvability

Engage in solving? Give up?

Feeling of rightness

Provide the initial response? Reconsider?

Intermediate conﬁdence

Provide current response? Try another strategy?

Analytic processing

Answer choice Final conﬁdence

Feeling of error

Final judgement of solvability

Provide chosen answer? "Don't know"? Seek help?

ratings were higher when the first response was produced rapidly rather
than slowly, indicating the importance of response fluency. Most
research indicates response fluency is a fallible measure of response
accuracy. For example, people give higher feeling-of-rightness ratings
to reasoning problems having familiar rather than unfamiliar content
even when the former problems are harder (Ackerman & Thompson, 2017).

Evaluation What are the strengths of the contemporary dual-process
approach? First, dual-process theories have become increasingly popular
and wide-ranging. For example, they provide explanations for syllogistic
reasoning and conditional reasoning (Verschueren et al, 2005, discussed
earlier, pp. 674--675). In addition, such theories account for findings
in problem solving (see Chapter 12), judgement and decision-making (see
Chapter 13). Second, "Dual-process theory . . . provides a valuable
high-level framework within which more specific and testable models can
be developed" (Evans, 2018, p. 163). Third, there have been increasingly
sophisticated attempts to clarify the relationship between Type 1 and
Type 2 processes (e.g., whether they are used serially or in parallel).
Fourth, we have an enhanced understanding of meta-reasoning processes
(especially those involved in monitoring). Fifth, recent theory and
research are starting to take account of the flexibility of processing
on reasoning problems due to the precise form of the problem and
individual differences (Thompson et al., 2018). What are the limitations
with the dual-process approach? First, the processes used by reasoners
vary depending on their abilities and preferences,

689 Figure 14.6 The approximate time courses of reasoning and
meta-reasoning processes during reasoning and problem solving. From
Ackerman & Thompson (2017).

690

Thinking and reasoning

their motivation and their task requirements. Melnikoff and Bargh (2018;
see Chapter 13) identified two ways many dual-process theories are
oversimplified: (1) they often imply that Type 1 processes are "bad" and
errorprone, whereas Type 2 processes are "good"; and (2) they assume
many cognitive processes can be assigned to just two types. Second, "The
absence of a clear and general definition of a Type 1 or Type 2 response
does create difficulty for researchers wishing to test \[dual-process\]
theories" (Evans, 2018, p. 163). For example, it is often assumed
theoretically that fast responses reflect Type 1 processing and are
error-prone whereas slow responses reflect Type 2 processing and are
generally accurate. However, we have discussed various studies
disconfirming those assumptions. Third, there has been a rapid increase
in the findings that require to be explained theoretically, and theories
have not kept pace with this increase. For example, meta-reasoning often
plays an important role in influencing reasoners' processing strategies
and performance. As yet, however, no theorists have integrated
meta-reasoning processes into a comprehensive dual-process theory of
reasoning.

BRAIN SYSTEMS IN REASONING

Interactive feature: Primal Pictures' 3D atlas of the brain

Figure 14.7 Brain regions most consistently activated across 28 studies
of deductive reasoning. PG = precentral gyrus; MFG = middle frontal
gyrus; PPC = posterior parietal cortex; IFG = inferior frontal gyrus; BG
= basal ganglia; MeFG = medial frontal gyrus. From Prado et al. (2011).
© Massachusetts Institute of Technology, by permission of the MIT Press.

In recent years, there has been increased research designed to identify
the brain regions associated with deductive reasoning. Prado et
al. (2011) reported a meta-analytic review of 28 neuroimaging studies on
deductive reasoning (see Figure 14.7). They obtained evidence for a core
brain system centred in the left hemisphere involving frontal and
parietal areas. Specific brain areas activated during deductive
reasoning included the inferior frontal gyrus, the medial frontal gyrus,
the precentral gyrus and the basal ganglia. Coetzee and Monti (2018)
reported findings broadly consistent with those of Prado et al. (2011).
They used fMRI to assess brain activation while participants performed
deductive-reasoning tasks. There were two key findings. First, core
regions (left rostrolateral cortex, in BA10; medial prefrontal cortex,
in BA8) were more strongly activated with complex (rather than) simple
deductive reasoning. Second, the main language areas

691

Reasoning and hypothesis testing

in the left hemisphere had very little involvement in deductive
reasoning -- their main role was in encoding problems presented
verbally. The left hemisphere dominance reported by Prado et al. (2011)
has also been found in patient data. Goel et al. (2007) studied patients
with damage to the left or right parietal cortex. Those with left-side
damage performed worse than those with right-side damage on reasoning
tasks when complete information was provided. In similar fashion,
Reverberi et al. (2009) found patients with damage to the right frontal
cortex had intact deductive reasoning whereas those with left frontal
damage showed reasoning deficits. Strong evidence for the crucial role
of the left hemisphere in deductive reasoning was reported by Urbanski
et al. (2016) in a meta-analytic review (see Chapter 12). Impaired
analogical reasoning was more strongly associated with damage to the
left rostrolateral prefrontal cortex area than damage to any other area.
Goel and Waechter (2018) provide an overview of research on reasoning in
brain-damage patients. How can we explain the left hemisphere's role in
deductive reasoning? Gazzaniga et al. (e.g., 2008; see Chapter 16)
argued there is a single conscious system based in the left hemisphere.
This system is the interpreter, which tries to make coherent sense of
the information available to it. According to Prado et al. (2011), the
core brain system they identified in the left hemisphere may depend at
least in part on this interpreter.

Individual differences Large individual differences have been found in
belief bias (the tendency to accept invalid but believable conclusions
and reject valid but unbelievable ones). As we saw earlier, more
intelligent individuals exhibit less belief bias because they make more
use of analytic processing strategies (e.g., Trippas et al., 2015, see
p. 684). According to Houdé and Borst's (2015) inhibitory control theory
of reasoning, the ability to inhibit incorrect responses produced by
Type 1 thinking is of crucial importance in reducing belief bias. Houdé
and Borst's (2015) theory was based in part on research by Tsujii and
Watanabe (2009). They argued the right inferior frontal cortex is
involved in inhibiting incorrect responses triggered by Type 1
processes. Accordingly, they predicted individuals with high levels of
activation in that area would have less belief bias than those with low
activation. In their study, the reasoning task was accompanied by a
secondary task involving low or high cognitive load. The findings
supported their hypothesis (see Figure 14.8). High performance accuracy
(and thus low belief bias) were strongly associated with activation in
the right inferior frontal cortex regardless of secondary task. In
addition, this brain region was less activated under high- than low-load
conditions and there was much more belief bias in the high-load
condition.

Sequence of processes Neuroimaging data typically indicate the brain
areas activated during reasoning, but provide no information about when
each brain area was activated. Bonnefond et al. (2013) used
magneto-encephalography (MEG)

KEY TERM Magnetoencephalography (MEG) A non-invasive brainscanning
technique based on recording the magnetic fields generated by brain
activity; it has good spatial and temporal resolution.

692

Thinking and reasoning

Figure 14.8 Relationships between reasoning task performance (accuracy)
and inferior frontal cortex activity in the left hemisphere (LH) and the
right hemisphere (RH) in (a) the low-load condition and (b) the
high-load condition. From Tsujii and Watanabe (2009). Reprinted with
permission from Elsevier.

to study brain processes associated with conditional reasoning focusing
on modus ponens (If P then Q:P//Therefore, Q; see earlier in the
chapter, pp. 673--674). Bonnefond et al. (2013) reported two main
findings. First, participants expected the second premise to match the
first one (e.g., P following If P then Q): there was enhanced brain
activity 300 ms after presentation of the second premise when it failed
to match the first one. Second, when the second premise matched the
first one, participants generated the inference that followed validly
from the two premises (activation in the parietofrontal network at 400
ms). This occurred sometime before the conclusion was presented. Thus,
participants engaged in much anticipatory processing before the second
premise and conclusion were presented. More evidence that reasoners form
expectations was reported by Bonnefond et al. (2014) in a study on
conditional reasoning involving valid modus ponens inferences. Here is
an example: Premises If John studies hard, he will pass the test. He
studies hard. Conclusion John passes the test.

Reasoning and hypothesis testing

The conclusion is logically valid. However, many people can readily
think of additional considerations making the conclusion invalid (e.g.,
John has a low IQ; the test was very hard). Bonnefond et al. (2014)
recorded event-related potentials (ERPs; see Glossary) while
participants read the conclusion. They reported two key findings. First,
valid conclusions were much less likely to be accepted when there were
several additional considerations rather than only a few. Second,
presentation of a valid conclusion was more associated with an ERP
pattern indicative of violated expectations when there were several
additional considerations.

Evaluation What are the strengths of the cognitive neuroscience approach
to reasoning? According to Goel and Waechter (2018, p. 240), its main
contribution has been "the fractionation of the \[reasoning\] system and
the identification of some of the component parts, such as a conflict
detection system \[and\] a system sensitive to conceptual content".
However, Goel and Waechter admitted the data tell us little about how
these systems interact. Second, progress has been made in identifying
important executive or control processes involved in effective deductive
reasoning. For example, it appears that inhibitory processes are used to
prevent incorrect responses (e.g., Houdé & Borst, 2015). Third, many
reasoners form expectations in conditional reasoning prior to the
presentation of the second premise and the conclusion. This anticipatory
processing is an important new finding given that reasoners might
equally well await the presentation of the conclusion before engaging in
full processing. What are the limitations of the cognitive neuroscience
approach? First, much research is based on oversimplified assumptions
(e.g., there is a "reasoning module": Goel & Waechter, 2018, p. 232). In
fact, "The brain did not develop a dedicated device for reasoning . . .
Reasoning . . . is associated with an internally-driven dynamics:
processing times and stages, and brain geometry are largely
unconstrained" (Papo, 2015, p. 2). Second, relatively little research
has focused on testing contemporary theories (e.g., dual-process
theories). For example, only a few studies (e.g., Bonnefond et al.,
2014) have provided evidence of the brain areas associated with Type 1
intuitive processing (Oaksford, 2015). Third, and related to the second
point, most research in this area has used functional magnetic resonance
imaging (fMRI; see Glossary). It has limited temporal resolution meaning
we cannot establish precisely when any given brain area is involved in
reasoning. This makes it hard to identify rapid Type 1 processes using
fMRI. Fourth, there are problems with Prado et al.'s (2011)
identification of their core left-hemisphere brain system with
Gazzaniga's interpreter. This is problematical since the interpreter is
not specifically involved in deductive reasoning but is more involved in
drawing elaborative inferences (Oaksford, 2015).

693

694

Thinking and reasoning

KEY TERM

INFORMAL REASONING

Straw man fallacy Refuting an opponent's views by misrepresenting them
in some way.

Traditional research on deductive reasoning is artificial because it
emphasises the role of formal logic and treats past knowledge as
irrelevant. As mentioned earlier, these limitations have led to the
rapid development of research on informal reasoning (see Glossary)
designed to assess how reasoning depends on knowledge and experience
rather than logic. The switch in research from formal or deductive
reasoning to informal reasoning is very important. Elqayam (2018,
p. 145) discussed the emergence of a new paradigm, according to which
"We reason, not with the binary truth and falsity of classical logic,
but with the many shades of uncertainty and of degrees of belief". Thus,
the contemporary focus is on probabilities. The content of an argument
is generally important in informal reasoning but (in principle) is
irrelevant in formal deductive reasoning. Consider the following
superficially similar arguments (Hahn & Oaksford, 2007): (a) Ghosts
exist because no one has proved they do not. (b) The drug is safe
because we have found no evidence that it is not. The implausibility of
ghosts existing means most people find (a) much less persuasive than
(b). Another difference is that contextual factors are important in
informal reasoning but not formal deductive reasoning. For example, in
informal reasoning we are typically more persuaded by an expert's
arguments than those of a non-expert (Walton, 2010). We turn now to the
most important difference between deductive and informal reasoning. As
Elqayam (2018) noted, traditional research on deductive reasoning is
based on binary logic. We must assume the initial premises or statements
in a problem are definitely true and then we decide whether the
conclusion necessarily follows (answering "yes" or "no"). In contrast,
informal (or everyday) reasoning is all about probabilities -- we regard
most statements, arguments or conclusions as possibly or probably true
rather than certainly true or certainly false. We can see the importance
of the above differences by considering fallacies (Hahn & Oaksford,
2014). Take the straw man fallacy in which someone else's views are
misrepresented by distorting or weakening them. According to classical
logic, such fallacies are totally inadequate arguments unsupported by
logic. However, that position is too extreme given there are various
forms of straw man argument (Aikin & Casey, 2016). One version of the
straw man fallacy (the weak man fallacy) involves selecting one's
opponent's weakest arguments without distorting them and then trying to
demolish. This version seems legitimate and so is not a fallacy. There
is more on fallacies shortly (see pp. 700--701). Finally, the reasoner's
motives often differ in deductive reasoning compared to informal
reasoning. Individuals solving deductive-reasoning problems are supposed
to be motivated to reason accurately and logically. In contrast, much
informal reasoning occurs in social contexts and involves producing
arguments that will persuade other people. More generally, people are
"natural-born arguers" (Mercier et al., 2017, p. 1), and "their

695

Reasoning and hypothesis testing

reasoning seeks to identify reasons that support their . . . prior
beliefs or decisions" (p. 4). In sum, there several differences between
deductive and informal reasoning. However, the processes used by most
individuals confronted by deductive-reasoning tasks are closer to
informal than deductive reasoning. For example, many reasoners exhibit
belief bias with syllogistic reasoning -- they accept invalid but
believable conclusions and reject valid but unbelievable ones (see
earlier in the chapter, pp. 678--679). In essence, belief bias occurs
when people make use of their world knowledge when reasoning even though
they have been told to ignore such knowledge. Such findings suggest the
value of studying informal reasoning processes directly by using
informal-reasoning tasks rather than indirectly via the errors made on
formal logic tasks.

KEY TERM Ad hominem fallacy Discrediting an argument by attacking the
person making the argument.

Findings: motivation Many people's informal reasoning and thinking are
seriously flawed. For example, tens of millions of Americans believe the
moon landing was a hoax, that global warming is not a problem, and do
not believe humans evolved from apes. Why is this the case? According to
Thagard (2011, pp. 156--157), the answer lies in motivated inference,
which "occurs when people distort their judgements because of their
underlying personal goals . . . motivated inference is based on wishes,
not facts". Supporting evidence is discussed in the Box on climate
change.

IN THE REAL WORLD: DOES CLIMATE CHANGE EXIST? Over 95% of the world's
greatest experts on climate believe in climate change. However, many
people refuse to accept this strong scientific consensus. Climate change
deniers show evidence of distorted memory. For example, Howe and
Leiserowitz (2013) tested Americans' memory of the previous unusually
hot summer. Those most dismissive of global warming were only half as
likely as those most alarmed by it to remember the preceding summer had
been very hot. Leviston et al. (2013) discovered another distortion.
Australian disbelievers in climate change grossly overestimated the
percentage of other people holding the same views (43% vs the actual
figure of 6%). Individuals exhibiting this high false consensus bias
were less likely than others to change their opinions over time. Cann
and Raymond (2018) reported evidence that those opposing climate change
increasingly resort to attacks on the integrity of climate scientists
rather than the uncertainties of climate science. This is an example of
the ad hominem fallacy -- dismissing an argument by belittling the
person advocating the argument. The association between beliefs about
global warming and political ideology is strongest in the United States.
For example, Kahan (2015) found 75% of Americans with left-wing or
liberal views agreed there is solid evidence of global warming compared
to only 22% of those with right-wing or conservative views. In general,
Americans strongly supporting the industrial capitalist system (e.g.,
right-wing individuals; men) are most likely to be sceptical of global
warming (McCright et al., 2016). Campbell and Kay (2014) asked
right-wing Americans to indicate whether they believed in climate change
in the context of two possible solutions (restrictive emissions policies
or green technology). Far fewer indicated a belief in climate change
when the proposed solution was undesirable

696

Thinking and reasoning

(restrictive emissions) rather than desirable: 22% vs 55%. This is an
example of solution aversion (see Glossary). It is irrational because
the existence of climate change is totally independent of the
desirability of any proposed solutions. We might expect individuals
having high science literacy and numeracy to be most concerned about
climate change. In fact, cultural values are much more important. Kahan
et al. (2012) identified two groups having different values: (1)
egalitarian communitarians believing in equality and the value of
society; (2) hierarchical individualists believing in a hierarchical
society and personal responsibility. Both groups estimated the risks of
climate change. What did Kahan et al. (2012) find? First, the impact of
science literacy and numeracy was surprisingly small (see Figure 14.9).
Second, egalitarian communitarians regarded climate-change risks as
considerably greater than hierarchical individualists.

Figure 14.9 Mean responses to the question "How much risk do you believe
climate change poses to human health, safety or prosperity?" by
individuals who were low or high in science literacy/numeracy and who
were egalitarian communitarians or hierarchical individualists. From
Kahan et al. (2012).

How can we explain the above findings? In essence, "Positions on climate
change have come to signify the kind of person one is. People whose
beliefs are at odds with those of the people with whom they share their
basic cultural commitments risk being labelled as weird" (Kahan, 2012,
p. 255). This explains why many disbelievers in climate change largely
ignore the scientific evidence and show a false consensus bias.

The notion of motivated inference resembles that of myside bias, which
is the tendency for people to select and interpret information in a
manner biased towards their prior beliefs. Stanovich and West (2007)
asked students to rate the accuracy of contentious (but factually
correct) propositions such as the following:

697

Reasoning and hypothesis testing

(1) 
(2) 

College students who drink alcohol while in college are more likely to
become alcoholic in later life. The gap in salary between men and women
generally disappears when they are employed in the same position.

What did Stanovich and West (2007) find? Students who regularly drank
alcohol rated the accuracy of proposition (1) lower than those who did
not. Women rated the accuracy of proposition (2) lower than men. Thus,
there was strong myside bias with its extent depending on the strength
of participants' prior beliefs. However, the extent of myside bias was
unrelated to cognitive ability or intelligence suggesting participants
made little use of analytical thinking. These findings were replicated
in subsequent research (Stanovich et al., 2013). Čavojová et al. (2018)
conducted a stronger test of the existence of myside bias. Participants
(who had pro-life or pro-choice views with respect to abortion) were
presented with abortion-relevant syllogisms (see Glossary; and
pp. 678--679). They were instructed to assume the two premises were
valid and decide whether the conclusion followed logically from them.
Evidence was obtained for myside bias -- participants found it hard to
accept logically valid conclusions conflicting with their beliefs and to
reject invalid conclusions coinciding with their beliefs. Thus, myside
bias can be found even when people are instructed not to allow their
beliefs to influence their reasoning. How can we reduce myside bias?
McCrudden et al. (2017) asked participants to rate the strength of
arguments concerning climate change from their own perspective and also
from that of a climate scientist. Adopting the perspective of a climate
scientist eliminated myside bias when rating weak arguments but not
strong arguments. Thus, perspective taking can produce a modest decrease
in myside bias. Before proceeding, we should note the motivation to
support one's own beliefs or view sometimes improves performance.
Earlier (p. 677), we discussed Dawson et al.'s (2002) study using the
Wason selection task. Individuals strongly motivated to disprove the
rule because it implied they would die young showed much more accurate
reasoning than those lacking such motivation.

Argumentative theory Mercier (e.g., 2016) proposed an argumentative
theory of reasoning emphasising the importance of argumentation. For
example, according to Mercier (2018, p. 1), "Reason is a specific
cognitive mechanism that evolved so that humans can exchange
justifications and arguments with each other." Mercier (2016, p. 690)
claimed that his theory provided an explanation for myside bias: The
function of argument production is to convince someone in an interactive
setting. Conviction can hardly be achieved by providing interlocutors
\[others involved in a discussion\] with arguments for their views or
against that of the speaker. Argument production should thus be marked
by a strong myside bias. (p. 690)

KEY TERMS Solution aversion A bias in reasoning in which individuals
deny the existence of a problem (e.g., climate change) because they
dislike the proposed solution (e.g., restricting damaging emissions).
Myside bias In informal reasoning, the tendency to select and interpret
information in terms of one's own beliefs or to generate reasons or
arguments supporting those beliefs.

698

Thinking and reasoning

It also follows that we should be more critical of others' arguments
than of our own (especially when their views disagree with ours).
Support for argumentative theory was reported by Trouche et al. (2016).
Participants solved syllogistic reasoning problems, produced arguments
for their answers, and then evaluated other people's arguments for the
same problems. The key condition was one in which participants evaluated
their own arguments but were led to believe these arguments were someone
else's. Participants not detecting this deception were highly critical
of their own arguments, rejecting them 56% of the time. Of importance,
they were more likely to reject their own arguments for invalid answers
than valid ones (66% vs 41%, respectively). Thus, the participants were
more critical and better able to discriminate between valid and invalid
arguments when they believed they were someone else's. In a second
experiment, Trouche et al. (2016) presented syllogisms and asked
participants to provide "fast, intuitive answers". After that, they
provided arguments for their answers and were able to change their
answer. The arguments participants provided for their invalid answers
were generally superficial with only 17% of these answers being changed.
These findings provide further evidence that most individuals are not
critical of their own arguments.

Evaluation Informal reasoning is far more important than deductive
reasoning in our everyday lives. Motivational factors (e.g., myside
bias; desire to win arguments by persuading others) play a major role in
informal reasoning. In the case of climate change, people's views are
often much more strongly influenced by their notions concerning the kind
of person they regard themselves as being than by the available research
evidence. What are the limitations of the research discussed so far?
First, we lack a comprehensive theory clarifying how motivational
factors influence informal reasoning. Second, several studies (e.g.,
Kahan et al., 2012; Stanovich & West, 2007) have found surprisingly
small differences in informal reasoning between individuals of high and
low cognitive ability or intelligence. More research is needed to
establish whether this is a general finding or whether it depends on the
precise nature of the reasoning task.

Findings: probabilities As noted earlier, probabilities are much more
important in informal than in deductive reasoning (e.g., we believe
statements are possibly or probably true). In contrast, statements in
formal logic are true or false -- there is no half-way house. The
Bayesian approach (also discussed in Chapter 13 and below), focuses on
probabilities. According to this approach, our prior beliefs have
subjective probabilities associated with them based on our knowledge and
experience. These subjective probabilities are changed (increased or
decreased) as we encounter new evidence. Support for the Bayesian
approach was reported by Hahn and Oaksford (2007). They identified
several factors influencing the perceived strength of a conclusion:

Reasoning and hypothesis testing

(1) 
(2) 
(3) 

degree of previous conviction or belief; positive arguments have more
impact than negative ones; strength of the evidence.

Hahn and Oaksford (2007) studied the above factors using scenarios such
as the following (note that digesterole is a fictitious drug): Barbara:
Adam: Barbara: Adam: Barbara: Adam:

Are you taking digesterole for it? Yes, why? Well, because I strongly
believe that it does have side-effects. It does have side-effects. How
do you know? Because I know of an experiment in which they found
side-effects.

This scenario presents a strong prior belief (i.e., strongly believe), a
positive belief (i.e., it has side-effects) and weak evidence (i.e., one
experiment). The three factors were manipulated in other versions of
this scenario. Participants decided how strongly Barbara should now
believe the conclusion the drug has side-effects. Argument strength was
regarded as greater when the prior belief was strong rather than weak,
when the prior belief was positive rather than negative, and when the
evidence was strong rather than weak. Thus, as predicted by the Bayesian
approach, ratings of argument strength took account of Barbara's prior
beliefs and the strength of the new evidence. In addition, Hahn and
Oaksford (2007) found a model based on the Bayesian approach provided an
excellent fit to the data. Harris et al. (2016) carried out a similar
study where participants received fictional medical information (e.g.,
concerning whether Pfortanine lowers cholesterol). Three factors were
manipulated: (1) expert vs nonexpert opinion; (2) trustworthiness of the
expert/non-expert: high (friend) vs low (enemy); and (3) opinion of
other experts: agreed with expert/nonexpert; disagreed with
expert/non-expert; or not mentioned. Participants indicated their degree
of belief in the medical information by providing convincingness
ratings. All three factors had the predicted effects: convincingness was
higher with expert than non-expert opinion, with a friend's opinion
rather than an enemy's, and with other experts agreeing rather than
disagreeing. Some findings are shown in Figure 14.10. A Bayesian model
predicted the convincingness ratings extremely well. Hornikx et
al. (2018) investigated the impact of expert opinion in more detail.
They presented scenarios in which an expert's opinion differed from that
of laypeople. There were five levels of expert expertise and five levels
of layperson expertise. Participants indicated how many laypeople they
thought were required to counter the expert's opinion. According to the
Bayesian approach, participants should have been sensitive to the
expertise of the expert and the laypeople in their responses. Thus, the
number of laypeople required should increase as the expert's expertise
increases and that of laypeople decreases. The findings were in general
agreement with prediction.

699

700

Thinking and reasoning

Figure 14.10 Effects of trustworthiness and others' opinions on
convincingness ratings.

70 Mean convincingness ratings (%)

From Harris et al. (2016).

80

60 50 40 30 20 No mention Agree Disagree

10 0 Enemy

Friend Trustworthiness

KEY TERM Slippery-slope argument The claim that an innocuous first step
will lead to an undesirable outcome; sometimes regarded as a fallacy.

Within the framework of traditional reasoning research, several types of
arguments were classified as "fallacies". For example, consider the
slippery-slope argument, according to which a small first step will lead
to a chain of events producing an undesirable outcome. One such argument
(from Corner et al., 2011) is as follows: "If voluntary euthanasia is
legalised, then in the future there will be more cases of 'medical
murder'." Another example concerns genetic engineering, which, it has
been argued, will inevitably lead to attempts to create a super race of
human beings (Walton, 2017). As mentioned earlier, so-called "fallacies"
were rejected as totally invalid according to classical logic. In
contrast, it is assumed within the Bayesian approach that most so-called
fallacies involve weak conclusions poorly supported by the evidence
presented. According to this approach, then, we should not reject all
slippery-slope arguments. Such arguments vary in strength, with strong
arguments being regarded as more persuasive than weak ones. Two
important factors determining argument strength are: (1) the probability
of the negative outcome; and (2) how negative the outcome would be.
Thus, strong slippery-slope arguments are those where the negative
outcome is both highly probable and very undesirable. Corner et
al. (2011) tested the above predictions using various topics (e.g.,
legislation of euthanasia; introduction of ID cards). As predicted, both
factors influenced the assessment of argument strength (see Figure
14.11). Haigh et al. (2016) pointed out that slippery-slope arguments
are typically perceived to be arguments implying resistance to change.
They then hypothesised such arguments will only be perceived as
persuasive when it is clear the speaker is resistant to change. That is
exactly what they found. This finding indicates the importance of a
contextual factor (i.e., the speaker's beliefs). As such, it is entirely
consistent with the Bayesian approach with its emphasis on perceived
persuasiveness being influenced by all relevant factors.

Reasoning and hypothesis testing

701

Evaluation The Bayesian approach (assuming that prior subjective
probabilities are modified by new information to produce posterior
subjective probabilities) provides a valuable framework for
understanding informal reasoning. Several factors (e.g., strength of
prior beliefs; strength of evidence) influencing the rated strength of
informal arguments have been identified. The Bayesian approach accounts
for the perceived strength (or otherwise) of the arguments within
so-called fallacies. The Bayesian approach has generated precise models
predicting accurately the perceived strength of conclusions in informal
reasoning. Other theoretical approaches have proved less successful
(Hahn & Hornikx, 2016). What are the limitations of the Bayesian
approach? Bowers and Davis (2012) argued it is too flexible and thus
hard to falsify. For Figure 14.11 example, the strength of prior beliefs
is often Mean-rated argument strength as a function of the probability
of the outcome (likely vs unlikely) and how negative the not assessed
with precision. This argument outcome would be (very negative vs
moderately negative). is too sweeping in two ways. First, Bayesian From
Corner et al. (2011). With permission from Elsevier. models vary
considerably in terms of their falsifiability (Hahn, 2014). Second, we
must distinguish between model flexibility and vague predictions.
Bayesian models are often flexible in terms of their assumptions.
However, many such models make precise predictions from those
assumptions (Hahn, 2014). For example, Harris et al. (2012) studied the
ad hominem fallacy (see Glossary). The convincingness of an argument was
systematically affected when it was attributed to Hitler. Of most
importance, however, the perceived persuasiveness of ad hominem
arguments was influenced by the content of the arguments. Of note, a
Bayesian model provided a precise quantitative fit to the data. Third,
while Bayesian models accurately predict the perceived effectiveness of
arguments, they often fail to identify the underlying processes.
According to the Bayesian approach, informal reasoning involves
extensive use of probabilities. However, "People flounder with even the
simplest probability questions . . . How can a supposedly Bayesian brain
reason so poorly with probabilities?" (Sanborn & Chater, 2016, p. 883).
As yet, it remains somewhat unclear how we use probabilities in numerous
cognitive tasks (including informal reasoning).

ARE HUMANS RATIONAL? Much research discussed in this chapter and the
previous two apparently indicates deficient and irrational human
thinking and reasoning. For example, we often fail on fairly simple
problems (e.g., Frederick's Cognitive Reflection Test), we generally
ignore base-rate information when making

702

KEY TERM Bounded rationality The notion that people are as rational as
the environment and their limited processing capacity permit.

Thinking and reasoning

judgements (see Chapter 13), 90% of us produce the wrong answer on the
Wason selection task, and we perform poorly on deductive-reasoning
tasks. The above findings lead to an apparent paradox. Most people (but
not all!) cope reasonably well with everyday problems and challenges but
often seem "irrational" and "illogical" with laboratory thinking and
reasoning problems. We can resolve this paradox by assuming our everyday
thinking is less rational than we like to believe, whereas our thinking
and reasoning in the laboratory is more rational than often supposed.
With respect to the latter point, laboratory deductive-reasoning tasks
are often very artificial: background knowledge is totally irrelevant,
and conclusions involve certainties (i.e., valid vs invalid) rather than
varying levels of probability. Before examining the relevant evidence,
we must consider what we mean by "human rationality". As we will see,
there is controversy concerning the appropriate definition.

Bounded rationality Simon considered the issue of human rationality at
length (Schraagen, 2018). He argued behaviour is rational "in so far as
it selects alternatives . . . conducive to the achievement of previously
selected goals" (Simon, 1945, p. 5). Thus, an individual's informal
reasoning is rational if it achieves their goal of arguing persuasively
even if it differs from the experimenter's prior expectations (e.g., by
demonstrating myside bias; see Glossary). Simon (1957) argued we possess
bounded rationality (our thinking and decision-making are "bounded" by
environmental constraints (e.g., information costs) and cognitive
constraints (e.g., limited attention). This allows us to produce
workable solutions to problems in spite of limited processing ability by
using various short-cut strategies (e.g., heuristics). More
specifically, our thinking is "bounded" or constrained by the
environment and processing constraints (e.g., limited attention; limited
short-term memory). According to Simon (1990, p. 7), "Human rational
behaviour is shaped like a scissors whose blades are the structure of
task environments and the computational capabilities of the actor." If
we consider only one blade, we will have only a partial understanding of
human thinking. In sum, many "errors" in human thinking reflect limited
processing capacity rather than irrationality. As mentioned above, Simon
also argued such "errors" can also reflect environmental constraints.
Simon's definition of "bounded rationality" included factors such as
incomplete knowledge, problems in anticipating future consequences and
limited behavioural alternatives. As Schraagen (2018, p. 488) pointed
out, "These issues have more to do with the complexity of the
environment that humans find themselves in than with their limited
information processing capacities."

Instrumental vs broad rationality Deciding whether humans are rational
depends on how we define "rationality". Historically, an important
approach (championed by Piaget, Wason and many others) claimed rational
thought is governed by logic. It follows that deductive reasoning (which
many have thought requires logical thinking) is very relevant for
assessing human rationality. Sadly, most people

703

Reasoning and hypothesis testing

perform poorly on complex deductive-reasoning tasks. Thus, humans are
irrational if we define rationality as logical reasoning. The above
approach exemplifies normativism. Normativism "is the idea that human
thinking reflects a normative system \[one conforming to norms or
standards\] against which it should be measured and judged" (Elqayam &
Evans, 2011, p. 233). For example, human thinking is "correct" only if
it conforms to classical logic. Logic (or deductive reasoning) does not
provide a suitable normative system for evaluating human thinking. Why
is that? As Sternberg (2011, p. 270) pointed out, "Few problems of
consequence in our lives had a deductive or even any meaningful kind of
'correct' solution. Try to think of three, or even one!" We can make
headway by distinguishing two broad types of rationality (Stanovich,
2013, 2016). First, there is instrumental rationality, which involves
"the maximisation of expected utility \[subjective value associated with
our choices or decisions\]" (Stanovich, 2016, p. 24). We could label
this thin rationality because it is narrowly focused on the current
task. Second, there is broad rationality, which involves taking account
of the individual's personal goals and contextual factors (especially
social ones) additional to the immediate task goals. One type of broad
rationality was labelled "social rationality" by Hoffrage et al. (2018).
Social rationality "is concerned with goals, such as choosing an option
that one can defend with argument or moral justification, or that can
create a consensus" (pp. 331--332). In Chapter 13, we discussed
Tetlock's (2002) social functionalist approach, which focuses on social
rationality and the role played by accountability in decision-making. We
will clarify the above distinction. Consider a situation where
individuals must decide between risking harm through inaction and
risking harm through action. An example would be a parent deciding
whether to have their child vaccinated against various diseases. If the
decision is to select the option where the probability of harm is less,
the decision would be based on instrumental rationality. However, as
Brewer et al. (2016) found in a meta-analysis, such decisions are often
strongly influenced by anticipated regret (i.e., the option involving
less anticipated regret is selected). Thus, the decision to select the
option having less instrumental rationality may be selected because it
is associated with less anticipated regret. It is arguable that such
decisions are consistent with broad rationality. In sum, we should
distinguish between thin or instrumental rationality and broad
rationality. We may exaggerate human irrationality if we focus only on
instrumental or thin rationality. However, it is often hard to decide
whether an individual is demonstrating broad rationality. Why is that?
Broad rationality involves thinking and reasoning consistent with an
individual's goals, but these goals are often unclear.

Findings Stanovich (2013) compared rationality in humans and other
species. If we focus on instrumental rationality, other species
sometimes outperform humans. For example, Pope et al. (2015; see Chapter
12) found baboons

KEY TERMS Normativism The notion that human thinking should be regarded
as "correct" or "incorrect" depending on how closely it follows certain
norms or standards (e.g., those of classical logic). Instrumental
rationality Maximising the utility (subjective value) of one's choices
or decisions with respect to achieving task-related goals.

704

Thinking and reasoning

were much less likely than humans to exhibit the negative effects of
mental set (see Glossary) in problem solving. How can we explain such
surprising findings? Humans are far more likely than other species to
pursue complex goals not directly relevant to the current task. The fact
that our cognitive processes and goals are often complex means human
thinking can often be regarded as rational even when it does not
correspond to instrumental rationality. Here we will consider another
example of the sunk-cost effect (see Glossary). Two people decide to go
on a holiday for which they have paid a non-refundable deposit even
though they both feel slightly unwell on the way there and think they
would prefer to go home (Dawes, 1988; see Chapter 13). Keys and Schwartz
(2007) argued some participants may well have taken into account the
regret they would experience if they returned home having forfeited the
deposit. In that case, it might be more "rational" to exhibit the
sunk-cost effect. Thus, we should distinguish between the decision and
its consequences. According to Keys and Schwartz, the anticipated
experience following a decision often "leaks" into the decision-making
process. "Leakage" may also explain apparently irrational framing
effects (see Glossary and Chapter 13). Most people choose beef labelled
"75% lean" rather than beef labelled "25% fat", which seems irrational
(Levin & Gaeth, 1988). However, the labelling influenced participants'
experience: the 75% lean beef tasted better than the 25% fat beef. Thus,
we could argue participants' choices were rational. Findings such as
those discussed above may suggest human thinking and behaviour typically
correspond to broad rationality. However, there are plentiful exceptions
(more are discussed shortly). In one study (Koehler & James, 2009) 40
marbles were drawn from a bag: 30 were green and 10 red. Participants
guessed the colours of 20 more marbles drawn as replacements from the
bag. The optimal strategy is maximising (i.e., choosing green every
time). However, most participants used probability matching (i.e.,
guessing green about 75% of the time). Subsequently, 39% of participants
using probability matching acknowledged the superiority of maximising,
thus accepting the inadequacy of their chosen strategy.

Limitations of human rationality

Case study: Exploring dual-system theories of deductive reasoning

An important theoretical approach of relevance to the issue of human
rationality is the dual-process (or dual-system) approach (reviewed by
Evans & Stanovich, 2013a). In essence, it is assumed there is a rapid
process (Type 1 or System 1) which is often followed by a slower process
(Type 2 or System 2) that involves working memory. This theoretical
approach has been applied to deductive reasoning (see earlier in this
Chapter) and to judgement (Kahneman, 2003; see Chapter 13). It was
originally assumed Type 2 or System 2 responses are generally based on
analytical, logical or rational processes, whereas Type 1 or System 1
responses reflect more intuitive processes. In fact, matters are much
more complicated. Research on reasoning discussed (e.g., Newman et al.,
2017; Trippas et al., 2017) indicates there is only modest evidence

705

Reasoning and hypothesis testing

for the assumptions that fast responses are intuitive whereas slow ones
are analytical or rational. For example, there are numerous exceptions
to the prediction that Type 2 or System 2 responses should be associated
with far more correct answers on reasoning problems than Type 1 or
System 1 responses (Evans, 2018). Oaksford and Hall (2016, p. 343)
proposed a radical new theoretical approach: "In a reversal of current
wisdom \[i.e., dual-system theory\], System 1 is rational whereas System
2 leads to error." Why did they propose this reversal? (1) (2) (3)

They argued that other species rely primarily on System 1 but seem less
prone than humans to serious cognitive biases. System 2 depends heavily
on working memory, but working memory is limited in its functioning
(Johnson-Laird, 1983; see Chapter 6). System 2 involves language often
lacking in precision (e.g., individuals differ greatly in their
interpretations of words such as "probable" and "likely").

In sum, the assumptions that irrationality stems from System 1 and
rationality from System 2 are seriously flawed. An interesting example
of limited human rationality is the DunningKruger effect (Kruger &
Dunning, 1999), in which "those who are incompetent . . . have little
insight into their incompetence" (Dunning, 2011, p. 260). Individuals
largely unaware of their own thinking exhibit signs of "irrationality".
For example, Motta et al. (2018) found those knowing the least about the
causes of autism were most likely to think they knew more than medical
doctors about autism's causes! Why does the Dunning-Kruger effect exist?
Perhaps those showing the effect lack the knowledge and expertise to
evaluate the correctness (or otherwise) of their own thinking. Dunning
(2011) discussed a study using the Wason selection task (see earlier in
the chapter, pp. 676--678). Some participants used the same correct rule
across different versions of the task and so achieved a success rate of
100%. Other participants used the same incorrect rule consistently and
had a 0% success rate. However, both groups believed they had solved
between 80% and 90% of the problems correctly!

Individual differences: intelligence Even though average performance on
most judgement, decision-making and reasoning tasks appears relatively
poor, it is still possible highly intelligent individuals perform
consistently well. That is partially true (Stanovich, 2012). Students
with high IQs perform better than those with lower IQs on many
deductive-reasoning tasks. However, intelligence often only modestly
predicts performance on judgement tasks (e.g., framing problems;
sunkcost effects; omission bias). For example, Toplak et al. (2011)
obtained a correlation of +.32 between cognitive ability and performance
across 15 judgement and decision tasks. Stanovich (2012) developed a
tripartite model to explain the impact of intelligence on thinking and
reasoning (see Figure 14.12). At the bottom

KEY TERM Dunning-Kruger effect The finding that less skilled individuals
overestimate their abilities more than those who are more skilled.

706

Thinking and reasoning

is Type 1 processing (e.g., use of heuristics) within the autonomous
mind. It is rapid and fairly "automatic". Above that is Type 2
processing which is slow and effortful. Stanovich's (2012) model has two
major novel features. First, there are two levels of cognitive control
at the higher level. One consists of Type 2 processes (the algorithmic
mind) which contains mindware -- "the rules, knowledge, procedures, and
strategies that a person can retrieve from memory . . . to aid decision
making and problem solving" (Stanovich, 2012, p. 355). The algorithmic
mind can override the (often incorrect) heuristic responses generated by
the autonomous mind. Figure 14.12 Type 2 processes are only used when
Stanovich's tripartite model of reasoning. According to the individuals
realise that they are necessary model, Type 1 processing within the
autonomous mind is and have sufficient motivation to initiate typically
fast and fairly automatic. There are two major forms them. The other
level of control involves the of Type 2 processing: (1) the algorithmic
mind, which contains reflective mind which has access to
individinformation about rules, strategies and procedures; and (2) the
uals' goals, beliefs and general knowledge. reflective mind, which makes
use of the individual's goals and beliefs. Individual differences in
reasoning are generally much Deciding whether to use Type 2 processes
greater with respect to the reflective mind and the algorithmic involves
the reflective mind. mind than the autonomous mind. Second, the model
considers individual From Stanovich (2012). By permission of Oxford
University Press. differences in intelligence. Fluid intelligence is of
direct relevance to the functioning of the algorithmic mind. Individuals
high in fluid intelligence possess more Type 2 processes and use them
more efficiently (Stanovich, 2012). Stanovich (2016) developed a test
(the Comprehensive Assessment of Rational Thinking: the CART) to assess
individual differences in the reflective mind. The items in the CART
(e.g., various heuristics and biases tasks; items based on the Cognitive
Reflection Test: see Glossary) mostly involve a conflict between a
readily available intuitive answer and the correct one. The development
of the CART opens the way to more systematic study of the similarities
and differences between the algorithmic and reflective minds. According
to the tripartite model incorrect, intuition-based answers on problems
can occur for three reasons: (1)

KEY TERM Fluid intelligence Non-verbal reasoning ability applied to
novel problems.

(2) 
(3) 

Individuals may lack the appropriate mindware within the algorithmic
mind to override incorrect responses. Individuals with the appropriate
mindware may have insufficient processing capacity to override incorrect
Type 1 processing using the algorithmic mind. Individuals may have the
appropriate mindware but fail to use it because its use is not triggered
by the reflective mind.

707

Reasoning and hypothesis testing

Findings

KEY TERM

Several findings are consistent with the tripartite model. First,
different measures of rational thinking typically correlate moderately
with each other (e.g., Toplak et al., 2017 obtained correlations between
+.26 and .60). This suggests rational thinking is a relatively general
aspect of individual differences. Second, as predicted, rational
thinking assessed by heuristics and bias tasks correlates moderately
with active open-minded thinking assessed by self-report questionnaire
(Toplak et al., 2017). Third, individual differences in rational
thinking as assessed by heuristics and bias tasks (e.g., belief bias)
predict several real-world outcomes (e.g., sound financial behaviour;
good security on computers) (Toplak et al., 2017). There are two
important limitations with Stanovich's approach. First, consider his
claim that "rationality and intelligence are two different things"
(Stanovich, 2016, p. 23). The CART (designed to assess rationality)
correlates +.69 with measures of cognitive ability (e.g., analogies)
(Ritchie, 2017). Thus, there is much overlap between rationality and
intelligence. Second, and relatedly, there is only limited evidence
concerning incremental validity (the extent to which a new test has
predictive power over and above that provided by previous tests). For
example, the relationship between rational thinking and real-world
outcomes found by Toplak et al. (2017) may have been due mostly to
individual differences in intelligence rather than to rational thinking
itself.

Incremental validity The ability of a new test to predict behaviour or
other outcomes to a greater extent than existing tests.

Conclusions What are the main arguments for human rationality? First, as
argued by Simon (1957) with his notion of bounded rationality, human
reasoning is generally moderately effective given constraints in our
processing ability (e.g., limited attention; limited short-term memory)
and environmental constraints. Our lives mostly involve uncertain
information and so our reasoning and decision-making often appear
"rational" when evaluated against Bayesian and other models of
probabilistic thinking. Second, we should distinguish between thin and
broad rationality (Stanovich, 2013). Human reasoning can seem
"irrational" when considered solely within the context of the current
task (thin rationality) but "rational" when we take account of our
personal goals. These goals can include the need to be accountable to
others (Tetlock, 2002), the desire to win arguments (Mercier, 2018), and
the wish to signify the kind of person one is (Kahan, 2012). Third,
apparent "errors" involving heuristics (rules of thumb) often fail to
indicate "irrationality". As Maule and Hodgkinson (2002, p. 71) pointed
out, "Often . . . people have to judge situations or objects that change
over time, making it inappropriate to expend a good deal of time to make
a precise judgment . . . an approximate judgement based on a simpler,
less effortful heuristic may be much more appropriate." What are the
main arguments against human rationality? First, humans are often
cognitive misers -- even when they possess the necessary knowledge

708

Thinking and reasoning

and skills to reason effectively, they often fail to do so. For example,
inaccurate performance on the Cognitive Reflection Test (Frederick,
2005; see Chapter 12) often reflects a failure to use the reflective
mind (Stanovich, 2012, 2016). Second, people often fail to think
rationally because they are unaware of limitations and errors in their
thinking (the Dunning-Kruger effect). They are also often too ready to
accept incorrect responses associated with a strong feeling-of-rightness
(Ackerman & Thompson, 2017). Third, we might expect experts to interpret
correctly problems in their area of expertise and so avoid cognitive
biases. However, medical experts often make biased judgements and
decisions (Croskerry, 2018). Fourth, Camerer and Hogarth (1999) reviewed
74 studies concerned with the effects of motivation (financial
incentives) on thinking and reasoning. The provision of incentives
rarely improved performance suggesting poor reasoning is not typically
due to insufficient motivation.

CHAPTER SUMMARY •

Introduction. Inductive reasoning involves drawing general conclusions
from statements referring to particular instances. These conclusions can
never be shown to be definitely valid. Inductive reasoning is often used
when testing scientific hypotheses. Deductive reasoning (originating in
formal logic), allows us to draw definitely valid conclusions provided
we assume other statements are true. It is of little relevance to
everyday life. As a result, there has been a rapid increase in research
on informal reasoning based on our knowledge and experience rather than
logic.

•

Hypothesis testing. Wason argued that performance was poor on his 2-4-6
task because people show confirmation bias and rarely engage in
falsification. However, there are many falsification attempts when
participants test others' hypotheses. The 2-4-6 task is unrepresentative
of hypothesis testing because the rule is very general and so hard to
discover. Scientists typically adopt a confirmatory approach when
testing non-absolute hypotheses but a disconfirmatory or falsificatory
approach when testing absolute or universal hypotheses. Many scientists
show evidence of confirmation bias when analysing and interpreting their
research findings.

•

Deductive reasoning. Performance is generally poor on
conditional-reasoning problems. Such problems have their origins in
propositional logic. However, researchers increasingly encourage
participants to use their relevant knowledge and to think
probabilistically on conditional-reasoning tasks. With Wason's selection
task, reasoners typically perform poorly unless the rule is deontic or
they are motivated to disprove the rule because of concerns about future
costs. Syllogistic reasoning is based on

Reasoning and hypothesis testing

propositional logic. Performance is often poor because reasoners ignore
the dictates of logic and interpret problems based on everyday meanings
of expressions. This leads to incorrect reasoning (e.g., belief bias). •

Theories of "deductive" reasoning. According to Johnson-Laird's mental
model theory, people form mental models representing what is common to a
set of possibilities. As predicted, reasoners often reduce the load on
working memory by forming mental models representing explicitly only
what is true. There is much less search for counterexamples than assumed
theoretically, the processes involved in forming mental models are
underspecified, and most people engage in less deductive reasoning than
assumed theoretically. According to early dual-process theories,
reasoners initially use rapid, intuitive Type 1 processes generating an
answer that is sometimes corrected by a slower and more deliberate
answer based on analytic Type 2 processes. In contrast to this serial
processing approach, recent dual-process theories (e.g., the logical
intuition model) emphasise the importance of parallel Type 1 and Type 2
processes. These theories provide more detailed accounts of the
monitoring processes determining whether reasoners accept the first
answer they produce. They also focus on how the requirements of
reasoning tasks and individual differences in reasoners' abilities lead
to considerable flexibility in reasoning strategies.

•

Brain systems in reasoning. Key brain regions (e.g., left rostrolateral
prefrontal cortex; left parietal cortex) are involved in deductive
reasoning. Individuals having superior inhibitory control abilities
often outperform others on reasoning tasks (e.g., they are less likely
to exhibit belief bias). Reasoners often engage in anticipatory
processing in conditional reasoning (e.g., anticipating the second
premise and conclusion). Much research in cognitive neuroscience is
relatively uninformative concerning contemporary reasoning theories. Of
relevance, fMRI's limited temporal resolution means we cannot establish
precisely when any given brain area is active.

•

Informal reasoning. Informal reasoning depends on the reasoner's
knowledge and experience as well as on the content of arguments and
contextual factors. Motivational factors are often important with
individuals seeking support for their beliefs (e.g., when arguing with
others). The Bayesian approach based on the assumption that new
information changes the probabilities of beliefs is more realistic than
the traditional approach based on binary logic. For example, the
Bayesian approach explains why so-called "fallacies" differ in
persuasiveness, whereas the

709

710

Thinking and reasoning

traditional approach dismisses them as totally invalid. The Bayesian
approach does not provide a detailed account of the processes involved
in informal reasoning. •

Are humans rational? Human rationality often seems "irrational" on many
laboratory tasks because such tasks are often very artificial (e.g.,
background knowledge is irrelevant). We possess bounded rationality,
which allows us to produce workable solutions to problems despite
limited processing ability. Humans appear more rational if we focus on
broad rationality, interpreting our reasoning performance with reference
to our personal goals and the social context. Dual-system theories
propose an oversimplified distinction between fast intuitive processes
and slow analytical or rational processes. Human reasoning is often
deficient because we have limited awareness of our own cognitive
incompetence. More intelligent individuals perform better than less
intelligent ones on reasoning (especially deductive reasoning) tasks.
However, some intelligent individuals fail to think rationally because
they are cognitive misers who use limited mental effort when solving
problems.

FURTHER READING Chater, N., Felin, T., Funder, C.D., Gigerenzer, G.,
Koenderink, J.J., Krueger, J.I. (2018). Mind, rationality, and
cognition: An interdisciplinary debate. Psychonomic Bulletin and Review,
25, 793--826. This article contains the contrasting views of many
experts on key issues relating to rationality. Collins, P.J. & Hahn, U.
(2018). Fallacies of argumentation. In L.J. Ball and V.A. Thompson
(eds), Routledge International Handbook of Thinking and Reasoning
(pp. 88--108). Abingdon, Oxon.: Routledge. Peter Collins and Ulrike Hahn
discuss recent theory and research on informal reasoning. De Neys, W.
(ed.) (2018). Dual Process Theory 2.0. Abingdon, Oxon.: Routledge. Wim
De Neys is the editor of this book in which leading experts discuss (and
evaluate) various versions of dual-process theory as applied to thinking
and reasoning. Elqayam, S. (2018). The new paradigm in psychology of
reasoning. In L.J. Ball and V.A. Thompson (eds), Routledge International
Handbook of Thinking and Reasoning (pp. 130--150). Abingdon, Oxon.:
Routledge. Shira Elqayam discusses in detail the shift from traditional
theories of reasoning based on logic to theories focusing on informal
reasoning. Goel, V. & Waechter, R. (2018). Inductive and deductive
reasoning: Integrating insights from philosophy, psychology, and
neuroscience. In L.J. Ball and V.A. Thompson (eds), Routledge
International Handbook of Thinking and Reasoning (pp. 218--247).
Abingdon, Oxon.: Routledge. This chapter indicates how cognitive
neuroscience has enhanced our understanding of human reasoning. Gorman,
M.E. (2018). Scientific thinking. In L.J. Ball and V.A. Thompson (eds),
Routledge International Handbook of Thinking and Reasoning
(pp. 248--267).

Reasoning and hypothesis testing Abingdon, Oxon.: Routledge. Real-life
and laboratory research of relevance to scientific thinking and
hypothesis testing is discussed by Michael Gorman. Pohl, R.F. (ed.)
(2017). Cognitive Illusions: Intriguing Phenomena in Thinking, Judgement
and Memory (2nd edn). Abingdon, Oxon.: Routledge. This book, with its
emphasis on discussing a very wide range of cognitive illusions,
provides solid evidence for evaluating human rationality. Stanovich,
K.E. (2013). Why humans are (sometimes) less rational than other
animals: Cognitive complexity and the axioms of rational choice.
Thinking & Reasoning, 19, 1--26. Keith Stanovich provides an excellent
of the complexities of human rationality.

711

713

One of the most exciting developments within cognitive psychology has
been a broadening of its horizons. In this section of the book, we
consider two of the most important manifestations of that broadening.
First, there is the issue of the ways in which emotion and mood are
related to human cognition (Chapter 15). Second, there is the issue of
consciousness (Chapter 16). It is appropriate to place these two topics
here because both are relevant to most of the topics within cognitive
psychology that we have discussed throughout the book. Emotional factors
influence attention, perception, memory, language processing, judgements
and decision-making. In addition, our current mood state is strongly
influenced by cognitive processes. So far as consciousness is concerned,
it is important to distinguish between conscious and non-conscious
processes when studying almost any aspect of human cognition.

COGNITION AND EMOTION The origins of the notion that our emotional
states are partly determined by our cognitions go back at least as far
as Aristotle over two thousand years ago. Aristotle (who may have been
the cleverest person who ever lived) had this to say: "Let fear, then,
be a kind of pain or disturbance resulting from the imagination of
impending danger" (quoted by Power & Dalgleish, 2008, p. 35). The key
word is "imagining" -- how much fear we experience depends on our
expectations. Aristotle developed this point: "Those in great prosperity
. . . would not expect to suffer; nor those who reckon they have already
suffered everything terrible and are numbed as regards the future, such
as those who are actually being crucified" (quoted by Power & Dalgleish,
2008, p. 35). Aristotle emphasised the impact that cognitions have on
emotion. However, emotional states influence our cognitions. As
discussed in Chapter 15, emotional states influence many cognitive
processes. There has been significant progress in psychologists' ability
to predict the circumstances in which such effects will occur.

PART V

Broadening horizons

714

Broadening horizons

KEY TERM

One reason why it is important to study the effects of emotional states
on cognition is because such effects are often present in everyday life.
For example, we have more negative thoughts about ourselves and the
future when feeling sad or depressed than when happy.

Introspection A careful examination and description of one's own mental
thoughts.

Finally, note that some research on emotion and cognition has been
discussed earlier in this book. For example, emotional states influence
eyewitness memory and autobiographical memory (Chapter 8) and can impair
decision-making (Chapter 13).

CONSCIOUSNESS The topic of consciousness did not fare well during most
of the twentieth century. John Watson, a leading behaviourist, argued
strongly that the concept of "consciousness" should be eliminated from
psychology. He was also scathing about the value of introspection, which
involves an examination and description of one's own thoughts. Consider,
however, this quotation from Watson (1920): "A good deal more can be
learned about the psychology of thinking by making subjects think aloud
about definite problems, than by trusting to the unscientific method of
introspection." This quotation is somewhat bizarre given that "thinking
aloud" is essentially synonymous with introspection! Watson's view was
that thinking aloud is acceptable because it can simply be regarded as
verbal behaviour. It is increasingly accepted that consciousness is an
extremely important and fascinating (although undeniably complex!)
topic. The first author remembers clearly a conversation with Endel
Tulving (a leading memory researcher) in the mid-1980s. He said one
criterion he used when evaluating a textbook on cognitive psychology was
the amount of coverage of consciousness. Reference back to the fourth
edition of this textbook indicated that consciousness was discussed on
only 2 pages out of 525 -- so that edition clearly failed the Tulving
test! However, the burgeoning research on consciousness was reflected by
an increase to 30 pages in the seventh edition (and even more in this
edition). The role of non-conscious processes in human cognition is
considered in several chapters of this book. Subliminal perception and
blindsight are discussed in Chapter 2, "automatic" processes are
analysed in Chapter 5, implicit learning is discussed in Chapter 6,
implicit memory is dealt with in Chapter 7, and the potential importance
of non-conscious processing in decision-making is discussed in Chapter
13. Such research has increased interest in studying consciousness -- if
some processes are conscious whereas others are non-conscious, we
clearly need to identify the crucial differences between them. Finally,
several concepts used by cognitive psychologists are very relevant to
consciousness. Examples include many theoretical ideas about attention
(Chapter 5) and the central executive of Baddeley's working memory
system (Chapter 6).

Chapter

Cognition and emotion

INTRODUCTION Historically, most cognitive psychologists ignored the
effects of emotion on cognition by trying to ensure their participants
were in a neutral emotional state. In recent years, however, there has
been a dramatic increase in research concerned with the relationship
between cognition and emotion. Examples include research on everyday
memory (Chapter 8) and decision-making (Chapter 13). Two issues are
central. First, how do cognitive processes influence our emotional
experience? Second, how does emotion influence cognitive processes? For
example, how do different emotions influence learning and memory? In
short, we consider the effects of cognition on emotion and those of
emotion on cognition. Four major topics are discussed in this chapter.
First, we consider how our emotional experience is influenced by our
cognitive appraisals (interpretations) of our current situation. Second,
we discuss issues relating to emotion regulation. Emotion regulation is
concerned with the processes (mostly deliberate) involved in managing
our emotions and so allowing us to be relatively happy and achieve our
goals. Third, we consider the effects of emotion on cognition. Emotional
states influence attention, memory, judgement and decision-making. Of
practical and theoretical importance, each emotional state produces a
different pattern of effects. Fourth, we discuss cognitive biases (e.g.,
interpreting ambiguous situations in a threatening way) associated with
anxiety and depression. A key issue is whether cognitive biases
influence the development of anxiety and depression or whether they are
merely a consequence of anxiety or depression. We address this issue by
considering research designed to reduce or eliminate these biases. Such
research has high societal relevance.

15

716

Broadening horizons

KEY TERMS

Emotion, mood and affect

Emotion A short-lived affective state typically triggered by a specific
event.

How can we define "emotion"? According to Colman (2015, p. 244), emotion
is "any short-term evaluative, affective, intentional, psychological
state". How do emotions differ from moods? First, emotions typically
last for less time. Second, emotions are more intense than moods and so
are more likely to attract our attention. Third, emotions are generally
caused by a specific event (e.g., passing an examination), whereas the
reason for being in a given mood is often unclear. However, there is no
sharp distinction between emotions and moods; they are "parallel
interacting processes" (Eldar et al., 2016, p. 16). We will often use
the broader term affect which encompasses emotions and moods. Positive
affect refers to positive emotions and moods whereas negative affect
refers to negative emotions and moods. Valence refers to the emotional
value (positive or negative) associated with a stimulus (e.g., person;
event).

Mood State resembling emotion but generally longer lasting, less intense
and of unknown cause. Affect A general term referring to evaluative
(positive or negative) reactions; it encompasses mood and emotion.
Valence The positive or negative character of emotional experience.

Structure of emotions

What is the structure of emotions? Some theorists (e.g., Izard, 2007)
argue we should adopt a categorical approach, according to which there
are several distinct emotions. For example, Cowen and Keltner (2017,
2018) analysed the emotional states produced by over 2,000 short videos
and identified 27 different emotions (e.g., admiration; adoration;
amusement; Case study: anger; calmness; envy; fear; guilt; relief; and
sadness). This approach probaBasic emotions as natural bly fits your
subjective experience. kinds Other theorists prefer a dimensional
approach. Barrett and Russell (1998) argued for two uncorrelated or
orthogonal dimensions of misery--pleasure (valence) and arousal-- sleep.
In contrast, Watson and Tellegen (1985) favoured two uncorrelated
dimensions of positive and negative affect. In spite of their
differences, both approaches refer to the same two-dimensional space
(see Figure 15.1). This figure also indicates how we can reconcile the
categorical and dimensional approaches. Emotions such as happy and
excited fall in the topright quadrant, contented, relaxed and calm are
in the bottom-right quadrant, depressed and bored are in the bottom-left
quadrant, and stressed and tense are in the top-left quadrant. Figure
15.1 There is much support for the dimenThe two-dimensional framework
for emotion showing the two sional approach. Watson and Tellegen (1985)
dimensions of pleasure--misery and arousal--sleep (Barrett & analysed
data from numerous studies using Russell, 1998) and the two dimensions
of positive affect and various self-report mood measures and found
negative affect (Watson & Tellegen, 1985). 50%--65% of the variance was
accounted for Based on Barrett and Russell (1998), and Watson and
Tellegen (1985). © American Psychological Association. by dimensions of
negative and positive affect.

Cognition and emotion

717

Brain mechanisms What brain mechanisms are associated with emotion? The
full answer is unknown, but we discuss very briefly a few key points.
First, locationist theories (assuming each emotion is associated with a
different brain area) used to be popular (see Lindquist et al., 2012,
for a review). For example, fear was allegedly strongly associated with
the amygdala, disgust with the insula, anger with the orbitofrontal
cortex and sadness with the anterior cingulate. However, Lindquist et
al. found minimal support for the locationist approach in a
meta-analytic review. Instead, it is now generally accepted that most
emotions are associated with the same (or similar) large-scale brain
networks (Pessoa, 2017). Second, support for the importance of
large-scale networks to emotional experience was reported by Lindquist
et al. (2016). They carried out a meta-analysis (see Glossary) of
studies focusing on brain regions associated with positive and negative
affect. Very similar brain areas were activated to emotionally positive
and negative stimuli (see Figure 15.2). Brain areas common to positive
and negative stimuli included the anterior insula, ventromedial
prefrontal cortex, anterior cingulate cortex, amygdala, thalamus and
occipito-temporal cortex. Of theoretical importance, these findings
suggest the same high-arousal brain networks are associated with
positive and negative affect. Third, our ability to move beyond broad
dimensions such as arousal and valence depends largely on various
cognitive processes. For example, Lindquist et al. (2012) found brain
areas associated with attentional

--24

--14

--4

6

16

26

Interactive feature: Primal Pictures' 3D atlas of the brain

36

46

Figure 15.2 The top and middle rows show brain areas more activated by
positive than neutral stimuli (illustrated in purple) and negative than
neutral stimuli (illustrated in green); the bottom row shows areas more
activated by both positive and negative stimuli than neutral ones
(illustrated in orange). From Lindquist et al. (2016).

718

KEY TERM Amygdala A small almond-shaped subcortical structure towards
the front of the temporal lobe strongly associated with several emotions
including fear.

Broadening horizons

processes, language and long-term memory were activated across several
emotions. Lindquist et al. (2014) showed the importance of language to
emotion. They studied patients with semantic dementia (a condition
involving substantial impairments of concept knowledge; see Glossary).
These patients viewed photographs of faces showing anger, sadness, fear,
disgust, happiness or a neutral expression, and sorted them into
meaningful piles. They distinguished clearly between positive and
negative emotions but showed poor discrimination between the negative
emotions.

Bottom-up and top-down processes Emotional experience depends on
bottom-up (or stimulus-driven) processes involving attention and
perception. It also depends on top-down processes involving appraisal of
the situation (see below, pp. 719--723), drawing on stored knowledge of
situations similar to the present one. We can see the differences
between these two kinds of processes in a study by Ochsner et al. (2009)
using brain imaging. In the bottom-up condition, participants were
presented with aversive photographs and told to respond naturally to the
images. In the top-down condition, participants interpreted neutral
photographs as if they were aversive. What did Ochsner et al. (2009)
find? The answer is shown in Figure 15.3. In the bottom-up condition,
brain areas in the occipital, temporal and parietal lobes associated
with visual perceptual processing were activated. There was also high
activation within the amygdala (a structure

Figure 15.3 Brain areas showing greater activity for top-down than for
bottom-up processing (shades of blue) and those showing greater activity
for bottom-up than for topdown processes (shades of yellow and red).
From Ochsner et al. (2009). Reprinted by permission of SAGE
Publications.

Cognition and emotion

located deep within the temporal lobe). Self-reported negative affect
was associated most closely with amygdala activation. Somewhat different
brain areas were activated in the top-down condition. Top-down
processing involved the dorsolateral and medial prefrontal cortex (areas
associated with high-level cognitive processes) and the anterior
cingulate and amygdala were also activated. Self-reported negative
affect was associated most strongly with activation of the medial
prefrontal cortex (associated with producing cognitive representations
of stimulus meaning). Inhibitory control is an important top-down
process in human cognition (see Chapter 6). Individuals with good
inhibitory control showed smaller increases in anger and anxiety than
those with poor control when those emotions were induced (Tang &
Schmeichel, 2014). Thus, inhibitory control influences the experience of
negative emotional states. In sum, there are substantial differences
between bottom-up and topdown processes in emotion. Appraisal and
emotion regulation theories (see below, pp. 723--730) emphasise the role
of top-down processes in emotional experience. However, we must not
neglect bottom-up processes. Note the distinction between bottom-up or
relatively "automatic" processes and top-down or effortful processes is
oversimplified. Emotional experience may also depend on intermediate
processes (neither entirely automatic nor effortful) (Viviani, 2013).

APPRAISAL THEORIES Cognitive processes (especially cognitive appraisal
of the situation) influence when we experience emotional states and what
emotional state we experience. Appraisal theories assume "emotional
responses are elicited as the organism evaluates the relevance of
environmental changes for its well-being" (Brosch, 2013, p. 370). Most
appraisal theories assume each emotion is elicited by its own specific
appraisal pattern. For example, Scherer and Ellsworth (2009) identified
appraisal profiles for major emotions. For example, you experience anger
if you blame someone else for the current situation and you appraise it
as offering you control and power. In contrast, you experience sadness
if you appraise the situation as one permitting very little control or
power. C. Smith and Kirby (e.g., 2009) distinguished between appraisal
involving deliberate conscious processing and appraisal involving
automatic processes and based on activation of memories. The former is
slower and more flexible. Smith and Lane (2015) developed this idea by
proposing multiple appraisal mechanisms (see Figure 15.4). Fast
appraisal mechanisms start 100 ms after stimulus presentation and
respond to its novelty and concern relevance (i.e., relevance to the
individual's concerns). Slower appraisal mechanisms process information
about goal congruence, agency and norm or value compatibility. Finally,
there is a situational appraisal. Appraisal theories typically assume
appraisal is the key determinant of emotional states. They also assume
appraisal leads to other components of emotion (e.g., bodily sensations;
action tendencies).

719

Figure 15.4 Multiple appraisal mechanisms used in emotion generation.
VTA = ventral tegmental area; nACC = nucleus accumbens; DMPFC =
dorsomedial prefrontal cortex; DLPFC = dorsolateral PFC; VLPFC =
ventrolateral PFC; VMPFC = ventromedial PFC; dACC = dorsal anterior
cingulate cortex; TPJ = temporoparietal junction; MTL = medial temporal
lobe. From Smith and Lane (2015). Reprinted with permission of Elsevier.

Broadening horizons

Appraisal hierarchy Aﬀective meaning • VMPFC, MTL

Stable ﬁnal appraisal of the aﬀective signiﬁcance of one's situation

Norm/value compatibility • Superior temporal cortex • DLPFC

Processing time

720

Agency (caused by self or other?) • Sensorimotor feedback • DMPFC, TPJ

Slower appraisal mechanisms (340--800 ms)

Goal congruence • VTA, nACC (congruent) • dACC, DLPFC (incongruent)
Concern relevance • Amygdala (modulated by other structures) Novelty •
Amygdala • Hippocampus/perirhinal cortex • Orbitofrontal cortex

Fast appraisal mechanisms (100--140 ms)

Sensory representation (externally or internally generated)

Findings: conscious appraisals Fontaine et al. (2013) investigated
appraisal's importance in emotion. Participants from 27 countries
indicated, for various emotion words, the probability that various
features of appraisal and other components of emotion would apply to
someone experiencing each emotion. Emotions were correctly classified
solely from appraisal features in 71% of cases. The other components of
emotion (e.g., bodily sensations; motor expressions; action tendencies)
improved classification accuracy only slightly. Tong (2015) asked
participants to recall an experience of 13 different positive emotions
(e.g., amusement; contentment; hope; pride) and to provide appraisals
for each experience. The correct positive emotion was identified from
these appraisals 42% of the time (chance = 7.7%). Much research has used
scenarios with participants identifying with the central character. Here
is an example from Smith and Lazarus (1993). A student performed poorly
in an examination and then appraised the situation. Participants
indicated he would experience anger if he blamed the unhelpful teaching
assistant but guilt if he blamed himself (e.g., for doing work at the
last minute). Appraisal manipulations generally had the predicted
effects on emotion ratings. However, manipulated appraisals accounted
for less than 30% of the variance in emotion ratings (Parkinson, 2001).
There are substantial individual differences in cognitive appraisal of
emotional events (Kuppens, 2013). Kuppens et al. (2003) studied four
appraisals (goal obstacle; other accountability: someone else is to
blame; unfairness; and control) relevant to anger. No appraisal
component was

Cognition and emotion

721

essential for the experience of anger in unpleasant situations (e.g.,
some individuals felt angry without the appraisal of unfairness or the
presence of a goal obstacle). Tong (2010) studied four negative emotions
(anger; sadness; fear; and guilt). No single appraisal (or combination
of appraisals) was necessary or sufficient for the experience of any
emotional state. Participants are typically presented with hypothetical
scenarios and so experience little actual emotion. Bennett and Lowe
(2008) rectified this by asking nurses to identify their most stressful
recent work-related incident. Anger and frustration were the emotions
most strongly experienced and these emotional reactions were predicted
reasonably well by the nurses' appraisals of the stressful situation.
Most research reports associations or correlations between cognitive
appraisals and emotional states and so cannot shed direct light on
causality. We can decide whether appraisals help to cause emotional
states by manipulating people's cognitive appraisals when confronted by
emotional stimuli. Schartau et al. (2009) had participants watch films
of humans and animals experiencing marked distress. Some participants
received training in positive cognitive appraisal (e.g., "silver lining:
there are usually some good aspects to every situation" (p. 19)). This
training reduced horror, distress and physiological arousal indexed by
the galvanic skin response (see Figure 15.5). Similar research has
focused on interpretive bias (interpreting ambiguous situations as
threatening). The existence of interpretive bias in anxious individuals
suggests their appraisals are unduly negative. We could show such
appraisals influence emotional reactions by using training to reduce
interpretive bias (interpretive bias modification). As predicted,
reductions in experienced anxiety generally follow such training (Liu et
al., 2017; discussed later, p. 762).

Figure 15.5 Changes in self-reported horror and distress and in galvanic
skin response (GSR) between pretraining and post-training for
individuals instructed to simply watch the films (watch condition) and
those training in positive cognitive appraisal (appraisal condition).
From Schartau et al. (2009). © American Psychological Association.

722

KEY TERM Affective blindsight The ability of braindamaged patients to
discriminate among different emotional stimuli in spite of the absence
of conscious perception of those stimuli.

Broadening horizons

Factors other than situational appraisal influence emotional experience.
According to the James-Lange theory of emotion (James, 1890), our
awareness of our own bodily states influences experienced emotion. The
theory predicts those who have had Botox (which often paralyses the
muscles involved in facial expression) should have reduced emotional
experience. Davis et al. (2010) obtained support for this prediction
using positive and negative video clips. According to the James-Lange
theory, each emotion has its own specific pattern of physiological
activity. Which emotion we experience in any given situation depends
importantly on our awareness of the current pattern of physiological
activity. Thus, patients with spinal cord injury (who have dramatically
reduced awareness of their own bodily activity) should have very weak
emotional experience. In fact, most such patients report experiencing as
much emotion as healthy controls (Deady et al., 2010). Siegel et
al. (2018) carried out a meta-analysis of studies focusing on the
autonomic nervous system activity associated with each emotion. They
failed to support the James-Lange theory because each emotion did not
have its own "fingerprint" (autonomic nervous system pattern). In sum,
the emotions we experience probably depend far more on situational
appraisal than on feedback from physiological activity.

Findings: non-conscious emotional processing Much evidence suggests
emotional reactions can depend on non-conscious processes. Winkielman et
al. (2005) presented happy and angry faces subliminally (below the
conscious level) to thirsty participants. Those presented with
subliminal happy faces poured and drank twice as much liquid as those
presented with subliminal angry faces. In another experiment, thirsty
participants paid an average of 38 cents for a drink after being
presented with happy faces but only 10 cents following angry faces.
Thus, affective reactions can be unconscious. In Chapter 2, we discussed
patients with blindsight (see Glossary). Several of these patients show
affective blindsight -- emotional stimuli are discriminated in the
absence of conscious perception of those stimuli. Tamietto et al. (2009)
presented two blindsight patients with pictures of facial or bodily
expressions of fear or happiness to their intact or blind visual field.
The zygomaticus major muscle (involved in smiling) was activated more by
happy expressions whereas the corrugator supercilli (involved in
frowning) was activated more by fearful expressions whether or not the
expressions were consciously perceived. Of importance, these facial
reactions occurred 200--300 ms faster for non-consciously perceived
expressions, probably because this emotional processing largely bypasses
the cortex. Diano et al. (2017) reviewed research on conscious and
non-conscious emotion processing. There are two routes between
presentation of an emotional stimulus and activation of the amygdala (a
brain area of central importance in emotion): (1)

Processing typically involves a cortical route with emotional stimuli
being consciously perceived.

Cognition and emotion

(2) 

There is also a subcortical route involving the superior colliculus and
pulvinar when emotional stimuli are not consciously perceived.

Evaluation Appraisal processes influence whether we experience emotion
and which emotion we experience. Individual differences in emotional
experience occur in part because appraisals vary across individuals.
Evidence supports the proposed distinction between conscious and
"automatic" appraisal processes. Evidence based on manipulating
cognitive appraisals suggests they causally influence emotion. Most
evidence suggests that situational appraisals are more important in
determining which emotion is experienced than is feedback from
physiological activity. What are appraisal theory's limitations? First,
the assumption that situational appraisal is always crucial in
determining emotional experience is too strong. In fact, individuals'
emotional experience is only moderately well predicted by their
situational appraisals because there are other determinants of emotional
experience (e.g., awareness of one's own bodily state). Second, most
research focuses on individuals on their own responding passively to a
hypothetical emotional situation. In the real world, however, most
emotional experiences occur in social settings and our emotional
reactions depend on the reactions of others (Parkinson & Manstead,
2015). Third, appraisal theorists assume a clear-cut distinction between
cognition and emotion. However, appraisals and emotional experiences
often blur into each other (McEachrane, 2009). Fourth, most research has
used relatively unambiguous situations producing a single emotion. In
real life, however, we often experience mixed emotions (e.g., nostalgia
combines wonderful memories with sadness for what has been lost)
(Frijda, 2013). Fifth, appraisal theories typically focus on appraisals
of the current situation. However, appraisals can also relate to the
past and/or future. For example, part of the anger experienced by one
person towards another person may be caused by appraisals relating to
that person's past behaviour and concerns whether they will make amends
in the future (Parkinson, 2011). Sixth, the impact of appraisals on
other components of emotion is more flexible than assumed theoretically.
For example, individuals producing the same appraisal in a given
situation may nevertheless differ in their physiological responding and
behaviour because of their past experiences and personality (Kuppens,
2013).

EMOTION REGULATION So far we have considered what happens when an
individual encounters a situation and responds to it with an emotional
experience. This is emotion generation (a spontaneous emotional response
to the current situation). In the real world, matters are often more
complex. For example, an authority figure makes you angry by saying
something unpleasant. You decide (wisely!) to inhibit your anger and
pretend all is well. This illustrates a

723

KEY TERM Emotion generation The immediate and spontaneous emotional
response to a given situation; see emotion regulation.

Research activity: Appraisals in daily life

724

KEY TERM Emotion regulation The use of explicit (deliberate and
effortful) processes or implicit (relatively automatic) processes to
change the spontaneous emotional state (usually a negative one) produced
by the emotion-generation process.

Broadening horizons

two-stage approach: an initial emotional reaction is followed by
attempts to change it. The above example involves emotion regulation.
Emotion regulation is "the activation of a goal to modify which emotion
one has, when one has the emotion, or how one experiences or expresses
the emotion" (Ghafur et al., 2018, p. 31). Thus, emotion regulation
occurs when an individual overrides their initial, spontaneous emotional
response. We can compare emotion generation and emotion regulation in
the laboratory. For example, two groups of participants experience the
same emotional situation. One group is instructed to react naturally
(emotion generation). The other group is told to regulate their
emotional responses using a specified strategy (emotion regulation).
Emotional responding (e.g., self-reported emotion; brain activation) in
the two conditions is then compared. The distinction between emotion
generation and emotion regulation is often blurred. For example,
emotional-generation processes often lead to behaviour that changes the
situation and thus the emotional response. More generally, the notion of
emotion generation implies unrealistically that our emotional
experiences are often unregulated and that emotions occur as passive
reactions to appraisals (Parkinson, 2015). Suppose you see several very
unpleasant pictures. You can simply watch them or use the
emotion-regulation strategy of reappraisal (reinterpreting the meaning
of the pictures to reduce negative emotions). Since reappraisal is
generally effective, it seems very likely you would prefer reappraisal.
In fact, when such a study was carried out (Suri et al., 2015),
reappraisal was used only 16% of the time. Thus, most individuals are
not fully aware of the potential benefits of emotion regulation.

Process model A process model of emotion regulation put forward by Gross
and Thompson (2007) has been very influential. In Figure 15.6, the basic
processes involved in emotion generation are shown along the horizontal
line. Of importance, it is assumed emotional intensity generally
increases over time as we move from left to right. Figure 15.6 also
incorporates the crucial assumption that emotionregulation strategies
can alter the emotion-generation process at various points in time
(indicated by the arrows). For example, a socially anxious person could
reduce anxiety in the following ways: (i) (ii) (iii) (iv) (v)

avoiding potentially stressful social situations (situation selection);
asking a friend to accompany them (situation modification); focusing on
distracting thoughts (attention deployment); telling themselves that
most people are friendly (cognitive change); inhibit the behavioural
expression of anxiety (response modulation).

It is unclear in the above process model how emotion-regulation
strategies start and stop. Accordingly, Gross (2015) proposed the
extended process model of emotion regulation, which identifies three
stages of emotion regulation:

Cognition and emotion

725 Figure 15.6 A process model of emotion regulation based on five
major types of strategy (situation selection, situation modification,
attention deployment, cognitive change and response modulation). From
Gross and Thompson (2007). Reprinted with permission of Guilford Press.

(1) 
(2) 
(3) 

identification (deciding whether to regulate); selection (deciding which
strategy to select); implementing (making use of a given strategy).

In the original process model, the emphasis was on a linear sequence of
processes starting with situation selection and ending with response
modulation. In the extended model, the processes are arranged in a
circular format -- this makes it clear that response modulation can
influence situation selection and so set off a new chain of processes.
Most emotion-regulation strategies involve the attentional deployment
stage (e.g., distraction -- disengaging attention from emotional
processing) or the cognitive change stage (e.g., reappraisal --
elaborating emotional information and then changing its meaning).
Sheppes et al. (2014) considered when distraction and reappraisal are
most likely to be used. They assumed the emotional intensity of an event
generally increases over time if not subject to emotion regulation.
Distraction is less cognitively demanding than reappraisal and can be
used early to control negative emotion and "nip it in the bud".
Reappraisal is more cognitively demanding but can produce long-lasting
benefits. Sheppes et al. (2014) used the above analysis to make two
predictions (both supported by research). First, distraction will be
preferred to reappraisal in high negative intensity situations because
it blocks emotional information before it intensifies. Second,
reappraisal will be used more often with emotional stimuli encountered
frequently than those encountered only once -- reappraisal of repeated
stimuli reduces their subsequent emotional impact. So far we have
considered controlled conscious processes (explicit emotion regulation).
In contrast, implicit emotion regulation "is characterised by the
absence of an explicit instruction, is evoked automatically by the
stimulus itself, runs to completion without conscious monitoring, and
can happen without insight and awareness" (Etkin et al., 2015, p. 694).
Using an explicit-regulation strategy repeatedly often leads to the
development of implicit processes (Braunstein et al., 2017). Implicit
regulation has the advantage over explicit regulation that it is less
costly in its use of cognitive resources. How do implicit processes
support emotion regulation? Koole et al. (2015) put forward three
answers. First, implicit processes can help

KEY TERMS Distraction A strategy used in emotion regulation in which the
individual disengages attention from emotional processing and focuses on
neutral information. Reappraisal A strategy used in emotion regulation
in which the individual elaborates emotional information from an event
prior to changing its meaning.

726

Broadening horizons

individuals decide whether to engage in emotion regulation. Second, they
can simplify the selection of appropriate emotion-regulation strategies.
Third, they may facilitate the execution of such strategies.

Findings: behavioural Which are the most effective emotion-regulation
strategies? In a metaanalysis, Augustine and Hemenover (2009)
distinguished between cognitive strategies (involving thinking) and
behavioural strategies (involving physical action). In general,
cognitive strategies (especially reappraisal and distraction) were more
effective. Webb et al. (2012) carried out the most thorough
meta-analysis of the effectiveness of different emotion-regulation
strategies making use of the process model shown in Figure 15.6.
Overall, strategies involving cognitive change had a moderately
beneficial effect on emotion, those involving response modulation had a
small effect, and strategies involving deployment had a non-significant
effect. Webb et al. (2012) argued that combining several different
strategies in the same category is oversimplified. For example, although
attentional deployment strategies overall had a non-significant effect,
distraction clearly had beneficial effects. With respect to
cognitive-change strategies, reappraising the emotional situation was
more beneficial than reappraising the emotional response. With response
modulation, suppressing emotional expression had a moderate effect on
emotion but suppressing emotional experience had no effect. In sum, what
matters is the specific strategy rather than the broad category. There
is an important qualification on the findings discussed so far -- the
effectiveness of any given emotion-regulation strategy typically varies
across situations. For example, consider a study by Troy et al. (2013).
They hypothesised that reappraisal would be effective in situations
where stress was uncontrollable but not those where it was controllable.
In the latter situations, problem-focused coping would be superior to
changing one's emotional state. Troy et al.'s (2013) findings confirmed
their hypotheses. Participants with high appraisal ability were less
depressed than those with low appraisal ability when high stress was
uncontrollable (see Figure 15.7). However, high appraisal ability was
associated with more depression when high stress was controllable.
Deciding which of two emotion-regulation strategies is more "effective"
can be harder than might be imagined. Troy et al. (2018) compared the
emotion-regulation strategies of reappraisal (reinterpreting meaning)
and acceptance (accepting one's emotions) when participants saw sad
movie clips. Reappraisal was more effective than acceptance at reducing
negative emotions. However, acceptance was more effective than
reappraisal at regulating physiological responding and it was also less
effortful. We turn now to the use of implicit processes in emotion
regulation. Mauss et al. (2007) exposed participants to an
anger-provocation experience (the experimenter was impatient and
irritated). Those previously encountering reappraisal-relevant words
(e.g., restrains; stable) on an unrelated task experienced less anger
and fewer negative emotions

Cognition and emotion

Figure 15.7 Mean level of depression as a function of stress severity
and cognitive reappraisal ability (high = - - - -; low = ------------)
when the situation was low in controllability (left-hand side) and high
in controllability (right-hand side). From Troy et al. (2013). Reprinted
by permission of SAGE Publications.

generally than controls because of the implicit processes they used when
provoked. Wang and Xuebing (2017) carried out a similar study and
obtained similar findings. They also found that implicit emotion
regulation affected processing within the brain approximately 170 ms
after stimulus onset. Thus, implicit emotion regulation influences early
processing and is probably relatively "automatic". Doré et al. (2016)
argued the effectiveness of emotion regulation depends on interactions
involving the individual person, the situation and the strategy being
adopted. Moreover, such interactions are present at three different
stages of emotion regulation: identification of an opportunity to
regulate; selection of a specific regulation strategy; and
implementation of that strategy (Gross, 2015). More research is needed
before we can specify which strategies are most beneficial for a given
person in a given situation.

Findings: neuroimaging Much research on emotion regulation has focused
on the relevant brain mechanisms (e.g., Braunstein et al., 2017; Etkin
et al., 2015). Most effective emotion-regulation strategies involve
cognitive control processes associated with activation within the
prefrontal cortex (especially the dorsolateral and ventrolateral
prefrontal cortex). These effortful processes cause reduced activation
in the amygdala (strongly implicated in emotional responding) and
reduced negative affect. Lee et al. (2012) reported relevant evidence in
a study on the use of reappraisal to reduce negative affect while
viewing negative pictures. Individuals with the strongest links between
prefrontal areas and the amygdala used reappraisal most effectively.
Klumpp et al. (2018) found that

727

728

Broadening horizons

Figure 15.8 A three-stage neural network model of emotion regulation.
(a) In the emotion evaluation network, affective arousal is relayed via
the amygdala (Amy) and basal ganglia (BG) to the ventrolateral
prefrontal cortex (VLPFC). (b) In the initiationof-regulation network,
the dorsolateral prefrontal cortex (DLPFC) is involved in processing the
emotion regulation. (c) The execution-of-regulation network centring on
the superior temporal gyrus (STG), the supplementary motor area (SMA)
and the angular gyrus generates a regulated emotional state. From Kohn
et al. (2014). Reprinted with permission from Elsevier.

individuals most successful at using reappraisal to reduce negative
emotions had the greatest prefrontal activity and the least amygdala
activation. In a meta-analysis, Kohn et al. (2014) identified several
brain areas associated with explicit emotion regulation. Their findings
were consistent with a three-stage neural network model (see Figure
15.8): (1) (2) (3)

Emotion evaluation: this network centres on the ventrolateral prefrontal
cortex (VLPFC) and is involved in initiating appraisal and signalling
the need to regulate emotion. Initiation of regulation: this network
centres on the dorsolateral prefrontal cortex (DLPFC) and is involved in
processing the regulation of emotion. Execution of regulation: this
network regulates affective arousal by changing the emotional state.

The crucial role played by the dorsolateral prefrontal cortex in emotion
regulation received strong support from Feeser et al. (2014).
Participants used reappraisal to increase or decrease their emotional
reactions to negative pictures. On some trials, transcranial direct
current stimulation (tDCS; see Glossary) was used to increase the
excitability of the dorsolateral prefrontal cortex. As predicted, the
use of tDCS increased selfreported emotional arousal when participants
were instructed to increase their emotional reactions and decreased it
when they were told to decrease their reactions. In sum, tDCS enhanced
cognitive control mediated by the dorsolateral prefrontal cortex.
Braunstein et al. (2017) reviewed neuroimaging research showing the
brain mechanisms associated with implicit emotion regulation differ from
those associated with explicit regulation. More specifically, implicit
regulation involves the ventral anterior cingulate and the ventromedial
prefrontal cortex but not the dorsolateral or ventrolateral prefrontal
cortex.

Cognition and emotion

729

IN THE REAL WORLD: EMOTION REGULATION AND MENTAL DISORDERS
Unsurprisingly, patients with anxiety disorders or major depressive
disorders have difficulties in explicit emotion regulation. For example,
D'Avanzato et al. (2013) found anxious and depressed patients engaged in
the maladaptive emotion-regulation strategies of rumination (obsessive
thinking about emotional issues) and expressive suppression (hiding or
inhibiting emotional behaviour). Visted et al. (2018) confirmed these
findings in a meta-analysis of studies on depressed patients. They also
found that these patients made less use than healthy controls of
adaptive strategies such as acceptance (accepting one's emotions),
problem solving and reappraisal. It has often been argued that flexible
emotion regulation is desirable because of frequent changes in the
problems we face. Patients with emotional disorders often exhibit
inflexible emotion regulation which probably contributes to their
emotional disturbances (Aldao et al., 2015). There is also evidence that
patients with emotional disorders have difficulties with implicit
emotion regulation. For example, patients with generalised anxiety
disorder (characterised by excessive worry and anxiety in several life
domains) have deficient implicit regulation of emotional conflict (Etkin
& Schatzberg, 2011). Why are patients with emotional disorders poor at
emotion regulation? Fernandez et al. (2016) discussed four reasons.
First, they find it hard to identify emotions that need regulating; (2)
they often fail to select an effective emotion-regulation strategy; (3)
they sometimes implement the selected strategy ineffectively; and (4)
they often fail to monitor the implemented strategy to decide whether a
different strategy should be used. Which emotion-regulation strategies
are associated with beneficial effects on anxiety and depression? In
their review, Aldao et al. (2010) found acceptance, problem solving and
reappraisal all reduced the symptoms of anxiety and depression. Mennin
et al. (2015) argued emotion-regulation therapy might be valuable.
Accordingly, they devised therapy emphasising the teaching of effective
emotion-regulation strategies and encouraging patients to use these
strategies when they anticipated being in a stressful situation. This
therapy was used with anxious patients, half of whom also had depressive
symptoms. Therapy increased patients' use of effective
emotion-regulation strategies (e.g., reappraisal) and reduced the
symptoms of anxiety and depression. Renna et al. (2018) obtained similar
findings. Reductions in anxious and depressive symptoms produced by
emotion regulation therapy were maintained over a period of nine months
post-treatment. What are the long-term effects of emotion-regulation
therapy? One approach is to consider changes in brain activity resulting
from therapy. Successful emotion regulation often involves increased
activity in prefrontal areas (e.g., dorsolateral prefrontal cortex),
indicative of enhanced cognitive control, and decreased activity in
limbic areas (e.g., amygdala), reflecting responsiveness to emotional
stimuli. This pattern has often been found in anxious and depressed
patients posttherapy (Messina et al., 2016).

Evaluation Several advances have been made. First, effective
emotion-regulation strategies often involve effortful cognitive
processing in the prefrontal cortex leading to reduced amygdala
activation. Second, the extended process model (Gross, 2015) is more
realistic than Gross's previous model, which was based on a linear
sequence of processes, and it also identifies factors responsible for
the initiation of emotion regulation. Third, emotion-regulation

KEY TERM Major depressive disorder A mental disorder characterised by
depressed mood, tiredness and lack of pleasure and interest in various
activities.

730

Broadening horizons

strategies can be explicit or implicit. Fourth, factors influencing
which strategy is selected in a given situation have been identified.
Fifth, there are promising signs emotion-regulation therapy is
successful in treating anxiety and depression. What are the limitations
of theory and research in this area? (1) (2) (3) (4)

(5) 

There is no clear-cut distinction between emotion generation and emotion
regulation. Behavioural emotion-regulation strategies (e.g., drinking
alcohol; arguing with others) have been de-emphasised. The effectiveness
of emotion regulation depends on complex (but poorly understood)
interactions involving the individual, the situation and the
emotion-regulation strategy selected (Doré et al., 2016). We do not know
why most people have limited awareness of the benefits of
emotion-regulation strategies and often fail to use effective
strategies. For example, Suri et al. (2015) found only 16% of
participants used the effective strategy of reappraisal even when its
use was explicitly suggested. A possible explanation is that people
prefer strategies they have used recently and/or frequently even when
such strategies are relatively ineffective in the current situation
(Ghafur et al., 2018). Little is known concerning individual differences
in the ability to use any given strategy. However, McRae et al. (2012)
made a start: individuals using reappraisal successfully had
above-average well-being and working memory capacity (see Glossary).

AFFECT AND COGNITION: ATTENTION AND MEMORY Much laboratory research
differs considerably from everyday life because individuals' cognitive
processes and performance are assessed in a relatively neutral emotional
state. In real life, emotions often influence our behaviour. Consider
"road rage" (i.e., frustrated drivers become angry and so drive
dangerously). Zhang and Chan (2016) reviewed studies on driving anger
and driving behaviour. Driving anger was associated with aggressive
driving, risky driving and driving errors. However, it was only modestly
associated with near misses and accidents. Qu et al. (2016) confirmed
that experiencing driving anger was a poor predictor of car crashes.
However, individuals expressing anger verbally (e.g., shouting insults)
and physically (e.g., making hostile gestures) were much more likely to
cause car crashes. Our emotional state influences numerous aspects of
cognition including perception, attention, interpretation of situations,
learning, memory, judgement, decision-making and reasoning (Blanchette &
Richards, 2010). We discuss research on attention and memory here and
the next section focuses on judgement and decision-making. Most theories
assume the effects of positive and negative affect on cognitive
processes (e.g., attention; memory; judgement; decision-making) are
fixed and constant. However, this assumption is oversimplified.
Huntsinger et al. (2014) and Ray and Huntsinger (2017) argued
persuasively the

Cognition and emotion

influence of affect on cognitive processes is typically flexible. More
specifically, affect provides useful feedback concerning an individual's
current mental state: "Positive affective feelings act as a 'go signal'
that promotes the use of accessible processing styles, and negative
affective feelings act as a 'stop signal' that inhibits their use" (Ray
& Huntsinger, 2017. p. 2). This is an affect-as-cognitive-feedback
account. Several techniques have been used to manipulate people's mood
state (Lench et al., 2011). The most common technique (24% of studies)
involves presenting emotional films. Another popular technique (20% of
studies) involves autobiographical recall (e.g., describing an intense
emotional experience).

Attention We have flexibility in what we attend to and also the scope of
focal attention (see Chapter 5). Some theorists (e.g., Eriksen & St
James, 1986) have compared visual attention to a zoom lens allowing the
attended area to be increased or decreased. This issue is relevant to
understanding longterm memory: our memory of an event is strongly
influenced by what we attended to during learning. How does affect
influence attentional breadth? Easterbrook (1959) provided an
influential answer with respect to negative affect. He hypothesised the
range of cues processed (i.e., the breadth of attention) decreases as
arousal or anxiety increases. Thus, high negative affect produces
"tunnel vision". Easterbrook's hypothesis enhances our understanding of
eyewitness memory (see Chapter 8), because eyewitnesses are often very
anxious when observing a crime. It is also relevant to the effects of
anxiety on driving. Anxious drivers attend less than non-anxious ones to
peripheral information (Janelle et al., 1999). Briggs et al. (2011) used
a simulated driving task with spider-phobic drivers. They showed
narrowing of attention while driving when made anxious by having a
conversation about spiders. What about the effects of positive affect on
attentional breadth? According to Fredrickson and Branigan (2005,
p. 315), positive emotions "widen the array of percepts, thoughts, and
actions presently in mind." Thus, positive affect produces broadening of
attention rather the narrowing of attention assumed for negative affect
by Easterbrook (1959). Gable et al. (2015a) argued we should also
consider motivational intensity (e.g., having the goal of approaching or
avoiding a stimulus). Positive affect can involve low motivational
intensity (e.g., listening to music) or high motivational intensity
(e.g., seeing an attractive member of the opposite sex). Similarly,
negative affect can involve low motivational intensity (e.g., being
exposed to sad situations) or high emotional intensity (e.g., being
exposed to threatening situations). Gable et al. (2015a) argued positive
and negative affective states of high motivational intensity produce
attentional narrowing because this helps individuals to acquire
desirable objects and avoid unpleasant ones. In contrast, there is
attentional broadening with positive and negative

731

732

Broadening horizons

affective states of low motivational intensity because it leaves people
open to encountering new opportunities.

Findings Easterbrook's hypothesis and the theoretical viewpoint of Gable
et al. (2015a) both predict that anxiety (which has high motivational
intensity) should produce attentional narrowing. Relevant evidence has
been obtained from several studies where participants performed a
primary task presented in the centre of the visual field and a secondary
task in the periphery. If anxiety causes attentional narrowing, it
should impair performance on the secondary task more than the primary
task. That prediction has received consistent support (Eysenck et al.,
2007). Both theories predict anger (also having high motivational
intensity) should produce attentional narrowing; this finding was
reported by Gable et al. (2015b). The two theories differ with respect
to the effects of sadness (a mood state involving low motivational
intensity). According to Gable et al.'s motivational intensity theory,
sadness should produce attentional broadening whereas the opposite
prediction follows from Easterbrook's hypothesis. Gable and
Harmon-Jones' (2010b) findings supported motivational intensity theory.
Fredrickson and Branigan (2005) predicted that positive affect leads to
attentional broadening. Vanlessen et al. (2016) reported strong support
for this prediction in their meta-analytic review. How can we explain
these findings? According to Pourtois et al. (2017), positive affects
leads to reduced cognitive control and so less attentional selectivity.
Note that Gable et al.'s (2015a) motivational intensity theory predicts
positive affect should produce attentional narrowing if there is high
motivational intensity. This prediction (opposite to that of Fredrickson
and Branigan's theory) was supported in a study by Gable et al. (2015b).
In sum, most of the findings support Gable et al.'s (2015a) theoretical
approach. Thus, attentional narrowing (or broadening) depends much more
on whether affective states have high or low motivational intensity than
on whether they are positive or negative. Huntsinger (2012) added a
complication to this picture. He argued individuals generally interpret
positive affect as indicating they should continue with their current
processing strategy. In contrast, negative affect indicates they should
inhibit their current processing strategy. These assumptions were
incorporated into the affect-as-cognitive-feedback account mentioned
earlier. In Huntsinger's (2012) study, participants initially performed
a task using a broad (global) attentional focus, a narrow or local
attentional focus, or a mixture. Then they performed a different task:
deciding whether a central letter was an H or S. This central letter was
flanked by letters compatible or incompatible with it. It was assumed
individuals with a broad attentional focus would be more influenced by
flanker compatibility than those with a narrow attentional focus. As
predicted, those in a happy mood had the same attentional focus as on
the initial task whereas those in a sad mood had the opposite
attentional focus (see Figure 15.9). The effects of mood on memory
(discussed further shortly, pp. 734--738) depend in part on whether the
mood narrows or broadens attention. For

Cognition and emotion

20

Figure 15.9 The incompatibility flanker effect (incompatible
trials--compatible trials) on reaction times as a function of mood
(happy or sad) and whether a global, local or mixed focus had been
primed on a previous task.

15

From Huntsinger (2012).

Happy

40 Flanker imcompatibility eﬀect

733

Sad

35 30 25

10 5 0 Global

Local Perceptual prime

Mixed

example, emotion often increases memory for information central to our
current goals but reduces it for unimportant information (Levine &
Edelstein, 2009). Consider the weapon focus effect (the tendency for
eyewitnesses to attend narrowly to a weapon and thus fail to remember
peripheral details) reviewed by Fawcett et al. (2016) (see Chapter 8).
It is tempting to link "memory narrowing" associated with emotional
states to attentional narrowing during learning. However, there are
problems with that argument. First, visual attention at learning often
fails to predict the extent of "memory narrowing" (Steinmetz et al.,
2016). Second, the predicted memory narrowing is not always found.
Steinmetz et al. (2016) presented positive, negative or neutral objects
on neutral backgrounds. When the object cued recall of the associated
background, memory for background or peripheral information was actually
greater when emotional objects (positive or negative) had been
presented. Thus, peripheral information is often stored in memory and
emotional cues may facilitate its retrieval. Third, it follows from
Gable et al.'s (2015a,b) theory that attention (and perhaps memory)
depend on the motivational intensity of an emotional state. Thus, there
should be memory broadening if the emotional state has low motivational
intensity. Talarico et al. (2009) asked participants to recall eight
emotional autobiographical memories. Peripheral details were poorly
recalled with memories associated with emotions having high motivational
intensity (anger; fear; negative surprise). However, sad memories were
associated with reasonably good recall of peripheral memories perhaps
because of the low motivational intensity of that emotional state.
Talarico et al. (2009) found good recall of peripheral details for all
types of positive memories. This fits with Frederickson and Branigan's
(2005) theory and also fits Gable et al.'s (2015a,b) theory if we assume
(perhaps mistakenly) that most positive mood states occur with low
motivational intensity. Of relevance, Gable and Harmon-Jones (2010a)
found positive affect enhanced memory for peripheral details when there
was low motivational intensity but not when there was high motivational
intensity.

734

Broadening horizons

Conclusions The hypotheses that negative affect produces attentional
narrowing and positive affect produces attentional broadening are
oversimplified. The obtained findings depend mostly on the level of
motivational intensity. The notion (Huntsinger et al., 2014) that
positive affect leads individuals to maintain their previous cognitive
processes whereas negative affect causes them to change those processes
has received support. There is strong support for two conclusions.
First, positive and negative affect typically have significant
influences on attentional processes. Second, "Affective influences on
cognition are . . . not fixed but malleable \[flexible\]" (Clore et al.,
2018, p. 78). We probably benefit from this attentional flexibility
rather than having our attentional processes inflexibly determined by
our current emotional state.

Memory

Case study: Hills et al. (2011)

How does emotion influence long-term memory? Emotional events are
forgotten more slowly than neutral ones (especially those that produce
negative rather than positive affect: Bowen et al., 2018). As a result,
the memory advantage for emotional events generally increases over time
(Yonelinas & Ritchey, 2015). Evidence that emotional events are often
better remembered than neutral ones comes from research on flashbulb
memories (vivid memories of dramatic events such as 9/11; see Chapter
8). Flashbulb memories are especially long-lasting when there is an
initial intense emotional experience. For example, those near the World
Trade Centre when it was destroyed had more vivid memories of that event
than those further away (Sharot et al., 2007).

Brain mechanisms: amygdala The effects of mood or emotion on long-term
memory depend on activation within several brain regions. Of central
importance is the amygdala (see Glossary), which is associated with
several emotions. Researchers often refer to the amygdala but note that
it consists of at least three component parts (Hortensius et al., 2017)
and so is more complex than usually assumed. Emotion's memory-enhancing
effects depend in part on amygdala activation (Dolcos et al., 2017).
Tambini et al. (2017) even found participants showed enhanced long-term
memory for neutral items presented up to 30 minutes following the
processing of emotionally arousing stimuli. This occurred because the
emotionally arousing stimuli produced long-lasting activation within the
amygdala and related brain areas. Adolphs et al. (2005) found healthy
controls showed enhanced memory for gist when the encoding context was
emotional rather than neutral. In contrast, patients with amygdala
damage showed a specific impairment limited to gist memory with an
emotional context at encoding, but such damage was not associated with
impaired memory for background details. These findings suggest the
amygdala is required for focused attention on

Cognition and emotion

important information and are thus consistent with Easterbrook's (1959)
hypothesis (discussed above, see p. 731). We can also assess the role of
the amygdala in influencing the effects of emotion on memory by studying
patients with Urbach-Wiethe disease, in which the amygdala and nearby
areas are largely or totally destroyed (see Feinstein, 2013, for a
review). Cahill et al. (1995) found a patient (BP) had poorer recall of
a very emotional story event than of an emotionally neutral event. In
contrast, healthy controls had much better recall of the emotional
event. Similarly, Siebert et al. (2003) found Urbach-Wiethe patients had
greater memory impairment for emotional pictures than neutral ones. It
is often assumed amygdala activation facilitates the storage of
emotional memories in long-term memory via a physiologically based
process of consolidation (see Glossary). This theory implies healthy
individuals would have superior long-term memory for all the information
associated with an emotional event. In fact, that is not the case.
Sharot and Yonelinas (2008) found negative pictures were remembered
better than neutral ones 24 hours after learning. However, emotion did
not influence contextual information (i.e., whether the pictures had
been presented in the context of a colour or complexity task). A major
reason why the amygdala is of importance in explaining the enhancing
effects of mood on memory is because it is a hub having numerous
connections to 90% of cortical regions and it is involved in various
brain networks. Supporting evidence was reported by Murty et al. (2010)
in a meta-analysis of neuroimaging studies. Good long-term memory for
emotional material was associated with greater activation during
learning in a network including the amygdala, the hippocampus and the
medial prefrontal cortex. Dolcos et al. (2017) provided a comprehensive
account of the brain networks concerned with emotion's memory-enhancing
effects (see Figure 15.10). They identified two brain mechanisms. First,
there is a bottom-up

Lateral parietal cortex

C

PF

dI

PCC

/PC un

mPFC

FC

Insula

vIP

e l lob pora tem tem ory sys ia d Me L) mem (MT

OFC AMY

TOC

735

KEY TERM Urbach-Wiethe disease A disease in which the amygdala and
adjacent areas are destroyed; patients with this disease have impaired
emotional processing.

Figure 15.10 Two main brain mechanisms involved in the memoryenhancing
effects of emotion: (1) the medial temporal lobes (MTL, including the
hippocampus) and the amygdala (AMY); (2) the medial, dorsolateral and
ventrolateral prefrontal cortex (mPFC; dlPFC; and vlPFC, respectively).
Encoding of negative emotions involves the temporo-occipital cortex
(TOC) and encoding of self-relevant information involves the posterior
cingulate cortex/precuneus (PCC/PCun). From Dolcos et al. (2017).

736

KEY TERMS Mood congruity Learning and memory of emotional material are
better when the learner's/ rememberer's mood state matches the affective
value of the material than when it does not. Mood-state-dependent memory
Memory performance is better when the individual's mood state is the
same at learning and retrieval than when it differs.

Broadening horizons

mechanism, including the medial temporal lobes, which is strongly
influenced by emotional arousal. Second, there is a top-down mechanism,
which includes several areas within the prefrontal cortex and is
involved in various cognitive processes (e.g., attention; working
memory; and cognitive control). Of importance, the amygdala is involved
in both mechanisms.

Mood congruity Affect influences learning and memory in various ways.
What memories would spring to mind if you were in a negative mood
because of personal problems? People generally recall mostly negative or
unpleasant memories in such circumstances. In contrast, we typically
recall happy memories when in a good mood. These examples illustrate
mood congruity -- emotionally toned material is learned and retrieved
best when its affective value matches the learner's (or rememberer's)
mood state. There is much evidence for mood-congruent memory. For
example, depressed individuals recall more negative information than
positive or neutral information (e.g., Rinck & Becker, 2005; discussed
later, p. 759). Holland and Kensinger (2010) reviewed research on mood
and autobiographical memory. Positive mood was associated with strong
evidence of mood congruity. However, mood congruity was less apparent
with negative mood. Similar findings have been found in studies using
nonautobiographical material (Rusting & DeHart, 2000). Many failures of
mood congruity in a negative mood state occur because individuals in
that mood state are motivated to enhance their mood state. Rusting and
DeHart (2000) used a negative mood induction and found participants
claiming they could successfully reduce their negative moods showed less
evidence of mood congruity than other participants. How can we explain
mood congruity? Tulving's (1979) encoding specificity principle (Chapter
6) is applicable. According to this principle, memory depends on the
overlap between the information available at retrieval and that in the
memory trace. This overlap is greater when the to-be-remembered material
is congruent with the rememberer's mood state. Lewis et al. (2005)
extended the encoding specificity principle, arguing that brain
activation at learning and at retrieval would be more alike in
conditions producing mood congruity. As predicted, one brain region (the
subgenual cingulate) was activated when positive stimuli were presented
and was reactivated when participants were in a positive mood at test. A
different brain region (the posteriolateral orbitofrontal cortex) was
activated when negative stimuli were presented and was reactivated when
participants' mood at test was negative.

Mood-state-dependent memory Another effect of mood on memory is
mood-state-dependent memory: memory is better when an individual's mood
state at retrieval matches (rather than mismatches) that at learning. In
a review, Ucros (1989) found

Cognition and emotion

737

stronger evidence for mood-state-dependent memory when participants were
in a positive rather than negative mood. This probably occurred because
individuals experiencing a negative mood state are motivated to change
their mood state into a positive one. We can clarify the processes
underlying mood-state-dependent memory effects by considering a study by
Kenealy (1997). Participants viewed a map and learned a given route. The
next day they received tests of free recall (no cues) and cued recall
(the map's visual outline). Happy or sad mood states were created at
learning and test. Mood-state-dependent memory was found in free recall
but not cued recall (see Figure 15.11). The free recall findings can be
explained with reference to the encoding specificity principle
(discussed above, p. 736). If information about mood state is stored
during learning, the overlap between retrieval information and
information in the memory trace will be greater when the mood state is
the same at learning and test. How can we explain the absence of
mood-state-dependent memory with cued Figure 15.11 recall? Eich (1995)
argued mood state has (a) Free and (b) cued recall as a function of mood
state (happy less influence when crucial information is or sad) at
learning and at recall. presented explicitly at retrieval, as happens
Based on data in Kenealy (1997). with cued recall. He discussed a
"do-it-yourself principle" -- memory is most likely to be mood-dependent
when effortful processing at learning and/or retrieval is required.
Support for the "do-it-yourself principle" was obtained by Eich and
Metcalfe (1989). At learning, participants were assigned to read (e.g.,
river-valley) or generate (e.g., river-v\_\_\_\_\_) conditions. In the
generate condition, they completed the second word in each pair during
learning which involved effortful processing. The mood-state-dependent
effect was four times greater in the generate condition.

Evaluation Several effects of mood state on attention and memory have
been established. Mood states involving high motivational intensity
typically produce attentional narrowing, whereas mood states involving
low motivational intensity produce attentional broadening. These effects
on attention influence long-term memory. Positive affect often leads
individuals to maintain their current attentional strategy, whereas
negative affect leads them to change that strategy. There is much
evidence for mood congruity and

738

Broadening horizons

mood-state-dependent memory, and both effects can often be explained by
the encoding specificity principle. Finally, we have an increasingly
detailed understanding of the brain networks associated with the
memory-enhancing effects of emotion. What are the limitations of
research in this area? First, the notion that attentional narrowing or
broadening has direct effects on long-term memory is only partially
correct. Second, there is less evidence for mood congruity and
mood-state-dependent memory with negative mood states than positive
ones. Third, the reasons why stronger mood-state memory effects are
found with some memory tasks than others are not fully understood.

AFFECT AND COGNITION: JUDGEMENT AND DECISION-MAKING Judgement and
decision-making are discussed in Chapter 13. Decisionmaking involves
choosing among various options varying between the trivial (e.g., what
am I going to drink?) and the hugely important (e.g., which career path
will I follow?). Judgement is an important component of decision-making.
It involves assessing the probability of various events occurring and
then deciding how we would feel if each one happened. This section is
concerned with the effects of affect on judgement and decision-making.
This is an important area of research. As Lerner et al. (2015, p. 801)
pointed out, "Many psychological scientists assume that emotions are . .
. the dominant driver of most meaningful decisions in life." Below we
start by considering how emotions influence what, in the real world, are
life-and-death issues.

Moral dilemma: emotion vs cognition (reason)

Figure 15.12 Two well-known moral dilemma problems: (a) the trolley
problem; and (b) the footbridge problem.

It is commonly believed emotion leads us to make fast relatively
"automatic" decisions whereas cognition (reason) produces slower, more
considered decisions. For example, consider Greene et al.'s (2008)
dual-process model of decisions made with moral dilemmas. They
distinguished between two systems: (1) a fast, automatic and affective
system; and (2) a slower, effortful and more "cognitive" system. This
model has been investigated using various moral dilemmas. For example,
the trolley problem poses a moral dilemma. You must decide whether to
divert a runaway trolley threatening the lives of five people

Cognition and emotion

onto a side-track where it will kill only one person (see Figure
15.12a). The footbridge problem also poses a moral dilemma. You must
decide whether to push a fat person over a bridge causing that person's
death but saving five people's lives (see Figure 15.12b). What did you
decide? Research indicates 90% of people decide to divert the trolley
(trolley problem) but only 10% decide to push the person off the
footbridge (footbridge problem). Greene et al. (2008) argued the
footbridge problem is a personal moral dilemma because we might directly
harm one or more individuals through our actions. In contrast, the
trolley problem is an impersonal dilemma because any harm is only
indirectly due to our actions. With personal moral dilemmas, those
making deontological judgements based on moral rules or obligations
(e.g., do not kill) respond mainly based on the first, affective system.
Deontological judgements are very common with the footbridge dilemma. In
contrast, those making practical or utilitarian judgements based on
maximising the consequences (e.g., saving as many lives as possible) use
the second, cognitive system. Utilitarian judgements are very common
with the trolley problem. In crude terms, you can use your heart
(deontological judgements) or your head (utilitarian judgements) to
resolve moral dilemmas (Greene, 2014). Different brain areas are
associated with the two systems (see Figure 15.13). The dorsolateral
prefrontal cortex (DLPFC; BA9/46) is involved in cognitive control. In
contrast, the ventromedial prefrontal cortex (VMPFC; BA10/11) is
involved in emotion generation.

739

KEY TERMS Deontological judgements Judgements based on moral rules and/
or obligations when resolving moral dilemmas; see utilitarian
judgements. Utilitarian judgements Judgements based on practical and
pragmatic considerations when resolving moral dilemmas; see
deontological judgements.

Findings According to the dual-process model, individuals making
utilitarian judgements should have more activity in the dorsolateral
prefrontal cortex than those making deontological judgements. This
finding was reported by Greene et al. (2004). Tassy et al. (2012)
applied repetitive transcranial magnetic stimulation (rTMS; see
Glossary) to the DLPFC to inhibit its functioning. This reduced
utilitarian judgements with moral dilemmas of high emotional intensity.
Patients with damage to the ventromedial prefrontal cortex (VMPFC) have
reduced emotional responsiveness and so should be less influenced than
healthy controls by emotional factors. As predicted, they make more
utilitarian judgements than controls (Thomas et al., 2011). It is
assumed theoretically that deontological judgements depend much more on
emotional processing than utilitarian ones Figure 15.13 only with
personal moral dilemmas. Perkins The dorsolateral prefrontal cortex is
located approximately in et al. (2013) gave an anti-anxiety drug to par-
Brodmann areas 9 and 46; the ventromedial prefrontal cortex ticipants to
reduce the impact of emotion on is located approximately in Brodmann
areas 10 and 11. judgements. As predicted, anti-anxiety drugs From Ward
(2010).

740

Broadening horizons

increased utilitarian judgements (and reduced deontological ones) only
with personal moral dilemmas. According to Greene's theoretical
approach, utilitarian judgements are regarded as reflecting concern for
the greater good. However, Kahane et al. (2015) obtained evidence
apparently inconsistent with that approach. They found antisocial
individuals (e.g., those with psychopathic tendencies) were more likely
to produce utilitarian judgements with personal moral dilemmas than were
other people. Conway et al. (2018) replicated the above findings when
participants were forced to choose between utilitarian and deontological
judgements. However, they pointed out that such findings are ambiguous
-- they may reflect increased utilitarian inclinations in antisocial
individuals and/or reduced deontological inclinations. When they used
more sensitive measures, Conway et al. discovered antisocial individuals
had reduced deontological inclinations rather than increased utilitarian
inclinations. These findings are broadly consistent with Greene's
theoretical approach.

Consequences (C), moral norms (N) and preference for inaction (I): CNI
model Gawronski and Beer (2017) also argued that forcing participants to
decide between utilitarian and deontological judgements provides
ambiguous information. Accepting the killing of one person to save the
lives of five other people on the trolley dilemma may reflect a
utilitarian moral judgement. However, it could also indicate a lack of
aversion to harming others. Deciding not to push the person off the
footbridge on the footbridge problem may indicate either a deontological
moral judgement or a general preference for inaction regardless of any
moral norms. Gawronski et al. (2017) argued we can resolve such
ambiguities by manipulating factors relevant to utilitarian judgements
(i.e., changing outcomes or consequences) and those relevant to
deontological judgements (i.e., changing moral norms). In addition,
individual preferences for inaction or action can be assessed by
including problems where moral norms prohibit action (e.g., using
illegal torture methods to discover where children have been hidden).
Accordingly, Gawronski et al. obtained separate measures of sensitivity
to consequences or outcomes (utilitarian judgements) and to moral norms
(deontological judgements), and a general preference for inaction vs
action. Gawronski et al. (2017) compared individuals high and low in
psychopathy (antisocial tendencies). Those high in psychopathy had a
greater preference than low scorers for action over inaction (see Figure
15.14). However, they had less sensitivity than low scorers to
consequences and to moral norms. These findings seem more plausible than
previous reports (e.g., Kahane et al., 2015) that high psychopathy is
associated with an emphasis on utilitarian moral judgements.

Cognition and emotion

1.0 Low psychopathy

0.9

High psychopathy 0.8

Parameter estimate

0.7

741 Figure 15.14 Sensitivity to consequences (C), sensitivity to moral
norms (N) and preference for inaction vs action as a function of
psychopathy (low vs high). From Gawronski et al. (2017).

0.6 0.5 0.4 0.3 0.2 0.1 0.0 C parameter

N parameter

I parameter

IN THE REAL WORLD: DRIVERLESS CARS The prospect that our roads may soon
be full of driverless cars raises important moral issues. Approximately
75% of people argue driverless cars should be programmed to sacrifice
one passenger rather than kill ten pedestrians (Bonnefon et al., 2016).
This is a utilitarian moral decision. However, Bonnefon et al. (2016)
found complex moral issues arose when they asked additional questions.
Support for the utilitarian judgement (morality of sacrifice) was lower
when people imagined they were in the driverless car alone, or with a
co-worker or family member (see Figure 15.15). If you want to compare
your moral decisions in such dilemmas, you can do so at the following
address: http://moralmachine.mit.edu. When deciding how likely they
would be to buy a driverless car designed to minimise casualties (which
might threaten their own lives) or one programmed to protect the
passengers, their enthusiasm for the utilitarian approach was weak. As
Bonnefon et al. concluded, "Although people tend to agree that everyone
would be better off if \[driverless cars\] were utilitarian (in the
sense of minimising casualties), these same people have a personal
incentive to ride in \[driverless cars\] that will protect them at all
costs" (p. 1575). The moral issues involved in programming driverless
cars have often been compared to those involved in the trolley problem
(discussed earlier, pp. 738--739). However, there are important
differences (Nyholm, 2018). First, the outcomes of the possible decision
choices are known with certainty with the trolley problem but are much
less clear-cut when considering most roaddriving conditions. For
example, if a driverless car is programmed to mount the pavement where
pedestrians are walking, the harm that would be caused depends on
numerous factors (e.g., whether the pedestrians are looking at the car;
the mobility of the pedestrians). Second, there are complexities
associated with real-world driving absent from the trolley problem
(Nyholm, 2018). For example, it could be argued that driverless cars
should be programmed to

742

Broadening horizons

Study 3 Alone

With co-worker

With family

Morality of sacriﬁce

Buy minimise

Buy protective

Agreement with morality (or) willingness to buy

80

60

40

20

Figure 15.15 Agreement with a utilitarian approach (morality of
sacrifice and willingness to buy a driverless car programmed to minimise
casualties) or to protect passengers as a function of whether the person
is alone in the car or with a co-worker or family member. From Bonnefon
et al. (2015).

attach more value to the lives of young children (whose entire lives are
ahead of them) than to older adults. Third, suppose that in the future
driverless cars are much safer than cars driven by humans. Should the
driverless cars be programmed to minimise lives lost (the utilitarian
judgement)? The "natural" reaction is to answer "Yes". However, the
problem with that approach is that people would be reluctant to buy cars
that would not prioritise their own safety in the case of an accident.
Thus, programming driverless cars to use utilitarian judgements is
generally regarded as morally desirable. However, it would have the
unfortunate consequence that fewer driverless cars would be bought. As a
result, more people would die in car accidents using this morally
desirable approach because fewer of the safe driverless cars would be
bought!

Evaluation Research on moral dilemmas focuses on complex emotional
issues relevant to everyday life. Individuals confronting a moral
dilemma can use fast affective processes and/or slow cognitive ones. The
brain areas associated with those two types of processes have been
identified using neuroimaging studies and studies on brain-damaged
patients. The dual-process model is of relevance to many real-life
situations (e.g., programming driverless cars).

Cognition and emotion

What are the dual-process model's limitations? First, it is
oversimplified (as are the moral dilemmas typically used to test it). As
Gawronski et al. (2017, p. 21) pointed out, "The traditional
\[experimental\] approach conflates sensitivity to consequences,
sensitivity to norms, and general preferences for inaction in a single
outcome measures." In addition, the outcomes of the decision choices on
the trolley and footbridge problems are known with certainty but this is
generally not the case in the real world. Second, little is known of the
extent to which responses to hypothetical dilemmas predict responses to
real-life dilemmas. Bostyn et al. (2018) found that judgements in a
real-life dilemma (administering an electric shock to one mouse vs
allowing five other mice to receive the shock) were not predicted by
judgements on hypothetical trolley-like problems. One possibility is
that people are more likely to make what they regard as socially
desirable judgements in hypothetical situations. Third, according to the
dual-process model, the processes underlying deontological judgements
occur more rapidly and with less effort than those underlying
utilitarian judgements. However, Bialek and De Neys (2017) found that
participants making deontological judgements often processed information
relevant to utilitarian judgements rapidly and in parallel with
information relevant to deontological judgements. Thus, the processes
underlying moral judgements are often more complex than assumed by
Greene's model.

Judgement and decision-making: anxiety, sadness, anger and positive mood
There has recently been a dramatic increase in research considering the
impact of affect on judgement and decision-making. As discussed earlier,
there are numerous emotions and mood states. However, research has
focused mostly on four mood states (anxiety; sadness; anger; positive
mood) and our coverage will reflect that focus. Angie et al. (2011)
provided a research review of this area. They drew two general
conclusions. First, major mood states have different effects on
judgement and decision-making. Second, moods influence decision-making
more than judgement. We will also consider the effects of personality on
judgement and decision-making because there are moderately strong links
between personality and mood. For example, individuals high in the
personality dimension of trait anxiety (see Glossary) are in an anxious
mood state much more often than those low in trait anxiety. What
predictions might we make? First, we might expect mood valence (positive
vs negative) to be important. More specifically, individuals
experiencing negative moods (e.g., fear; anger; sadness) should be
pessimistic and risk-averse, whereas those experiencing positive moods
should be optimistic and willing to take risks. Second, we might expect
any given mood state to be associated with risky or cautious
decision-making regardless of the situation or the nature of the
decision. As we will see, both assumptions are only partially correct.
Lerner et al. (2015, p. 801) provided a useful overarching principle to
explain the effects of emotions on decision-making: "Decisions can be

743

744

KEY TERMS Integral emotions Emotions experienced while engaged in making
a judgement or decision that arise from the judgement or decision.
Incidental emotions Emotions experienced while engaged in making a
judgement or decision that are irrelevant to the judgement or decision.
Optimism bias The tendency to exaggerate our chances of experiencing
positive events and to minimise our chances of experiencing negative
events relative to other people.

Broadening horizons

viewed as a conduit through which emotions guide everyday attempts at
avoiding negative feelings (e.g., guilt and regret) and increasing
positive feelings (e.g., pride and happiness)." We must distinguish
between integral and incidental emotions (Lerner et al., 2015). Integral
emotions arise from the current judgement or choice. For example, an
individual deciding whether or not to gamble a lot of money on a risky
project may experience anxiety. In contrast, incidental emotions are
unrelated to the current task (judgement or decision-making). For
example, the positive affect you experience having passed an important
examination may influence your subsequent judgements and decisions on
totally different issues. Much research has involved incidental
emotions. For example, participants describe an intensely emotional
experience and then perform an unrelated task. In contrast, real-world
judgement and decision-making very often involve integral emotions
(e.g., the emotions associated with the choices available when making a
crucial decision often influence our decision). Why is it important to
distinguish between integral and incidental emotions? One reason is that
the effects of incidental emotion on judgement and decision-making are
often weaker than those of integral emotion. For example, individuals
high in emotional intelligence (including the ability to understand
emotions) are better able to identify the event causing their emotions
and so minimise the impact of incidental emotions on decision-making
(Yip & Côté, 2013). The effects of incidental emotion on judgement are
sometimes easy to eliminate. Schwarz and Clore (1983) studied the
effects of mood produced by weather conditions on ratings of life
satisfaction. These ratings were lower on rainy than sunny days because
the weather influenced people's mood. However, the negative effect of
bad weather on judged life satisfaction disappeared when people were led
to attribute their bad mood to the weather.

Anxiety Fear or anxiety is consistently associated with pessimistic
judgements about the future. Lerner et al. (2003) carried out a study
soon after the 9/11 terrorist attacks. Participants focused on aspects
of the attacks that made them afraid, angry or sad. The estimated
probability of future terrorist attacks was higher in fearful
participants than sad or angry ones. Most individuals have an optimism
bias -- they believe they are more likely than others to experience
positive events (e.g., career success) but less likely to experience
negative events (e.g., divorce; serious illness). Anxious individuals
exhibit less optimism bias than non-anxious ones. Lench and Levine
(2005) asked college students to judge the likelihood of various events
(positive and negative) happening to them compared to the average
college student. Those put into a fearful mood were more pessimistic
than those in a happy or neutral mood. Harris et al. (2008) reported
similar findings. Individuals high in trait anxiety were less likely
than non-anxious individuals to perceive others as more vulnerable than
themselves to future risks (e.g., having a heart attack; getting
divorced).

Cognition and emotion

745

Decision-making Anxious individuals typically make less risky decisions
than non-anxious individuals (see Chapter 13). Lee et al. (2006)
provided real-world evidence. High-anxious individuals were much less
likely than low-anxious ones to die from accidental causes or suffer
non-fatal injuries because they were more risk-averse. Raghunathan and
Pham (1999) asked participants to decide whether to accept job A (high
salary + low job security) or job B (average salary + high job
security). Those in an anxious mood state were much less likely than
those in a neutral state to choose the high-risk option (i.e., job A)
(see Figure 15.16). Gambetti and Giusberti (2012) studied real-life
financial decision-making. Anxious Figure 15.16 individuals made safer
(more conservative) Effects of mood manipulation (anxiety, sadness or
neutral) on financial decisions. They were more likely to percentages of
people choosing a high-risk job option. have put their money into
interest-bearing Based on data in Raghunathan and Pham (1999). With
permission from accounts but less likely to have invested large
Elsevier. sums in stocks and shares. Oehler et al. (2018) found that
individuals with anxious personalities made less risky financial
investment decisions than non-anxious ones. Charpentier et al. (2017)
identified two potential reasons for findings such as those discussed
above. First, anxious individuals may be loss averse (aversion to
negative outcomes). Second, anxious individuals may be risk averse
(avoiding uncertainty even when only gains are involved). Their findings
provide clear-cut support for the second reason.

Sadness Sadness and anxiety are both negative emotional states. However,
sadness (which becomes depression when intense) is more strongly
associated with an absence of positive affect (Clark & Watson, 1991; see
later discussion, p. 755). As a result, sad individuals may be less
optimistic than other people. Lench and Darbor (2014) found the
perceived likelihood of risk from formaldehyde exposure was greater when
participants were in a sad rather than neutral mood. Waters (2008)
reviewed research concerning mood state and likelihood estimates of
health hazards and life events. Sad or depressed individuals had less
optimism bias than non-depressed ones.

Decision-making As discussed earlier, Raghunathan and Pham (1999) found
anxious individuals preferred a low-risk job to a high-risk one. In
contrast, sad individuals chose the high-risk job (see Figure 15.16).
According to Raghunathan and

746

KEY TERMS Misery-is-not-miserly effect The tendency for sad individuals
to be willing to pay more for some product than other people. Myopic
misery The notion that misery or sadness leads to an excessive focus on
replacing lost rewards.

Broadening horizons

Pham, sad individuals find the environment relatively unrewarding and so
are especially motivated to obtain rewards. Real-life risk taking was
studied by Langille et al. (2012). Depressed adolescents were much more
likely than non-depressed ones to engage in multiple sexual risk-taking
forms of behaviour. Perhaps depressed individuals feel they have "little
to lose". Drivers exhibited riskier driving behaviour after being put
into a sad mood state (Eherenfreund-Hager et al., 2017). Cryder et
al. (2008) found evidence for the misery-is-not-miserly effect -- sad
individuals paid more than others to obtain a given commodity. More
specifically, sad individuals (especially those high in self-focus) were
willing to pay almost four times as much those in a neutral mood for a
water bottle (see Figure 15.17). These findings suggest sadness
increases the motivation to acquire possessions to enhance the self
(especially when sad individuals focus their attention on the self).
Garg et al. (2018) conducted a meta-analysis and reported reliable
evidence for the misery-is-notmiserly effect. They also found suggestive
evidence the effect is partly due to the sense of helplessness
associated with sadness. Many people believe in the "sadder-but-wiser"
hypothesis -- sad individuals make wiser decisions. Lerner et al. (2013)
tested this hypothesis by assessing the extent to which individuals
prefer immediate rewards to larger (but later) ones. Participants in a
neutral mood required \$56 immediately to forego receiving \$85 in
3-months' time. However, those in a sad mood required only \$37
immediately. How can we explain the above findings? Lerner et al. (2013)
argued they indicated myopic misery -- sad individuals have a sense of
loss and so are impatient to obtain rewards to replace what has been
lost. Sad individuals were more likely than those in a neutral mood to
have impatient thoughts and to focus on what they might buy with the
money while deciding whether to prefer an immediate or a delayed reward.
In sum, depressed individuals experience a combination of high negative
affect and low positive affect (Clark & Watson, 1991). Depressed
individuals often engage in risky decision-making because their
motivation to enhance their low level of positive affect leads them to
seek immediate rewards.

\$3.00 High self-focus

Buying price

\$2.50

Figure 15.17 Mean buying price for a water bottle as a function of mood
(neutral vs sad) and self-focus (low vs high). From Cryder et
al. (2008).

Low self-focus

\$2.00 \$1.50 \$1.00 \$0.50 \$0 Neutral

Sadness

Emotion condition

Cognition and emotion

Anger Anger is typically regarded as a negative affect. However, it can
be experienced as relatively pleasant because it leads individuals to
believe they can control the situation and dominate those they dislike
(and perhaps also those they like) (Lerner & Tiedens, 2006).
Schadenfreude (experiencing pleasure at the misfortune of disliked
others) is increased by anger (Hareli & Weiner, 2002). How does anger
influence judgement? There are striking differences between the effects
of anger and other negative emotional states. Anger is associated with
relatively optimistic judgements about the likelihood of negative events
whereas anxiety and sadness are both associated with pessimistic
judgements (Waters, 2008). Angry individuals rate themselves as less at
risk of severe negative life events (e.g., divorce; work problems; heart
disease) than other people even though they are actually more likely to
experience these events (Lerner & Keltner, 2001). Why is anger
associated with optimistic judgements rather than the pessimistic ones
associated with other negative mood states? Anger differs from other
negative moods in being associated with a sense of certainty about what
has happened and with perceived control over the situation (Litvak et
al., 2010; discussed further later, pp. 751--752). These unique features
of anger (especially high perceived control) explain why anger produces
optimistic judgements. Anger often causes judgements to be made using
relatively shallow or heuristic processing. Ask and Granhag (2007) found
angry police investigators processed witness statements more
superficially than did sad ones.

Decision-making Since angry individuals perceive themselves to have high
control over situations, we might expect them to make risky decisions.
This prediction has received support. Lerner and Keltner (2001) used the
Asian disease problem on which most people exhibit risk-averse
decision-making (see Chapter 13). Fearful participants were risk-averse
but angry ones were risk-seeking. In a study by Gambetti and Giusberti
(2012) discussed earlier (p. 745), individuals with angry personalities
made riskier financial decisions (e.g., more likely to have invested
money in stocks and shares) than non-angry ones. Other research reveals
complexities in the effects of anger on decision-making. First, Kugler
et al. (2012) found angry participants on their own were much less
risk-averse than happy or fearful ones on a lottery task involving large
real-money payoffs. However, only 7% of angry participants chose the
risky option when the outcome depended on the other person's choice.
These angry participants did not want to lose control of the situation
by being reliant on someone else. Second, Ferrer et al. (2017) assessed
risky decision-making on a task where money could be earned by pumping
up balloons provided they did not burst. Angry male participants engaged
in riskier decision-making than sad or neutral participants, but angry
female participants did not exhibit risky behaviour. This gender
difference was also found when Ferrer et al.

747

748

Broadening horizons

conducted a meta-analysis of previous research. It may occur because
anger is more associated with perceived control in men than women. Anger
often impairs individuals' decision-making. In the words of Ralph Waldo
Emerson, it "blows out the light of reason". For example, consider
research on driving behaviour. As discussed earlier (p. 730), Zhang and
Chan (2016) found in a review that anger was associated with aggressive
and risky driving, and with driving errors. Techer et al. (2017)
discovered the high arousal and mind-wandering caused by anger partly
explained the negative effects of anger on driving performance. Why does
anger impair decision-making? It can lead to shallow processing based on
heuristics (rules of thumb) rather than systematic or analytic
processing (Litvak et al., 2010). For example, Coget et al. (2011) found
film directors mostly resorted to intuitive decision-making when
moderately or very angry, whereas moderate anxiety led to analytic
processing. If angry individuals engage in little analytic processing,
we would expect their decision-making to be unaffected if they performed
an additional task designed to prevent analytic processing at the same
time. That is precisely what Small and Lerner (2008) found.

Positive mood Campos et al. (2013) argued there are at least eight
different positive moods: awe, amusement, interest, pride, gratitude,
joy, love and contentment. Their approach was developed by Shiota et
al. (2017; see Figure 15.18). All positive emotions depend on a common
neural reward system including the mesolimbic pathway (linking the
ventral tegmental areas and nucleus accumbens)

Awe Nurturant love

Amusement Contentment

Sexual desire

From Shiota et al. (2017).

Cann abin oids Op io id s

Te sto ste ro ne S er oto nin

Enthusiasm

Figure 15.18 The positive emotion "family tree" with the trunk
representing the neural reward system and the branches representing nine
semi-distinct positive emotions.

n toci Oxy

Pride

Attachment love

Dopaminergic reward system

Gratitude

Liking/ pleasure

Cognition and emotion

and involving the neurotransmitter dopamine. As a result of evolution,
humans possess nine positive emotions that are elicited in different
situations and involve different combinations of neurotransmitters and
hormones. In spite of increasing evidence that we possess several
positive emotions, there is a puzzling difference between research on
negative and positive affect. Three different kinds of negative affect
(anxiety; sadness; anger) have been emphasised in research on judgement
and decision. However, until recently, the effects of only a single
broad category of positive affect on judgement and decision-making have
been explored. Much research on positive affect has focused on optimism
bias (individuals anticipate experiencing more positive and fewer
negative events than others). We would expect optimism bias to be
stronger among those in a positive mood than those in a negative or
neutral mood. Lench and Levine (2005) found individuals in a happy mood
had greater optimism bias than fearful participants. However, they were
no more optimistic than individuals in a neutral mood. Koellinger and
Treffers (2015) studied a related effect: overconfidence in one's
performance on a general knowledge quiz. Positive affect caused by
unexpectedly receiving a gift (bear-shaped jelly sweets) produced
overconfidence when participants were unlikely to attribute their
positive affect to the gift. In contrast, there was no overconfidence
when they were aware of the source of their positive feelings. Thus, one
reason why positive affect is often associated with optimistic
judgements is because it is regarded as providing positive feedback on
their performance.

Decision-making In a review, Blanchette and Richards (2010) concluded
positive mood states are typically associated with a risk-averse
approach to decision-making. For example, sex behaviour increasing the
risk of HIV for gay men is less common among those with high positive
affect (Mustanski, 2007) and individuals in a positive mood make less
risky decisions when betting on hypothetical horse races (Cahir &
Thomas, 2010). Decision-making can vary depending on the specific form
of positive affect. Eherenfreund-Hager and Taubman-Ben-Ari (2016)
compared the effects of relaxed positive affect (produced by thinking of
a calm and peaceful event) and aroused positive affect (produced by
thinking of a happy and exciting event). Only the former was associated
with a reduced willingness to drive recklessly. Thus, decision-making
may typically be risk-averse when individuals experience high positive
affect but not when positive affect involves excitement. Positive affect
is associated with increased use of heuristic or loweffort processing
and decreased use of analytic processing. Suppose you must choose
repeatedly between two gambles: (1) 50% chance of winning 1.20 euros and
50% chance of winning nothing; and (2) 50% chance of winning 1.00 euro
and 50% chance of winning nothing. Analytic thinking would lead you to
choose the first gamble on every trial. De Vries et al. (2012) found
happy participants were less likely than sad ones to use analytic
thinking. They were more likely to engage in heuristic processing (e.g.,
switching gambles if the previous one proved unsuccessful).

749

Figure 15.19 Probability of selecting a candy bar by participants in a
happy or sad mood as a function of implicit attitudes on the Implicit
Association Test (IAT) with higher scores indicating a preference for
candy bars. From Holland et al. (2012).

Broadening horizons

100 Probability of choosing candy (in %)

750

Happy mood 80

Sad mood

60 40 20 0 Apple

Candy Personalised IAT

Holland et al. (2012) assessed participants' explicit attitudes
(involving analytic processing) towards apples and candy bars and their
implicit attitudes (involving non-analytic or heuristic processing).
Then the participants were asked to choose between an apple and a candy
bar. For happy participants, their choice was predicted only by their
implicit attitudes (see Figure 15.19). For sad participants, in
contrast, their choice was predicted only by their explicit attitudes
(see Figure 15.19). Thus, decision-making (i.e., candy bar or apple?)
was based on heuristic processing for happy individuals but by analytic
thinking for sad ones. Griskevicius et al. (2010) studied the effects of
several positive mood states on the ability to assess the persuasiveness
of strong and weak arguments. Participants experiencing three positive
emotions (anticipatory enthusiasm; amusement; attachment love) exhibited
heuristic or shallow processing. However, for reasons that are unclear,
participants experiencing two other positive emotions (awe; nurturant
love) exhibited less heuristic processing than those in a neutral mood
state.

JUDGEMENT AND DECISION-MAKING: THEORETICAL APPROACHES We have now
discussed the effects of several mood states on judgement and
decision-making. Mood states differ in the pattern of effects (see
Figure 15.20). Of theoretical importance, the pattern varies across the
three negative mood states of anxiety, sadness and anger.

Figure 15.20 Effects of mood states on judgement and decision-making.

Cognition and emotion

How can we make sense of Figure 15.20? Anxiety occurs in threatening
situations involving uncertainty and unpredictability. Accordingly,
anxious individuals are motivated to reduce anxiety by increasing
certainty and predictability, which can be achieved by minimising risk
taking and choosing non-risky options. Individuals become sad or
depressed when they discover a desired goal is unattainable. Sadness or
depression leads individuals to abandon the unachievable goal and engage
in extensive thinking (i.e., analytic processing) to focus on new goals
(Andrews & Thomson, 2009). This helps us to understand why sadness is
the only mood state associated with analytic processing. Anger has the
function of overcoming some obstacles to an important goal by taking
direct and aggressive action. This approach is most likely to be found
when individuals feel they have personal control and are thus optimistic
the goal can be achieved (Lerner & Tiedens, 2006). This perception of
personal control also persuades angry individuals to take risks to
achieve their goals. An important function of positive mood states is to
maintain the current mood (Oatley & Johnson-Laird, 1987). This leads
happy individuals to engage in shallow or heuristic processing and to
avoid taking risks that might endanger their positive mood state.

Appraisal-tendency framework The appraisal-tendency framework (Lerner &
Keltner, 2000) is relevant to understanding how moods influence
judgement and decision-making. This framework (see Han et al., 2007)
extends the appraisal-theory approach discussed earlier (pp. 719--724).
It is assumed each emotion results from certain cognitive appraisals.
Emotions often alter cognitive processes to assist the individual to
respond appropriately to the situation triggering the emotion. Of
crucial importance, it is assumed theoretically the effects of any given
emotion on judgement and decision-making depend more on the appraisal
processes associated with it than on its valence (positive or negative
affect).

Findings The appraisal-tendency framework explains many findings
discussed earlier. Here are two examples. According to the framework,
emotions differ along the appraisal continuum of uncertainty-certainty
(i.e., the extent to which future events seem predictable). More
specifically, anger and positive affect (happiness) are associated with
high certainty whereas fear or anxiety and sadness are associated with
low certainty. Bagneux et al. (2013) used the Iowa Gambling Task (see
Glossary) on which decision-making is generally superior when
participants use intuitive rather than deliberative processing. They
predicted participants experiencing certainty-associated emotions would
use intuitive processing based on emotional cues from previous outcomes.
In contrast, those experiencing uncertainty-associated emotions would
use deliberative processing. As predicted, participants induced to feel
certainty (anger; happiness; disgust) made superior decisions to those
induced to feel uncertainty (fear; sadness). İyilikci and Amado (2018)
replicated these findings for disgust, fear and sadness.

751

752

Broadening horizons

According to the appraisal-tendency framework, anger differs from most
other mood states in being associated with high perceived control
leading to risk-taking behaviour. Beisswingert et al. (2015) exposed
participants to a situation involving loss of control which they
predicted would produce anger and lead to risk-taking behaviour. The
findings were as predicted. Of particular importance, the impact of the
situation on risk-taking behaviour depended on the extent to which it
caused anger.

Emotion-imbued choice model You are probably thinking the effects of
affect on judgement and decision-making are complex. If so, you are
right! Much of this complexity is included within Lerner et al.'s (2015)
emotion-imbued choice model (Figure 15.21). We start with the solid
lines. These indicate the major factors included in traditional models
of decision-making: decision-makers evaluate the available options by
considering the expected outcomes associated with each option.
Characteristics of the options (e.g., probabilities; time delays) and of
the decision-maker (e.g., risk aversion; personality) are also
considered as is the notion that expected emotions influence the
decision process (line A). The roles of emotion are shown by the green
dotted lines. Current emotions are influenced by: (1) characteristics of
the decision-maker (e.g., chronic anxiety; line B'); (2) characteristics
of the choice options (line C'); (3) predicted emotions (e.g., if you
expect to be made anxious you may experience anxiety now; line F); (4)
contemplating the decision (especially if the options are nearly equally
(un)attractive; line G'); and (5) incidental emotions (e.g., those
caused by the weather; line H). Current emotions directly influence the
evaluation of the outcomes (e.g., whether heuristic or analytic
processing is used; which motivational goals are active; line G). They
also indirectly influence decision-making by

Paths included in traditional rational choice models Paths not included
in traditional rational choice models

Characteristics of decision-maker e.g., preferences, personality

B'

C'

Characteristics of options e.g., likelihood or probability, time delay,
interpersonal outcomes

Current emotions i.e., emotions felt at time of decision

H

Figure 15.21 The emotion-imbued choice model (see text for details).
From Lerner et al. (2015).

Incidental inﬂuences e.g., mood, weather, carry-over eﬀects

G G'

A

B

C

Conscious and/or non-conscious evaluation

D

Decision

E

Expected outcomes (including expected emotions)

Cognition and emotion

changing the predicted emotional reactions to different potential
decision choices (line I). In sum, the emotion-imbued choice model
provides the most comprehensive account of the ways decision-making is
influenced by emotion. We can see earlier decision-making approaches
(e.g., von Neumann and Morgenstern's 1944 utility theory; see chapter
13) were more limited with reference to Figure 15.21. According to these
approaches, each option during decision-making is evaluated with respect
to the three factors shown by the solid lines A, B and C. What are the
limitations of the emotion-imbued choice model? First, it provides a
framework rather than a fully fledged theory or model. Second, it is
oversimplified. As Lerner et al. (2015, p. 814) admitted, "It assumes
that the decision-maker faces a one-time choice between given options,
without the possibility of seeking additional information or options."

ANXIETY, DEPRESSION AND COGNITIVE BIASES Most research discussed above
dealt with effects of mood manipulations on cognitive processing and
performance. We can also focus on cognitive processing in individuals
who are generally in a given mood state (e.g., patients with an anxiety
disorder or major depressive disorder). Alternatively, we can study
healthy individuals having anxious or depressive personalities. For
example, anxious individuals can be selected by using questionnaires
assessing trait anxiety (susceptibility to experiencing anxiety).
Implementing the above research strategies is complicated because
anxious individuals tend to be depressed and vice versa. Comorbidity is
the term indicating a patient has two or more mental disorders at the
same time. Comorbidity of anxiety and depressive disorders is found in
20% to 40% of patients (Huppert, 2008). In similar fashion, anxiety and
depression are moderated highly correlated in healthy individuals. In
spite of the overlap between anxiety and depression, there are important
differences between them. Later we consider three major theoretical
approaches focusing on such differences. Why is it important to study
cognitive processes in anxious and depressed individuals? Anxious and
depressed patients differ from healthy individuals in several ways
(e.g., cognitively; behaviourally; physiologically). Therapies differ in
terms of the symptoms that are the central focus in treatment. Within
this context, it is of major theoretical importance to establish the
role played by cognitive factors. Many theorists (e.g., Beck & Dozois,
2011) assume vulnerability to clinical anxiety and depressions partly
depends on cognitive factors. It is also often assumed that one goal of
cognitive therapy (and cognitivebehavioural therapy) should be to reduce
various cognitive biases. Here are four important cognitive biases: ●

Attentional bias: selective attention to emotionally negative stimuli
presented at the same time as neutral stimuli; this can involve rapid
attentional engagement with negative stimuli and/or slow attentional
disengagement.

753

KEY TERMS Trait anxiety A personality dimension based on individual
differences in susceptibility to anxiety. Comorbidity The state of
affairs when a patient has two (or more) mental disorders at the same
time. Attentional bias Selective allocation of attention to emotionally
negative stimuli when presented simultaneously with neutral stimuli.

754

Broadening horizons

KEY TERMS

●

Interpretive bias The tendency when presented with ambiguous stimuli or
situations to interpret them in a negative way. Explicit memory bias The
retrieval of relatively more negative information than positive or
neutral information on tests of explicit memory. Implicit memory bias
Relatively better memory performance for negative than for neutral or
positive information on tests of implicit memory.

●

●

Interpretive bias: the tendency to interpret ambiguous stimuli and sit-

uations in a negative fashion. Explicit memory bias: the tendency to
retrieve mostly negative or unpleasant rather than positive or neutral
information on memory tests involving conscious recollection. Implicit
memory bias: the tendency to exhibit superior performance for negative
than for positive or neutral information on memory tests not involving
conscious recollection.

An individual possessing all the above cognitive biases would attend
excessively to negative environmental events, would interpret most
ambiguous situations negatively, and so would perceive themselves as
having experienced numerous unpleasant events. As a consequence, it is
assumed they would be more likely than other people to develop an
anxiety disorder or depression. However, a key issue here is causality:
do cognitive biases trigger anxiety and depression; do anxiety and
depression enhance cognitive biases; or is causality bidirectional?

Theoretical approaches Below we discuss major theoretical approaches to
understanding the similarities (and differences) between anxiety and
depression. Note these approaches are not necessarily incompatible with
each other (see Eysenck & Fajkowska, 2018; Eysenck & Holmes, in press).

Functional approach Anxiety and depression both have adaptive functions
even though they often involve high short-term costs (Del Guidice &
Ellis, 2015). Depression is typically caused by goal loss (Oatley &
Johnson-Laird, 1987) and has the adaptive function of leading to
sustained thinking about disengaging from the lost goal and generating a
new one. Anxiety is typically caused by a threat to self-preservation
(Oatley & Johnson-Laird, 1987) and has the function of increasing
selective attention to potential environmental threats and rapid
detection of danger (Eysenck, 1992). The above functional approach
implies depression is mostly associated with a past orientation whereas
anxiety is mostly associated with a future orientation. Eysenck et
al. (2006) asked healthy individuals to identify personal events
strongly associated with anxiety or depression. Anxious events related
more to the future than the past. In contrast, depressive events were
much more associated with the past. Additional supportive evidence comes
from research on worry and rumination. Worry and rumination both involve
persistent, repetitive negative thoughts. However, they differ because
worry is typically triggered by "What if?" questions whereas rumination
is triggered by "Why?" questions (Papageorgiou, 2006). Unsurprisingly,
worry is associated with a greater future orientation than rumination
whereas rumination is associated with a greater past orientation
(Watkins et al., 2005). Of relevance to the functional approach,
rumination in the clinical literature is mostly considered in the
context of major depressive disorder

Cognition and emotion

(a mental disorder involving low mood and reduced interest in
pleasurable activities). In contrast, worry is the central symptom of
generalised anxiety disorder (pervasive anxiety across several life
domains). Williams et al. (1997) made several specific predictions based
on the functional approach. Before discussing these predictions, we must
consider their distinction between perceptual and conceptual processes.
Perceptual processes are stimulus-driven or bottom-up: they are often
fast and "automatic" and are used in basic attention and implicit
memory. In contrast, conceptual processes are top-down and are slower
and more controlled than perceptual ones. They are involved in explicit
memory and can also be involved in some attentional processes and
implicit memory. Since anxiety has the function of anticipating danger,
it should facilitate the perceptual processing of threat-related
stimuli. In contrast, depression has the function of replacing failed
goals. As a result, "the conceptual processing of internally generated
material related to failure or loss may be more relevant to this
function than perceptual vigilance" (Williams et al., 1997, p. 315). The
above assumptions generate several predictions: (1)

(2) 
(3) 
(4) 

Anxious individuals should have an attentional bias for threatening
stimuli when perceptual processes are involved. Depressed individuals
should have an attentional bias only when conceptual processing is
involved. Anxious and depressed individuals should have an interpretive
bias for ambiguous stimuli and situations. Depressed individuals should
have an explicit memory bias, but anxious ones should not. Anxious
individuals should have an implicit memory bias, but depressed ones
should not when only perceptual processes are involved.

Tripartite model Clark and Watson's (1991) tripartite model (developed
by Watson, 2009) identified major similarities and differences between
anxiety and depression. They resemble each other in that both are
strongly associated with distress and other negative emotional states.
They differ in two ways: (1) (2)

Positive emotionality (involving energy and pleasurable engagement) is
lacking in depression but not anxiety. Physiological hyperarousal is
present in anxiety but not depression.

It follows that anxious and depressed individuals should differ in their
processing of emotionally positive stimuli. Depressed (but not anxious)
individuals should have reduced responsiveness to such stimuli.

Attentional bias Various tasks assess attentional bias (Yiend et al.,
2013). First, there is the dot-probe task (see Figure 15.22). Two
stimuli are presented simultaneously

755

756

Broadening horizons

Figure 15.22 The dot-probe task. Participants initially focus the
central +, then view two stimuli varying in emotion and then respond
rapidly to a dot that replaces one of the stimuli. ©
ZoneCreative/iStock.

at different locations on a computer screen. In Figure 15.22, one
stimulus is emotionally positive (e.g. smiling face) and the other is
neutral. On critical trials, however, one stimulus is emotionally
negative (e.g., angry face) and the other neutral (e.g., expressionless
face). The participant's allocation of attention is assessed by
recording the speed of detection of a dot replacing one stimulus.
Attentional bias is indicated by shorter detection latencies when the
dot replaces the negative stimulus. Second, there is the emotional
Stroop task in which participants rapidly name the colour in which words
are printed (see Figure 15.23). Some words are emotionally negative
whereas others are neutral. Attentional bias is defined by participants
taking longer to name the colours of emotional than neutral words or
faces (but see below).

Findings Bar-Haim et al. (2007) carried out a metaanalysis of
attentional bias in anxious individuals. There was strong evidence of
attentional Figure 15.23 bias across all anxiety disorders and in high
The emotional Stroop task. Participants name the colours in
trait-anxious healthy individuals. which emotional or neutral words are
printed. Attentional We can distinguish two aspects of biased bias is
allegedly shown if participants take longer to name the attention: (1)
speed of attentional engagement colours of emotional words than those of
neutral words. with negative stimuli (attentional bias); and (2)
subsequent attentional disengagement from such stimuli. Anxious patients
have fast attentional engagement (dependent on a largely "automatic"
threat-detection mechanism) and slow disengagement (mostly due to poor
attentional control) (Cisler & Koster, 2010). The dot-probe and
emotional Stroop tasks provide only a snapshot of where attention is
directed. In contrast, eye-tracking provides a fairly direct and
continuous assessment of visual attention. Armstrong and Olatunji

Cognition and emotion

TABLE 15.1 EFFECTS OF ANXIETY AND DEPRESSION ON ATTENTIONAL BIAS
(ENGAGEMENT AND DISENGAGEMENT) Attentional bias (fast engagement) and
Attentional bias (slow disengagement) Emotionally negative stimuli
Anxiety

YES

YES

Depression

NO (?)

YES

Anxiety

NO

?

Depression

OPPOSITE BIAS

?

Emotionally positive stimuli

(2012) found in a review that anxious individuals had faster attentional
       engagement to (and slower disengagement from) negative stimuli.
       However, anxiety did not influence the time taken to fixate
       emotionally positive stimuli. The evidence relating to
       attentional bias in depression is less consistent. Kircanski and
       Gotlib (2015) reported in a review that patients with major
       depressive disorder did not show rapid engagement with negative
       stimuli but had slow disengagement. In a meta-analysis, Winer and
       Salem (2016) found significant avoidance of emotionally positive
       stimuli in depressed individuals. The tendency for attentional
       bias (fast engagement) to be stronger in anxious than depressed
       individuals is consistent with the functional approach and its
       assumption that anxious individuals focus on potential future
       threats (Eysenck & Fajkowska, 2018). The finding that depressed
       individuals (but not anxious ones) avoid emotionally positive
       stimuli is partly consistent with the tripartite model which
       assumes they have a very limited ability to exhibit positive
       emotion. However, that model does not explain why depressed
       individuals avoid (rather than ignore) positive stimuli.
       According to Winer and Salem (2016), depressed individuals
       actively inhibit rewarding stimuli. Finally, we turn to the
       effects of depression on engagement with emotionally negative
       stimuli. Most research has failed to obtain significant findings.
       However, Peckham et al. (2010) reported that depressed
       individuals showed attentional bias with depression-relevant
       stimuli but not when physically or socially threatening stimuli
       were used. These findings are consistent with the
       content-specific hypothesis (Beck, 1976; Beck & Dozois, 2011).
       According to this hypothesis depressed individuals have very
       negative beliefs about themselves, the world and the future, and
       attend to stimuli relevant to those beliefs.

Limitations What are the limitations of research in this area? First,
the two main paradigms (i.e., dot-probe; emotional Stroop) provided
limited information concerning the time course of attentional
processing. However, more detailed information is available from
eye-tracking studies. Second, most findings indicate an association
between anxiety or depression and attentional bias. Such findings cannot
clarify the causality issue. Later we discuss research showing that
changes in attentional

757

758

KEY TERM Generalised anxiety disorder A condition involving excessive
anxiety and worry across many areas of everyday life.

Broadening horizons

bias can produce changes in anxiety. Other research shows that changes
in anxiety can produce changes in attentional bias. Van Bockstaele et
al. (2014, p. 682) concluded their review as follows: "The relation
between attentional bias and fear and anxiety is best described as a
bidirectional, maintaining or mutually reinforcing relation."

Interpretive bias We often encounter ambiguous situations. For example,
suppose someone walks past you without acknowledging your presence.
Perhaps they simply failed to notice you or perhaps they actively
dislike you. Individuals who generally interpret ambiguous situations in
a negative way have an interpretive bias. Anxious individuals have an
interpretive bias. Eysenck et al. (1987) asked participants varying in
trait anxiety to write down the spellings of auditorily presented words.
Some were homophones (two words with the same pronunciation but
different spellings (e.g., die, dye; pain, pane). Trait anxiety
correlated +.60 with the number of negative or threatening homophone
interpretations. Individuals high in trait anxiety do not have an
interpretive bias for all potentially threatening situations. High trait
anxiety is associated with an interpretive bias for ambiguous situations
potentially involving social or intellectual threat but not those
involving physical or health threat (Walsh et al., 2015). Thus,
interpretive bias in high-anxious individuals is limited to
interpersonal threats (i.e., negative reactions of others to one's
behaviour). Eysenck et al. (1991) studied patients with generalised
anxiety disorder (see Glossary) who heard ambiguous sentences such as
the following: (1) (2) (3)

At the refugee camp, the weak/week would soon be finished. The doctor
examined little Emma's growth. They discussed the priest's convictions.

Generalised anxiety disorder patients were more likely than healthy
controls to interpret such sentences in a negative or threatening way.
Thus, they exhibited interpretive bias. Everaert et al. (2017b) obtained
two main findings in a meta-analytic review of interpretive bias in
depression. First, there was a moderately strong relationship between
depression and interpretive bias for both patients with clinical
depression and depressed healthy individuals. Second, this relationship
was stronger with self-referential material (i.e., making reference to
the individual's character and/or experience) than with material that
was not self-referential. Does interpretive bias depend mostly on rapid,
"automatic" processes or on slower, strategic ones? Both processes are
involved (Mathews, 2012). Evidence for strategic processes was reported
by Calvo and Castillo (1997). High-anxious individuals had an
interpretive bias for ambiguous sentences 1,250 ms after the sentence
but not at 500 ms. Evidence interpretive bias can occur fairly rapidly
was reported by Moser et al. (2012). Participants satisfying the
criteria for social anxiety disorder (excessive fear of social
situations) or major depressive disorder

Cognition and emotion

(see Glossary) showed more evidence than healthy controls of the
development of interpretive bias within approximately 400 ms.

Memory biases Why is it important to study memory biases in anxious and
depressed individuals? Such biases may well maintain negative mood
states via conscious processes (explicit memory bias) or relatively
automatic processes (implicit memory bias). We start with explicit
memory bias. There is convincing evidence for an explicit memory bias
associated with depression (Blaney, 1986). This memory bias was also
found when research on autobiographical memory was reviewed (Holland &
Kensinger, 2010). A positive memory bias (i.e., enhanced memory for
positive versus neutral material) is sometimes absent in depressed
individuals (Foland-Ross and Gotlib, 2012). This finding is consistent
with the tripartite model's assumption that depressed individuals have a
limited ability to exhibit positive emotions. Several studies have
focused on implicit memory bias in depression. Phillips et al. (2010)
reported a small (but significant) relationship between depression and
implicit memory bias in a meta-analysis. Williams et al. (1997) argued
this would not be found when perceptual processes were involved.
However, Phillips et al. found evidence for an implicit memory bias
associated with depression even when perceptual processing occurred at
encoding or learning and retrieval. What are the effects of anxiety on
memory biases? Herrera et al. (2017) addressed this issue in a
meta-analytic review. They obtained three main findings. First, there
was an explicit memory bias in anxiety for free recall (see Glossary)
but not cued recall (see Glossary) or recognition memory. More extensive
retrieval processes are required for free recall than for cued recall or
recognition, providing more scope for the involvement of emotion.
Second, there was no implicit memory bias associated with anxiety, which
is directly contrary to the prediction of Williams et al. (1997). In
sum, the effects of depression and anxiety on memory biases differ;
indeed, there are greater differences between depressed and anxious
individuals with respect to memory biases than attentional or
interpretive biases. Explicit memory bias is typically stronger and
found across a wider range of memory tests in depressed individuals.
Implicit memory bias is generally found in depressed individuals but is
absent in anxious ones. These findings are consistent with the notion
that depression is more associated than anxiety with an orientation
towards the past (Eysenck et al., 2006) and are partially consistent
with the theoretical approach of Williams et al. (1997).

Combined cognitive biases hypothesis Most theorists have treated the
various cognitive biases as if they were entirely separate from each
other. Hirsch et al. (2006) challenged this approach. According to their
combined cognitive biases hypothesis, cognitive biases often interact
with each other. Suppose an anxious person attends selectively to the
threatening aspects of a situation. This might lead

759

760

Broadening horizons

to a threatening interpretation of that situation, and to a memory bias
in which negative information is more accessible than positive
information. There is reasonable support for the above hypothesis.
Consider a study by Amir et al. (2010) with socially anxious
participants. Training to reduce interpretive bias made it easier for
participants to disengage attention from threat. These findings suggest
attentional and interpretive biases reflect (at least in part) the
operation of shared mechanisms. Everaert et al. (2014) conducted a study
in which depressed and non-depressed participants received a scrambled
sentences task (e.g., "am winner born loser a I") and constructed
sentences using all the words bar one. Subsequently, the participants
recalled their previously constructed sentences. Everaert et
al. assessed attentional, interpretive and explicit memory biases. The
memory bias associated with depression was mediated by attentional and
interpretive biases.

Cognitive or attentional control Anxious and depressed individuals may
have the various cognitive biases discussed above primarily because they
are sensitive to emotionally negative or threatening information.
However, more general processes also play a part. For example, suppose
anxious and depressed individuals have deficient cognitive or
attentional control. As a consequence, they might have increased
attentional bias because they find it hard to disengage from negative
stimuli and increased interpretive bias because they cannot easily
suppress threatening interpretations. Booth et al. (2017) reported
findings consistent with the notions above. They assessed attentional
and interpretive biases in individuals differing in trait anxiety. In
one condition, these biases were assessed while participants performed a
secondary task restricting their ability to exercise cognitive control.
The relationship between anxiety and both cognitive biases was stronger
when participants had limited use of cognitive control. Two key
cognitive control processes are inhibition and shifting (see Chapter 6).
Inhibition involves overriding dominant responses and resisting
distraction, whereas shifting involves switching flexibly between tasks.
Joormann et al. (2007) proposed a theory based on the assumption
depressed individuals have impaired cognitive control. As you can see in
Figure 15.24, the theory predicts this impaired cognitive control causes
problems in disengaging attention from negative information. Depressed
individuals are likely to elaborate on this information while attending
to it. This can lead to enhanced memory for such information (i.e., a
memory bias). Joormann & Tanovic (2015) reviewed research on depression
and cognitive control. There was clear evidence depression is associated
with difficulties in both inhibition and shifting. For example, Zetsche
and Joormann (2012) found deficient inhibitory control was associated
with a greater number of depressive symptoms and predicted the
maintenance of depressive symptoms over the following six months.
Joormann and Tanovic also discussed research suggesting the deficient
inhibitory control of depressed individuals is associated with their
cognitive biases. Impaired cognitive control is also relevant to
understanding the effects of anxiety on cognitive processing and biases.
According to attentional

Cognition and emotion

761

control theory (Eysenck et al., 2007), anxiety reduces the available
capacity of working memory. This impairs the efficiency of attentional
or cognitive control (which depends on working memory) in two ways.
First, it impairs inhibitory control including the ability to avoid
processing task-irrelevant stimuli. Second, it impairs the ability to
shift attention or cognitive control optimally within and between tasks.
Eysenck and Derakshan (2011) reviewed research findings showing that
high trait anxiety is associated with inefficient inhibitory control and
shifting. Derryberry and Reed (2002) found attentional or cognitive
control was important in determining attention bias. Attentional bias
was weaker in high-anxious individuals with high attentional control
than those with low attentional control. Taylor et al. (2016) found
individuals high in social anxiety showed slow disengagement from social
threat stimuli only if low in the shifting form of attentional control.
Figure 15.24 Finally, we consider why anxious and According to the
impaired cognitive control account put depressed individuals spend much
of their forward by Joormann et al. (2007), depression is associated
time engaged in worry and/or rumination. In with cognitive control
impairments that lead to impaired essence, their deficient cognitive and
atten- attentional disengagement, elaborative processing and tional
control makes it harder for them than memory biases. for other people to
disengage from their nega- From Everaert et al. (2012). With permission
from Elsevier. tive internal thoughts. In sum, one reason why
high-anxious and depressed individuals have cognitive biases is because
they have deficient cognitive or attentional control. Shortly we will
discuss therapy for anxiety and depression based on the attempt to
enhance cognitive control. The success of such therapy suggests
deficient cognitive control maintains cognitive biases and high levels
of anxiety and depression.

COGNITIVE BIAS MODIFICATION AND BEYOND We have seen anxiety and
depression are both associated with various cognitive biases. The
direction of causality is crucial -- do cognitive biases make
individuals vulnerable to developing anxiety or depression or does being
anxious or depressed lead to the development of cognitive biases? An
appropriate method for addressing this issue is cognitive bias
modification: "methods designed to modify cognitive factors that
maintain psychiatric conditions such as anxiety and depression" (Lau,
2015, p. 735). Cognitive bias modification is a form of cognitive
behavioural therapy, which involves using psychological methods to
change unhelpful distorted or biased cognitions and behaviour. Thus,
cognitive behavioural therapy encompasses numerous techniques in
addition to those associated with cognitive bias modification.

KEY TERM Cognitive bias modiﬁcation Training typically designed to
reduce attentional bias and/ or interpretive bias in anxious or
depressed individuals.

762

Broadening horizons

IN THE REAL WORLD: REDUCING ANXIETY AND DEPRESSION If cognitive biases
increase individuals' vulnerability to anxiety and depression, then
cognitive bias modification might be effective in reducing those
negative emotional states. Cognitive bias modification typically
involves attempts to reduce attentional bias and/or interpretive bias. A
common form of training to reduce attentional bias involves the
dot-probe task (discussed earlier, pp. 755--756). The task is altered so
the dot always appears where the neutral stimulus had been presented,
leading participants to learn to avoid attending to the threat-related
stimulus. Training to reduce interpretive bias often involves presenting
ambiguous sentences that can be interpreted negatively or positively
(e.g., "When some of your colleagues unexpectedly see you, their
reaction is one of . . ."). Each sentence is followed by a word fragment
to be completed by the participant. The word fragment is selected to
produce a positive sentence completion (e.g., pl \_ \_ sure producing
pleasure). How effective is cognitive bias modification? Liu et
al. (2017) carried out a meta-analysis on the use of cognitive bias
modification to treat social anxiety disorder. Treatment reduced
attentional bias and interpretive bias (especially interpretive bias).
Both forms of bias modification produced modest reductions in anxiety,
with interpretive bias modification being more effective. Cristea et
al. (2015) conducted a meta-analysis to assess the effects of cognitive
bias modification on individuals high in anxiety or depression.
Treatment reduced both anxiety and depression. However, the effects were
typically fairly modest. Why were the findings so modest? Grafton et
al. (2017) pointed out that Cristea et al. (2015) failed to
differentiate between studies where attentional and/or interpretive bias
were successfully reduced and those where these biases were not
significantly reduced. Since the crucial theoretical assumption is that
beneficial effects of cognitive bias modification on anxiety and
depression are mediated by reducing cognitive biases, there should be no
beneficial effects when such biases are not reduced. Grafton et
al. re-analysed Cristea et al.'s data. There were moderately strong
reductions in anxiety and depression in every study in which cognitive
biases were successfully reduced but no reductions when they were not
reduced. Jones and Sharpe (2017) provided the most comprehensive account
of the effectiveness of cognitive bias modification based on 12
meta-analyses. Cognitive bias modification was generally reasonably
effective in the treatment of anxiety. However, its beneficial effects
were weaker in the treatment of depression. How can we enhance cognitive
bias modification? Lee et al. (2015) argued that the standard approach
to reducing interpretive bias is limited because it only requires
participants to provide positive interpretations of ambiguous sentences.
Accordingly, they extended this approach by requiring some participants
to imagine a future positive event related to their interpretation of
each ambiguous sentence. This extended approach was more effective than
the standard one perhaps because it made clearer the relevance of
positive interpretations of ambiguous events for the future.

Cognitive control We saw earlier that anxious and depressed individuals
have impaired attentional or cognitive control and that this impaired
control partially explains their various cognitive biases. A plausible
inference from these findings is that therapy designed to enhance
cognitive control might prove effective in treating anxious and
depressed patients. Cognitive bias modification of attentional bias may
depend on improved top-down attentional control or more specific
processes (e.g., reduced

Cognition and emotion

sensitivity to threat-related stimuli). Booth et al. (2014) obtained
evidence that attentional control is important -- cognitive bias
modification of attentional bias in anxious individuals was ineffective
when the conditions reduced participants' ability to use attentional
control. Sari et al. (2016) provided training designed to enhance
attentional control. Individuals exhibiting the largest gains in
attentional control tended to show the greatest reductions in trait
anxiety. Koster et al. (2017) carried out a meta-analytic review of
research on cognitive control interventions in the treatment of
depression. They concluded that "Most CCT \[cognitive control training\]
studies have yielded promising effects in MDD \[major depressive
disorder\] samples in terms of reducing cognitive vulnerability for
depression" (p. 86). We need to achieve a greater understanding of how
cognitive control and cognitive biases interact to determine an
individual's level of anxiety or depression. Everaert et al. (2017a)
addressed this issue by obtaining measures of cognitive control (e.g.,
inhibition; shifting), attentional and interpretive biases and
depressive symptoms. They obtained three main findings: (1) (2) (3)

There were no direct effects of deficient cognitive control on
depressive symptoms. Deficient cognitive control influenced depressive
symptoms indirectly through its effects on attentional bias. Deficient
inhibitory control influenced interpretive bias which was in turn
associated with depressive symptoms.

Evaluation What are the strengths of research in this area? First,
studies of cognitive bias modification have shown treatment effective in
reducing attentional and interpretive biases generally leads to
reductions in anxiety and depression (especially anxiety). Thus, an
important reason why many individuals have high levels of anxiety and
depression is because they have attentional and interpretive biases.
Second, other forms of treatment for anxiety and depression (e.g.,
cognitive-behavioural therapy) involve several components. As a
consequence, it is often unclear why a given form of treatment reduces
clinical symptoms. In contrast, cognitive bias modification techniques
are very focused, making it easier to identify the underlying
mechanisms. What are the limitations of cognitive bias modification
techniques? First, the effects of these techniques on cognitive biases
and on levels of anxiety and depression are somewhat variable. A major
factor here is the rapid increase of studies in which modification
techniques were presented online via the internet under poorly
supervised and controlled conditions. MacLeod and Clarke (2015) found
attentional bias was successfully reduced in only 11% of online studies
compared to 74% of studies conducted in laboratory conditions. Second,
cognitive biases in anxiety and depression depend on general, top-down
control processes as well as on processes specific to processing
emotionally loaded information. There is suggestive evidence that
therapy

763

764

Broadening horizons

designed to reduce these biases influences both general and specific
processes. However, the relative importance of these two types of
processes and how they interact remain unclear. Third, the assessment of
symptomatology following cognitive bias modification typically focuses
only on self-report measures. Future studies should use additional
measures (e.g., physiological; behavioural) to identify the full range
of changes produced.

CHAPTER SUMMARY •

Introduction. Moods typically last longer than emotions but are less
intense. The brain mechanisms underlying emotions consist of large-scale
networks not specific to any given emotion. Emotional experience is
determined by complex interactions between bottom-up and top-down
processes.

•

Appraisal theories. Appraisal theories assume emotional experience is
mostly determined by cognitive appraisals of the current situation. They
also assume cognitive appraisal can involve automatic processes as well
as more controlled ones. Limitations of appraisal theories include: (1)
the unwarranted assumption that situational appraisal is always crucial
in determining emotional experience; (2) the de-emphasis of social
factors in influencing our emotional reactions; and (3) the assumption
there is a clear-cut distinction between cognition and emotion.

•

Emotion regulation. Emotion regulation involves individuals overriding
their initial emotional responses. Key emotionregulation strategies are
attention deployment, cognitive change (e.g., reappraisal) and response
modulation. Cognitive change is generally the most effective strategy
for reducing negative affect and response modulation the least
effective, but strategy effectiveness depends on the precise situation.
Many successful strategies are associated with prefrontal activation
leading to reduced amygdala activation. Effortful emotion-regulation
strategies are most effective early in processing of negative emotional
situations, whereas timing matters less for relatively undemanding
strategies. Emotionregulation strategies can involve explicit and/or
implicit processes.

•

Affect and cognition: attention and memory. Negative affect often
produces attentional narrowing whereas positive affect produces
attentional broadening. However, emotional states (positive or negative)
involving high motivational intensity are associated with attentional
narrowing, whereas those involving low motivational intensity are
associated with attentional broadening. In addition, positive affect
often causes individuals to maintain

Cognition and emotion

their current attentional strategy whereas negative affect causes them
to change their attentional strategy. Mood states influence memory
through mood congruity and mood-state-dependent memory; these effects
are stronger with positive mood states. Two brain networks (one mostly
involved in memory and the other in attention and cognitive control)
influence the memory-enhancing effects of mood or emotion. The amygdala
is of importance within both networks. •

Affect and cognition: judgement and decision-making. According to the
dual-process model, deontological judgements with moral dilemmas are
based on rapid affective processing, whereas utilitarian ones are based
on slower, cognitive processing. This model is oversimplified as is
demonstrated by a model focusing on consequences, moral norms and
preference for inaction vs action. Anxiety, sadness, anger and positive
affect all have different patterns of effects on judgement and
decision-making. Many effects can be explained by assuming anxiety
increases the need to reduce uncertainty, sadness increases the need to
rethink priorities, anger creates a sense of personal control, and
positive affect creates a desire to maintain the current mood state. The
emotionimbued choice model provides a comprehensive account of the main
factors (e.g., current emotion; characteristics of the decision-maker;
nature of the task) influencing judgement and decision-making.

•

Anxiety, depression and cognitive biases. Anxiety and depression are
associated with various cognitive biases such as: attentional bias;
interpretive bias; explicit memory bias; and implicit memory bias.
Changes in one cognitive bias often produce changes in other cognitive
biases. Attentional bias tends to be somewhat stronger in anxiety than
depression, whereas the opposite is the case with memory biases. These
differences are understandable given that anxiety has the function of
anticipating future threat whereas depression replaces failed goals with
new ones. Anxious and depressed individuals have deficient cognitive
control (e.g., inhibition; shifting) and this deficient control plays a
role in the maintenance of their cognitive biases.

•

Cognitive bias modification. When cognitive bias modification techniques
decrease attentional and/or interpretive bias, they are typically
successful in reducing anxiety and depression (especially anxiety).
These techniques are very focused which makes it easier to identify the
underlying mechanisms. More research is required to establish the extent
to which the successful use of cognitive bias modification techniques
depends on enhancing cognitive or attentional control.

765

766

Broadening horizons

FURTHER READING Brownstein, L.M., Gross, J.J. & Ochsner, K.N. (2017).
Explicit and implicit emotion regulation: A multi-level framework.
Social Cognitive and Affective Neuroscience, 12, 1545--1557. The authors
provide a theoretical framework for categorising and understanding
emotion regulation strategies based on implicit--explicit and
automatic--controlled dimensions. Dolcos, F., Katsumi, Y., Weymar, M.,
Moore, M., Tsukiura, T. & Dolcos, S. (2017). Emerging directions in
emotional episodic memory. Frontiers in Psychology, 8 (Article 1867).
This review article discusses thoroughly the neural mechanisms
associated with the enhancing effects of emotion on memory. Eysenck,
M.W. & Holmes, A. (in press). Anxiety, depression and cognitive
dysfunction. In P. Corr (ed.), The Cambridge Handbook of Personality
Psychology (2nd edn). Cambridge: Cambridge University Press. Michael
Eysenck and Mandy Holmes discuss the cognitive biases associated with
anxiety and depression and the use of cognitive bias modification
techniques to reduce these biases. Kuckertz, J.M. & Amir, N. (2017).
Cognitive bias modification. In S. Hofmann and G. Asmundson (eds), The
Science of Cognitive Behavioural Therapy (pp. 463--491). London:
Academic Press. Jennie Kuckertz and Nader Amir discuss the theoretical
foundations of cognitive bias modification and review its effectiveness.
Lerner, J.S., Valdesolo, P. & Kassam, K.S. (2015). Emotion and
decision-making. Annual Review of Psychology, 66, 799--823. Jennifer
Lerner and her colleagues discuss their model of the effects of emotion
on decision-making. This model provides the most comprehensive account
in this area. Scherer, K.R. & Moors, A. (2019). The emotion process:
Event appraisal and component differentiation. Annual Review of
Psychology, 70, 719--745. Klaus Scherer and Agnes Moors discuss the role
played by appraisal in emotion. Smith, R. & Lane, R.D. (2015). The
neural basis of one's own conscious and unconscious emotional states.
Neuroscience and Biobehavioral Reviews, 57, 1--29. An integrative model
of emotion focusing on interactions among several appraisal mechanisms
and bodily states is presented in this article. This model combines
insights from several previous appraisal and other theories.

Chapter

Consciousness

INTRODUCTION What exactly is "consciousness"? There is an important
distinction between conscious content and conscious level (Bor & Seth,
2012). Conscious content refers to the information of which we are
currently aware. Consciousness in this sense is "characterised by the
experience of perceptions, thoughts, feelings, awareness of the external
world, and often in humans . . . self-awareness" (Colman, 2009, p. 164).
This definition is limited because it leads us to ponder the exact
meanings of the words "experience" and "self-awareness". In contrast,
conscious level refers to the state of consciousness. It runs from the
total unconsciousness of coma through to alert wakefulness. These two
aspects of consciousness are related -- a non-zero conscious level is
required for individuals to experience conscious content or awareness.
The notion of levels implies that different states of consciousness lie
along a single dimension. Thus, for example, patients with disorders of
consciousness were traditionally categorised as having different levels
of consciousness solely on the basis of behavioural measures (e.g.,
wakefulness; capacity for intentional behaviour). However, some patients
exhibit consciousness via their patterns of brain activity in spite of
displaying no behavioural evidence of consciousness (Bayne et al.,
2017). The above considerations indicate that states of consciousness
differ from each other in several dimensions. For example, Bayne et
al. (2016) identified two separate dimensions: (1) the range of contents
of consciousness; and (2) functions of consciousness (e.g., attentional
control; action selection). Thus, we need a multidimensional approach to
understanding consciousness rather than a uni-dimensional one based on
levels of consciousness. In this chapter, we focus mostly on
consciousness in the former sense of conscious awareness. For example,
Block (e.g., 2012) distinguished between two forms of consciousness:

16

768

KEY TERMS Access consciousness A form of consciousness where its
contents are available for use by processes such as attention and
memory; information within access consciousness can be communicated to
others; phenomenal consciousness. Phenomenal consciousness Direct
conscious experience; see access consciousness.

Broadening horizons

(1) 
(2) 

Access consciousness can be reported and its contents are available for
use by other cognitive processes (e.g., attention; memory). It "refers
to the functions that can be associated with consciousness" (Fazekas &
Overgaard, 2018, p. 1). Phenomenal consciousness is our raw, private
experience; it "refers to the experiential characteristics of
consciousness" (Fazekas & Overgaard, 2018, p. 1).

Most people believe their immediate conscious experience (phenomenal
consciousness) is much richer than the information about that experience
we can communicate to others (access consciousness). There is scepticism
regarding the above distinction. As Naccache (2018) pointed out, we only
know about someone else's phenomenal consciousness from their
self-reports (e.g., "I can see the view very clearly"). However, that is
very similar to the case with access consciousness (e.g., "I can see two
cows in that field"), which suggests the distinction is less important
than often assumed. Another problem with phenomenal consciousness is
that it is very hard to assess the accuracy (or otherwise) of its
alleged contents. Baumeister and Masicampo (2010) proposed a different
distinction. First, there is phenomenal consciousness, which "describes
feelings, sensations, and orienting to the present moment" (p. 945). It
is a basic form of consciousness. Second, there is a higher form of
consciousness (conscious thought). It "involves the ability to reason,
to reflect on one's experiences, and have a sense of self" (p. 945).
Pinker (1997) provided an example of this form of consciousness: "I
cannot only feel pain and see red, but think to myself, 'Hey, here I am,
Steve Pinker, feeling pain and seeing red!'" Much progress has been by
cognitive neuroscientists with respect to several issues relating to
consciousness. These include our ability to: discriminate and categorise
stimuli; integrate information; access our own internal states; and
control our own behaviour. However, we still do not understand why "some
neural mechanisms, but not others, should be associated with
consciousness" (Tononi et al., 2016, p. 450). This is what Chalmers
(2007) called the "hard problem" of consciousness.

FUNCTIONS OF CONSCIOUSNESS What are the main functions of consciousness?
Below are listed some of its proposed functions (although there is
fierce ongoing controversy concerning some of them): (1) (2) (3) (4)

It is associated with perceiving the environment. It plays a key role in
social communication and understanding what others are thinking. It
plays a role in controlling our actions. It allows us to think about
events and issues far removed from the present. People's conscious
thoughts wander away from their current activity (thus displaying
"stimulus independence" between 25% and 50% of the time (Konishi &
Smallwood, 2016). Such mind-wandering is very useful when planning for
the future.

Consciousness

(5) 

Tononi et al. (2016) argued that consciousness is remarkably
informative, and this has great functional value. In their own words,
Conscious brains may have evolved \[because\] the world is immensely
complex . . . and organisms with brains that can incorporate statistical
regularities that reflect the causal structure of the environment into
their own causal structure have an adaptive advantage for prediction and
control. (p. 458)

(6) 

It is important with respect to bodily self-consciousness, which is "the
experience of being the subject of a given experience" (Blanke et al.,
2015, p. 145).

If we want to understand the functions of consciousness, it is relevant
to consider the controversy concerning the functions and usefulness of
unconscious processes. It has often been argued that unconscious
processes are inflexible and of limited value (see Chapter 5). In
contrast, Sigmund Freud famously emphasised its massive power. In this
book, we have seen many processes can occur without conscious awareness:
perceptual processes (Chapter 2); learning (Chapter 6); memory (Chapter
7); and, possibly, decision-making (Chapter 13). Hassin (2013, p. 195)
provocatively proposed the "Yes It Can" principle: "Unconscious
processes can carry out every fundamental high-level \[cognitive\]
function that conscious processes can perform." Hassin focused on
evidence that goal pursuit, cognitive control and reasoning can all
occur below the conscious level. If his "Yes It Can" principle is
correct, this would devalue the importance of consciousness. Marien et
al. (2012) obtained support for the "Yes It Can" principle. Participants
performed a proofreading task and the unconscious goal of socialisation
was induced in some of them by presenting socialisationrelevant words
(e.g., partying; celebrating) subliminally (below the level of conscious
awareness). This unconscious socialisation goal impaired proofreading
performance in participants for whom socialisation was an important goal
(see Figure 16.1). Related effects of subliminally presented stimuli on
behaviour have often been found, especially when important goals are
activated (see Weingarten et al., 2016, for a meta-analytic review).
There are two issues with Hassin's (2013) principle. First, he did not
consider problems with establishing that findings supporting his
principle depended solely on the use of unconscious processes. Second,
he ignored numerous findings apparently inconsistent with his principle
(Hesselmann & Moors, 2015). In sum, cognitive functions involving
unconscious processes are probably much more limited in scope than those
involving conscious ones. Consciousness sometimes provides misleading
interpretations or rationalisations of events after they have happened
(Nisbett & Wilson, 1977). Adriaanse et al. (2016) obtained relevant
evidence in a study using participants low or high in emotional eating
(i.e., the tendency to overeat in response to negative emotions). After
they were told they had overeaten, only those high in emotional eating
incorrectly claimed their mood state

769

KEY TERM Bodily self-consciousness A form of selfconsciousness involving
body-centred perception (e.g., of the face, hand or trunk) based on
integration of bodily signals from several different sense modalities.

770

Broadening horizons

Figure 16.1 Mean scores for error detection on a proofreading task as a
function of whether the goal of socialisation had been induced
unconsciously (unconscious goal vs no-goal control) and the importance
of the goal of socialisation to the participants (low vs high goal
importance). Scores closer to zero indicate better error-detection
performance. From Marien et al. (2012). © American Psychological
Association.

was negative before eating. Thus, their conscious belief they had eaten
too much because they were sad was a mistaken explanation for
overeating. We turn now to a consideration of two major functions of
consciousness. Social communication is discussed first, followed by
controlling action.

Social communication A crucial function of consciousness is to
facilitate social communication. Humans have lived in social groups for
tens of thousands of years and so have needed to predict, understand and
manipulate others' behaviour. This is much easier to do if you can
imagine yourself in their position. Graziano and Kastner (2011, p. 98)
proposed a theory along those lines: "The machinery that computes
information about other people's awareness is the same machinery that
computers information about our own awareness" (p. 98). Within this
theory, "Awareness . . . is one's social intelligence perceiving one's
focus of attention" (p. 98). Key aspects of this theory are shown in
Figure 16.2. Abel forms a model of Bill's mental state ("Bill is aware
of the cup") using neuronal machinery specialised for social perception.
This machinery is also used for self-awareness. Awareness may originally
have been developed to understand others with humans only later
developing self-awareness.

Consciousness

771

KEY TERMS Out-of-body experiences Vivid feelings of being outside of
(and detached from) one's own body. Free will The notion that we freely
or voluntarily choose what to do from various options.

Figure 16.2 Awareness as a social perceptual model of attention. Abel
observes Bill and constructs a model of Bill's mental state using
mechanisms specialised for social perception. This model includes the
notion that Bill is aware of the cup. The mechanisms of social
perception used to perceive awareness in other people may be used to
perceive awareness in ourselves. From Graziano & Kastner (2011).

Graziano and Catmur (2011) argued this neural machinery (involving the
ability to switch perspectives) depends crucially on the temporoparietal
junction (meeting of the temporal and parietal lobes). In support,
attributing states of awareness to other people is associated with
activation in the temporo-parietal junction (Graziano, 2016). In
addition, transcranial magnetic stimulation (TMS; see Glossary) applied
to this area to inhibit its functioning impairs the ability to switch
between representations of the self and another person (Sowden & Catmur,
2015). If perceiving someone else's awareness and self-awareness depend
on the same neuronal mechanisms, we might sometimes be confused as to
the source of our awareness. This is, indeed, the case with out-of-body
experiences, which are "sensations in which a person's consciousness
seems to become detached from the body and take up a remote viewing
position" (Blanke et al., 2002, p. 269). Bos et al. (2016) discussed the
case of a female patient undergoing brain surgery. Electrical
stimulation of part of the temporo-parietal junction caused her to feel
"as if she was floating just below the ceiling and saw her own body
lying on the operating table" (p. 10). Finally, Baumeister et al. (2011,
p. 74) identified another social function of conscious thoughts: "Many
investigators operationally define conscious thought as those thoughts
the person can report to others . . . the purpose of conscious thought
is precisely for enabling people to tell their thoughts to one another."
Thus, much of conscious thinking is for talking.

Controlling our actions? Numerous times every day we think of doing
something followed by actually doing it. For example, "I will get myself
a coffee" is followed by me finding myself in a café drinking coffee.
Such experiences suggest we have free will: "the ability to make choices
and to determine one's own outcomes

772

Broadening horizons

free from constraints" (Aarts & van den Bos, 2011, p. 532). As
Baumeister et al. (2018, p. 2) argued, "It seems wildly implausible that
human conscious thought evolved purely as a side effect, with no
adaptive benefits depending on its ability to guide behaviour." Over the
centuries, philosophers have debated whether humans possess free will
without resolving the issue. Many (probably most) psychologists are
sceptical about free will. For example, Wegner (2003) claimed we have
only the illusion of free will. Our actions are actually caused by
unconscious processes, but we mistakenly infer our actions are
determined by our conscious intentions. He argued this illusion depends
on the principles of priority, consistency and exclusivity: When a
thought appears in consciousness just before an action (priority), is
consistent with the action (consistency), and is not accompanied by
conspicuous alternative causes of the action (exclusivity), we
experience conscious will and ascribe authorship to ourselves for the
action. (p. 67) Much research apparently supports Wegner's (2003)
position that free will is an illusion. In a study by Wegner and
Wheatley (1999), two participants (one genuine and the other the
researcher's confederate) placed their fingers on a small board. When
they moved the board, a cursor moved over a screen showing pictures of
objects. The participants were instructed to stop the cursor every 30
seconds or so and indicate whether they had consciously intended the
cursor to stop where it did. Both participants heard words referring to
objects through headphones. The confederate was instructed through
headphones where to stop the cursor. Genuine participants tended to
believe wrongly they had caused the cursor to stop where it did (e.g. on
a picture of a cat) if they had heard the word "cat" 1 or 5 seconds
beforehand. Their mistaken belief can be explained by the principles of
priority, consistency and exclusivity. However, the findings are less
impressive than they sound for two reasons. First, only 60% of
participants believed their conscious intention caused the cursor to
stop even when all three principles applied. Second, the set-up was very
artificial and designed to make it hard for participants to understand
what was happening. By analogy, no one would argue visual perception is
hopelessly fallible simply because we misidentify objects in a thick
fog! Van der Weiden et al. (2013) conducted a similar study.
Participants stopped a rapid sequence of words by pressing a response
key to a stop cue. The sequence stopped at a word (e.g., glass)
determined by the computer but the participants were not told this.
Participants believed they had caused the outcome when the stopped word
matched their goal (i.e., it was the one they intended to stop at). They
also believed they had caused the outcome when the stopped word matched
an earlier prime word presented below the level of conscious awareness.
Thus, there are various ways people can be misled into thinking they
have caused a given outcome. Below we consider additional experimental
evidence. We start with behavioural research followed by cognitive
neuroscience research.

Consciousness

773

Findings: behavioural evidence

KEY TERM

Baumeister et al. (2011) reviewed evidence suggesting individuals'
behaviour often depends crucially on their conscious thoughts even
though those thoughts may have been preceded by various unconscious
processes. Strong evidence comes from research on implementation
intentions (if-then plans designed to attain some goal; see Glossary;
and Chapter 8). Here is an example of an implementation intention: "If I
feel depressed, then I will immediately become actively involved in some
task"). Toli et al. (2016) found in a meta-analysis (see Glossary) that
implementation intentions had a large effect on goal attainment in
individuals with mental health problems. Implementation intentions are
effective because they produce strong associations between the current
situation (if part of the plan) and the goal-related action (then part
of the plan). It follows that relatively little effortful action control
should be required for goal attainment. As predicted, people have
reduced activity in brain areas involved in effortful control (e.g.,
dorsolateral prefrontal cortex) when their behaviour is controlled by
implementation intentions (Wieber et al., 2015). Much behavioural
research has focused on individuals' sense of agency -- the "feeling of
being in the driving seat when it comes to our actions" (Moore, 2016,
p. 1). It would pose some problems for the notion of free will if
individuals sometimes have a sense of agency when it is not warranted
and lack a sense of agency when it is warranted. Olson et al. (2015)
produced a mistaken sense of agency in participants using a simple card
trick. A professional magician riffled rapidly through a pack of cards
having asked participants to choose one. One card (the target card) was
shown for longer than the others. The findings were clear-cut. Almost
all (98%) the participants chose the target card. Even though their
choice of card had been forced by the magician, 91% of participants felt
they had had a free choice. Thus, there was a strong dissociation
between participants' beliefs and reality. Olson et al. (2016) obtained
evidence people can mistakenly believe they lack agency. Participants
inside a mock brain scanner chose arbitrary numbers. In a mind-reading
task, the scanner apparently guessed their chosen number, and in a
mind-influencing task it apparently influenced their choice of numbers.
As predicted, participants performing the latter task had a reduced
sense of agency -- they reported lower levels of internal voluntary
control over their choices. Among their comments was the following
(p. 21): "I feel like it's a voice . . . dragging me from the number
that already exists in my mind." We can explain the above findings with
reference to Wegner's (2003) exclusivity principle -- being consciously
aware of a single apparently external thought led participants to
attribute their choices of numbers to the mock scanner. A related
phenomenon occurs in schizophrenic patients with delusions of control
causing loss of a sense of agency. Here is what was said by a
schizophrenic patient (cited by Gallagher & Trigg, 2016, p. 4): "They
inserted a computer in my brain. It makes me turn to the left or right.
It's just as if I were being steered around, by who or what I don't
know."

Sense of agency The belief we are determining our own actions.

774

Broadening horizons

Findings: cognitive neuroscience In a famous (or notorious!) study,
Libet et al. (1983) asked participants to decide when to bend their
wrist and fingers and to indicate when they were consciously aware of
their intention to perform those movements. They also recorded
event-related potentials (ERPs; see Glossary) to assess the readiness
potential (reflecting preplanning of a bodily movement). Surprisingly,
the readiness potential occurred 350 ms before participants reported
conscious awareness of the intention to bend their wrist and fingers and
550 ms before the actual hand movement. Superficially, Libet et al.'s
(1983) findings suggest much processing relating to the intention to
make a movement occurs before conscious awareness. However, there are
various problems with their study. For example, they focused on the late
stage of motor preparation rather than on earlier high-level decision
processes. In addition, they studied only when decisions (when shall I
move my hand? and ignored what decisions (e.g., what movement shall I
make?)). Bode et al. (2011) addressed these limitations. They assessed
brain activity in the anterior fronto-polar cortex (associated with
decisionmaking) while participants decided whether to respond with their
left or right index finger. Their key finding was that participants'
decisions could

Figure 16.3 (a) Region in left frontopolar cortex for which decoding of
upcoming motor decisions was possible. (b) Decoding accuracy of these
decisions (times preceding conscious awareness of the intention are
labelled as negative numbers). Chance performance = 50%. From Bode et
al. (2011).

Consciousness

be predicted on the basis of brain activity up to 7½ seconds before they
were consciously aware oftheir decision (see Figure 16.3). For various
reasons, Bode et al.'s (2011) findings do not cast doubt on the
existence of free will. First, predicting accurately participants'
decisions from their preceding brain activity was rarely above 55%
(chance = 50%) except very shortly before the conscious decision. Thus,
conscious processing may have strongly influenced participants' actions.
Second, the requirement to make unpredictable and random responses
reduced any pre-decision conscious processing to a minimum by
encouraging participants to use "automatic tie-breaking mechanisms"
(Mele, 2013, p. 781). In contrast, most people make extensive use of
conscious thinking prior to important decisions (e.g., shall I marry
X?). Third, as Nachmias (2015, p. 78) wittily pointed out, if our
decisions are made several seconds before we act, "we would all have
died in car crashes by now!". Fried et al. (2017) reviewed research
indicating that frontal and parietal areas are of crucial importance
with respect to conscious planning, decision-making and a sense of
agency. For example, Rens et al. (2017) found there was much greater
activation in the fronto-parietal network (associated with cognitive
control) when participants made voluntary choices than when they were
instructed which choice to make. More generally, a key aspect of human
decision-making is our ability to use conscious processes to think ahead
and plan goal-directed action (Fried et al.).

Evaluation Various strands of behavioural and cognitive neuroscience
research apparently cast doubt on the notion of free will. Behavioural
research has shown we can have a mistaken sense of agency when we are
not responsible for some action and we can also lack a sense of agency
even when we are responsible for an action. Such findings are
interesting and potentially important. However, they are often obtained
in rather artificial situations -- in everyday life our actions probably
often depend on a mixture of conscious and unconscious processes.
Cognitive neuroscience research casts less doubt on human free will than
sometimes claimed. For example, researchers' ability to predict
participants' decisions from their preceding brain activity in the Bode
et al. (2011) study was only slightly above chance. Thus, participants'
actions in that study probably depended in part on processes associated
with early brain activity but this does not rule out a strong
involvement of conscious processing. There is much evidence that
conscious planning within frontal and parietal areas is of considerable
importance in influencing goal-directed action (Fried et al., 2017).

ASSESSING CONSCIOUSNESS AND CONSCIOUS EXPERIENCE How can we assess (and
understand) conscious experience? Unsurprisingly, the most popular
answer is that we should use behavioural or introspective

775

776

Case study: Towards a true neural stance

Broadening horizons

measures. For example, we could decide whether individuals have
conscious experience of an object by asking them to provide verbal
reports of their visual experience. Alternatively, they could make
yes/no decisions concerning the presence of a target object. Lamme
(2006, 2018) argued that our actual conscious experience is often much
richer than our report of that experience. Why is that? According to
Lamme (2006, p. 499), "You cannot know whether you have a conscious
experience without resorting to cognitive functions such as attention,
memory or inner speech." Thus, reports of our conscious experience may
be limited due to processes intervening between the experience and its
report rather than limitations in the experience itself. Another problem
is that different behavioural or self-report measures often produce
different answers. For example, consider research on subliminal
perception (see Glossary; and Chapter 2). Observers sometimes show
"awareness" of visual stimuli when making forced-choice decisions about
them (objective threshold) but not when reporting their experience
(subjective threshold).

Under-reporting of conscious experience? Suppose you look briefly at a
photograph of a social event and then immediately describe your
conscious experience. You would probably refer to the main individuals
in the photograph. However, you would probably not mention the size of
the photograph, whether it is matt or gloss, or the distances between
the individuals. Research evidence indicating we often under-report our
conscious experience was reported by Sperling (1960; see Chapter 6). He
presented a visual array consisting of three rows of four letters each
for 50 ms. Participants typically reported only four to five letters but
claimed to have seen many more. Sperling (1960) assumed this
under-reporting occurred because relevant visual information faded
before it could be reported. He tested this assumption by asking
participants to recall only part of the information presented (e.g., the
second row). As predicted, part recall was high provided the
to-be-recalled information was cued very shortly after the offset of the
visual display. Much subsequent experimentation supports Sperling's
(1960) findings. Two object arrays are presented several seconds apart,
and observers decide whether a given object has changed between arrays
(see Lamme, 2010). Performance was poor when this object was cued at the
same time as the second array was presented. However, it was very good
when the cue was presented some time ahead of the second array. Such
findings suggest observers have access to considerable information for
some time following the offset of the first array. There are two
possible interpretations of the above findings (Gross, 2018). First, our
conscious experience "overflows" our capacity to report it. In the terms
used by Block (2012; discussed earlier, pp. 767--768), phenomenal
consciousness (our private experience) is richer and more extensive than
our access consciousness (experience we can report). This approach is
probably consistent with most people's introspections, but that provides
very weak evidence.

Consciousness

777

Second, some letters or objects may be represented consciously with most
(or all) of the remainder being represented unconsciously. Under some
circumstances, cueing can make observers consciously aware of these
unconscious representations which are then reported. Evidence we can
exaggerate the richness of our conscious experience was reported by de
Gardelle et al. (2009) using a modified version of the Sperling task.
Participants expected letters to be presented but sometimes
pseudo-letters (real letters rotated and flipped) were presented
instead. Participants rarely detected the presence of pseudo-letters.
Thus, their conscious experience was less accurate and detailed than
they thought it was.

Over-reporting of conscious experience? Further evidence our conscious
experience is less accurate than we believe comes from research on
change blindness (see Glossary; and Chapter 4). Most people
substantially overestimate their ability to avoid change blindness
(Levin et al., 2002). You can obtain some sense of what is going on here
by looking out of the window and taking note of what you perceive. Your
conscious perception probably suggests you can see the entire view
clearly. In fact, that is an illusion because peripheral vision is much
more limited than central vision (Rosenholtz, 2016). Freeman and
Simoncelli (2011) reported relevant evidence. Observers saw an original
undistorted photograph followed by distorted versions of that photograph
(see Figure 16.4). The observers could not distinguish between the
original undistorted photographs and those with gross peripheral
distortions. Why isn't our conscious perception of the world blurred? We
use top-down processes (e.g., expectations) to fill in the gaps in the
information available to us. Thus, as Cohen et al. (2016, p. 324)
concluded, "We see far less than we think we see."

Figure 16.4 Undistorted photograph of the Brunnen der Lebensfreude in
Rostock, Germany (left-hand picture) and distorted versions of it
(middle and right-hand pictures). With rapid presentation and fixation
at the centre (red dot), the two distorted versions appeared nearly
identical to each other and to the undistorted photograph. From Freeman
and Simoncelli (2011). Reproduced with permission from Nature Publishing
Group.

778

Broadening horizons

KEY TERMS

Consciousness in brain-damaged patients

Vegetative state A brain-damaged condition in which patients exhibit
wakefulness but lack conscious awareness. Minimally conscious state A
condition in which patients exhibit partial preservation of conscious
awareness.

Three stages of degraded consciousness have been identified in
braindamaged patients. The most severe stage is coma -- there is no
conscious awareness and no wakefulness. The next stage is a vegetative
state; patients in this state "appear to be awake but show no external
evidence of awareness" (De Salvo et al., 2015, p. 237). The third stage
is a minimally conscious state, involving wakefulness and some evidence
of consciousness. This categorisation implies that states of
consciousness differ along a single dimension. In fact, conscious states
differ from each other with respect to several dimensions (Bayne et al.,
2016, 2017; discussed earlier, p. 767). How can we explain differences
between patients in a vegetative state and those in a minimally
conscious state? Chen et al. (2018b) provided an answer. Conscious
awareness in healthy individuals depends in part on connections from
brainstem arousal systems and cortical areas. These connections are
impaired in patients in a minimally conscious state but totally lacking
in vegetative state patients. Much research interest has focused on
vegetative state patients. Behavioural measures (e.g., responsiveness to
external stimuli) provide no evidence such patients have conscious
awareness whereas neuroimaging research indicates some vegetative state
patients have partial conscious awareness (see Box).

IN THE REAL WORLD: VEGETATIVE STATE PATIENTS AND CONSCIOUSNESS What
tasks would reveal whether some vegetative state patients have conscious
awareness? Active tasks where participants generate the responses
themselves by responding to commands are of special value (Owen, 2013).
For example, Monti et al. (2010) gave a vegetative state patient various
yes-or-no questions (e.g., "Is your father's name Thomas?"). He was told
to imagine playing tennis for "Yes" answers and to imagine navigating
his house for "No" answers. The patient's patterns of brain activity
corresponded to the correct answers. Cruse et al. (2011) reported
interesting findings on 16 vegetative state patients instructed to
respond to two commands ("squeeze your right hand"; "squeeze your
toes"). In healthy participants, these commands produce activation in
the hand and toe motor areas, respectively. Three patients showed very
similar patterns of brain activation (see Figure 16.5). These findings
are impressive: successful task performance requires sustained
attention, language comprehension (of the task instructions) and
response selection. Monti et al. (2013) studied a patient with a severe
disorder of consciousness. He was presented with superimposed pictures
of faces and houses and instructed to shift his attention between the
faces and the houses. His changing patterns of brain activation
indicated the patient's intentions were successful in changing his
attentional focus. Kondziella et al. (2016) argued the demanding nature
of active tasks may mean that conscious awareness in vegetative state
patients is underestimated. Accordingly, they compared evidence of
conscious awareness in active tasks and passive ones (responses were not
required) by assessing functional cortical connectivity in networks
associated with conscious awareness. Here are their main findings.
First, 14% of vegetative state patients and 32% of minimally conscious
state patients showed signs of consciousness on active tasks. Second,
26% of vegetative state patients and 55% of minimally conscious patients
showed signs of consciousness on passive tasks.

Consciousness

779

Figure 16.5 Modulation of the appropriate frequency bands of the EEG
signal associated with motor imagery in one healthy control and three
patients. Red colours show values more than zero, while blue colours
show values less than zero. There are clear focal areas over the hand
and toe motor areas (directly relevant to the task) for all four
participants. From Cruse et al. (2011). Reprinted with permission from
Elsevier.

In sum, the above research indicates the value of using cognitive
neuroscience techniques to assess consciousness in vegetative state
patients. Of importance, behavioural measures consistently indicate that
conscious experience is absent in such patients. What are the
limitations of research in this area? First, it is hard to interpret the
differences between active and passive tasks reported by Kondziella et
al. (2016). As they concluded, "Unresolved dilemmas include the lack of
a gold standard for \[assessing\] consciousness" (p. 7). Second, it is
also hard to assess consciousness in patients because it often
fluctuates over time (Kondziella et al.). Third, we have only limited
understanding of the conscious experience of vegetative state patients
exhibiting signs of consciousness (Owen, 2013). In addition, most
vegetative patients show no signs of consciousness and we do not know
the extent to which this reflects insensitivity of assessment.

Neural correlates of consciousness We have seen that relying solely on
self-report measures to assess conscious awareness is limited.
Alternatively, we could focus on the neural correlates of consciousness:
"the minimum neural mechanisms jointly sufficient

780

Broadening horizons

for any one specific conscious experience" (Koch et al., 2016, p. 307).
This approach typically involves relating behavioural measures of
conscious awareness to associated patterns of brain activity. This
approach has two advantages. First, it is theoretically important to
compare behavioural and neuroimaging measures to identify their
similarities and differences. Second, neuroimaging measures may assess
consciousness more directly than behavioural measures if uncontaminated
by additional processes such as attention and memory (discussed above,
p. 776). Several reviews on the neural correlates of consciousness are
available (e.g., Koch et al., 2016). Here we will focus on two issues.
First, problems in establishing the neural correlates of consciousness
are discussed. Second, we discuss the role of recurrent processing in
conscious awareness. Findings of direct theoretical relevance are
discussed in the next section.

Major problems In studies on the neural correlates of consciousness,
several brain regions are typically activated. We cannot assume all
these brain regions are necessarily associated with conscious
experience. Consider a study where visual stimuli are presented very
briefly to observers, who indicate whether they saw each stimulus and
try to identify it. The observers will use several cognitive processes
(e.g., attention; monitoring their conscious awareness; remembering what
they have seen; reporting what they have seen) additional to conscious
experience itself. As a consequence, it can be very hard to disentangle
which neural activity is associated with conscious awareness and which
neural activity is associated with other task-related processes (Storm
et al., 2017). Relevant evidence was reported by Frässle et al. (2014)
in a study on binocular rivalry (see Glossary). In one condition,
observers indicated by button presses which stimulus they saw (active
condition). In the other condition, observers simply observed changes in
which stimulus they perceived without responding (passive condition).
What did Frässle et al. (2014) find? Occipital and parietal areas were
activated in both active and passive conditions (see Figure 16.6).
However, frontal areas (including dorsolateral prefrontal cortex) were
much more activated in the active condition. If the researchers had used
only the active condition, we might have mistakenly exaggerated the
association between frontal activation and conscious awareness. In fact,
that activation mostly reflected processes relating to making
behavioural reports (e.g., self-monitoring) rather than directly to
conscious experience. Another problem is that of establishing the
relationship between a given pattern of neural activity and
consciousness. Neural activity may directly reflect conscious awareness.
Alternatively, the observed neural activity may precede and influence
conscious awareness or may occur merely as a consequence of conscious
awareness (de Graaf et al., 2012). Another problem is that most research
is limited in scope. There has been a strong emphasis on the neural
correlates of visual conscious awareness to currently presented visual
stimuli. Why is that? We can easily control the conditions (e.g., by
altering exposure time) to ensure observers are (or are not) consciously
aware of any given visual stimulus.

Consciousness

781

KEY TERM Backward masking Suppression of the processing (and conscious
perception of) a stimulus by presenting a second, masking stimulus very
shortly thereafter.

Figure 16.6 Activation patterns on a binocular-rivalry task when
observers (a) reported what they perceived or (b) passively experienced
rivalry. From Frässle et al. (2014).

As a result of this emphasis, relatively little is known about the
neural processes associated with conscious awareness of past or future
events. More generally, cognitive neuroscientists have rarely studied
what Baumeister and Masicampo (2010; discussed earlier, p. 768) called
conscious thought.

Feedforward processing and recurrent processing Lamme (2018) provided an
account of the various stages of visual processing (see Figure 16.7) in
the most recent version of his recurrent processing theory: (1)

(2) 
(3) 

Fast processing starts in early visual cortex and proceeding to higher
levels (Figure 16.7a); this feedforward sweep takes approximately
150--200 ms. Feedforward processing is not accompanied by conscious
experience. Recurrent or top-down processing starts approximately 100 ms
after stimulus presentation and occurs between low-level visual areas
(Figure 16.7b); it involves phenomenal consciousness (direct conscious
experience). Recurrent or top-down processing spreads throughout the
brain (including prefrontal areas) (Figure 16.7c); it involves access
consciousness (its contents can be communicated to other people).

Why is conscious experience associated with recurrent processing rather
than the feedforward sweep? First, the feedforward sweep involves
fragmented processing of different kinds of information (e.g., shape;
colour), whereas recurrent processing is integrated. Second, conscious
visual experience is typically coherent even when the available visual
information is ambiguous. Top-down processes (e.g., expectations)
associated with recurrent processing are important in producing this
coherence (O'Reilly et al., 2013). How can we prevent (or reduce)
recurrent processing to assess its importance for conscious perception?
Masking is one method. Backward masking

782

Broadening horizons

(a) action conﬂict motion control depth

Shape colour

face object gist

Feedforward sweep: unconscious

(b) 
(c) 

Figure

x10--8

1.0 0.5 0

V1 ConMod Ground

2

VAN

t = 436 ms

frontoparietal

fMRI PPI

--200 0 200 400 600 inferior frontal x10--8

1 0

--200 0 200400 600

P300--400

action

action conﬂict

motion

conﬂict motion

control depth

shape colour

control depth

face

shape colour

object gist

Recurrent processing: P-conscious

face object gist

Global ignition: A-conscious

Figure 16.7 Three successive stages of visual processing following
stimulus presentation. Feedforward processing is shown by green lines
and recurrent processing by red lines. See text for a full account. From
Lamme (2018).

involves blocking the processing and perception of a stimulus by
following it rapidly with a second, masking stimulus. Alternatively, we
can use transcranial magnetic TMS (see Glossary). TMS can be applied to
early visual cortex to disrupt recurrent processing but not the
feedforward sweep. Finally, we can study brain activation in
brain-damaged patients with limited or no conscious awareness. Koivisto
et al. (2011) used TMS to disrupt recurrent processing while observers
decided whether natural scenes contained animals. As predicted,
conscious visual perception was impaired. This finding suggests
conscious visual perception partly depends on recurrent processing. Boly
et al. (2011) found feedforward processes were comparable in vegetative
state patients, minimally conscious patients and healthy controls when
presented with expected and unexpected tones. However, only the
vegetative state patients had impaired top-down connectivity from
frontal to temporal areas indicative of reduced recurrent processing.
These findings are consistent with other research on vegetative state
patients (discussed earlier).

Consciousness

783

Koivisto et al. (2014) presented photographs briefly followed by
backward masking to prevent recurrent processing. Accurate
categorisation of photographs as showing or not showing animals was
comparable with and without masking (86% vs 88%, respectively). However,
participants reported less conscious awareness of what was shown on each
photograph under masked conditions (see Figure 16.8). These findings
suggest conscious visual perception can occur without recurrent
processing with easy visual tasks. Similar findings also using backward
masking were reported by Koivisto and Rientamo (2016). Recurrent
processing is not always associated with conscious awareness. Observers
detecting white vowels in a stream of black and white letters were
occasionally presented with unexpected square figures (Scholte et al.,
Figure 16.8 2006). These figures produced recurrent pro- Percentage of
trials on which participants reported awareness cessing but 50% of
observers did not perceive of the content of photographs under masked
and unmasked them consciously. The figures were consistently conditions
for animal and non-animal (e.g., landscapes; seen only when there was
widespread recurrent vehicles) photographs. processing. Thus, conscious
awareness can be From Koivisto et al. (2014). © Massachusetts Institute
of Technology, by permission of the MIT Press. lacking when inattention
to unexpected stimuli is combined with limited recurrent processing. In
sum, conscious visual perception is typically associated with the
occurrence of recurrent processing, whereas feedforward processing
without recurrent processing generally does not lead to conscious
perception. Recurrent processing may play an important role in producing
the widespread integrated activity across the brain strongly associated
with conscious awareness (discussed further below). However, simple
visual discrimination (e.g., animal vs non-animal) can occur without
recurrent processing, and recurrent processing of unattended stimuli is
not always associated with conscious experience. Thus, there is not a
direct one-to-one relationship between conscious awareness and recurrent
processing.

GLOBAL WORKSPACE AND GLOBAL NEURONAL WORKSPACE THEORIES Many theories of
consciousness have been put forward. Here we will focus on a theoretical
approach that successfully relates cognitive factors to neuroscience.
Global workspace theory was proposed by Baars (1988) and a similar
global neuronal workspace theory was developed by Dehaene and Changeux
(2011). Initially, global workspace theory emphasised behavioural data
whereas global neuronal workspace theory focused more on identifying the
main brain areas associated with conscious awareness. However, Baars et
al. (2013) expanded global workspace theory by considering the role of
the cortex and thalamus in conscious experience. Both versions of global
workspace theory have been highly influential.

784

Broadening horizons

Here we focus on the main common assumptions of the two theories. First,
it is argued early stimulus processing involves numerous specialpurpose
unconscious processors operating in parallel. These processors are
distributed across numerous brain areas with each processor carrying out
a specialised function (e.g., colour or motion processing; see Chapter
2). This early unconscious processing should be very similar regardless
of whether a stimulus is subsequently consciously perceived. Second, it
is assumed consciousness is associated with integrating information from
these special-purpose processors relatively late in processing. More
specifically, a combination of bottom-up processing and top-down control
produces "ignition" leading to synchronised activity across large areas
of the brain. This makes information globally available and corresponds
to conscious experience. Third, it is assumed the brain areas associated
with consciousness vary as a function of the content of conscious
experience (e.g., visual areas with awareness of visual but not auditory
stimuli). However, some brain areas are consistently activated during
conscious awareness. For example, Dehaene and Changeux (2011, p. 210)
emphasised the role of "prefrontal, cingulate, and parietal regions" in
conscious experience. Fourth, it is assumed conscious awareness is
typically determined by prior selective attention. Consider a sentence
such as "I look in order to see". The word look refers to attention
whereas the word see refers to consciousness. In other words, attention
resembles choosing a television channel and consciousness resembles what
is presented on the screen. There are several other views concerning the
relationship between attention and conscious awareness. Webb and
Graziano (2015) identified five different hypotheses about that
relationship (see Figure 16.9). The global (neuronal) workspace
theoretical approach is most like (C). Webb and Graziano favoured
hypothesis (E). According to this hypothesis, there can be attention
with or without awareness. In the latter case, however, attention is
under less control. Note that it is assumed within Lamme's (2018)
recurrent processing theory (discussed earlier, pp. 781--783), that
conscious perception can occur in the absence of prior attention. More
specifically, phenomenal consciousness can occur without prior
attention, but access consciousness typically requires prior attention
(see Figure 16.7).

Integrated information theory Tononi (e.g., Tononi et al., 2016)
proposed an integrated information theory. The theory starts with the
key features of conscious experience. It then makes assumptions about
the characteristics of the brain substrate required to support such
experience. It is assumed conscious experience includes the following
features: (1) intrinsic existence (accessible only to oneself); (2)
composition (it has structure); (3) specificity (different from other
experiences); and (4) unitary (content is integrated within a unitary
consciousness). These key features of conscious experience mean it is
typically very rich and informative. What is the relationship between
conscious experience and the underlying neural substrate? According to
integrated information theory, the brain processes associated with
conscious experience are often extraordinarily

Consciousness

Figure 16.9 (a) Awareness and attention are the same thing; (b)
awareness precedes attention; (c) attention precedes awareness; (d)
awareness and attention are independent processes; (e) attention is
possible without awareness, but is under less control.

(a) # Awareness

    Attention

(b) Awareness

Attention

Attention

Awareness

Awareness

Attention

(c) 
(d) 
(e) Awareness

785

Attention

complex. As a consequence, it is impossible for us (with our limited
processing capacity) to access all the information associated with those
brain processes. In sum, integrated information theory has clarified the
main features of conscious experience. Of most relevance here, the
theory assumes the richness of conscious experience depends crucially on
integrated activation within large brain networks. This assumption is
entirely consistent with global workspace theory (although the theories
differ in many other ways). Note that the findings discussed below all
relate to global workspace theory although some are also of relevance to
integration information theory.

Findings: early processing The first theoretical assumption is that
early stimulus processing is unaffected by whether or not an object is
subsequently consciously

From Webb and Graziano (2015).

786

Broadening horizons

perceived. Much research supports this assumption. For example, Lamy et
al. (2009) asked observers to indicate the location of a stimulus and
indicate whether they had conscious awareness of its presence.
Event-related potentials (ETPS; see Glossary) were recorded. The
amplitude of early ERP components was unaffected by whether or not there
was conscious awareness (see Figure 16.10). However, conscious awareness
was associated with a late wave of activity (P3) between 400 and 600 ms
after stimulus onset. The bottom part of Figure 16.10 shows brain
positivity was far more widespread in the presence (rather than absence)
of conscious awareness. Koivisto and Grassini (2016) used more sensitive
stimuli and analyses and found the N200 (180--280 ms) was greater on
trials when there was conscious awareness. Their findings suggest the
N200 is directly associated with visual awareness whereas the P3
reflects additional conscious processing following awareness. Melloni et
al. (2011) argued the time taken for visual awareness to occur might be
reduced if a stimulus is expected. As predicted, differences between the
ERPs to seen and unseen stimuli started 100 ms earlier for expected
stimuli than unexpected ones. Of importance, the early stages of
processing were very similar for seen and unseen stimuli regardless of
whether these stimuli were expected.

Figure 16.10 Event-related potential (ERP) waveforms in the
aware-correct, unawarecorrect and unawareincorrect conditions. The
greatest differences among the conditions occurred for the P3 component
(shown in light grey). In the bottom part of the figure, the extent of
brain positivity in the three conditions is shown in red. From Lamy et
al. (2009). © Massachusetts Institute of Technology, by permission of
the MIT Press.

Consciousness

Findings: integrated brain functioning As we have seen, several
theorists assume integrated brain functioning is crucial to conscious
awareness. This assumption makes much sense given that what we are
consciously aware of is nearly always integrated information. For
example, it is almost impossible to perceive an object while ignoring
its colour. Melloni et al. (2007) tested the above assumption. They
presented words that were hard to perceive and compared brain activity
for those that were or were not consciously perceived. Only consciously
perceived words produced synchronised (or integrated) neural activity
involving frontal, parietal and occipital areas, especially between 40
and 182 ms (see Figure 16.11). King et al. (2013b) used
electroencephalography (EEG; see Glossary) to assess integrated brain
functioning in response to auditory stimuli using a measure known as
weighted symbolic mutual information (wSMI). The four groups of
participants had varying levels of conscious awareness: (1) (2) (3) (4)

patients in a vegetative state (no conscious awareness; see earlier in
the chapter, p. 778); minimally conscious state patients; conscious
patients with brain damage (often recovering from a vegetative state or
state of minimal consciousness); healthy participants.

Figure 16.11 Synchronisation of neural activity across cortical areas
(shown by connecting lines) for consciously perceived words (visible
condition) and non-perceived words (invisible condition) during
different time periods. 0 ms = stimulus onset. From Melloni et
al. (2007). Republished with permission of The Society for Neuroscience.
Permission conveyed through Copyright Clearance Center, Inc.

787

788

Broadening horizons

Figure 16.12 (a) Overall information sharing or integration across the
brain for vegetative state, minimally conscious and conscious
brain-damaged patients and healthy controls (blue = low integration;
red/brown = high integration). (b) Information sharing (integration)
across short, medium and long distances within the brain for the four
groups. From King et al. (2013b). Reprinted with permission from
Elsevier.

What did King et al. (2013b) find? There were dramatic differences in
the extent of integrated brain activity across these four groups (see
Figure 16.12). As predicted, there was much more integrated brain
activity in those groups having high levels of conscious awareness.
Research on anaesthesia-induced unconsciousness has produced similar
findings to those obtained with brain-damaged patients (Mashour &
Hudetz, 2018). For example, Randt et al. (2016) found that the
anaesthetic sevoflurane reduced connectivity within higher-level frontal
networks but not low-level sensory networks. There is evidence that
disrupted information transfer at hubs (highly connected regions within
prefrontal cortex) is especially important in unconsciousness produced
by anaesthesia or brain damage (Mashour & Hudetz). The findings
discussed in this section are clearly consistent with the global
workspace and integrated information theories. However, there is a
tricky issue concerning causality. Synchronised neural activity may
directly reflect conscious awareness. However, it is also possible
synchronised neural activity precedes and influences conscious awareness
or that it occurs merely as a consequence of conscious awareness (de
Graaf et al., 2012).

Findings: key brain areas (e.g., prefrontal cortex) Interactive feature:
Primal Pictures' 3D atlas of the brain

There is much support for the assumption the prefrontal cortex and
related areas are especially likely to be associated with conscious
awareness. For example, Neghavi and Nyberg (2005) argued similar brain
areas are associated with consciousness, attention and working memory.
They reported

Consciousness

overlaps among these functions were greatest in dorsolateral prefrontal
cortex (BA6 and BA9) and parietal cortex (BA and BA40). These areas
represent the fronto-parietal network often assumed to be of major
importance to attention and consciousness. Gaillard et al. (2009)
studied event-related potentials in response to visual stimuli that were
or were not consciously perceived. They used epileptic patients and so
had the rare opportunity to record ERPs directly from the brain with
electrodes implanted in the brain (rather than scalp electrodes).
Conscious awareness (from about 350 ms after stimulus presentation) was
associated with much larger effects on activation in the frontal cortex
than any other brain region. The above findings are correlational, and
do not show activation of the prefrontal cortex is causally related to
conscious awareness. For example, the findings may indicate prefrontal
processes are involved in attention as well as conscious awareness. One
approach to this causality issue is to study brain-damaged patients. Del
Cul et al. (2009) studied patients with damage to the prefrontal cortex.
It was harder for these patients to perceive a masked number than
healthy controls, and the magnitude of this effect was greater in
patients having the most damage to prefrontal cortex. Another approach
to the causality issue is to apply transcranial magnetic stimulation
(TMS) to prefrontal cortex to inhibit its functioning. Rounis et
al. (2010) found disrupting prefrontal processing via TMS made
participants less aware of the quality of their information processing.
Koch et al. (2016) argued the role of prefrontal cortex (or the
fronto-parietal network) in conscious awareness has been exaggerated.
For example, Markowitsch and Kessler (2000, p. 94) studied a young
female patient with "severe degeneration of the prefrontal cortex". In
spite of that, the patient showed essentially intact conscious
awareness. Goldberg et al. (2006) presented participants with pictures
and audio clips. In one condition, they self-introspected about their
emotional reactions to the stimuli; in a second condition, they
categorised the stimuli (e.g., animal vs non-animal). Different brain
regions were activated for each task. Of most relevance here, the
prefrontal cortex was less important when stimuli were categorised than
when conscious awareness involved self-related processes. Various
findings suggest visual awareness is associated with numerous brain
regions in addition to the prefrontal cortex and parietal regions.
Bisenius et al. (2015, p. 177) carried out a meta-analysis and
concluded: "\[There is\] a subcortical-extrastriate-fronto-parietal
network rather than a single region that constitutes the necessary NCC
\[neural correlates of consciousness\]." Several frontal areas formed
part of that extensive network. Evidence indicating the prefrontal
cortex can be activated during unconscious as well as conscious
processing was reported by van Gaal et al. (2010). Participants were
instructed to inhibit responses to a visible stimulus when preceded by a
white square. When this square was visible, participants showed good
inhibitory control associated with extensive prefrontal activation. Of
greater theoretical importance, participants responded more slowly and
had some activation in the inferior frontal cortex when the square was
presented subliminally.

789

790

Broadening horizons

Findings: attention and consciousness We turn now to the theoretical
assumption that consciousness depends on prior selective attention. That
probably sounds reasonable to you. However, several theorists have
disagreed with that assumption. For example, Koch and Tsuchiya (2012)
argued attention without consciousness and consciousness without
attention are both possible. As mentioned earlier, it is assumed within
recurrent processing theory (Lamme, 2018) that conscious awareness can
occur without prior attention. Attention can influence behaviour in the
absence of conscious awareness. For example, Jiang et al. (2006)
presented pictures of male and female nudes subliminally. Each trial was
followed immediately by a task with visible stimuli to assess direction
of attention while the nudes were presented. The invisible nude pictures
influenced participants' attentional processes. Heterosexual males
attended to subliminal female nudes whereas heterosexual females
attended to subliminal male nudes. How can unseen emotional stimuli
influence attention? Troiani et al. (2014) discovered that subliminal
fearful faces produced increased amygdala activation (associated with
emotional processing). This activation in turn was associated with
activation of brain areas formed an attentional network. The assumption
within the global workspace approach that conscious awareness is always
preceded by attention has proved controversial (Pitts et al., 2018,
2019). Of relevance are change blindness and inattentional blindness
(see Glossary; see Chapter 4). These phenomena suggest that novel
objects (or changes to objects) within a visual scene are rarely (if
ever) detected consciously in the absence of attention. However, it has
been claimed various other phenomena show conscious awareness in the
absence of attention. Three are discussed below: (1) natural-scene
perception; (2) visual pop-out; and (3) iconic memory. We seem to
perceive the gist of natural scenes without attention. However, that may
be illusory. In a study by Cohen et al. (2011), observers saw rapidly
presented digits and letters against changing chessboard masks and
counted the number of digits. Unexpectedly, a natural scene containing
an animal or vehicle replaced a mask. Only 23% of the participants could
immediately identify the object in the scene and 50% reported no
conscious perception of it. In contrast, when participants attended to
the background, they classified the natural scenes accurately 93% of the
time. Thus, attention seems necessary to have conscious perception of
the gist of natural scenes. Visual pop-out occurs when a target stimulus
is detected rapidly when it differs in some obvious way (e.g., colour;
orientation) from surrounding distractor stimuli. It has often been
assumed attention is not required to detect such target stimuli.
However, Cohen et al. (2012) reviewed the evidence and concluded the
pop-out effect typically fails to occur when observers' attention is
focused on another task. Finally, we turn to iconic memory (very brief
storage of visual information following stimulus offset; see Glossary)
which is often assessed using the Sperling (1960) task discussed earlier
(p. 776). Iconic memory has been assumed to be attention-free (see
Chapter 6). This assumption

Consciousness

was challenged by Mack et al. (2016). Participants were presented with
letters in the centre of a visual array (iconic memory task) and four
circles surrounding the letters (the task involved deciding whether all
circles were the same colour) but were only required to perform one task
on each trial. Mack et al. (2016) found performance on the iconic memory
task was much worse when the probability of having to perform it was
only 10% rather than 90%. This happened because there was much less
attention to the letters in the former condition. Most strikingly, most
participants failed to note that all the letters had been removed from
the screen when their attention was strongly focused on the circle task.
These findings indicate that conscious awareness of information in
iconic memory depends on prior attention. In sum, most of the available
evidence suggests consciousness depends on prior attention (Pitts et
al., 2018, 2019). However, this conclusion is disputed (e.g., Lamme,
2018). Agreement will be hard to achieve given the varying definitions
of the terms "attention" and "consciousness" used by different
researchers.

Overall evaluation There is support for all the major assumptions of the
global workspace approach. First, early processing of seen stimuli
typically does not differ from that of unseen ones in patterns of brain
activity during the first 200 ms or 300 ms after stimulus onset. Second,
conscious awareness is generally associated with widespread integrated
or synchronised brain activity. This integrated brain activity generally
(but not invariably) includes prefrontal cortex and parietal regions,
and often the anterior cingulate. As predicted theoretically,
anaesthetics inducing unconsciousness produce greatly impaired
functional connectivity within prefrontal networks, and patients with
limited or no conscious awareness have considerably less integrated
brain activity than healthy controls (King et al., 2013b). Of
importance, research on patients with disorders of consciousness (e.g.,
vegetative state patients) indicates that recovery of consciousness is
typically associated with enhanced integrated brain activity (Bodien et
al., 2017). Third, the assumption that brain regions associated with
conscious awareness reflect the content of such awareness has received
support. For example, Eriksson et al. (2006) found that conscious
awareness of pictures of objects was associated with activation in
visual areas whereas conscious awareness of object sounds was associated
with activation in auditory areas. Fourth, most evidence supports the
assumption that conscious awareness is always (or nearly always)
preceded by selective attention (Pitts et al., 2018). However, there may
sometimes be rather limited conscious awareness of objects in the
absence of prior selective attention. In addition, the relationship
between attention and conscious awareness is more complex than assumed
theoretically. As well as effects of attention on conscious awareness,
there are effects in the opposite direction (e.g., Webb et al., 2016b):
conscious awareness increases attentional control.

791

792

KEY TERM Split-brain patients Patients in whom most of the direct links
between the two hemispheres of the brain have been severed.

Broadening horizons

What are the limitations of the global workspace approach? First, its
emphasis is on the neural correlates of conscious visual perception.
Demertzi et al. (2013) drew a distinction between external awareness
(awareness of the environment) and internal awareness (self-relevant
thinking). External awareness is associated with activity in the
dorsolateral prefrontal cortex and posterior parietal regions. In
contrast (and not considered by the global workspace approach), internal
awareness is associated with activity in the posterior cingulate cortex,
anterior cingulate and medial prefrontal cortex. Second, the assumption
that prefrontal cortex plays a major role in conscious experience has
attracted much research support. However, there are findings suggesting
its role may have been exaggerated (Boly et al., 2017). Third, much of
the integrated brain functioning associated with conscious awareness is
not necessarily the neural substrate of conscious awareness. Other
possibilities are that integrated brain functioning is a prerequisite or
consequence of conscious experience (de Graaf et al., 2012). For
example, prefrontal activation may reflect selective attention preceding
conscious awareness. Fourth, identifying the brain areas and patterns of
brain activity associated with conscious awareness is of value. However,
this focus on cognitive neuroscience has led to a relative neglect of
the associated psychological processes. Fifth, there are complexities in
interpreting the findings from studies of anaesthesia-induced
unconsciousness and unconsciousness in braindamaged patients. For
example, it is typically assumed in both cases that impaired integrated
brain activity reflects loss of consciousness. However, it may also
depend in part on loss of attentional processes (Mashour & Hudetz,
2018).

IS CONSCIOUSNESS UNITARY? Most people assume they have a single, unitary
consciousness although a few are in two minds on the matter. This issue
became controversial because of research on split-brain patients, who
have few connections between the two brain hemispheres following
surgery. In most cases, the corpus callosum (bridge) between the two
brain hemispheres was cut surgically to contain epileptic seizures
within one hemisphere. This structure is a collection of 250 million
axons connecting the two hemispheres. The dramatic reduction in
structural connectivity between the hemispheres in split-brain patients
does not always produce an equivalent reduction in functional
connectivity (Uddin, 2013). Tyszka et al. (2011) studied patients
lacking a corpus callosum because of developmental abnormalities.
Surprisingly, the patients had largely normal functional networks in
both hemispheres, probably because their brains had undergone extensive
functional reorganisation early in life. Thus, they may differ
importantly from patients lacking a corpus callosum due to surgery in
adult life. It was not realised initially that cutting the corpus
callosum caused significant problems. The reason is that split-brain
patients ensure environmental information reaches both hemispheres by
moving their eyes around.

Consciousness

Split-brain patients also use cross-cueing: one hemisphere supplies
information to the other (Volz & Gazzaniga, 2017). For example, a
patient, VP, was presented with break to the right hemisphere and fast
to the left hemisphere. She started to say "bre-" as in brake, but then
instantly corrected herself, saying "breck". The left hemisphere used
the auditory input from the right hemisphere to produce the correct
pronunciation. Split-brain patients typically have intact verbal IQ and
problemsolving abilities. They also have the "illusion of unity": "They
report that they experience a single consciousness" (Volz & Gazzaniga,
2017, p. 2059). However, split-brain patients exhibit impaired
laboratory performance when visual stimuli are presented briefly to one
hemisphere, so the information is unavailable to the other hemisphere.
Do split-brain patients have two minds, each with its own consciousness?
Many psychologists subscribe to that viewpoint. Sperry (1968, p. 723)
argued as follows: "The minor hemisphere \[the right one\] constitutes a
second conscious entity that . . . runs along in parallel with the more
dominant stream of consciousness in the major hemisphere \[the left
one\]". He regarded the left hemisphere as dominant because language
processing is typically centred there. Tononi et al. (2016) argued in
their integrated information theory (discussed earlier, pp. 784--785),
that the physical basis of consciousness involves integrated or
synchronised brain activity across relatively large brain areas. When
there is little connectivity between the two brain hemispheres (as with
split-brain patients), there are two separate regions of integrated
brain activity with the larger region in the left hemisphere. Bayne
(2010) agreed in his switch model that consciousness can occur in both
hemispheres. However, he argued a single stream of consciousness
switches between the hemispheres. Which hemisphere experiences
consciousness depends on the allocation of attentional resources. The
switch model can also explain why there are relatively few disagreements
between the two hemispheres. However, there are considerable doubts
whether split-brain patients have a truly single stream of
consciousness. One reason is because most experiments are designed to
ensure each hemisphere has access to (and processes) different
information. It is more likely patients have two distinct streams of
activity even if only one is accessible to consciousness at any given
moment (Schechter, 2012). Another problem with the switch model is that
split-brain patients would "experience radical and sudden changes in the
character and content of their streams of consciousness" (Friesen, 2013,
p. 96). Gazzaniga argued that the major conscious system (the
interpreter) is based in the left hemisphere (dominant for language).
According to Marinsek and Gazzaniga (2016, p. 157), "Even though the
left hemisphere does not have access to the information presented to the
right hemisphere . . . the interpreter will often provide an explanation
for the right hemisphere's behaviour."

Findings It is relevant to consider the right hemisphere's abilities in
patients following hemispherectomy -- a procedure involving removal of
an entire cerebral

793

KEY TERM Cross-cueing The (often subtle) communication of information
from one hemisphere to the other in split-brain patients.
Hemispherectomy a radical surgical procedure in which one of the
cerebral hemispheres is destroyed and removed.

794

KEY TERMS Plasticity Changes within the brain occurring as a result of
brain damage or experience. Wada test A procedure in which one cerebral
hemisphere is anaesthetised.

Broadening horizons

hemisphere. Nearly all such patients have conscious experience following
left hemispherectomy (Blackmon, 2016). Patients following left
hemispherectomy exhibit considerable plasticity -- the remaining
hemisphere reorganises to reduce the adverse effects of removal of the
other hemisphere. If hemispherectomy of the left hemisphere occurs when
the patient is a young child, there is typically good language
development (de Bode et al., 2015). BL, a patient who had a left
hemispherectomy at the age of five, had above-average intelligence
(VanlanckerSidtis, 2004). Of major importance, there is typically
"widespread \[brain\] rewiring" (Sebastianelli et al., 2017, p. 1427)
following hemispherectomy. Additional evidence has been obtained from
the Wada test -- this involves injecting sodium amobarbital to
anaesthetise one cerebral hemisphere. Meador et al. (1997) found basic
aspects of consciousness seemed unaltered in 28% of patients when their
left hemisphere was anaesthetised and in 41% of the same patients when
their right hemisphere was anaesthetised. Before proceeding, note that
information from the left visual field goes to the right hemisphere and
information from the right visual field goes to the left hemisphere (see
Chapter 2). More generally, the left half of the body is controlled by
the right hemisphere and the right half by the left hemisphere. Note
also that the typically limited language ability of the right hemisphere
makes it hard to establish whether it has its own consciousness in
split-brain patients.

Two streams What evidence supports Sperry's view that split-brain
patients have two streams of consciousness? On that view, we might
expect to find disagreements between the two hemispheres. Such
disagreements have been reported occasionally. Mark (1996, p. 191)
discussed a patient having speech in both hemispheres: "She mentioned
she did not have feelings in her left hand. When I echoed the statement,
she said that she was not numb, and then the torrent of alternating
'Yes!' and 'No!' replies ensued, followed by a despairing, 'I don't
know!'". Baynes and Gazzaniga (2000) studied a female split-brain
patient (VJ), whose writing was controlled by the right hemisphere but
whose speech was controlled by the left hemisphere. According to Baynes
and Gazzaniga (p. 1362), "She \[VJ\] is discomfited by the fluent
writing of her left hand to unseen stimuli", which is suggestive of
limited dual consciousness. More evidence the two hemispheres of
split-brain patients can function simultaneously and independently was
reported by Schiffer et al. (1998). Patients with their hands hidden
from view behind a screen responded at the same time with each hand to
emotionally sensitive questions. The right hemisphere produced more
emotional answers. The ability to recognise one's own face generally
indicates reasonable self-awareness. However, patients with face
blindness or prosopagnosia (see Glossary) often fail to recognise their
own face despite good self-awareness. Uddin et al. (2005) found NG, a
split-brain patient, recognised her own face equally well with each
hemisphere. This suggests both hemispheres have basic self-awareness.

Consciousness

795

One dominant stream

KEY TERM

Gazzaniga (e.g., 2013) emphasised the importance of a stream of
consciousness (the interpreter) centred in the dominant left hemisphere.
This viewpoint is supported by the following observation: "No
split-brain patient has ever woken up following callostomy \[cutting of
the corpus callosum\] and felt as though his/her experience of self had
fundamentally changed or that two selves now inhabited the same body"
(Colvin & Gazzaniga, 2007, p. 189). This observation also provides
evidence against the notion that split-brain patients experience
consciousness simultaneously in both hemispheres. Gazzaniga and Ledoux
(1978) studied Paul S, a split-brain patient. He had unusually
well-developed right-hemisphere language abilities making it easier to
establish whether he had a separate consciousness in his right
hemisphere. He showed some evidence of right-hemisphere consciousness by
responding appropriately to questions using Scrabble letters with his
left hand. For example, he could spell his own name, that of his
girlfriend, his hobbies, his current mood and so on. There were some
interesting differences between Paul's hemispheres. For example, his
right hemisphere said he wanted to be a racing driver, whereas his left
hemisphere wanted to be a draughtsman! Gazzaniga (1992, 2013) discussed
other studies on Paul S. He was presented with a chicken claw to his
left hemisphere and a snow scene to his right hemisphere. When asked to
select relevant pictures from an array, he chose a chicken with his
right hand (connected to the left hemisphere) and a shovel with his left
hand (connected to the right hemisphere). The above findings may suggest
Paul S had two separate consciousnesses. However, here is how he
explained his choices: "The chicken claw goes with the chicken and you
need a shovel to clean out the chicken shed" (Gazzaniga, 1992, p. 124).
Thus, Paul S's left hemisphere was interpreting behaviour initiated by
the right hemisphere with little right-hemisphere contribution.
Similarly, PS obeyed when his right hemisphere was given the command to
walk. However, his left hemisphere explained his behaviour by saying
something such as that he wanted a Coke. Verleger et al. (2011) studied
a male patient (GH) with anarchic-hand syndrome. This is a condition
where one hand (the left in GH's case) sometimes counteracts the other
(e.g., GH put money on a shop counter with his right hand, but his left
hand took it back). GH was slower and less accurate when responding to
stimuli presented to his right hemisphere (and so requiring a left-hand
response) suggesting he had "lost control over his right hemisphere"
(p. 138). Verleger et al. (2011) found the P3 component of the
event-related potential was much smaller to stimuli presented to GH's
right hemisphere. This suggests his ability to attend to stimuli and
control processing was much less in that hemisphere. Of relevance, GH's
experiences in everyday life strongly suggested his consciousness
resided within his left hemisphere. Hesselmann et al. (2013) reported
similar findings in a male patient (AC) with severe damage to his corpus
callosum. Two stimuli (one to each hemisphere) were presented 100, 300
or 800 ms apart with instructions to respond rapidly to both stimuli. We
will focus on the ERP responses to the first stimulus. AC had a
pronounced P3 component (reflecting attention

Anarchic-hand syndrome Complex, goal-directed hand movements the patient
does not initiate voluntarily and cannot interpret.

796

Broadening horizons

Figure 16.13 Event-related potentials (ERPs) in the left hemisphere
(left-hand figure) and the right hemisphere (right-hand figure) to the
first of two stimuli by AC (a patient with severe corpus callosum
damage). The time course of the ERPs is shown on the horizontal axis in
seconds. The second stimulus was presented 100 ms (red line), 300 ms
(green line) or 800 ms (blue line) after the first stimulus (SOA =
stimulus onset asynchrony). From Hesselmann et al. (2013). Reprinted
with permission from Elsevier.

and stimulus appraisal) to left-hemisphere stimuli but no P3 component
to right-hemisphere stimuli (see Figure 16.13). These findings suggest
AC had much greater conscious access to information about stimuli
presented to the left hemisphere.

Summary and evaluation Research has not fully resolved the issue of
whether it is possible to have two separate consciousnesses. The
commonest view is that split-brain patients have conscious experience in
both hemispheres with the left hemisphere playing the dominant role.
This occurs because language processing is typically centred in the left
hemisphere and because it is the location of the interpreter or
self-supervisory system. This view is supported by findings showing the
left hemisphere overruling the right hemisphere and by the persistent
failure to observe genuine inter-hemispheric dialogue.

Consciousness

797

In contrast, the right hemisphere engages in various processing
activities (e.g., basic self-awareness; emotional processing; aspects of
visual and touch perception). Consciousness within the right hemisphere
is hard to assess fully because of its very limited language abilities.
However, research using event-related potentials supports the view there
is much less conscious awareness in the right hemisphere, a view
supported by research using the Wada test (see Glossary) on healthy
individuals. However, the right hemisphere can develop impressive
language and other abilities, and full conscious awareness in the
absence of the left hemisphere, especially if hemispherectomy occurs
early in life. The main limitation of research is that it is harder than
might be thought to interpret many of the findings. We will consider a
concrete example. Pinto et al. (2017) studied two split-brain patients
(DDV; DDC) who had been operated on many years earlier. The patients
decided whether a circle had been presented briefly; if so, they
indicated its location. They responded using their left hand, their
right hand or verbally. Note that the right hemisphere receives visual
input from the left visual field and controls the left hand. In
contrast, the left hemisphere receives visual input from the right
visual field and controls the right hand and language processing. What
would we predict? As Pinto et al. (2017) pointed out, the typical
finding is that split-brain patients only respond to left-field stimuli
when using their left hand and only respond to right-field stimuli when
using their right hand or verbally. Such findings suggest such patients
have a separate consciousness in each hemisphere. In marked contrast,
Pinto et al. found performance was very good for stimuli presented
anywhere in the visual field regardless of response type (see Figure
16.14). They concluded that these patients show "unity of consciousness"
(p. 1236). There are two major interpretive problems with Pinto et al.'s
(2017) findings. First, the patients may have learned over the years to
compensate for the lack of connections between the two hemispheres by
means of cross-cueing (communication between the hemispheres). For
example,

PRESENT ABSENT Indicate location

Verbal Left hand Right hand Detect circles DDC

DDV 1

DDV Distance error

Fraction correct

Localise circles

0 LVF

RVF

LVF

RVF

DDC

10

0 LVF

RVF

LVF

RVF

Figure 16.14 Detection and localisation of circles presented to left
visual field (LVF) or right visual field (RVF) by two patients (DDV;
DDC) responding verbally, with the left hand or with the right hand.
From Pinto et al. (2017).

798

Broadening horizons

Research activity: From intention to action

"Subtle cues may be given by minimal movements of the eyes or facial
muscles, which . . . are capable of encoding . . . the location of a
stimulus for the hemisphere that did not see it" (Volz et al., 2018,
p. 1). Second, the patients' surprisingly good performance may reflect
the involvement of a subcortical system that connects the two
hemispheres even in split-brain patients.

CHAPTER SUMMARY •

Introduction. There is a distinction between conscious content and
conscious level of consciousness. The notion of levels is oversimplified
because it implies different states of consciousness lie along a single
dimension. There is another important distinction between phenomenal or
basic consciousness and higher-level consciousness (not restricted to
the here-and-now).

•

Functions of consciousness. The functions claimed for conscious
awareness include perception, social communication, action control,
thinking beyond the here-and-now, and intensive integration of
information. The machinery used to compute information about other
people's awareness is also used to compute information about our own
awareness. Some behavioural evidence suggests perceived conscious
control of action (sense of agency) is an illusion driven by the
principles of priority, consistency and exclusivity. However, this
research mostly uses artificial situations. Cognitive neuroscience
research suggests some decision-relevant processing occurs prior to
conscious awareness. However, the modest effects do not rule out a major
role for conscious awareness.

•

Assessing consciousness and conscious experience. Our verbal reports of
our conscious experience sometimes involve underreporting because of our
attentional and memory limitations. These verbal reports can also
involve over-reporting. For example, visual perception is typically
clear and distinct in spite of the deficiencies of peripheral vision
because we use topdown processes (e.g., expectations) to fill in the
gaps in the information available to us. Patients in the vegetative
state show no behavioural signs of consciousness. However, a few show
evidence of conscious awareness based on neuroimaging data obtained
while they respond to orders. Some vegetative state patients also show
functional cortical connectivity in networks associated with conscious
awareness. There is evidence recurrent processing is typically required
for conscious visual perception because it is associated with integrated
processing within the brain.

•

Global workspace and global neuronal workspace theories. According to
global workspace theory, selective attention

Consciousness

influences the information of which we become consciously aware. Another
key assumption (also made by integrated information theory) is that
conscious awareness is associated with integrated, synchronous activity
preceded by parallel non-conscious processing in special-purpose
processors. The activity associated with consciousness involves many
brain areas, especially the prefrontal cortex, the anterior cingulate
and parts of the parietal cortex. There is reasonable support for all
the major assumptions of global workspace theory. However, research
focuses on conscious visual perception and de-emphasises consciousness
based on self-awareness and self-knowledge. Another issue is whether
integrated brain functioning is a prerequisite or merely a consequence
of conscious awareness. Finally, it has proved hard to disentangle the
relationship between selective attention and conscious awareness. •

Is consciousness unitary? Evidence from split-brain patients indicates
they probably have separate consciousnesses in each hemisphere. However,
the left hemisphere is dominant because language is typically centred in
that hemisphere and because it is the site of an interpreter that makes
sense of behaviour triggered by the right hemisphere. The limited
language abilities of the right hemisphere make it hard to assess
whether it is conscious. However, electrophysiological evidence from
split-brain patients and the Wada test on healthy individuals indicate
the right hemisphere has some conscious awareness. Interpreting findings
from split-brain patients is complex.

FURTHER READING Bayne, T., Hohwy, J. & Owen, A.M. (2016). Are there
levels of consciousness? Trends in Cognitive Sciences, 20, 405--413. Tim
Bayne and colleagues discuss ways of moving beyond simplistic accounts
based on the notion of levels of consciousness. Dehaene, S. (2014).
Consciousness and the Brain: Deciphering How the Brain Codes our
Thoughts. New York: Viking Press. Stanislas Dehaene provides a detailed
and authoritative account of consciousness from the perspective of
cognitive neuroscience. Hill, C.S. (2018). Unity of consciousness. Wiley
Interdisciplinary Reviews -- Cognitive Science, 9, e1465. Christopher
Hill reviews theoretical views on the unity of consciousness with an
emphasis on research involving split-brain patients. Kondziella, D.,
Friberg, C.K., Frokjaer, V.G., Fabricius, M. & Møller, K. (2016).
Preserved consciousness in vegetative and minimal conscious states:
Systematic review and meta-analysis. Journal of Neurology, Neurosurgery
and Psychiatry, 87, 485--492. The extent to which consciousness is
present in patients in the minimal conscious state or vegetative state
is evaluated in this meta-analytic review. Pitts, M.A., Lutsyshyna, L.S.
& Hillyard, S.A. (2018). The relationship between attention and
consciousness: An expanded taxonomy and implications for "no-report"
paradigms. Philosophical Transactions of the Royal Society B, 373
(Article no. 21070348). Michael Pitts and colleagues compare two major
theories

799

800

Broadening horizons of consciousness (global workspace theory and
recurrent processing theory) in the light of the relationship between
attention and consciousness. Tononi, G., Boly, M., Massimini, M. & Koch,
C. (2016). Integrated information theory: From consciousness to its
physical substrate. Nature Reviews Neuroscience, 17, 450--461. Giulio
Tononi and his colleagues discuss their influential integrated
information theory and the neural correlates of conscious experience.
Troscianko, E. & Blackmore, S. (2018). Consciousness: An introduction
(3rd edn). Abingdon, Oxon.: Routledge. Emily Troscianko and Susan
Blackmore provide a very readable account of all the main issues
relating to consciousness. Volz, L.J. & Gazzaniga, M.S. (2017).
Interaction in isolation: 50 years of insights from split-brain
research. Brain, 140, 2051--2060. Lukas Voltz and Michael Gazzaniga (a
leading expert) discuss issues involved in trying to understand the
conscious experience of split-brain patients.

Glossary access consciousness: a form of consciousness where its
contents are avail-

able for use by processes such as attention and memory; information
within access consciousness can be communicated to others; see
phenomenal consciousness. accommodation: a depth cue based on changes in
optical power produced by thickening of the eye's lens when an observer
focuses on close objects. achromatopsia: a condition caused by brain
damage in which there is very limited colour perception, but form and
motion perception are relatively intact. ad hominem fallacy:
discrediting an argument by attacking the person making the argument.
affect: a general term referring to evaluative (positive or negative)
reactions; it encompasses mood and emotion. affect heuristic: using
one's emotional responses to influence rapid judgements or decisions.
affective blindsight: the ability of brain-damaged patients to
discriminate among different emotional stimuli in spite of the absence
of conscious perception of those stimuli. affordances: the potential
uses of an object, which Gibson claimed are perceived directly.
agrammatism: literally, "without grammar"; a condition in which speech
production lacks grammatical structure and many function words and word
endings are omitted; there are often also problems with language
comprehension. akinetopsia: a brain-damaged condition in which motion
perception is severely impaired even though stationary objects are
perceived reasonably well. algorithm: a computational procedure
providing a specified set of steps to problem solution; see heuristic.
allocentric coding: visual or spatial coding of objects relative to each
other; see egocentric coding. allophones: variant forms of a given
phoneme; for example, the phoneme /p/ is associated with various
allophones (e.g., in pit and spit). Alzheimer's disease: a disease in
which general deterioration of the brain leads to progressive mental
degeneration.

802

Glossary

amblyopia: a condition in which one eye sends an inadequate input to the

visual cortex; colloquially known as lazy eye. Ames room: a very
distorted room that nevertheless looks normal under

certain viewing conditions. amnesia: a condition caused by brain damage
in which there is severe impairment of long-term memory (mostly
declarative memory). amygdala: a small almond-shaped subcortical
structure towards the front

of the temporal lobe strongly associated with several emotions including
fear. analogy: a comparison between two objects (or between a current
and previous problem) that emphasises similarities between them.
anaphor: a word or phrase that refers back to a previous word or phrase
(e.g., a pronoun may refer back to a given individual mentioned
earlier). anarchic-hand syndrome: complex, goal-directed hand movements
the patient does not initiate voluntarily and cannot interpret.
anchoring-and-adjustment heuristic: when someone makes an initial
estimate (the anchor) and then adjusts it to produce a final estimate,
the adjustment is generally insufficient. anomia: a condition caused by
brain damage in which there is an impaired ability to name objects.
anterior: towards the front of the brain. anterograde amnesia: reduced
capacity for new learning (and subsequent remembering) after the onset
of amnesia. Anton's syndrome: a condition found in some blind people in
which they misinterpret their visual imagery as visual perception.
aphantasia: the inability to form mental images of objects when those
objects are not present. aphasia: severe problems in the comprehension
and/or production of language caused by brain damage. apraxia: a
condition caused by brain damage in which there is greatly reduced
ability to perform purposeful or planned bodily movements in spite of
the absence of muscular damage. articulatory suppression: Rapid
repetition of a simple sound (e.g., "the the the"), which uses the
articulatory control process of the phonological loop. artificial
intelligence: this involves developing computer programs that produce
intelligent outcomes. Asperger's syndrome: an autism spectrum disorder
involving problems with social communication in spite of at least
average intelligence and no delays in language development. association:
the finding that certain symptoms or performance impairments are
consistently found together in numerous brain-damaged patients.
attentional bias: selective allocation of attention to emotionally
negative stimuli when presented simultaneously with neutral stimuli.
audience design: this involves speakers tailoring what they say to the
specific needs and knowledge of their audience. autism spectrum disorder
(ASD): a disorder involving difficulties in social interaction and
communication, and repetitive patterns of behaviour and thinking.

Glossary

autobiographical memory: long-term memory for the events of one's own

life. autostereogram: a complex two-dimensional image perceived as
three-

dimensional when not focused on for a period of time. availability
heuristic: the rule of thumb that the frequencies of events can

be estimated accurately by the subjective ease with which they can be
retrieved. back-propagation: a learning mechanism in connectionist
models based on comparing actual responses to correct ones. backward
crosstalk effect: aspects of Task 2 influence response selection and
performance speed on Task 1 in studies on the psychological refractory
period (PRP) effect. backward masking: suppression of the processing
(and conscious perception of) a stimulus by presenting a second, masking
stimulus very shortly thereafter. base-rate information: the relative
frequency of an event in a given population. Bayesian inference: a form
of statistical inference in which initial beliefs (prior probabilities)
are modified by evidence or experience to produce posterior
probabilities. belief bias: in syllogistic reasoning, the tendency to
accept invalid but believable conclusions and reject valid but
unbelievable ones. binding problem: the issue of integrating different
types of information to produce coherent visual perception. binocular
cues: cues to depth that require both eyes to be used together.
binocular disparity: a depth cue based on the slight disparity in the
two retinal images when an observer views a scene; it is the basis for
stereopsis. binocular rivalry: when two different visual stimuli are
presented one to each eye, only one stimulus is seen; the seen stimulus
alternates over time. blindsight: the ability to respond appropriately
to visual stimuli in the absence of conscious visual experience in
patients with damage to the primary visual cortex. bodily
self-consciousness: a form of self-consciousness involving bodycentred
perception (e.g., of the face, hand or trunk) based on integration of
bodily signals from several different sense modalities. body size
effect: an illusion in which misperception of one's own bodily size
causes the perceived size of objects to be misjudged. BOLD: blood
oxygen-level-dependent contrast; this is the signal measured by fMRI.
bottom-up processing: processing directly influenced by environmental
stimuli; see top-down processing. boundary extension: misremembering a
scene as having a larger surround area than was actually the case.
bounded rationality: the notion that people are as rational as the
environment and their limited processing capacity permit. bridging
inferences: inferences or conclusions drawn to increase coherence
between the current and preceding parts of a text; also known as
backward inferences.

803

804

Glossary

Broca's aphasia: a form of aphasia involving non-fluent speech and gram-

matical errors. CAPTCHA: a Completely Automated Turing test to tell
Computers and

Humans Apart involving distorted characters connected together is often
used to establish that the user of an internet website is human rather
than an automated system. cascade processing: later processing stages
start before earlier processing stages have been completed when
performing a task. case-series study: a study in which several patients
with similar cognitive impairments are tested; this allows consideration
of individual data and of variation across individuals. categorical
perception: a sound intermediate between two phonemes is perceived as
being one or other of the phonemes; a similar phenomenon is found in
vision with colour perception. category-specific deficits: disorders
caused by brain damage in which semantic memory is disrupted for certain
semantic categories. central coherence: the ability to make use of all
the information when interpreting an utterance or situation. central
executive: a modality-free, limited capacity, component of working
memory. change blindness: failure to detect various changes (e.g., in
objects) in the visual environment. change blindness blindness: the
tendency of observers to overestimate greatly the extent to which they
can detect visual changes and so avoid change blindness. Charles Bonnet
syndrome: a condition in which individuals with eye disease form vivid
and detailed visual hallucinations sometimes mistaken for visual
perception. child-directed speech: the short, simple, slowly spoken
sentences used by parents and others when talking to young children.
chromatic adaptation: changes in visual sensitivity to colour stimuli
when the illumination alters. chunks: stored units formed from
integrating smaller pieces of information. clause: a group of words
within a sentence that contains a subject and a verb. co-articulation: a
speaker's production of a phoneme is influenced by their production of
the previous sound and by preparations for the next sound. cocktail
party problem: the difficulties involved in attending to one voice when
two or more people are speaking at the same time. cognitive
architecture: comprehensive framework for understanding human cognition
in the form of computer programs. cognitive bias modification: training
typically designed to reduce attentional bias and/or interpretive bias
in anxious or depressed individuals. cognitive miser: someone who is
economical with their time and effort when performing a thinking task.
cognitive neuroscience: an approach that aims to understand human
cognition by combining information from behaviour and the brain.
cognitive psychology: an approach that aims to understand human
cognition by the study of behaviour; a broader definition also includes
the study of brain activity and structure.

Glossary

Cognitive Reflection Test: a test assessing individuals' tendencies to
over-

ride intuitive (but incorrect) answers to problems. colour constancy:
the tendency for an object to be perceived as having the

same colour under widely varying viewing conditions. common ground:
shared knowledge and beliefs possessed by a speaker and

a listener; its use facilitates communication. comorbidity: the state of
affairs when a patient has two (or more) mental

disorders at the same time. computational modelling: this involves
constructing computer programs

that simulate or mimic human cognitive processes. concepts: mental
representations of categories of objects or items. conceptual priming: a
form of priming in which there is facilitated process-

ing of stimulus meaning. conditional reasoning: a form of deductive
reasoning based on if ... then

propositions. confirmation bias: (1) a tendency for eyewitnesses' memory
to be distorted

by their prior expectations; (2) in hypothesis testing, seeking evidence
that supports one's beliefs. conjunction fallacy: the mistaken
assumption that the probability of a conjunction of two events is
greater than the probability of one of them. connectionist models:
models in computational cognitive science consisting of interconnected
networks of simple units or nodes; the networks exhibit learning through
experience and specific items of knowledge are distributed across
numerous units. connectome: a comprehensive wiring diagram of neural
connections within the brain. consolidation: a basic process within the
brain involved in establishing long-term memories; this process lasts
several hours or more and newly formed memories are fragile. converging
operations: an approach in which several methods with different
strengths and limitations are used to address a given issue. covert
attention: attention to an object in the absence of an eye movement
towards it. cross-cueing: the (often subtle) communication of
information from one hemisphere to the other in split-brain patients.
cross-modal attention: the coordination of attention across two or more
modalities (e.g., vision and audition). crosstalk: in dual-task
conditions, the direct interference between the tasks that is sometimes
found. crystallised intelligence: a form of intelligence that involves
the ability to use one's knowledge and experience effectively. cued
recall: a test of episodic memory in which previously presented
to-be-remembered items are recalled in response to relevant cues.
decision-making: making a selection from various options; if full
information is unavailable, judgement is required. declarative memory: a
form of long-term memory that involves knowing something is the case; it
involves conscious recollection and includes memory for facts (semantic
memory) and events (episodic memory); sometimes known as explicit
memory.

805

806

Glossary

decoding: using the pattern of brain activity exhibited by an individual
to a

stimulus to work out the nature of that stimulus. deductive reasoning:
reasoning to reach a conclusion from a set of prem-

ises or statements where that conclusion follows necessarily from the
assumption the premises are true; see inductive reasoning. deep
dyslexia: a condition in which reading unfamiliar words and non-words is
impaired and there are semantic errors (e.g., reading missile as
rocket). deep dysphasia: a condition involving semantic errors when
trying to repeat spoken words and a generally poor ability to repeat
spoken words and non-words. default mode network: a network of brain
regions that is active "by default" when an individual is not involved
in a current task; it is associated with internal processes including
mind-wandering, remembering the past and imagining the future.
deliberate practice: this form of practice involves the learner being
provided with informative feedback and having the chance to correct
their errors. deontic rules: rules relating to obligation and
permissibility. deontological judgements: judgements based on moral
rules and/or obligations when resolving moral dilemmas; see utilitarian
judgements. depictive representation: a representation (e.g., visual
image) resembling a picture in that objects within it are organised
spatially. diaschisis: the disruption to distant brain areas caused by a
localised brain injury or lesion. dichotic listening task: a different
auditory message is presented to each ear and attention has to be
directed to one message. dichromacy: a deficiency in colour vision in
which one of the three cone classes is missing. directed forgetting:
reduced long-term memory caused by instructions to forget information
that had been presented for learning. directed retrospection: a
technique in which individuals (e.g., writers) categorise their
immediately preceding thoughts. direct retrieval: effortless recall of
autobiographical memories triggered by a specific cue (e.g., being in
the same place as the original event); see generative retrieval.
discourse: language that is a minimum of several sentences in length; it
includes written text and connected speech. discourse markers: spoken
words and phrases that do not contribute directly to the content of what
is being said but still serve various functions (e.g., clarifying the
speaker's intentions). distinctiveness: this characterises memory traces
that are distinct or different from other memory traces stored in
long-term memory. distraction: a strategy used in emotion regulation in
which the individual disengages attention from emotional processing and
focuses on neutral information. divided attention: a situation in which
two tasks are performed at the same time; also known as multi-tasking.
dorsal: towards the top. dorsal stream: the part of the visual
processing system most involved in visually guided action.

Glossary

double conjunction fallacy: a stronger form of the conjunction fallacy
in

which a conjunction of two statements is judged more likely than each of
the statements judged separately. double dissociation: the finding that
some brain-damaged individuals have intact performance on one task but
poor performance on another task, whereas other individuals exhibit the
opposite pattern. Dunning-Kruger effect: the finding that less skilled
individuals overestimate their abilities more than those who are more
skilled. dysexecutive agraphia: severely impaired writing abilities in
individuals with damage to the frontal lobes whose central executive
functioning is generally impaired. dysexecutive syndrome: a condition in
which damage to the frontal lobes causes impairments to the central
executive component of working memory. dysgraphia: impaired ability to
write (including spelling). dyslexia: impaired ability to read not
attributable to low intelligence. echoic memory: a sensory store that
holds auditory information for approximately 2--3 seconds. ecological
validity: the applicability (or otherwise) of the findings of laboratory
studies to everyday settings. efference copy: an internal copy of a
motor command (e.g., to the eyes); it can be used to identify movement
within the retinal image that is not due to object movement in the
environment. egocentric coding: visual or spatial coding dependent on
the position of the observer's body; see allocentric coding. egocentric
heuristic: a strategy used by listeners in which they interpret what
they hear based on their own knowledge rather than knowledge shared with
the speaker. elaborative inferences: inferences based on our knowledge
of the world that involve adding details to a text that is being read
(or speech being listened to). electroencephalography (EEG): recording
the brain's electrical potentials through a series of scalp electrodes.
emotion: a short-lived affective state typically triggered by a specific
event. emotion generation: the immediate and spontaneous emotional
response to a given situation; see emotion regulation. emotion
regulation: the use of explicit (deliberate and effortful) processes or
implicit (relatively automatic) processes to change the spontaneous
emotional state (usually a negative one) produced by the
emotiongeneration process. encoding: the process by which information
contained in external stimuli is transformed into a representation that
can be stored within the memory system. encoding specificity principle:
the notion that retrieval depends on the overlap between the information
available at retrieval and the information in the memory trace.
endogenous spatial attention: attention to a stimulus controlled by
intentions or goal-directed mechanisms. episodic buffer: a component of
working memory; it is essentially passive and stores integrated
information briefly.

807

808

Glossary

episodic memory: a form of long-term memory concerned with personal

experiences or episodes occurring in a given place at a specific time.
event-related functional magnetic resonance imaging (efMRI): this is a
form of functional magnetic resonance imaging in which patterns of

brain activity associated with specific events (e.g., correct vs
incorrect responses on a memory test) are compared. event-related
potentials (ERPs): the pattern of electroencephalographic activity
obtained by averaging the brain responses to the same stimulus (or very
similar stimuli) presented repeatedly. event-based prospective memory: a
form of prospective memory that involves remembering to perform an
intended action (e.g., buying groceries) when the circumstances are
appropriate. executive functions: processes that organise and coordinate
the workings of the cognitive system to achieve current goals; key
executive functions include inhibiting dominant responses, shifting
attention and updating information in working memory. executive
processes: processes that organise and coordinate the functioning of the
cognitive system to achieve current goals. exogenous spatial attention:
attention to a given spatial location determined by "automatic"
processes. expertise: the high level of knowledge and performance in a
given domain that an expert has achieved through years of systematic
practice. explicit memory: memory that involves conscious recollection
of in-formation. explicit memory bias: the retrieval of relatively more
negative information than positive or neutral information on tests of
explicit memory. extinction: a disorder of visual attention in which a
stimulus presented to the side opposite the brain damage is not detected
when another stimulus is presented at the same time to the side of the
brain damage. face inversion effect: the finding that faces are much
harder to recognise when presented upside down; the effect of inversion
is less marked (or absent) with other objects. falsification: proposing
hypotheses and then trying to falsify them by experimental tests; the
logically correct means by which science should work, according to
Popper. figurative language: language that is not intended to be taken
literally; examples include metaphor, irony and idiom. figure-ground
segmentation: the perceptual organisation of the visual field into a
figure (object of central interest) and a ground (less important
background). flashbacks: intense emotional memories of traumatic events
that are recalled involuntarily by patients suffering from
post-traumatic stress disorder. flashbulb memories: vivid and detailed
personal memories of dramatic events (e.g., 9/11). fluid intelligence:
non-verbal reasoning ability applied to novel problems. focal task: an
ongoing task that involves similar processing to that involved in
encoding the target on a prospective-memory task performed at the same
time; see non-focal task.

Glossary

focused attention: a situation in which individuals try to attend to
only

one source of information while ignoring other stimuli; also known as
selective attention. focus of expansion: the point towards which someone
in motion is moving; it does not appear to move. fovea: a small area
within the retina, in the centre of the field of vision where visual
acuity is greatest. framing effect: the finding that decisions can be
influenced by situational aspects (e.g., problem wording) irrelevant to
optimal decision-making. free recall: a test of episodic memory in which
previously presented to-be-remembered items are recalled in any order.
free will: the notion that we freely or voluntarily choose what to do
from various options. Freudian slip: a speech error that reveals the
speaker's (often unconscious) sexual desires. functional fixedness: the
inflexible focus on the usual function(s) of an object in problem
solving. functional magnetic resonance imaging (fMRI): a technique based
on imaging blood oxygenation using an MRI machine; it provides
information about the location and time course of brain processes.
functional specialisation: the assumption that each brain area or region
is specialised for a specific function (e.g., colour processing; face
processing). fusiform face area: an area that is associated with face
processing; the term is somewhat misleading given that the area is also
associated with processing other categories of objects. Ganong effect:
the finding that perception of an ambiguous phoneme is biased towards a
sound that produces a word rather than a non-word. gene-environment
correlation: genetic differences between individuals partly determine
the different environments they experience. gene-environment
interaction: individuals differing in their genetic make-up respond in
different ways to environmental variation. generalised anxiety disorder:
a condition involving excessive anxiety and worry across many areas of
everyday life. generative retrieval: deliberate or voluntary
construction of autobiographical memories based on an individual's
current goals; see direct retrieval. grammar: the set of rules governing
the structure of a language (especially syntax and inflections).
grapheme: a small unit of written language corresponding to a phoneme
(e.g., the ph in photo). graphemic buffer: a store in which graphemic
information about the individual letters in a word is held immediately
prior to spelling the word. gyrus: prominent elevated area or ridge on
the brain's surface; ("gyri" is the plural). hallucinations: perceptual
experiences that appear real even though the individuals or objects
perceived are not present. haptic: relating to the sense of touch.
hemifield: one half of the visual field; information from the left
hemifield of each eye proceeds to the right hemisphere and information
from the right hemifield proceeds to the left hemisphere.

809

810

Glossary

hemispherectomy: a radical surgical procedure in which one of the
cerebral

hemispheres is destroyed and removed. heuristic: rule of thumb that is
cognitively undemanding and often produces approximately accurate
answers; see algorithm. highly superior autobiographical memory (HSAM):
exceptional ability to recall autobiographical memories in detail,
generally accompanied by

only average ability to recall other memories. hill climbing: a simple
heuristic used by problem solvers in which they focus

on making moves that will apparently put them closer to the goal.
hippocampal neurogenesis: the process of generating new neurons in the

hippocampus during early development. holistic processing: processing
that involves integrating information from

an entire object (especially faces). hollow-face illusion: a concave
face mask is misperceived as a normal face

when viewed from several feet away. homophones: words pronounced in the
same way but that differ in their

spellings (e.g., pain-pane; sale-sail). Honi phenomenon: the typical
apparent size changes when an individual walks along the rear wall of
the Ames room are reduced when female

observers view a man to whom they are very close emotionally. iconic
memory: a sensory store that holds visual information for

approximately 250--1000 milliseconds following the offset of a visual
stimulus. ill-defined problems: problems in which the problem is
imprecisely specified; for example, the initial state, goal state and
the methods available to solve the problem may be unclear. illuminant: a
source of light illuminating a surface or object. illusory conjunction:
mistakenly combining features from two different stimuli to perceive an
object that is not present. impact bias: overestimation of the intensity
and duration of negative emotional reactions to losses and positive
emotional reactions to gains. impasse: the experience of being blocked
and not knowing how to proceed when engaged in problem solving.
implacable experimenter: the situation in experimental research in which
the experimenter's behaviour is uninfluenced by the participant's
behaviour. implementation intentions: action plans designed consciously
to achieve some goal (e.g., healthier eating) based on specific
information concerning where, when and how the goal will be achieved.
implicit learning: learning complex information without conscious
awareness of what has been learned. implicit memory: memory that does
not depend on conscious recollection. implicit memory bias: relatively
better memory performance for negative than for neutral or positive
information on tests of implicit memory. inattentional blindness:
failure to detect an unexpected object appearing in the visual
environment. incidental emotions: emotions experienced while engaged in
making a judgement or decision that are irrelevant to the judgement or
decision. incremental validity: the ability of a new test to predict
behaviour or other outcomes to a greater extent than existing tests.

Glossary

incubation: a stage of problem solving in which the problem is put to
one

side for some time; it is claimed to facilitate problem solving.
inductive reasoning: forming generalisations (that may be probable but
are not certain) from examples or sample phenomena; see deductive
reasoning. infantile amnesia: the inability of adults to recall
autobiographical memories from early childhood; also known as childhood
amnesia. inferior: towards the bottom of the brain. inflections:
grammatical changes to nouns or verbs (e.g., adding -s to a noun

to indicate the plural; adding -ed to a verb to indicate the past
tense). informal reasoning: a form of reasoning based on one's relevant
knowledge

and experience rather than logic. inhibition of return: a reduced
probability of visual attention returning to a

recently attended location or object. inner scribe: according to Logie,
the part of the visuo-spatial sketchpad

dealing with spatial and movement information. insight: the experience
of suddenly realising how to solve a problem; some-

times referred to as the "the Aha! experience". instrumental
rationality: maximising the utility (subjective value) of one's

choices or decision with respect to achieving task-related goals.
integral emotions: emotions experienced while engaged in making a judge-

ment or decision that arise from the judgement or decision.
interoception: sensitivity to bodily stimuli (especially
emotion-relevant

ones) whether at the conscious or non-conscious level. interpretive
bias: the tendency when presented with ambiguous stimuli or

situations to interpret them in a negative way. introspection: a careful
examination and description of one's own mental

thoughts. invariants: properties of the optic array that remain constant
even though

other aspects vary; part of Gibson's theory. Iowa gambling task: a task
in which participants are presented with four

decks of cards; they are told some cards in each deck will produce
financial rewards whereas other cards will produce financial losses; two
decks produce immediate high gains but larger losses in the long run
(risky decks), whereas the other two decks have immediate low gains
followed by smaller losses and produce an overall net gain. jargon
aphasia: a brain-damaged condition in which speech is reasonably
correct, grammatically, but there are severe problems in accessing the
appropriate words. judgement: an assessment of the probability of a
given event occurring based on incomplete information. knowledge effect:
the tendency to assume others possess the same knowledge as us.
knowledge-lean problems: problems that can be solved by individuals in
the absence of specific relevant prior knowledge. knowledge-rich
problems: problems that can only be solved by those having considerable
relevant background knowledge. Korsakoff's syndrome: amnesia (impaired
long-term memory) caused by chronic alcoholism. lateral: situated at the
side of the brain.

811

812

Glossary

lateral inhibition: reduction of activity in one neuron caused by
activity in

a neighbouring neuron. law of Prägnanz: the notion that the simplest
possible organisation of the

visual environment is perceived; proposed by the gestaltists. lemmas:
abstract words possessing syntactic and semantic features but not

phonological ones. lesion: damage within the brain resulting from injury
or disease; it typically

affects a restricted area. lexical access: accessing detailed
information about a given word by entering the lexicon. lexical bias
effect: the tendency for speech errors to form words rather

than non-words. lexical decision task: participants presented with a
string of letters or audi-

tory stimulus decide rapidly whether it forms a word. lexicalisation:
the process of translating a word's meaning into its sound

representation during speech production. lexical parafoveal-on-foveal
effects: the finding that fixation duration on

the current word (word n) is influenced by lexical properties of the
next word (word n+1). lexicon: an individual's internal dictionary
containing information about word meanings. lexigrams: symbols used to
represent words in studies on communication. life script: a schema based
on cultural expectations concerning the nature and order of a typical
person's major life events. limb apraxia: a condition caused by brain
damage in which individuals have impaired ability to make skilled,
goal-directed movements towards objects even though they possess the
physical ability to perform them. linguistic relativity: the notion that
speakers of different languages think differently. linguistic
universals: features (e.g., preferred word orders; the distinction
between nouns and verbs) found in the great majority of the world's
languages. logical inferences: inferences that follow necessarily from
the meanings of word (e.g., a bachelor is a man who is unmarried).
long-term working memory: used by experts to store relevant information
rapidly in long-term memory and to access it through retrieval cues in
working memory. loss aversion: the finding that losses have a greater
subjective impact on individuals than gains of the same magnitude.
luminance: the intensity of light reflected from a surface or object.
magneto-encephalography (MEG): a non-invasive brain-scanning technique
based on recording the magnetic fields generated by brain activity; it
has good spatial and temporal resolution. major depressive disorder: a
mental disorder characterised by depressed mood, tiredness and lack of
pleasure and interest in various activities. matching bias: the tendency
on the Wason selection task to select cards matching the items
explicitly mentioned in the rule. McGurk effect: a mismatch between
spoken and visual (lip-based) information leads listeners to perceive a
sound or word involving a blending of the auditory and visual
information.

Glossary

means-ends analysis: a heuristic method for solving problems based on

creating a subgoal to reduce the difference between the current state
and the goal state. medial: situated in the middle of the brain.
mentalising: the ability to perceive and interpret behaviour in terms of
mental states (e.g., goals; needs). mental model: an internal
representation of some possible situation or event in the world having
the same structure as that situation or event. mental set: the tendency
to use a familiar problem-solving strategy that has proved successful in
the past even when it is no longer appropriate; also known as
Einstellung. meta-analysis: a form of statistical analysis based on
combining the findings from numerous studies on a given research topic.
meta-cognition: beliefs and knowledge concerning one's own cognitive
processes and likely level of performance. meta-memory: beliefs and
knowledge about one's own memory including strategies for learning and
memory. metaphor interference effect: the finding that it takes longer
to judge whether metaphorical sentences are literally true or false than
control sentences. meta-reasoning: monitoring processes that influence
the time, effort and strategies used during reasoning and problem
solving. minimally conscious state: a condition in which patients
exhibit partial preservation of conscious awareness. mirror neuron
system: neurons that respond to actions whether performed by oneself or
someone else; it is claimed these neurons assist in imitating (and
understanding) the actions of others. misery-is-not-miserly effect: the
tendency for sad individuals to be willing to pay more for some products
than other people. misinformation effect: the distorting effect on
eyewitness memory of misleading information presented after a crime or
other event. mixed-error effect: a form of speech error in which the
incorrect word spoken is related to the correct one in terms of both
meaning and sound. modularity: the assumption that the cognitive system
consists of many fairly independent or separate modules or processors,
each specialised for a given type of processing. monocular cues: cues to
depth that can be used by one eye but can also be used by both eyes
together. mood: state resembling emotion but generally longer lasting,
less intense and of unknown cause. mood congruity: learning and memory
of emotional material are better when the learner's/rememberer's mood
state matches the affective value of the material than when it does not.
mood-state-dependent memory: memory performance is better when the
individual's mood state is the same at learning and retrieval than when
it differs. morphemes: the basic units of meaning; words consist of one
or more morphemes. morphology: the study of words and how they are
formed from morphemes.

813

814

Glossary

motion parallax: a depth cue based on movement in one part of the
retinal

image relative to another. multi-tasking: performing two or more tasks
at the same time by switching

rapidly between them. mutual illumination: the light reflected from the
surface of an object

impinges on the surface of a second object. myopic misery: the notion
that misery or sadness leads to an excessive

focus on replacing lost rewards. myside bias: in informal reasoning, the
tendency to select and interpret

information in terms of one's own beliefs or to generate reasons or
arguments supporting those beliefs. naming task: a task in which
visually presented words are pronounced aloud rapidly. negative
afterimages: the illusory perception of the complementary colour to the
one that has just been fixated; green is the complementary colour to red
and blue is complementary to yellow. neglect: a disorder involving
right-hemisphere damage (typically) in which the left side of objects
and/or objects presented to the left visual field are undetected; the
condition resembles extinction but is more severe. neologisms: made-up
words produced by patients suffering from jargon aphasia. neural
decoding: using computer-based analyses of patterns of brain activity to
work out which stimulus an individual is processing. neural network
models: computational models in which processing involves the
simultaneous activation of numerous interconnected nodes (basic units).
nodes: the basic units within a neural network model. non-declarative
memory: forms of long-term memory that influence behaviour but do not
involve conscious recollection (e.g., priming; procedural memory); also
known as implicit memory. non-focal task: an ongoing task that involves
different processes to those involved in encoding the target on a
prospective-memory task performed at the same time; see non-focal task.
normativism: the notion that human thinking should be regarded as
"correct" or "incorrect" depending on how closely it follows certain
norms or standards (e.g., those of classical logic).
obsessive-compulsive disorder (OCD): an anxiety disorder in which the
symptoms include unwanted thoughts (obsessions) and repetitive
behaviours (compulsions) in response to those thoughts. oculomotor cues:
cues to depth produced by muscular contractions of the muscles around
the eye; use of such cues involves kinaesthesia (also known as the
muscle sense). omission bias: a biased preference for risking harm
through inaction compared to risking harm through action. ongoing task:
a task performed at the same time as a prospective-memory task in
studies on prospective memory. open-object illusion: the misperception
that objects with missing boundaries are larger than objects the same
size without missing boundaries.

Glossary

operation span: the maximum number of items (arithmetical questions +

words) for which an individual can recall all the words more than 50% of
the time. optic array: the structural pattern of light falling on the
retina. optic ataxia: a condition in which there are problems making
visually guided movements in spite of reasonably intact visual
perception. optic flow: the changes in the pattern of light reaching an
observer when there is movement of the observer and/or aspects of the
environment. optimism bias: the tendency to exaggerate our chances of
experiencing positive events and to minimise our chances of experiencing
negative events relative to other people. orthographic lexicon: part of
long-term memory in which learned word spellings are stored.
orthographic neighbours: with reference to a target word, the number of
words that can be formed by changing one of its letters. orthographic
working memory: a store in which information about the individual
letters in a word (and their ordering) is held immediately prior to
spelling the word. orthography: the study of letters and word spellings.
other-race effect: the finding that recognition memory for same-race
faces is generally more accurate than for other-race faces. out-of-body
experiences: vivid feelings of being outside of (and detached from)
one's own body. own-age bias: the tendency for eyewitnesses to identify
the culprit more often when they are of similar age to the eyewitness
than when they are of a different age. paradigm specificity: the
findings with a given experimental task or paradigm are not replicated
even when apparently very similar tasks or paradigms are used.
parafovea: the area in the retina immediately surrounding the fovea.
parallel processing: processing in which two or more cognitive processes
occur at the same time. Parkinson's disease: a progressive disorder
involving damage to the basal ganglia (including the striatum); the
symptoms include muscle rigidity, limb tremor and mask-like facial
expression. parsing: analysing the syntactical or grammatical structure
of sentences. part-whole effect: the finding that a face part is
recognised more easily when presented in the context of a whole face
rather than on its own. pattern recognition: the ability to identify or
categorise two-dimensional patterns (e.g., letters; fingerprints).
perceptual priming: a form of priming in which repeated presentations of
a stimulus facilitates its perceptual processing. perceptual span: the
effective field of view in reading (letters to the left and right of
fixation that can be processed). personal semantics: aspects of one's
personal or autobiographical memory that combine elements of episodic
memory and semantic memory. phenomenal consciousness: direct conscious
experience; see access consciousness.

815

816

Glossary

phonemes: the smallest units of sound that distinguish one word from

another and contribute to word meaning; the number and nature of
phonemes varies across languages. phonemic restoration effect: the
finding that listeners are unaware that a phoneme has been deleted and
replaced by a non-speech sound (e.g., cough) within a sentence.
phonological dysgraphia: a condition caused by brain damage in which
familiar words can be spelled reasonably well but unfamiliar words and
non-words cannot. phonological dyslexia: a condition in which familiar
words can be read but there is impaired ability to read unfamiliar words
and non-words. phonological loop: a component of working memory in which
speechbased information is processed and stored briefly and subvocal
articulation occurs. phonological neighbourhood: words are phonological
neighbours if they differ in only one phoneme (e.g., wipe, pipe and tap
are phonological neighbours of type). phonological output lexicon: it
contains information about the spoken form of words (e.g., number of
syllables) and is used in object naming and reading aloud. phonological
similarity effect: the finding that immediate serial recall of verbal
material is reduced when the items sound similar. phonology: the study
of the sounds of words and parts of words. phrase: a group of words
within a sentence expressing a single idea. plasticity: changes within
the brain occurring as a result of brain damage or experience. positron
emission tomography (PET): a brain-scanning technique based on the
detection of positrons; it has reasonable spatial resolution but poor
temporal resolution. posterior: towards the back of the brain.
pragmatics: the study of the ways in which language is used and
understood in the real world including a consideration of its intended
meaning; in general, the impact of contextual factors on meaning.
predictive inferences: expectations concerning what will happen next
(e.g., a new event) when reading text or listening to someone.
preformulation: the production by speakers of phrases used frequently
before; it reduces the demands of speech production. priming:
facilitating the processing of (and response) to a target stimulus by
presenting a stimulus related to it shortly beforehand. principle of
truth: the notion that assertions are represented by forming mental
models concerning what is true while ignoring what is false. proactive
interference: disruption of memory by previous learning (especially of
similar material). problem space: an abstract description of all the
possible states that can occur within a given problem. procedural
memory: this is memory concerned with knowing how and it includes the
knowledge required to perform skilled actions. process-dissociation
procedure: on learning tasks, participants try to guess the next
stimulus (inclusion condition) or avoid guessing the next

Glossary

stimulus accurately (exclusion condition); the difference between the
two conditions indicates the amount of explicit learning. production
rules: "IF ... THEN or condition-action rules in which the action is
carried out whenever the appropriate condition is present. production
systems: these consist of very large numbers of "IF ... THEN" production
rules and a working memory containing information. proposition: a
statement making an assertion or denial which can be true or false.
proprioception: an individual's awareness of the position and
orientation of parts of their body. prosodic cues: features of spoken
language such as stress, intonation, pauses and duration making it
easier for listeners to work out grammatical structure and meaning;
similar cues are often present in texts (e.g., commas; semi-colons).
prosopagnosia: a condition (also known as face blindness) in which there
is a severe impairment in face recognition but much less impairment of
object recognition; it is often the result of brain damage (acquired
prosopagnosia) but can also be due to impaired development of
face-recognition mechanisms (developmental prosopagnosia). prospective
memory: remembering to carry out some intended action in the absence of
an explicit reminder to do so; see retrospective memory. pseudo-neglect:
a slight tendency in healthy individuals to favour the left side of
visual space. pseudowords: non-words consisting of strings of letters
that can be pronounced (e.g., mantiness; fass). psychological refractory
period (PRP) effect: the slowing of the response to the second of two
stimuli when presented close together in time. pure alexia: severe
problems with reading but not other language skills; caused by damage to
brain areas involved in visual processing. pure word deafness: a
condition involving severely impaired speech perception but intact
speech production, reading, writing and perception of non-speech sounds.
rationalisation: in Bartlett's theory, errors in story recall that
conform to the rememberer's cultural expectations. reading span: the
largest number of sentences read for comprehension from which an
individual can recall all the final words over 50% of the time.
reappraisal: a strategy used in emotion regulation in which the
individual elaborates emotional information from an event prior to
changing its meaning. receptive field: the region of the retina in which
light influences the activity of a particular neuron. recognition
heuristic: using the knowledge that only one out of two objects is
recognised as the basis for making a judgement. reconsolidation: this is
a new process of consolidation occurring when a previously formed memory
trace is reactivated; it allows that memory trace to be updated.
recovered memories: childhood traumatic memories forgotten for several
years and then remembered in adult life. recursion: turning simple
sentences into longer and more complex ones by placing one or more
additional clauses within them.

817

818

Glossary

reminiscence bump: the tendency of older people to recall a
disproportion-

ate number of autobiographical memories from adolescence and early
adulthood. Remote Associates Test: this involves finding a word that is
related to three given words (e.g., opera, hand and dish are all related
to soap). repetition enhancement: the finding that stimulus repetition
sometimes leads to increased brain activity; however, stimulus
repetition more often leads to repetition suppression. repetition
priming: the finding that processing of a stimulus is facilitated if it
has been processed previously. repetition suppression: the finding that
stimulus repetition often leads to reduced brain activity (typically
with enhanced performance via priming). repetitive transcranial magnetic
stimulation (rTMS): the administration of transcranial magnetic
stimulation several times in rapid succession. replication: the ability
to repeat a previous experiment and obtain the same (or similar)
findings. representativeness heuristic: the assumption that an object or
individual belongs to a specified category because it is representative
(typical) of that category. repression: motivated forgetting of
traumatic or other threatening events (especially from childhood).
retinal flow field: the changing patterns of light on the retina
produced by movement of the observer relative to the environment as well
as by eye and head movements. retinal ganglion cells: retinal cells
providing the output signal from the retina. retinopy: the notion that
there is mapping between receptor cells in the retina and points on the
surface of the visual cortex. retroactive interference: disruption of
memory for previously learned information by other learning or
processing occurring during the retention interval. retrograde amnesia:
impaired ability of amnesic patients to remember information and events
from the time period prior to the onset of amnesia. retrospective
memory: memory for events, people and so on experienced in the past; see
prospective memory. reverse inference: as applied to functional
neuroimaging, it involves arguing backwards from a pattern of brain
activation to the presence of a given cognitive process. risk aversion:
a preference for certain gains over potentially larger (but less
certain) gains. rostral: towards the front of the brain. saccades: rapid
eye movements separated by eye fixations lasting about 250 ms.
satisficing: simplifying the decision-making process by using heuristics
and ignoring some relevant information sources; the term represents a
blend of the words satisfactory and sufficing. savings method: a measure
of forgetting introduced by Ebbinghaus in which the number of trials for
relearning is compared against the number for original learning.

Glossary

saying-is-believing effect: tailoring a message about an event to suit a

given audience causes subsequent inaccuracies in memory for that event.
schemas: organised packets of information about the world, events or
people stored in long-term memory. script: a form of schema containing
information about a sequence of events (e.g., events during a typical
restaurant meal). segmentation: dividing the almost continuous sounds of
speech into separate phonemes and words. selective exposure: a
preference for information that strengthens pre-existing views and
avoidance of information conflicting with those views. semantic
dementia: a condition involving damage to the anterior temporal lobes
involving widespread loss of information about the meanings of words and
concepts; however, episodic memory and executive functioning are
reasonably intact initially. semanticisation: the phenomenon of episodic
memories changing into semantic memories over time. semantic memory: a
form of long-term memory consisting of general knowledge about the
world, concepts, language and so on. semantic priming: the finding that
word recognition is facilitated by the prior presentation of a
semantically related word. semantics: the study of the meaning conveyed
by words, phrases and sentences. sense of agency: the belief we are
determining our own actions. serial dependence: systematic bias of
current visual perception towards recent visual input. serial
processing: processing in which one process is completed before the next
one starts; see parallel processing. serial reaction time task:
participants on this task respond as rapidly as possible to stimuli
typically presented in a repeating sequence; it is used to assess
implicit learning. serial recall: a test of episodic memory in which
previously presented to-be-remembered items must be recalled in the
order of presentation. shadowing: repeating one auditory message word
for word as it is presented while a second auditory message is also
presented; it is used on the dichotic listening task. shooter bias: the
tendency for unarmed black individuals to be more likely than unarmed
white individuals to be shot. single-unit recording: an invasive
technique for studying brain function, permitting the study of activity
in single neurons. size constancy: objects are perceived to have a given
size regardless of the size of the retinal image. slippery slope
argument: the claim that an innocuous first step will lead to an
undesirable outcome; sometimes regarded as a fallacy. social cognition:
an approach within social psychology in which the emphasis is on the
cognitive processing of information about other people and social
situations. solution aversion: a bias in reasoning in which individuals
deny the existence of a problem (e.g., climate change) because they
dislike the proposed solution (e.g., restricting damaging emissions).

819

820

Glossary

spillover effect: any given word is fixated longer during reading when

preceded by a rare word rather than a common one. split attention:
allocation of attention to two (or more) non-adjacent

regions of visual space. split-brain patients: patients in whom most of
the direct links between the

two hemispheres of the brain have been severed. spoonerism: a speech
error in which the initial letter or letters of two words

(typically close together) are switched to form two different words.
spreading activation: activation of a node (corresponding to a word or

concept) in the brain causes some activation to spread to several
related nodes or words. status quo bias: a preference for maintaining
the status quo (present state) rather than acting to change their
decision. stereopsis: depth perception based on the small discrepancy in
the two retinal images when a visual scene is observed (binocular
disparity). stimulus onset asynchrony (SOA): time interval between the
start of two stimuli. straw man fallacy: refuting an opponent's views by
misrepresenting them in some way. striatum: it forms part of the basal
ganglia and is located in the upper part of the brainstem and the
inferior part of the cerebral hemispheres. Stroop task: a task in which
participants have to name the ink colours in which colour words are
printed; performance is slowed when the to-benamed colour (e.g., green)
conflicts with the colour word (e.g., red). subadditivity effect: the
judged probability of the whole is less than the combined probabilities
of its parts. subliminal perception: perceptual processing occurring
below the level of conscious awareness that can nevertheless influence
behaviour. sulcus: a groove or furrow in the surface of the brain.
sunk-cost effect: investing additional resources to justify a previous
commitment that has so far proved unsuccessful. superior: towards the
top. super-recognisers: individuals with an outstanding ability to
recognise faces. surface dysgraphia: a condition caused by brain damage
in which there is impaired spelling of irregular words but reasonably
accurate spelling of regular words and non-words. surface dyslexia: a
condition in which regular words and non-words can be read but there is
impaired ability to read irregular or exception words. syllable: a unit
of speech consisting of one vowel sound with or without one or more
additional consonants (e.g., water has two syllables: wa and ter).
syllogism: a type of problem used in deductive reasoning; there are two
statements or premises and a conclusion that may or may not follow
logically from the premises. synaesthesia: the tendency for one sense
modality to evoke another. syndrome: the notion that symptoms that often
co-occur have a common origin.

Glossary

syntactic priming: the tendency for a speaker's utterances to have the
same

syntactic structure as those they have heard shortly beforehand. syntax:
the set of rules concerning word order to create well-formed

sentences. tangent point: from a driver's perspective, the point on a
road at which the

direction of its inside edge appears to reverse. template: as applied to
chess, an abstract schematic structure consisting

of a mixture of fixed and variable information about chess pieces and
positions. temporal ventriloquism effect: misperception of the timing of
a visual stimulus when an auditory stimulus is presented close to it in
time. testing effect: the finding that long-term memory is enhanced when
some of the learning period is devoted to retrieving to-be-learned
information rather than simply studying it. texture gradient: the rate
of change of texture density from the front to the back of a slanting
object. time-based prospective memory: a form of prospective memory,
which involves remembering to carry out an intended action at the
appropriate time. tip-of-the-tongue state: the frustrating experience of
being unable to find the correct word to describe a given concept or
idea. top-down processing: stimulus processing that is influenced by
factors such as the individual's past experience and expectations. trait
anxiety: a personality dimension based on individual differences in
susceptibility to anxiety. transcortical sensory aphasia: a condition in
which spoken words can be repeated but comprehension of spoken and
written language is severely impaired. transcranial direct current
stimulation (tDCS): a technique in which a very weak electrical current
is passed through an area of the brain (often for several minutes);
anodal tDCS often enhances performance, whereas cathodal tCDS often
impairs it. transcranial magnetic stimulation (TMS): a technique in
which magnetic pulses briefly disrupt the functioning of a given brain
area. It is often claimed that it creates a short-lived "lesion". More
accurately, TMS causes interference when the brain area to which it is
applied is involved in task processing as well as activity produced by
the applied stimulation. unconscious inference: the tendency of
eyewitnesses to misidentify a familiar (but innocent) face as being the
person responsible for a crime. underadditivity: the finding that brain
activation when tasks A and B are performed at the same time is less
than the sum of the brain activation when tasks A and B are performed
separately. underspecification: a strategy used to reduce processing
costs in speech production by using simplified expressions. uniform
connectedness: the notion that adjacent regions in the visual
environment having uniform visual properties (e.g., colour) are
perceived as a single perceptual unit. uniqueness point: the point in
time in spoken word recognition at which the available perceptual
information is consistent with only one word.

821

822

Glossary

Urbach-Wiethe disease: a disease in which the amygdala and adjacent

areas are destroyed; patients with this disease have impaired emotional
processing. utilitarian judgements: judgements based on practical and
pragmatic considerations when resolving moral dilemmas; see
deontological judgements. utility: how rewarding or satisfying a given
outcome is perceived to be subjectively. valence: the positive or
negative character of emotional experience. vegetative state: a
brain-damaged condition in which patients exhibit wakefulness but lack
conscious awareness. ventral: towards the bottom. ventral stream: the
part of the visual processing system most involved in object perception
and recognition, and the formation of perceptual representations.
ventriloquism effect: the mistaken perception that sounds are coming
from their apparent source (as in ventriloquism). verb bias: an
imbalance in the frequency with which a verb is associated with
different syntactic structures. vergence: a cue to depth based on the
inward focus of the eyes with close objects. visual buffer: within
Kosslyn's theory, a short-term visual memory store involved in visual
imagery and perception. visual cache: according to Logie, the part of
the visuo-spatial sketchpad that stores information about visual form
and colour. visual crowding: the inability to recognise objects in
peripheral vision due to the presence of neighbouring objects. visual
form agnosia: a condition in which there are severe problems in shape
perception (what an object is) but apparently reasonable ability to
produce accurate visually guided actions. visual search: a task
involving the rapid detection of a specified target stimulus within a
visual display. visuo-spatial sketchpad: a component of working memory
used to process visual and spatial information and to store this
information briefly. Wada test: a procedure in which one cerebral
hemisphere is anaesthetised. weapon focus effect: the finding that
eyewitnesses pay so much attention to the presence of a weapon (e.g.,
gun) that they ignore other details and so cannot remember them
subsequently. well-defined problems: problems in which the initial
state, the goal and the methods available for solving them are clearly
laid out. Wernicke's aphasia: a form of aphasia involving fluent speech
with many content words missing and impaired comprehension. Whorfian
hypothesis: the theoretical assumption that language influences
perception, thinking and behaviour. word-length effect: the finding that
verbal memory span decreases when longer words are presented. word
meaning deafness: a condition in which there is selective impairment of
the ability to understand spoken (but not written) language. word
superiority effect: a target letter is more readily detected in a letter
string when the string forms a word than when it does not.

Glossary

working memory: a limited-capacity system used in the processing and

brief holding of information. working memory capacity: an assessment of
how much information can be

processed and stored at the same time; individuals with high capacity
have higher intelligence and more attentional control.

823

References Aarts, H. & van den Bos, K. (2011). On the foundations of
beliefs in free will: Intentional binding and unconscious priming in
self-agency. Psychological Science, 22, 532--537. Aberegg, S.K.,
Haponik, E.F. & Terry, P.B. (2005). Omission bias and decision making in
pulmonary and critical care medicine. Chest, 128, 1497--1505.
Abdellaoui, M., Bleichrodt, H. & Kammoun, H. (2013). Do financial
professionals behave according to prospect theory? An experimental
study. Theory and Decision, 74, 411--429. Ablinger, I. & Radach, R.
(2016). Diverging receptive and expressive word processing mechanisms in
a deep dyslexic reader. Neuropsychologia, 81, 12--21. Ablinger, I.,
Abel, S. & Huber, W. (2008). Deep dysphasia as a phonetic input deficit:
Evidence from a single case. Aphasiology, 22, 537--556. Abramov, I. &
Gordon, J. (1994). Colour appearance -- on seeing red -- or yellow, or
green, or blue. Annual Review of Psychology, 45, 451--485. Achim, A.M.,
Achim, A. & Fossard, M. (2017). Knowledge likely held by others affects
speakers' choices of referential expressions at different stages of
discourse. Language, Cognition, and Neuroscience, 32, 21--36. Ackerman,
P.L. (2014). Nonsense, common sense, and science of expert performance:
Talent and individual differences. Intelligence, 45, 6--17. Ackerman, R.
& Thompson, V.A. (2017). Meta-reasoning: Monitoring and control of
thinking and reasoning. Trends in Cognitive Sciences, 21, 607--617.
Ackerman, P.L., Beier, M.E. & Boyle, M.O. (2005). Working memory and
intelligence: The same or different constructs? Psychological Bulletin,
131, 30--60. Aczel, B., Lukacs, B., Komlos, J. & Aitken, M.R.F. (2011).
Unconscious intuition or conscious analysis? Critical questions for the
deliberation-without-attention paradigm. Judgment and Decision Making,
6, 351--358. Adank, P. (2012). The neural bases of difficult speech
comprehension and speech production: Two Activation

Likelihood Estimation (ALE) meta-analyses. Brain & Language, 122,
42--54. Addis, D.R. (2018). Are episodic memories special? On the
sameness of remembered and imagined event simulation. Journal of the
Royal Society of New Zealand, 48, 64--88. Addis, D.R., Knapp, K.,
Roberts, R.P. & Schacter, D.L. (2012). Routes to the past: Neural
substrates of direct and generative autobiographical memory retrieval.
NeuroImage, 59, 2908--2922. Addyman, C. & French, R.M. (2012).
Computational modelling in cognitive science: A manifesto for change.
Topics in Cognitive Science, 4, 332--341. Adelman, J.S., Sabatos-De
Vito, M.G., Marquis, S.J. & Estes, Z. (2014). Individual differences in
reading aloud: A mega-study, item effects, and some models. Cognitive
Psychology, 68, 113--160. Adlam, A.-L.R., Patterson, K. & Hodges, J.R.
(2009). "I remember it as if it were yesterday": Memory for recent
events in patients with semantic dementia. Neuropsychologia, 47,
1344--1351. Adolphs, R., Tranel, D. & Buchanan, T.W. (2005). Amygdala
damage impairs emotional memory for gift but not details of complex
stimuli. Nature Neuroscience, 8, 512--518. Adriaanse, M.A., Prinsen, S.,
de Witt Huberts, J.C., de Ridder, D.T.D. & Evers, C. (2016). "I ate too
much so I must have been sad": Emotions as a confabulated reason for
overeating. Appetite, 103, 318--323. Aggleton, J.P. (2013).
Understanding HM -- Is it time to forget HM? Psychologist, 26, 612--614.
Ahtamad, M., Spence, C., Ho, C. & Gray, R. (2016). Warnings drivers
about impending collisions using vibrotactile flow. IEEE Transactions on
Haptics, 9, 134--141. Aikin, S.F. & Casey, J.P. (2016). Straw men, iron
men, and argumentative virtue. Topoi, 35, 431--440. Ajina, S., Pastilli,
F., Rokem, A., Kennard, C. & Beridge, H. (2015). Human blindsight is
mediated by an intact geniculoextrastriate pathway. eLIFE, 4 (Article
no. e08935). Akhtar, S., Justice, L.V., Morrison, C.M. & Conway, M.A.
(2018). Fictional first memories. Memory, 29, 1612--1619.

References Alain, C., Du, Y., Bernstein, L.J., Barten, T. & Banai, K.
(2018). Listening under difficult conditions: An activation likelihood
estimation meta-analysis. Human Brain Mapping, 39, 2695--2709. Alais, D.
& Burr, D. (2004). The ventriloquist effect results from near-optimal
bimodal integration. Current Biology, 14, 257--262. Al-Azary, H. &
Buchanan, L. (2017). Novel metaphor comprehension: Semantic
neighbourhood density interacts with concreteness. Memory & Cognition,
45, 296--307. Albo, Z. & Gräff, J. (2018). The mysteries of remote
memory. Philosophical Transactions of the Royal Society B, 373, 1--12.
Albouy, G., King, B.R., Maque, P. & Doyon, J. (2013). Hippocampus and
striatum: Dynamics and interaction during acquisition and sleep-related
motor sequence memory consolidation. Hippocampus, 23, 985--1004.
Albright, T.D. (2017). Why eyewitnesses fail. Proceedings of the
National Academy of Sciences, 114, 7758--7764. Aldao, A.,
Nolen-Hoeksema, S. & Schweizer, S. (2010). Emotion-regulation strategies
across psychopathology: A meta-analytic review. Clinical Psychology
Review, 30, 217--237. Aldao, A., Sheppes, G. & Gross, J.J. (2015).
Emotion regulation flexibility. Cognitive Therapy and Research, 39,
263--278. Alexeeva, S., Frolova, A. & Slioussar, N. (2017). Data from
Russian help to determine in which languages the possible word
constraint applies. Journal of Psycholinguistic Research, 46, 629--640.
Ali, S.S., Lifshitz, M. & Raz, A. (2014). Empirical neuroenchantment:
From reading minds to thinking critically. Frontiers in Human
Neuroscience, 8 (Article no. 357). Allen, R.J., Hitch, G.J., Mate, J. &
Baddeley, A.D. (2012). Feature binding and attention in working memory:
A resolution of previous contradictory findings. Quarterly Journal of
Experimental Psychology, 65, 2369--2383. Allopenna, P.D., Magnuson, J.S.
& Tanenhaus, M.K. (1998). Tracking the time course of spoken word
recognition using eye movements: Evidence for continuous mapping models.
Journal of Memory and Language, 38, 419--439. Al-Moteri, M.O., Symmons,
M., Plummer, V. & Cooper, S. (2017). Eye tracking to investigate cue
processing in medical decision-making: A scoping review. Computers in
Human Behavior, 66, 52--66. Alonso, J.M. & Martinez, L.M. (1998).
Functional connectivity between simple cells and complex cells in cat
striate cortex. Nature Neuroscience, 1, 395--403. Altenberg, B. (1990).
Speech as linear composition. In G. Caie, K. Haastrup, A.L. Jakobsen,
J.E. Nielsen, J. Sevaldsen, H. Sprecht, et al. (eds), Proceedings from
the Fourth Nordic Conference for English Studies (Vol. 1; pp. 133--143).
Copenhagen, Denmark: Copenhagen University Press.

825

Altmann, E.M., Trafton, J.G. & Hambrick, D.Z. (2017). Effects of
interruption length on procedural errors. Journal of Experimental
Psychology: Applied, 23, 216--229. Álvaro, L., Linhares, J.M.M.,
Moreira, H., Lillo, J. & Nascimento, S.M.N. (2017). Robust colour
constancy in red-green dichromats. PLoS ONE, 12 (Article no. e018310).
Aly, M. & Ranganath, C. (2018). Perspectives on the hippocampus and
memory. Neuroscience Letters, 680, 1--3. Amer, T., Anderson, J.A.E.,
Campbell, K.L., Hasher, L. & Grady, C.L. (2016b). Age differences in the
neural correlates of distraction regulation: A network interaction
approach. Neuroimage, 139, 231--239. Amer, T., Campbell, K.L. & Hasher,
L. (2016a). Cognitive control as a double-edged sword. Trends in
Cognitive Sciences, 20, 905--915. Ames, A. (1952). The Ames
Demonstrations in Perception. New York: Hafner Publishing. Amir, N.,
Bomyes, J. & Beard, C. (2010). The effect of single-session
interpretation modification on attention bias in socially anxious
individuals. Journal of Anxiety Disorders, 24, 178--182. Amitani, Y.
(2015). The natural frequency hypothesis and evolutionary arguments.
Mind and Society, 14, 1--19. Anderson, C.J. (2003). The psychology of
doing nothing: Forms of decision avoidance result from reason and
emotion. Psychological Bulletin, 129, 139--167. Anderson, F.T. &
McDaniel, M.A. (2019). Hey buddy, why don't we take it outside: An
experience sampling study of prospective memory. Memory & Cognition, 47,
47--62. Anderson, F.T., Rummel, J. & McDaniel, M.A. (2018). Proceeding
with care for successful prospective memory: Do we delay ongoing
responding or actively monitor for cues? Journal of Experimental
Psychology: Learning, Memory, and Cognition, 44, 1036--1050. Anderson,
J.R., Bothell, D., Byrne, M.D., Douglass, S., Lebiere, C. & Qin, Y.L.
(2004). An integrated theory of the mind. Psychological Review, 111,
1036--1060. Anderson, J.R., Fincham, J.M., Qin, Y. & Stocco, A. (2008).
A central circuit of the mind. Trends in Cognitive Sciences, 12,
136--143. Anderson, J.R., Zhang, Q., Borst, J.P. & Walsh, M.W. (2016a).
The discovery of processing stages: Extension of Sternberg's method.
Psychological Review, 123, 481--509. Anderson, M.C. & Green, C. (2001).
Suppressing unwanted memories by executive control. Nature, 410,
366--369. Anderson, M.C. & Huddleston, E. (2012). Towards a cognitive
and neurobiological model of motivated forgetting. Nebraska Symposium on
Motivation, 58, 53--120. Anderson, M.C., Bunce, J.G. & Barbas, H.
(2016b). Prefrontal-hippocampal pathways underlying inhibitory control
over memory. Neurobiology of Learning and Memory, 134, 145--161.

826

References

Anderson, R.C. & Pichert, J.W. (1978). Recall of previously unrecallable
information following a shift in perspective. Journal of Verbal Learning
and Verbal Behavior, 17, 1--12. Anderson, R.C., Pichert, J.W. & Shirey,
L.L. (1983). Effects of the reader's schema at different points in time.
Journal of Educational Psychology, 75, 271--279. Anderson, S.W., Rizzo,
M., Skaar, N., Stierman, L., Cavaco, S., Dawson, J., et al. (2007).
Amnesia and driving. Journal of Clinical and Experimental
Neuropsychology, 29, 1--12. Andrews, P.W. & Thomson, J.A. (2009). The
bright side of being blue: Depression as an adaptation for analysing
complex problems. Psychological Review, 116, 620--654. Andrews, S., Lo,
S. & Xia, V. (2017). Individual differences in automatic semantic
priming. Journal of Experimental Psychology: Human Perception and
Performance, 43, 1025--1039. Andrews-Hanna, J.R., Saxe, R. & Yarkoni, T.
(2014). Contributions of episodic retrieval and mentalising to
autobiographical thought: Evidence from functional neuroimaging,
resting-state connectivity, and fMRI meta-analyses. NeuroImage, 91,
324--335. Angelone, B.L., Levin, D.T. & Simons, D.J. (2003). The
relationship between change detection and recognition of centrally
attended objects in motion pictures. Perception, 32, 947--962. Angie,
A.D., Connelly, S., Waples, E.P. & Kligyte, V. (2011). The influence of
discrete emotions on judgment and decision-making: A meta-analytic
review. Cognition & Emotion, 25, 1393--1422. Ardila, A. (2016). Some
unusual neuropsychological syndromes: Somatoparaphrenia, akinetopsia,
reduplicative paramnesia, autotopagnosia. Archives of Clinical
Neuropsychology, 31, 456--464. Ardila, A. & Surloff, C. (2006).
Dysexecutive agraphia: A major executive dysfunction sign. International
Journal of Neuroscience, 116, 653--663. Armstrong, T. & Olatunji, B.O.
(2012). Eye tracking of attention in the affective disorders: A
meta-analytic review and synthesis. Clinical Psychology Review, 32,
704--723. Ask, K. & Granhag, P.A. (2007). Hot cognition in investigative
judgments: The differential influence of anger and sadness. Law and
Human Behavior, 31, 537--551. Atkins, J.E., Fiser, J. & Jacobs, R.A.
(2001). Experiencedependent visual cue integration based on
consistencies between visual and haptic percepts. Vision Research, 41,
449--461. Atkinson, A.P., Dittrich, W.H., Gemmell, A.J. & Young, A.W.
(2004). Emotion perception from dynamic and static body expressions in
point-light and full-light displays. Perception, 33, 717--746. Atkinson,
R.L., Atkinson, R.C., Smith, E.E. & Bem, D.J. (1993). Introduction to
Psychology (11th edn). New York: Harcourt Brace.

Atkinson, R.C. & Shiffrin, R.M. (1968). Human memory: A proposed system
and its control processes. In K.W. Spence & J.T. Spence (eds), The
Psychology of Learning and Motivation (Vol. 2; pp. 89--195). London:
Academic Press. Auckland, M.E., Cave, K.R. & Donnelly, N. (2007).
Nontarget objects can influence perceptual processes during object
recognition. Psychonomic Bulletin & Review, 14, 332--337. Augustine,
A.A. & Hemenover, S.H. (2009). On the relative merits of affect
regulation strategies: A meta-analysis. Cognition & Emotion, 23,
1181--1220. Avenanti, A., Paracampo, R., Annella, L., Tidoni, E. &
Aglioti, S.M. (2018). Boosting and decreasing action prediction
abilities through excitatory and inhibitory tDCS of inferior frontal
cortex. Cortex, 28, 1282--1296. Averell, L. & Heathcote, A. (2011). The
form of the forgetting curve and the fate of memories. Journal of
Mathematical Psychology, 55, 25--35. Awasthi, B., Williams, M.A. &
Friedman, J. (2016). Examining the role of red background in
magnocellular contribution to face perception. PeerJ, 4 (Article no.
e1617). Awh, E. & Pashler, H. (2000). Evidence for split attentional
foci. Journal of Experimental Psychology: Human Perception and
Performance, 26, 834--846. Axelrod, R. (2015). Structure of Decision:
The cognitive maps of political elites. Princeton, NJ: Princeton
University Press. Axelrod, V. & Yovel, G. (2015). Successful decoding of
famous faces in the fusiform face area. PLoS ONE, 10 (Article no.
e0117126). Aydelott, J., Jamaluddin, Z. & Pearce, S.N. (2015). Semantic
processing of unattended speech in dichotic listening. Journal of the
Acoustical Society of America, 138, 964--975. Azevedo, R.T., Garfinkel,
S.N., Critchley, H.D. & Tsakiris, M. (2017). Cardiac afferent activity
modulates the expression of racial stereotypes. Nature Communications, 8
(Article no. 13854). Baars, B.J. (1988). A Cognitive Theory of
Consciousness. Cambridge: Cambridge University Press. Baars, B.J.,
Franklin, S. & Ramsoy, T.Z. (2013). Global workspace dynamics: Cortical
"binding and propagation" enables conscious contents. Frontiers in
Psychology, 4 (Article no. 200). Baddeley, A.D. (1978). Trouble with
levels: Re-examinatioin of Craik and Lockhart5's framework for memory
research. Psychological Review, 85, 139--152. Baddeley, A.D. (1996).
Exploring the central executive. Quarterly Journal of Experimental
Psychology, 49A, 5--28. Baddeley, A.D. (2000). The episodic buffer: A
new component of working memory? Trends in Cognitive Sciences, 4,
417--423.

References Baddeley, A.D. (2003). New data: Old pitfalls. Commentary on
Ruchkin, Grafman, Cameron & Berndt. Behavioral and Brain Sciences, 26,
728--729. Baddeley, A.D. (2012). Working memory: Theories, models, and
controversies. Annual Review of Psychology, 63, 1--29. Baddeley, A.D.
(2017). Modularity, working memory and language acquisition. Second
Language Research, 33, 299--311. Baddeley, A.D. & Andrade, J. (2000).
Working memory and the vividness of imagery. Journal of Experimental
Psychology: General, 129, 126--145. Baddeley, A.D. & Hitch, G.J. (1974).
Working memory. In G.H. Bower (ed.), Recent Advances in Learning and
Motivation (Vol. 8; pp. 47--89). New York: Academic Press. Baddeley,
A.D. & Hitch, G.J. (2017). Is the levels of processing effect
language-limited? Journal of Memory and Language, 92, 1--13. Baddeley,
A.D., Eysenck, M.W. & Anderson, M.C. (2015). Memory (2nd edn). Hove, UK:
Psychology Press. Baddeley, A.D., Gathercole, S. & Papagno, C. (1998).
The phonological loop as a language learning device. Psychological
Review, 105, 158--173. Baddeley, A.D., Hitch, G.J. & Quinlan, P.T.
(2018). Is the phonological similarity effect in working memory due to
proactive interference? Journal of Experimental Psychology: Learning,
Memory, and Cognition, 44, 1312--1316. Baddeley, A.D., Papagno, C. &
Vallar, G. (1988). When longterm learning depends on short-term storage.
Journal of Memory and Language, 27, 586--595. Baddeley, A.D., Thomson,
N. & Buchanan, M. (1975). Word length and the structure of short-term
memory. Journal of Verbal Learning and Verbal Behavior, 14, 575--489.
Baddeley, A.D., Vallar, G. & Wilson, B.A. (1987). Sentence comprehension
and phonological memory: Some neuropsychological evidence. In M.
Coltheart (ed.), Attention and Performance XII: The psychology of
reading (pp. 509-- 529). Hove, UK: Lawrence Erlbaum Associates. Bader,
M. & Meng, M. (2018). The misinterpretation of non-canonical sentences
revisited. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 44, 1286--1311. Bae, G.-Y., Olkkonen, M., Allred, S.R. &
Flombaum, J.I. (2015). Why some colours appear more memorable than
others: A model combining categories and particulars in colour working
memory. Journal of Experimental Psychology: General, 14, 744--763.
Bagneux, V., Font, H. & Bollon, T. (2013). Incidental emotions
associated with uncertainty appraisals impair decisions in the Iowa
Gambling Task. Motivation and Emotion, 37, 818--827. Baker, C.M., Burks,
J.D., Briggs, R.G., Stafford, J., Conner, A.K., Glenn, C.A., et
al. (2018). A connectomic atlas of

827

the human cerebrum -- Chapter 9: The occipital lobe. Operative
Neurosurgery, 15, S372--S406. Bakker, M. & Wicherts, J.M. (2011). The
(mis)reporting of statistical results in psychology journals. Behavior
Research Methods, 43, 666--678. Bakroon, A. & Lakshminarayanan, V.
(2018). Do different experimental tasks affect psychophysical
measurements of motion perception in autism-spectrum disorder? An
analysis. Clinical Optometry, 10, 131--143. Baldassarre, A., Ramsey, L.,
Hacker, C.L., Callejas, A., Astafiev, S.V., Metcalf, N.V., et
al. (2014). Large-scale changes in network interactions as a
physiological signature of spatial neglect. Brain, 137, 3267--3283.
Baldassarre, A., Ramsey, L.E., Siegel, J.S., Shulman, G.L. & Corbetta,
M. (2016). Brain connectivity and neurological disorders after stroke.
Current Opinion in Neurology, 29, 706--713. Baldassi, C., Alemi-Neissi,
A., Pagan, M., DiCarlo, J.J., Zecchina, R. & Zoccolan, D. (2013). Shape
similarity, better than semantic membership, accounts for the structure
of visual object representations in a population of monkey
inferotemporal neurons. PloS Computational Biology, 9 (Article no. e1003
167). Ball, F. & Busch, N.A. (2015). Change detection on a hunch:
Pre-attentive vision allows "sensing" of unique feature changes.
Attention, Perception & Psychophysics, 77, 2570--2588. Ball, F.,
Bernasconi, F. & Busch, N.A. (2015). Semantic relations between visual
objects can be unconsciously processed but not reported under change
blindness. Journal of Cognitive Neuroscience, 27, 2253--2268. Ball, L.J.
& Thompson, V.A. (2018). Belief bias and reasoning. In L.J. Ball & V.A.
Thompson (eds), Routledge International Handbook of Thinking and
Reasoning (pp. 16--36). Abingdon, Oxon: Routledge. Balota, D.A., Paul,
S. & Spieler, D. (1999). Attentional control of lexical processing
pathways during word recognition and reading. In S. Garrod & M.J.
Pickering (eds), Language Processing (pp. 15--58). Hove, UK: Psychology
Press. Bannard, C., Klinger, J. & Tomasello, M. (2013). How selective
are 3-year-olds in imitating novel linguistic material? Developmental
Psychology, 49, 2344--2356. Bannard, C., Lieven, E. & Tomasello, M.
(2009). Modeling children's early grammatical knowledge. Proceedings of
the National Academy of Sciences of the United States of America, 106,
17284--17289. Bannert, M.M. & Bartels, A. (2017). Invariance of surface
colour representations across illuminant changes in the human cortex.
NeuroImage, 158, 356--370. Bannert, M.M. & Bartels, A. (2018). Human V4
activity patterns predict behavioural performance in imagery of object
colour. Journal of Neuroscience, 38, 3657--3668.

828

References

Baptista, M. (2012). On universal grammar, the bioprogram hypothesis and
creole genesis. Journal of Pidgin and Creole Languages, 27, 351--376.
Bar, M., Kassam, K.S., Ghuman, A.S., Boshyan, J., Schmid, A.M., Dale,
A.M., et al. (2006). Top-down facilitation of visual recognition.
Proceedings of the National Academy of Sciences, 103, 449--454. Barense,
M.D., Ngo, L.H.T & Peterson, M.A. (2012). Interactions of memory and
perception in amnesia: The figure-ground perspective. Cerebral Cortex,
22, 2680--2691. Bar-Haim, Y., Lamy, D., Pergamin, L.,
BakermansKronenburg, M.J. & van IJzendoorn, M.H. (2007). Threat-related
attentional bias in anxious and nonanxious individuals: A meta-analytic
study. Psychological Bulletin, 133, 1--24. Barliya, A., Omlor, L.,
Giese, M.A., Berthoz, A. & Flash, T. (2013). Expression of emotion in
the kinematics of locomotion. Experimental Brain Research, 225,
159--176. Baronchelli, A., Chater, N., Pastor-Satorras, R. &
Christiansen, M.H. (2012). The biological origin of linguistic
diversity. PLoS ONE, 7 (Article no. e48029). Barrett, L.F. & Russell,
J.A. (1998). Independence and bipolarity in the structure of current
affect. Journal of Personality and Social Psychology, 74, 967--984.
Barreyro, J.P., Cevasco, J., Burin, D. & Marotto, C.M. (2012). Working
memory capacity and individual differences in the making of
reinstatement and elaborative inferences. Spanish Journal of Psychology,
15, 471--479. Barry, S. (2009). Fixing My Gaze. New York: Basic Books.
Barsalou, L.W. (2009). Simulation, situated conceptualization, and
prediction. Philosophical Transactions of the Royal Society B:
Biological Sciences, 364, 1281--1289. Barsalou, L.W. (2012). The human
conceptual system. In M.J. Spivey, K. McRae & M.F. Joanisse, (eds), The
Cambridge Handbook of Psycholinguistics (pp. 239--258). Cambridge:
Cambridge University Press. Barsalou, L.W. (2016a). On staying grounded
and avoiding quixotic dead ends. Psychonomic Bulletin & Review, 23,
1122--1142. Barsalou, L.W. (2016b). Situated conceptualisation: Theory
and applications. In Y. Coello & M.H. Fischer (eds), Foundations of
Embodied Cognition (Vol 1): Perceptual and emotional embodiment (Vol 1;
pp. 11--37). London: Routledge. Barsalou, L.W., Dutriaux, L. &
Scheepers, C. (2018). Moving beyond the distinction between concrete and
abstract concepts. Philosophical Transactions of the Royal Society B,
373 (Article no. 2017.0144). Barth, M., Stahl, C. & Haider, H. (2019).
Assumptions of the process-dissociation procedure are violated in
implicit sequence learning. Journal of Experimental Psychology:

Learning, Memory, and Cognition. Advance online publication (19 July
2018), 641--676. Bartlett, F.C. (1932). Remembering: An experimental and
social study. Cambridge: Cambridge University Press. Bartley, J.E.,
Boeving, E.R. Riedel, M.C., Bottenhorn, K.L., Salo, T., Eickhoff, S.B.,
et al. (2018). Meta-analytic evidence for a core problem solving network
across multiple representational domains. Neuroscience and Biobehavioral
Reviews, 92, 318--337. Bartolo, A., Rossetti, Y., Revol, P., Urquizar,
C., Pisella, L. & Coello, Y. (2018). Reachability judgement in optic
ataxia: Effect of peripheral vision on hand and target perception in
depth. Cortex, 98, 102--113. Bartolomeo, P. (2002). The relationship
between visual perception and visual mental imagery: A re-appraisal of
the neuropsychological evidence. Cortex, 38, 357--378. Bartolomeo, P.
(2008). The neural correlates of visual mental imagery: An ongoing
debate. Cortex, 44, 107--108. Bartolomeo, P., Seidel-Malkinson, T. & De
Vito, S. (2017). Botallo's error, or the quandaries of the universality
assumption. Cortex, 86, 176--185. Barton, J.J.S. & Corrow, S.L. (2016).
Selectivity in acquired prosopagnosia: The segregation of divergent and
convergent operations. Neuropsychologia, 83, 76--87. Bartsch, M.V.,
Donohue, S.E., Strumpf, H., Schoenfeld, M.A. & Hopf, J.-M. (2018).
Enhanced spatial focusing increases feature-based selection in
unattended locations. Scientific Reports, 8 (Article no. 16132). Baruch,
O., Kimchi, R. & Goldsmith, M. (2018). Attention to distinguishing
features in object recognition: An interactive-iterative framework.
Cognition, 170, 228--244. Barzykowski, K. & Staugaard, S.R. (2016). Does
retrieval intentionality really matter? Similarities and differences
between involuntary memories and directly and generatively retrieved
voluntary memories. British Journal of Psychology, 107, 519--536.
Basehore, Z. & Anderson, R.B. (2016). The simple life: New experimental
tests of the recognition heuristic. Judgment and Decision Making, 11,
301--309. Bastin, C., Besson, G., Simon, J., Delhaye, E., Geurten, M.,
Willems, S., et al. (2019). An integrative memory model of recollection
and familiarity to understand memory deficits. Behavioral and Brain
Sciences, 1--66 (Epub 05 February 2019). Bauer, A.J. & Just,
M.A. (2017). A brain-based account of "basic-level" concepts.
NeuroImage, 161, 196--205. Baumeister, R.F. & Masicampo, E.J. (2010).
Conscious thought is for facilitating social and cultural interactions:
How mental simulations serve the animal-culture interface. Psychological
Review, 117, 945--971. Baumeister, R.F., Lau, S., Maranges, H.M. &
Clark, C.J. (2018). On the necessity of consciousness for sophisticated
human action. Frontiers in Psychology, 9 (Article no. 1925).

References Baumeister, R.F., Masicampo, E.J. & Vohs, K.D. (2011). Do
conscious thoughts cause behaviour? Annual Review of Psychology, 62,
331--361. Baumgartner, S.E., van der Schuur, W.A., Lemmens, J.S. & te
Poel, F. (2018). The relationship between media multitasking and
attention problems in adolescents: Results from two longitudinal
studies. Human Communication Research, 44, 3--30. Bäuml, K.-H. & Kliegl,
O. (2013). The critical role of retrieval processes in release from
proactive interference. Journal of Memory and Language, 68, 39--53.
Baurès, R., Balestra, M., Rosito, A. & VanRullen, R. (2018). The
detrimental influence of attention on time-to-contact perception.
Attention, Perception & Psychophysics, 80, 1591--1598. Bavelas, J. &
Healing, S. (2013). Reconciling the effects of mutual visibility on
gesturing: A review. Gesture, 13, 63--92. Baxendale, S. (2004). Memories
aren't made of this: Amnesia at the movies. British Medical Journal,
329, 1480--1483. Bayley, P.J., Hopkins, R.O. & Squire, L.R. (2006). The
fate of old memories after medial temporal lobe damage. Journal of
Neuroscience, 26, 13311--13317. Bayne, T. (2010). The Unity of
Consciousness. Oxford: Oxford University Press. Bayne, T., Hohwy, J. &
Owen, A.M. (2016). Are there levels of consciousness? Trends in
Cognitive Sciences, 20, 405--413. Bayne, T., Holwy, J. & Owen, A.M.
(2017). Reforming the taxonomy in disorders of consciousness. Annals of
Neurology, 82, 866--872. Baynes, K. & Gazzaniga, M. (2000).
Consciousness, introspection, and the split-brain: The two minds/one
body problem. In M.S. Gazzaniga (ed.), The New Cognitive Neurosciences
(pp. 1355--1368). Cambridge, MA: MIT Press. Bays, P.M., Singh-Curry, V.,
Gorgoraptis, N., Driver, J. & Husain, M. (2010). Integration of goal-and
stimulusrelated visual signals revealed by damage to human parietal
cortex. Journal of Neuroscience, 30, 5968--5978. Beauvais, C., Olive, T.
& Passerault, J.-M. (2011). Why are some texts good and others not?
Relationship between text quality and management of the writing process.
Journal of Educational Psychology, 103, 415--428. Beck, A.T. (1976).
Cognitive Therapy and the Emotional Disorders. New York: International
Universities Press. Beck, A.T. & Dozois, D.J.A. (2011). Cognitive
therapy: Current status and future directions. Annual Review of
Medicine, 62, 397--409. Beck, C., Kardatzki, B. & Ethofer, T. (2014a).
Mondegreens and soramimi as a method to induce misperceptions of speech
content -- Influence of familiarity, wittiness, and language competence.
PloS ONE, 9 (Article no. e84667).

829

Beck, S.M., Ruge, H., Walser, M. & Goschke, T. (2014b). The functional
neuroanatomy of spontaneous retrieval and strategic monitoring of
delayed intentions. Neuropsychologia, 52, 37--50. Beckers, G. & Zeki, S.
(1995). The consequences of inactivating areas V1 and V5 on visual
motion perception. Brain, 118, 49--60. Beeke, S., Wilkinson, R. & Maxim,
J. (2007). Grammar without sentence structure: A conversation analytic
investigation of agrammatism. Aphasiology, 21, 256--282. Beisswingert,
B.M., Zhang, K., Goetz, T., Fang, P. & Fischbavher, U. (2015). The
effects of subjective loss of control on risk-taking behaviour: The
mediating role of anger. Frontiers in Psychology, 6 (Article no. 774).
Bennett, C.M., Baird, A.A., Miller, M.B. & Wolford, G.L. (2009). Neural
correlates of interspecies perspective taking in the post-mortem
Atlantic salmon: An argument for proper multiple comparisons'
correction. 15th Annual Meeting of the Organisation for Human Brain
Mapping. San Francisco, CA. Bennett, P. & Lowe, R. (2008). Emotions and
their cognitive precursors: Responses to spontaneously identified
stressful events among hospital nurses. Journal of Health Psychology,
13, 537--546. Benoit, R.G. & Schacter, D.L. (2015). Specifying the core
network supporting episodic simulations and episodic memory by
activation likelihood estimation. Neuropsychologia, 75, 450--457.
Bereiter, C. & Scardamalia, M. (1987). The Psychology of Written
Composition. Mahwah, NJ: Lawrence Erlbaum Associates. Bereiter, C.,
Burtis, P.J. & Scardamalia, M. (1988). Cognitive operations in
constructing main points in written composition. Journal of Memory and
Language, 27, 261--278. Beres, A.M. (2017). Time is of the essence: A
review of electroencephalography (EEG) and event-related brain
potentials (ERPs) in language research. Applied Psychophysiological
Biofeedback, 42, 247--255. Bergeron, V. (2016). Functional independence
and cognitive architecture. British Journal of the Philosophical
Society, 67, 817--836. Berggren, N. & Eimer, M. (2018). Object-based
target templates guide attention during visual search. Journal of
Experimental Psychology: Human Perception and Performance, 44,
1368--1382. Bergman, E. & Roediger, H.L. (1999). Can Bartlett's repeated
reproduction experiments be replicated? Memory & Cognition, 27,
937--947. Bergmann, H.C., Rijpkema, M., Fernández, G. & Kessels, R.P.C.
(2012). Distinct neural correlate of associative working memory and
long-term memory encoding in the medial temporal lobe. NeuroImage, 63,
989--997. Bergström, Z.M., de Fockert, J.W. & Richardson-Klavehn, A.
(2009). ERP and behavioural evidence for direct

830

References

suppression of unwanted memories. NeuroImage, 48, 726--737. Berisha, V.,
Wang, S., LaCross, A. & Liss, J. (2015). Tracking discourse complexity
preceding Alzheimer's disease diagnosis: A case study comparing the
press conferences of Presidents Ronald Reagan and George Herbert Walker
Bush. Journal of Alzheimer's Disease, 45, 959--963. Berisha, V., Wang,
S., LaCross, A., Liss, J. & Garcia-Filion, P. (2017). Longitudinal
changes in linguistic complexity among professional football players.
Brain & Language, 169, 57--63. Berman, M.G., Jonides, J. & Lewis, R.L.
(2009). In search of decay in verbal short-term memory. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 35, 317--333.
Bermúdez-Rattoni, F. & McGaugh, J.L. (2017). Memory reconsolidation and
memory updating: Two sides of the same coin? Neurobiology of Learning
and Memory, 142, 1--3. Berninger, V.W. & Abbott, R.D. (2010). Listening
comprehension, oral expression, reading comprehension, and written
expression: Related yet unique language systems in grades 1, 3, 5, and
7. Journal of Educational Psychology, 102, 635--651. Berntsen, D.,
Rubin, D.C. & Siegler, I.C. (2011). Two different versions of life:
Emotionally negative and positive life events have different roles in
the organisation of life story and identity. Emotion, 11, 1190--1201.
Berwick, R.C., Friederici, A.D., Chomsky, N. & Bolhuis, J.J. (2013).
Evolution, brain, and the nature of language. Trends in Cognitive
Sciences, 17, 89--98. Besson, G., Barragan-Jason, G., Thorpe, S.J.,
Fabre-Thorpe, M., Puma, S., Ceccaldi, M., et al. (2017). From face
processing to face recognition: Comparing three different processing
levels. Cognition, 158, 33--43. Beukema, P. & Verstynen, T. (2018).
Predicting and binding: Interacting algorithms supporting the
consolidation of sequential motor skills. Current Opinion in Behavioral
Sciences, 20, 98--103. Bezdicek, O., Ballarini, T., Buschke, H.,
Ružička, F., Roth, J., Albrecht, F., et al. (2019). Memory impairment in
Parkinson's disease: The retrieval versus associative deficit hypothesis
revisited and reconciled. Neuropsychology, 33, 391--405. Bezuidenhout,
A. (2014). Reply to Brown-Schmidt and Heller. Journal of Pragmatics, 60,
285--290. Bhatt, R.S. & Quinn, P.C. (2011). How does learning impact
development in infancy? The case of perceptual organisation. Infancy,
16, 2--38. Bialek, M. (2017). Not that neglected! Base rates influence
related and unrelated judgements. Acta Psychologica, 177, 10--16.
Bialek, M. & De Neys, W. (2017). Dual processes and moral conflict:
Evidence for deontological reasoners' intuitive

utilitarian sensitivity. Judgment and Decision Making, 12, 148--167.
Bickerton, D. (1984). The language bioprogram hypothesis. Behavioral and
Brain Sciences, 7, 173--221. Bidelman, G.M. & Walker, B.S. (2017).
Attentional modulation and domain-specificity underlying the neural
organisation of auditory categorical perception. European Journal of
Neuroscience, 45, 690--699. Biederman, I. (1987).
Recognition-by-components: A theory of human image understanding.
Psychological Review, 94, 115--147. Biederman, I. & Gerhardstein, P.C.
(1993). Recognising depth-rotated objects: Evidence for 3-D viewpoint
invariance. Journal of Experimental Psychology: Human Perception &
Performance, 19, 1162--1182. Biedermann, B., Ruh, B., Nickels, L. &
Coltheart, M. (2008). Information retrieval in tip-of-the-tongue states:
New data and methodological advances. Journal of Psycholinguistic
Research, 37, 171--198. Bier, N., Bottari, C., Hudon, C., Jobert, S.,
Paquette, G. & Macoir, J.L. (2013). The impact of semantic dementia on
everyday actions: Evidence from an ecological study. Journal of the
International Neuropsychological Society, 19, 162--172. Biggs, A.T. &
Gibson, B.S. (2018). Opening the window: Size of the attentional window
dominates perceptual load and familiarity in visual selection. Journal
of Experimental Psychology: Human Perception and Performance, 44,
1780--1798. Biggs, A.T., Brockmole, J.R. & Witt, J.K. (2013). Armed and
attentive: Holding a weapon can bias attentional priorities in scene
viewing. Attention, Perception & Psychophysics, 75, 1715--1724. Bilalić,
M. (2016). Revisiting the role of the fusiform face area in expertise.
Journal of Cognitive Neuroscience, 28, 1345--1357. Bilalić, M., McLeod,
P. & Gobet, F. (2008a). Inflexibility of experts: Reality or myth?
Quantifying the Einstellung effect in chess masters. Cognitive
Psychology, 56, 73--102. Bilalić, M., McLeod, P. & Gobet, F. (2008b).
Why good thoughts block better ones: The mechanism of the pernicious
Einstellung effect. Cognition, 108, 652--661. Binder, E., Dovern, A.,
Hesse, M.D., Ebke, M., Karbe, H., Saliger, J., et al. (2017). Lesion
evidence for a human mirror neuron system. Cortex, 90, 125--137. Binder,
J.R. & Desai, R.H. (2011). The neurobiology of semantic memory. Trends
in Cognitive Sciences, 15, 527--536. Binder, J.R., Desai, R.H., Graves,
W.W. & Conant, L.L. (2009). Where is the semantic system? A critical
review and meta-analysis of 120 functional neuroimaging studies.
Cerebral Cortex, 19, 2767--2796. Bindschaedler, C., Peter-Favre, C.,
Maeder, P., Hirsbrunner, T. & Clarke, S. (2011). Growing up with
bilateral

References hippocampal atrophy: From childhood to teenage. Cortex, 47,
931--944. Binkofski, F. & Buxbaum, L.J. (2013). Two action systems in
the human brain. Brain and Language, 127, 222--229. Bird, C.M. (2017).
The role of the hippocampus in recognition memory. Cortex, 93, 155--165.
Bisenius, S., Trapp, S., Neumann, J. & Schroeter, M.L. (2015).
Identifying neural correlates of visual consciousness with ALE
meta-analyses. NeuroImage, 122, 177--187. Bixler, R. & D'Mello, S.
(2016). Automatic gaze-based under-independent detection of mind
wandering during computerised reading. User Modeling and User-Adapted
Interaction, 26, 33--68. Blackmer, E.R. & Mitton, J.L. (1991). Theories
of monitoring and the timing of repairs in spontaneous speech.
Cognition, 3, 173--194. Blackmon, J. (2016). Hemispherectomies and
independently conscious brain regions. Journal of Cognition and
Neuroethics, 3, 1--26. Blanchette, I. & Dunbar, K. (2000). How analogies
are generated: The roles of structural and superficial similarity.
Memory & Cognition, 28, 108--124. Blanchette, I. & Richards, A. (2010).
The influence of affect on higher level cognition: A review of research
on interpretation, judgement, decision making and reasoning. Cognition &
Emotion, 24, 561--595. Blaney, P.H. (1986). Affect and memory -- A
review. Psychological Bulletin, 99, 229--246. Blank, H. & Launay, C.
(2014). How to protect eyewitness memory against the misinformation
effect: A metaanalysis of post-warning studies. Journal of Applied
Research in Memory and Cognition, 3, 77--88. Blank, I.A. & Fedorenko, E.
(2017). Domain-general brain regions do not track linguistic input as
closely as language-selective regions. Journal of Neuroscience, 37,
9999--10011. Blanke, O., Ortigue, S., Landis, T. & Seeck, M. (2002).
Stimulating illusory own-body perceptions. Nature, 419, 269--270.
Blanke, O., Slater, M. & Serino, A. (2015). Behavioural, neural, and
computational principles of bodily selfconsciousness. Neuron, 88,
145--166. Bliss, D.P., Sun, J.J. & D'Esposito, M. (2017). Serial
dependence is absent at the time of perception but increases in visual
working memory. Scientific Reports, 7 (Article no. 14739). Block, N.
(2012). Response to Kouider et al.: Which view is better supported by
the evidence? Trends in Cognitive Sciences, 16, 141--142. Bluck, S. &
Alea, N. (2009). Thinking and talking about the past: Why remember?
Applied Cognitive Psychology, 23, 1089--1104. Blumenthal, A., Duke, D.,
Bowles, B., Gilboa, A., Rosenbaum, R.S., Köhler, S., et al. (2017).
Abnormal

831

semantic knowledge in a case of developmental amnesia. Neuropsychologia,
102, 237--247. Bode, S., He, A.H., Soon, C.S., Trampel, R., Turner, R. &
Haynes, J.-D. (2011). Tracking the unconscious generation of free
decisions using ultra-high field fMRI. PLoS ONE, 6 (Article no. 21612).
Bodien, Y.G., Chatelle, C. & Edlow, B.L. (2017). Functional networks in
disorders of consciousness. Seminars in Neurology, 37, 485--502.
Boiteau, T.W., Malone, P.S., Peters, S.A. & Almor, A. (2014).
Interference between conversation and a concurrent visuo-motor task.
Journal of Experimental Psychology: General, 143, 295--311. Bolden, G.B.
(2006). Little words that matter: Discourse markers "so" and "oh" and
the doing of other-attentiveness in social interaction. Journal of
Communication, 56, 661--688. Boly, M., Garrido, M.I., Gosseries, O.,
Bruno, M.A., Bovereux, P., Schnakers, C., et al. (2011). Preserved
feedforward but impaired top-down processes in the vegetative state.
Science, 332, 858--862. Boly, M., Massimini, M., Tsuchiya, N., Postle,
B.R., Koch, C. & Tononi, G. (2017). Are the neural correlates of
consciousness in the front or in the back of the cerebral cortex?
Clinical and neuroimaging evidence. Journal of Neuroscience, 37,
9603--9613. Bonato, M. & Cutini, S. (2016). Increased attentional load
moves the left to the right. Journal of Clinical and Experimental
Neuropsychology, 38, 158--170. Bonato, M., Priftis, K., Marenzi, R.,
Umiltà, C. & Zorzi, M. (2010). Increased attentional demands impair
contralesional space awareness following stroke. Neuropsychologia, 48,
3934--3940. Bonnefon, J.-F., Shariff, A. & Rahwan, I. (2016). The social
dilemma of autonomous vehicles. Science, 352, 1573--1576. Bonnefond, M.,
Kaliuzhna, M., Van der Henst, J.-B. & De Neys, W. (2014). Disabling
conditional inferences: An EEG study. Neuropsychologia, 56, 255--262.
Bonnefond, M., Noveck, I., Baillet, S., Cheylus, A., Delpuech, C.,
Bertrand, O., et al. (2013). What MEG can reveal about inference making:
The case of if...then sentences. Human Brain Mapping, 34, 684--697.
Booth, R.W., Mackintosh, B., Mobini, S., Oztop, P. & Nunn, S. (2014).
Cognitive bias modification of attention is less effective under working
memory load. Cognitive Therapy and Research, 38, 634--639. Booth, R.W.,
Mackintosh, B. & Sharma, D. (2017). Working memory regulates trait
anxiety-related threat processing biases. Emotion, 17, 616--627. Bor, D.
& Seth, A.K. (2012). Consciousness and the prefrontal parietal network:
Insights from attention, working memory, and chunking. Frontiers in
Psychology, 3 (Article no. 63).

832

References

Borges, J.L. (1964). Labyrinths. London: Penguin. Borghesani, V. &
Piazza, M. (2017). The neuro-cognitive representations of symbols: The
case of concrete words. Neuropsychologia, 105, 4--17. Borghesani, V.,
Buiatti, M., Eger, E. & Piazza, M. (2019). Conceptual and perceptual
dimensions of word meaning are recovered rapidly and in parallel during
reading. Journal of Cognitive Neuroscience, 31, 95--108. Bohrn, J.C.,
Altmann, U. & Jacobs, A.M. (2012). Looking at the brains behind
figurative language. A quantitative meta-analysis of neuroimaging
studies on metaphor, idiom, and irony processing. Neuropsychologia, 50,
2669--2683. Bormann, T. & Weiller, C. (2012). "Are there lexicons?" A
study of lexical and semantic processing in wordmeaning deafness
suggests "yes". Cortex, 48, 294--307. Bormann, T., Wolfer, S., Hachmann,
W., Neubauer, C. & Konieczny, L. (2015). Fast word reading in pure
alexia: "Fast, yet serial". Neurocase, 21, 251--267. Borst, J.P.,
Buwalda, T.A., van Rijn, H. & Taatgen, N.A. (2013). Avoiding the problem
state bottleneck by strategic use of the environment. Acta Psychologica,
144, 373--379. Bos, E.M., Spoor, J.K.H., Smits, M., Schouten, J.W. &
Vincent, A.J.P.E. (2016). Out-of-body experience during awake
craniotomy. World Neurosurgery, 92 (Article no. UNSP 586.e9). Bose, A.
(2013). Phonological therapy in jargon aphasia: Effects on naming and
neologisms. International Journal of Language & Communication Disorders,
48, 582--595. Bostyn, D.H., Sevenhant, S. & Roets, A. (2018). Of mice,
men, and trolleys: Hypothetical judgement versus real-life behaviour in
trolley-style moral dilemmas. Psychological Science, 29, 1084--1093.
Bourke, L., Davies, S.J., Sumner, E. & Green, C. (2014). Individual
differences in the development of early writing skills: Testing the
unique contribution of visuo-spatial working memory. Reading and
Writing, 27, 315--335. Bourne, L.E., Kole, J.A. & Healy, A.F. (2015).
Expertise: Defined, described, explained. Frontiers in Psychology, 5,
211--213 (Article no. 186). Bouvier, S.E. & Engel, S.A. (2006).
Behavioural deficits and cortical damage loci in cerebral achromatopsia.
Cerebral Cortex, 16, 183--191. Bowden, E.M., Jung-Beeman, M., Fleck, J.
& Kounios, J. (2005). New approaches to demystifying insight. Trends in
Cognitive Sciences, 9, 322--328. Bowen, H.J., Kark, S.M. & Kensinger,
E.A. (2018). NEVER forget: Negative emotional valence enhances
recapitulation. Psychonomic Bulletin & Review, 25, 870--891. Bower,
G.H., Black, J.B. & Turner, T.J. (1979). Scripts in memory for text.
Cognitive Psychology, 11, 177--220.

Bowers, J.S. (2017a). Parallel distributed processing theory in the age
of deep networks. Trends in Cognitive Sciences, 21, 950--961. Bowers,
J.S. (2017b). Grandmother cells and localist representations: A review
of current thinking. Language, Cognition and Neuroscience, 32, 257--273.
Bowers, J.S & Davis, C.J. (2012). Bayesian just-so stories in psychology
and neuroscience. Psychological Bulletin, 138, 389--414. Bowles, B.,
Crupi, C., Pigott, S., Parrent, A., Wiebe, S., Janzen, L., et
al. (2010). Double dissociation of selective recollection and
familiarity impairments following two different surgical treatments for
temporal-lobe epilepsy. Neuropsychologia, 48, 2640--2647. Bowles, B.,
O'Neil, E.B., Mirsattari, S.M., Poppenk, J. & Köhler, S. (2011).
Preserved hippocampal novelty responses following anterior temporal-lobe
resection that impairs familiarity but spares recollection. Hippocampus,
21, 847--854. Brainard, D.H. & Maloney, L.T. (2011). Surface colour
perception and equivalent illumination models. Journal of Vision, 11,
1--18. Brainerd, C.J. & Mojardin, A.H. (1998). Children's spontaneous
memories for narrative statements: Long-term persistence and testing
effects. Child Development, 69, 1361--1377. Brainerd, C.J., Gomes,
C.F.A. & Moran, R. (2014). The two recollections. Psychological Review,
121, 563--599. Brainerd, C.J., Reyna, V.F. & Ceci, S.J. (2008).
Developmental reversals in false memory: A review of data and theory.
Psychological Bulletin, 134, 343--382. Bramão, I. & Johansson, M.
(2017). Benefits and costs of context reinstatement in episodic memory:
An ERP study. Journal of Cognitive Neuroscience, 29, 52--64.
Braňas-Garza, P., Kujal, P. & Lenkei, B. (2015). Cognitive reflection
test: Whom, how, when. ESI Working Paper, 15--25. Brandt, A., Gebrian,
M. & Slevc, L.R. (2012). Music and early language acquisition. Frontiers
in Psychology, 3 (Article no. 327). Brandt, K.R., Eysenck, M.W., Nilsen,
M.K. & Von Oertzen, T.J. (2016). Selective lesion to the entorhinal
cortex leads to an impairment in familiarity but not recollection. Brain
and Cognition, 104, 82--92. Bransford, J.D. & Johnson, M.K. (1972).
Contextual prerequisites for understanding. Journal of Verbal Learning
and Verbal Behavior, 11, 717--726. Bransford, J.D., Barclay, J.R. &
Franks, J.J. (1972). Sentence memory: A constructive versus interpretive
approach. Cognitive Psychology, 3, 193--209. Brase, G.L. (2014).
Behavioural science integration: A practical framework of multi-level
converging evidence for behavioural science theories. New Ideas in
Psychology, 33, 8--20.

References Braunstein, M., Gross, J.J. & Ochsner, K.N. (2017). Explicit
and implicit emotion regulation: A multi-level framework. Social
Cognitive and Affective Neuroscience, 12, 1545--1557. Breitmeyer, B.G.
(2015). Psychophysical "blinding" methods reveal a functional hierarchy
of unconscious visual processing. Consciousness and Cognition, 35,
234--250. Bremmer, F., Kubischik, M., Pekel, M., Hoffmann, K.P. & Lappe,
M. (2010). Visual selectivity for heading in monkey area MST.
Experimental Brain Research, 200, 51--60. Brendel, E., DeLucia, P.,
Hecht, H., Stacy, R.L. & Larson, J.T. (2012). Threatening pictures
induce shortened time-to-contact estimates. Attention, Perception &
Psychophysics, 74, 979--987. Brenner, E. & Smeets, J.B.J. (2018). Depth
perception. In J.T. Serences (ed.), Stevens' Handbook of Experimental
Psychology and Cognitive Neuroscience, Vol. 2: Sensation, perception,
and attention (4th edn) (pp. 385--414). New York: Wiley. Brewer, N. &
Wells, G.L. (2011). Eyewitness identification. Current Directions in
Psychological Science, 20, 24--27. Brewer, N.T., DeFrank, J.T. & Gilkey,
M.B. (2016). Anticipated regret and health behaviour: A metaanalysis.
Health Psychology, 35, 1264--1275. Brewin, C.R. (2015). Re-experiencing
traumatic events in PTSDS: New avenues in research on intrusive memories
and flashbacks. European Journal of Psychotraumatology, 6 (Article no.
27180). Bridge, H. (2016). Effects of cortical damage on binocular depth
perception. Philosophical Transactions of the Royal Society B, 371
(Article no. 20150254). Bridge, H., Harrold, S., Holmes, E.A., Stokes,
M. & Kennard, C. (2012). Vivid visual mental imagery in the absence of
the primary visual cortex. Journal of Neurology, 259, 1062--1070.
Bridge, H., Thomas, O., Jbabdi, S. & Cowey, A. (2008). Changes in
connectivity after visual cortical brain damage underlie altered visual
function. Brain, 131, 1433--1444. Briggs, G.F., Hole, G.J. & Land, M.F.
(2011). Emotionally involving telephone conversations lead to driver
error and visual tunnelling. Transportation Research Part F, 14,
313--323. Broadbent, D.E. (1958). Perception and Communication. Oxford:
Pergamon. Brock, J. & Nation, K. (2014). The hardest butter to button:
Immediate context effects in spoken word identification. Quarterly
Journal of Experimental Psychology, 67, 114--123. Brooks, D.N. &
Baddeley, A.D. (1976). What can amnesic patients learn?
Neuropsychologia, 14, 111--122. Brooks, R., Faff, R., Mulino, D. &
Scheelings, R. (2009). Deal or no deal, that is the question? The impact
of

833

increasing stakes and framing effects on decision making under risk.
International Review of Finance, 9, 27--50. Brosch, T. (2013). Comment:
On the role of appraisal processes in the construction of emotion.
Emotion Review, 5, 369--373. Brothers, T., Hoverstein, L.J. & Traxler,
M.J. (2017). Looking back on reading ahead: No evidence for lexical
parafoveal-on-foveal effects. Journal of Memory and Language, 96, 9--22.
Brown, A.S., Caderao, K.C., Fields, L.M. & Marsh, E.J. (2015). Borrowing
personal memories. Applied Cognitive Psychology, 29, 471--477. Brown,
K.F., Kroll, J.S., Hudson, M.J., Ramsay, M., Green, J., Vincent, C.A.,
et al. (2010). Omission bias and vaccine rejection by parents of healthy
children: Implications for the influenza A/H1N1 vaccination programme.
Vaccine, 28, 4181--4185. Brown, T.J., Uncapher, M.R., Chow, T.E.,
Eberhardt, J.L. & Wagner, A.D. (2017). Cognitive control, attention, and
the other race effect in memory. PLoS ONE, 12 (Article no. e0173579).
Brown, R. & Kulik, J. (1977). Flashbulb memories. Cognition, 5, 73--99.
Brown-Schmidt, S. (2012). Beyond common and privileged: Gradient
representations of common ground in realtime language use. Language and
Cognitive Processes, 27, 62--89. Brown-Schmidt, S. & Duff, M.C. (2016).
Memory and common ground processes in language use. Topics in Cognitive
Sciences, 8, 722--736. Brown-Schmidt, S. & Heller, D. (2014). What
language processing can tell us about perspective taking: A reply to
Bezuidenhout. Journal of Pragmatics, 60, 279--284. Brown-Schmidt, S. &
Konopka, A.E. (2015). Processes of incremental message planning during
conversation. Psychonomic Bulletin & Review, 22, 833--843. Brownstein,
L.M., Gross, J.J. & Ochsner, K.N. (2017). Explicit and implicit emotion
regulation: A multi-level framework. Social Cognitive and Affective
Neuroscience, 12, 1545--1557. Bruce, V. & Tadmor, Y. (2015). Direct
perception: Beyond Gibson's (1950) direct perception. In M.W. Eysenck &
D. Groome (eds), Cognitive Psychology: Revisiting the classic studies
(pp. 24--37). London: Sage. Bruce, V. & Young, A. (1986). Understanding
face recognition. British Journal of Psychology, 77, 305--327. Bruce,
V., Green, P.R. & Georgeson, M.A. (2003). Visual Perception (4th edn).
Hove, UK: Psychology Press. Bruner, J.S., Goodnow, J.J. & Austin, G.A.
(1956). A Study of Thinking. New York: John Wiley. Brüning, J. & Manzy,
D. (2018). Flexibility of individual multitasking strategies in
task-switching with preview: Are preferences for serial versus
overlapping task processing

834

References

dependent on between-task conflict? Psychological Research, 82, 92--108.
Bruno, N. & Cutting, J.E. (1988). Mini-modularity and the perception of
layout. Journal of Experimental Psychology, 117, 161--170. Bruno, N.,
Bernardis, P. & Gentilucci, M. (2008). Visually guided pointing, the
Müller-Lyer illusion, and the functional interpretation of the
dorsal-ventral split: Conclusions from 33 independent studies.
Neuroscience and Biobehavioral Reviews, 32, 4213--4437. Brunyé, T.T.,
Carney, P.A., Allison, K.H., Shapiro, L.G. & Weaver, D.L. (2014). Eye
movements as an index of pathologist visual expertise: A pilot study.
PLoS ONE, 9 (Article no. e103447). Brunyé, T.T., Taylor, H.A. & Rapp,
D.N. (2008). Working memory in developing and applying mental models
from spatial descriptions. Journal of Memory and Language, 58, 701--729.
Brusovansky, M., Glickman, M. & Usher, M. (2018). Fast and effective:
Intuitive processes in complex decisions. Psychonomic Bulletin & Review,
25, 1542--1548. Bruyer, R. (2011). Configural face processing: A
meta-analytic survey. Perception, 40, 1478--1490. Brysbaert, M. &
Mitchell, D.C. (1996). Modifier attachment in sentence parsing: Evidence
from Dutch. Quarterly Journal of Experimental Psychology, 49, 664--695.
Buchanan, T.W., Tranel, D. & Adolphs, R. (2006). Memories for emotional
autobiographical events following unilateral damage to medial temporal
lobe. Brain, 129, 115--127. Buckley, M.J. & Mitchell, A.S. (2016).
Retrosplenial cortical contributions to anterograde and retrograde
amnesia in the monkey. Cerebral Cortex, 26, 2905--2918. Buckthought, A.,
Yoonessi, A. & Balker, C.L. (2017). Dynamic perspective cues enhance
depth perception from motion parallax. Journal of Vision, 17, 1--19.
Buetler, K.A., Rodriguez, D.L., Leganaro, M., Műri, R., Spierer, L. &
Annoni, J.-M. (2014). Language context modulates reading route: An
electrical neuroimaging study. Frontiers in Human Neuroscience, 8
(Article no. 83). Bullmore, E. & Sporns, O. (2012). The economy of brain
network organisation. Nature Reviews Neuroscience, 13, 336--349.
Bülthoff, I., Bülthoff, H. & Sinha, P. (1998). Top-down influences on
stereoscopic depth-perception. Nature Neuroscience, 1, 254--257.
Burdett, B.R.D., Charlton, S.G. & Starkey, N.J. (2018). Inside the
commuting driver's wandering mind. Transportation Research Part F, 57,
59--74. Burgess, P.W., Gilbert, S.J. & Dumontheil, I. (2007). Function
and localisation within rostral prefrontal cortex (area 10).
Philosophical Transactions of the Royal Society B: Biological Sciences,
362, 887--899.

Burgoyne, A.P., Sala, G., Gobet, F., Macnamara, B.N., Campitelli, G. &
Hambrick, D.Z. (2016). The relationship between cognitive ability and
chess skill: A comprehensive meta-analysis. Intelligence, 59, 72--83.
Bürki, A., Sadat, J., Dubarry, A.-S. & Alario, F.-X. (2016). Sequential
processing during noun phrase production. Cognition, 146, 90--99.
Burnham, B.R., Sabia, M. & Langan, C. (2014). Components of working
memory and visual selective attention. Journal of Experimental
Psychology: Human Perception and Performance, 40, 391--403. Burns, B.D.
(2004). The effects of speed on skilled chess performance. Psychological
Science, 15, 442--447. Burns, B.D. & Wieth, M. (2004). The collider
principle in causal reasoning: Why the Monty Hall dilemma is so hard.
Journal of Experimental Psychology: General, 133, 434--449. Burton,
A.M., Kramer, R.S.S., Ritchie, K.L. & Jenkins, R. (2016). Identity from
variation: Representations of faces derived from multiple instances.
Cognitive Science, 40, 202--223. Busigny, T., Graf, M., Mayer, E. &
Rossion, B. (2010a). Acquired prosopagnosia as a face-specific disorder:
Ruling out the general visual similarity account. Neuropsychologia, 48,
2051--2067. Busigny, T., Joubert, S., Felician, O., Ceccaldi, M. &
Rossion, B. (2010b). Holistic perception of the individual face is
specific and necessary: Evidence from an extensive case study of
acquired prosopagnosia. Neuropsychologia, 48, 4057--4092. Butterworth,
B. (1985). Jargon aphasia: Processes and strategies. In S. Newman & R.
Epstein (eds), Current Perspectives in Dysphasia (pp. 61--96).
Edinburgh: Churchill Livingstone. Byrne, M.D. (2012). Unified theories
of cognition. Wiley Interdisciplinary Reviews -- Cognitive Science, 3,
431--438. Cabeza, R., Stanley, M.L. & Moscovitch, M. (2018).
Processspecific alliances (PSAs) in cognitive neuroscience. Trends in
Cognitive Sciences, 22, 996--1010. Caccappolo-van Vliet, E., Miozz, M. &
Stern, Y. (2004). Phonological dyslexia: A test case for reading models.
Psychological Science, 15, 583--590. Caharel, S., Ramon, M. & Rossion,
B. (2014). Face familiarity decisions take 200ms in the human brain:
Electrophysiological evidence from a go/no-go speeded task. Journal of
Cognitive Neuroscience, 26, 81--95. Cahill, L., Babinsky, R.,
Markowitsch, H.J. & McGaugh, J.L. (1995). Involvement of the amygdaloid
complex in emotional memory. Nature, 377, 295--296. Cahir, C. & Thomas,
K. (2010). Asymmetric effects of positive and negative affect on
decision making. Psychological Reports, 106, 193--204. Cai, Z.G.,
Gilbert, R.A., Davis, M.H., Gaskell, M.G., Farrar, L., Adler, S., et
al. (2017). Accent modulates access to

References word meaning: Evidence for a speaker-model account of spoken
word recognition. Cognitive Psychology, 98, 73--101. Cai, Z.G., Sturt,
P. & Pickering, M.J. (2012). The effect of non-adopted analyses on
sentence processing. Language and Cognitive Processes, 27, 1286--1311.
Caird, J.K., Willness, C.R., Steel, P. & Scialfa, C. (2008). A
meta-analysis of the effects of cell phones on driver performance.
Accident analysis and Prevention, 40, 1282--1293. Calder, A.J. & Young,
A.W. (2005). Understanding the recognition of facial identity and facial
expression. Nature Reviews Neuroscience, 6, 645--651. Calderwood, L. &
Burton, A.M. (2006). Children and adults recall the names of highly
familiar faces faster than semantic information. British Journal of
Psychology, 97, 441--454. Calet, N., Gutierrez-Palma, N. & Defior, S.
(2017). Effects of fluency training on reading competence in primary
school children: The role of prosody. Learning and Instruction, 52,
59--68. Caliglore, D., Pezzulo, G., Baldassarre, G., Bostan, A.C.,
Strick, P.L., Doya, K., et al. (2017). Consensus paper: Towards a
systems-level view of cerebellar functions: The interplay between
cerebellum, basal ganglia, and cortex. Cerebellum, 16, 203--229. Calvo,
M.G. & Castillo, M.D. (1997). Mood-congruent bias in interpretation of
ambiguity: Strategic processes and temporary activation. Quarterly
Journal of Experimental Psychology, 50A, 163--182. Calvo, M.G. &
Castillo, M.D. (2001). Bias in predictive inferences during reading.
Discourse Processes, 32, 43--71. Calvo, M.G., Castillo, M.D. &
Schmalhofer, F. (2006). Strategic influence on the time course of
predictive inferences in reading. Memory & Cognition, 34, 68--77.
Camerer, C. & Hogarth, R.B. (1999). The effects of financial incentives
in experiments: A review and capital-labourproduction framework. Journal
of Risk and Uncertainty, 19, 7--42. Campbell, T.H. & Kay, A.C. (2014).
Solution aversion: On the relation between ideology and motivated
disbelief. Journal of Personality and Social Psychology, 107, 809--824.
Campbell, K.L. & Tyler, L.K. (2018). Language-related domain-specific
and domain-general systems in the human brain. Current Opinion in
Behavioral Sciences, 21, 132--137. Campitelli, G. & Gobet, F. (2011).
Deliberate practice: Necessary but not sufficient. Current Directions in
Psychological Science, 20, 280--285. Campos, B., Shiota, M.N., Keltner,
D., Gonzaga, G.C. & Goetz, J.L. (2013). What is shared, what is
different? Core relational themes and expressive displays of eight
positive emotions. Cognition & Emotion, 27, 37--52.

835

Campoy, G. (2012). Evidence for decay in verbal short-term memory: A
commentary on Berman, Jonides, and Lewis (2009). Journal of Experimental
Psychology: Learning, Memory, and Cognition, 38, 1129--1136. Cane, J.E.,
Ferguson, H.J. & Apperly, I.A. (2018). Using perspective to resolve
reference: The impact of cognitive load and motivation. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 43, 591--610.
Cann, H.W. & Raymond, L. (2018). Does climate denialism still matter?
The prevalence of alternative frames in opposition to climate policy.
Environmental Politics, 27, 433--454. Cappa, S.F. (2012). Neurological
accounts. In R. Bastiaanse & C.K. Thompson (eds), Perspectives on
Agrammatism (pp. 49--59). Hove, UK: Psychology Press. Caravolas, M.,
Lervåg, A., Defior, S., Seidlová Málková, G. & Hulme, C. (2013).
Different patterns, but equivalent predictors, of growth in reading in
consistent and inconsistent orthographies. Psychological Science, 24,
1398--1407. Carbonell, K.M. & Lotto, A.J. (2014). Speech is not
special... again. Frontiers in Psychology, 5 (Article no. 427).
Carpenter, S.K. & Yeung, K.L. (2017). The role of mediator strength in
learning from retrieval. Journal of Memory and Language, 92, 128--141.
Carrasco-Ortiz, H., Midgley, K.J., Grainger, J. & Holcomb, P.J. (2017).
Interactions in the neighbourhood: Effects of orthographic and
phonological neighbours on N400 amplitude. Journal of Neurolinguistics,
41, 1--10. Carrera, E. & Tonini, G. (2014). Diaschesis: Past, present,
future. Brain, 137, 2408--2422. Carriedo, N., Corral, A., Montoro, P.R.,
Herrero, L., Ballestrino, P. & Sebastian, I. (2016). The development of
metaphor comprehension and its relationship with relational verbal
reasoning and executive function. PLoS ONE, 11 (Article no. e950289).
Cartmill, E.A., Beilock, S. & Goldin-Meadow, S. (2012). A word in the
hand: Action, gesture and mental representation in humans and non-human
primates. Philosophical Transactions of the Royal Society B, 367,
129--143. Casasanto, D. (2016). A shared mechanism of linguistic,
cultural, and bodily relativity. Language Learning, 66, 714--730.
Cattinelli, I., Borghese, N.A., Gallucci, M. & Paulesu, E. (2013).
Reading the reading brain: A new meta-analysis of functional mapping
data on reading. Journal of Neurolinguistics, 26, 214--238. Cavaco, S.,
Anderson, S.W., Allen, J.S., Castro-Caldas, A. & Damasio, H. (2004). The
scope of procedural memory in amnesia. Brain, 127, 1853--1867. Čavojová,
V., Šrol, J. & Adamus, M. (2018). My point is valid, yours is not:
Myside bias in reasoning about abortion. Journal of Cognitive
Psychology, 30, 656--669.

836

References

Ceci, S.J. & Liker, J.K. (1986). A day at the races: A study of IQ,
expertise, and cognitive complexity. Journal of Experimental Psychology:
General, 115, 255--266. Celeghin, A., Bagnis, A., Diano, M., Méndez,
C.A., Costa, T. & Tamietto, M. (2019). Functional neuroanatomy of
blindsight revealed by activation likelihood estimation meta-analysis.
Neuropsychologia, 128, 109--118. Ceraso, J. & Provitera, A. (1971).
Sources of error in syllogistic reasoning. Cognitive Psychology, 2,
400--410. Cermak, L.S., Talbot, N., Chandler, K. & Wolharst, L.R.
(1985). The perceptual priming phenomenon in amnesia. Neuropsychologia,
23, 615--622. Chabanat, E., Jacquin-Courtois, S., Havé, L., Kihoulou,
C., Tilikete, C., Mauguière, F., et al. (2019). Can you guess the colour
of this moving object? A dissociation between colour and motion in
blindsight. Neuropsychologia, 128, 204--208. Challis, B.H.,
Velichkovsky, B.M. & Craik, F.I.M. (1996). Levels-of-processing effects
on a variety of memory tasks: New findings and theoretical implications.
Consciousness and Cognition, 5, 142--164. Challoner, J. (2009). 1,001
Inventions That Changed the World. Hauppauge, NY: Barron's Educational
Series. Chalmers, D. (2007). The hard problem of consciousness. In M.
Velmans & S. Schneider (eds), The Blackwell Companion to Consciousness
(pp. 225--235). Oxford: Blackwell. Chamberlain, F. (2003). Review of
"Behavioural Assessment of the Dysexecutive Syndrome (BADS)". Journal of
Occupational Psychology, 5, 33--37. Champod, C. (2015). Fingerprint
identification: Advances since the 2009 National Research Council
report. Philosophical Transactions of the Royal Society: B, 370,
20140259. Chan, E., MacPherson, S.E., Bozzali, M., Shallice, T. &
Cipolotti, L. (2018). The influence of fluid intelligence, executive
functions and premorbid intelligence on memory in frontal patients.
Frontiers in Psychology, 9 (Article no. 926). Chan, J., Paletz, S.B.F. &
Schunn, C.D. (2012). Analogy as a strategy for supporting complex
problem solving under uncertainty. Memory & Cognition, 40, 1352--1365.
Chan, J.C.K. & LaPaglia, J.A. (2013). Impairing existing declarative
memory in humans by disrupting reconsolidation. Proceedings of the
National Academy of Sciences, 110, 9309--9313. Chan, J.C.K., Manley,
K.D. & Lang, K. (2017). Retrievalenhanced suggestibility: A
retrospective and a new investigation. Journal of Applied Research in
Memory and Cognition, 6, 213--229. Chang, H. & Rosenholtz, R. (2016).
Search performance is better predicted by tileability than presence of a
unique basic feature. Journal of Vision, 16 (Article no. 13).

Chang, J.Y. & Lane, D.M. (2016). There is time for calculation in speed
chess, and calculation accuracy increases with expertise. American
Journal of Psychology, 129, 1--9. Chaplin, T.A., Hagan, M.A., Allitt,
B.J. & Lul, L.L. (2018). Neuronal correlations in MT and MST impair
population decoding of opposite directions of random dot motion. ENeuro,
5 (Article no. UNSP e0336--1.2018). Charness, N., Reingold, E.M.,
Pomplun, M. & Stampe, D.M. (2001). The perceptual aspect of skilled
performance in chess: Evidence from eye movements. Memory & Cognition,
29, 1146--1152. Charpentier, C.J., Aylward, J., Roiser, J.P. & Robinson,
O.J. (2017). Enhanced risk aversion, but not loss aversion, in
unmediated pathological anxiety. Biological Psychology, 81, 1014--1022.
Charpentier, C.J., De Neve, J.-E., Li, X., Roiser, J.P. & Sharot, T.
(2016). Models of affective decision making: How do feelings predict
choice? Psychological Science, 27, 763--775. Chater, N. & Christiansen,
M.H. (2018). Language acquisition as skill learning. Current Opinion in
Behavioral Sciences, 21, 205--208. Chater, N., McCauley, S.M. &
Christiansen, M.H. (2016). Language as skill: Intertwining comprehension
and production. Journal of Memory and Language, 89, 244--254. Chee, Q.W.
& Goh, W.D. (2018). What explains the von Restorff effect? Contrasting
distinctive processing and retrieval cue efficacy. Journal of Memory and
Language, 99, 49--61. Cheek, N.N. & Shwartz, B. (2016). On the meaning
and measurement of maximisation. Judgment and Decision Making, 11,
126--146. Chekaf, M., Cowan, N. & Mathy, F. (2016). Chunk formation in
immediate memory and how it relates to data. Cognition, 155, 96--107.
Chen, C.C. & Tyler, C.W. (2015). Shading beats binocular disparity in
depth from luminance gradients: Evidence against a maximum likelihood
principle for cue combination. PloS ONE, 10 (Article no. e0132658).
Chen, J., Lun, X., Guo, Y., Zhang, Y. & Gong, D. (2017). A survey on
breaking techniques of text-based CAPTCHA. Security and Communication
Networks, 2017 (Article no. UNSP 6898617). Chen, J., Sperandio, I. &
Goodale, M.A. (2018a). Proprioceptive distance cues restore perfect size
constancy in grasping, but not perception, when vision is limited.
Current Biology, 26, 927--932. Chen, Q. & Mirman, D. (2012). Competition
and cooperation among similar representations: Toward a unified account
of facilitative and inhibitory effects of lexical neighbours.
Psychological Review, 119, 417--430. Chen, S., Wu, X., Wang, L., Wang,
Y., Wu, B., Ge, M., et al. (2018b). Disrupted interactions between
arousal and cortical awareness networks in MCS and VS/UWS patients:

References Evidence from resting-state functional imaging connectivity.
Neuroscience, 382, 115--124. Chen, X.-J., Wang, Y., Li, L.-L., Cui,
J.-F., Gan, M.-Y., Shum, D.H.K. & Chan, R.C.K. (2015). The effect of
implementation intention on prospective memory: A systematic and
meta-analytic review. Psychiatry Research, 226, 14--22. Chen, Y. &
Zelinsky, G.J. (2019). Is there a shape to the attention spotlight?
Computing saliency over protoobjects predicts fixations during scene
viewing. Journal of Experimental Psychology: Human Perception and
Performance, 45, 139--154. Chen, Y.-C. & Spence, C. (2017). Assessing
the role of the "unity assumption" on multisensory integration: A
review. Frontiers in Psychology, 8 (Article no. 445). Chen, Z. (2002).
Analogical problem solving: A hierarchical analysis of procedural
similarity. Journal of Experimental Psychology: Learning, Memory &
Cognition, 28, 81--98. Chen, Z. (2012). Object-based attention: A
tutorial review. Attention, Perception & Psychophysics, 74, 784--802.
Chen, Z. & Cave, K.R. (2016). Zooming in on the cause of the perceptual
load effect in the go/no-go paradigm. Journal of Experimental
Psychology: Human Perception and Performance, 42, 1072--1087. Chen, Z. &
Cowan, N. (2009). Core verbal working memory capacity: The limit in
words retained without covert articulation. Quarterly Journal of
Experimental Psychology, 62, 1420--1429. Chenoweth, N.A. & Hayes, J.R.
(2003). The inner voice in writing. Written Communication, 20, 99--118.
Cherry, E.C. (1953). Some experiments on the recognition of speech with
one and two ears. Journal of the Acoustical Society of America, 25,
975--979. Cherubini, P., Castelvecchio, E. & Cherubini, A.M. (2005).
Generation of hypotheses in Wason's 2-4-6 task: An information theory
approach. Quarterly Journal of Experimental Psychology Section A --
Human Experimental Psychology, 58, 309--332. Chiarello, C., Vaden, K.I.
& Eckert, M.A. (2018). Orthographic influence on spoken word
identification: Behavioural and fMRI evidence. Neuropsychologia, 111,
103--111. Chica, A.B., Bartolomeo, P. & Lupiáñez, J. (2013). Two
cognitive and neural systems for endogenous and exogenous spatial
attention. Behavioural Brain Research, 237, 107--123. Chica, A.B.,
Bartolomeo, P. & Valero-Cabré, A. (2011). Dorsal and ventral parietal
contributions to spatial orienting in the human brain. Journal of
Neuroscience, 31, 8143--8149. Chick, C.F., Reyna, V.F. & Corbin, J.C.
(2016). Framing effects are robust to linguistic disambiguation: A
critical test of contemporary theory. Journal of Experimental

837

Psychology: Learning, Memory, and Cognition, 42, 238--256. Choe, H.
(2018). Type your listenership: An exploration of listenership in
instant messages. Discourse Studies, 20, 703--725. Cholewa, J., Mantey,
S., Heber, S. & Hollweg, W. (2010). Developmental surface and
phonological dysgraphia in German 3rd graders. Reading and Writing, 23,
97--127. Chomsky, N. (1957). Knowledge of Language: Its Nature, Origin,
and Use. New York: Praeger. Chomsky, N. (1959). Review of Skinner's
"Verbal Behaviour". Language, 35, 26--58. Chomsky, N. (1965). Aspects of
the Theory of Syntax. Cambridge, MA: MIT Press. Chouinard, B., Volden,
J., Hollinger, J. & Cummine, J. (2018). Spoken metaphor comprehension:
Evaluation using the metaphor interference effect. Discourse Processes,
361, 19--33. Christiansen, M.H. & Chater, N. (2008). Language as shaped
by the brain. Behavioral and Brain Sciences, 31, 489--558. Christiansen,
M.H. & Chater, N. (2016). The now-or-never bottleneck: A fundamental
constraint on language. Behavioral and Brain Sciences, 39, 1--19.
Christiansen, M.H., Kelly, M.L., Shillcock, R.C. & Greenfield, K.
(2010). Impaired artificial grammar learning in agrammatism. Cognition,
116, 382--393. Christianson, K., Luke, S.G. & Ferreira, F. (2010).
Effects of plausibility on structural priming. Journal of Experimental
Psychology: Learning, Memory and Cognition, 36, 538--544. Christopher,
M.E., Miyake, A., Keenan, J.M., Pennington, B., DeFries, J.C.,
Wadsworth, S.J., et al. (2012). Predicting word reading and
comprehension with executive function and speed measures across
development: A latent variable analysis. Journal of Experimental
Psychology: General, 141, 470--488. Christou, A.I., Miall, R.C., McNab,
F. & Galea, J.M. (2016). Individual differences in explicit and implicit
visuomotor learning and working memory capacity. Scientific Reports, 6
(Article no. 36633). Chrysikou, E.G., Hamilton, R.H., Coslett, H.B.,
Datta, A., Bikson, M. & Thompson-Schill, S.L. (2013). Noninvasive
transcranial direct current stimulation over the left prefrontal cortex
facilitates cognitive flexibility in tool use. Cognitive Neuroscience,
4, 81--89. Chukoskie, L., Snider, J., Mozer, M.C., Krauzlis, R.J. &
Sejnowski, T.J. (2013). Learning where to look for a hidden target.
Proceedings of the National Association of Sciences, 110, 10438--10445.
Chun, M.M., Golomb, J.D. & Turk-Browne, N.B. (2011). A taxonomy of
external and internal attention. Annual Review of Psychology, 62,
73--101. Chun, W.Y. & Kruglanski, A.W. (2006). The role of task demands
and processing resources in the use of base-rate

838

References

and individuating information. Journal of Personality and Social
Psychology, 91, 205--217. Chung, S. (2012). Are lexical categories
universal? The view from Chamorro. Theoretical Linguistics, 38, 1--56.
Churchland, P.S. & Sejnowski, T.J. (1988). Perspectives on cognitive
neuroscience. Science, 242, 741--745. Chuy, M., Scardamalia, M. &
Bereiter, C. (2012). Development of ideational writing through knowledge
building: Theoretical and empirical bases. In E.L. Grigorenko, E.
Mambrino & D. Preiss (eds), Writing: A mosaic of New Perspectives
(pp. 175--190). Hove, UK: Psychology Press. Cisler, J.M. & Koster,
E.H.W. (2010). Mechanisms of attentional biases towards threat in
anxiety disorders: An integrative review. Clinical Psychology Review,
30, 203--216. Clancy, S.A. & McNally, R.J. (2005/2006). Who needs
repression? Normal memory processes can explain "forgetting" of
childhood sexual abuse. Scientific Review of Mental Health Practice, 4,
66--73. Clark, C.M., Lawlor-Savage, L. & Goghari, V.M. (2017). Comparing
brain activations associated with working memory and fluid intelligence.
Intelligence, 63, 66--77. Clark, G.M., Lum, J.A.G. & Ullman, M.T.
(2014). A meta-analysis and meta-regression of serial reaction time
performance in Parkinson's disease. Neuropsychology, 28, 945--958.
Clark, I.A. & Maguire, E.A. (2016). Remembering preservation in
hippocampal amnesia. Annual Review of Psychology, 67, 51--82. Clark,
L.A. & Watson, D. (1991). Tripartite model of anxiety and depression:
Psychometric evidence and taxonomic implications. Journal of Abnormal
Psychology, 100, 316--336. Clarke, J. & Mack, A. (2015). Iconic memory
for natural scenes: Evidence using a modified change-detection
procedure. Visual Cognition, 23, 917--938. Clay, Z. & Genty, E. (2017).
Natural communication in bonobos: Insights into social awareness and the
evolution of language. In B. Hare & S. Yamamoto (eds), Bonobos: Unique
in mind, brain, and behaviour (pp. 105-- 122). Oxford: Oxford University
Press. Clifton, C., Ferreira, F., Henderson, J.M., Inhoff, A.W.,
Liversedge, S.P., Reichle, E.D., et al. (2016). Eye movements in reading
and information processing: Keith Rayner's 40 year legacy. Journal of
Memory and Language, 86, 1--19. Clore, G.L., Schiller, A.J. & Shaked, A.
(2018). Affect and cognition: Three principles. Current Opinion in
Behavioral Science, 19, 78--82. Close, J. & Pothos, E.M. (2012). "Object
categorisation: Reversals and explanations of the basic-level advantage"
(Rogers & Patterson, 2007): A simplicity account. Quarterly Journal of
Experimental Psychology, 65, 1615--1632.

Coch, D., Sanders, L.D. & Neville, H.J. (2005). An eventrelated
potential study of selective auditory attention in children and adults.
Journal of Cognitive Neuroscience, 17, 606--622. Coco, M.I. & Keller, F.
(2015). The interaction of visual and linguistic saliency during
syntactic ambiguity resolution. Quarterly Journal of Experimental
Psychology, 68, 46--74. Coetzee, J.P. & Monti, M.M. (2018). At the core
of reasoning: Dissociating deductive and non-deductive load. Human Brain
Mapping, 39, 1850--1861. Coget, J.-F., Haag, C. & Gibson, D.E. (2011).
Anger and fear in decision-making: The case of film directors on set.
European Management Journal, 29, 476--490. Cohen, L.R. (2002). The role
of experience in the perception of biological motion. Dissertation
Abstracts International: Section B: The Sciences & Engineering, 63,
3049. Cohen, M.A., Alvarez, G.A. & Nakayama, K. (2011). Natural-scene
perception requires attention. Psychological Science, 22, 1165--1172.
Cohen, M.A., Cavanagh, P., Chun, M.M. & Nakayama, K. (2012). The
attentional requirements of consciousness. Trends in Cognitive Sciences,
16, 411--417. Cohen, M.A., Dennett, D.C. & Kanwisher, N. (2016). What is
the bandwidth of perceptual experience? Trends in Cognitive Sciences,
20, 324--335. Colavita, F.B. (1974). Human sensory dominance. Perception
& Psychophysics, 16, 409--412. Cole, J. (2015). Prosody in context: A
review. Language, Cognition and Neuroscience, 30, 1--31. Collegio, A.J.,
Nah, J.C., Scott, P.S. & Schomstein, S. (2019). Attention scales
according to inferred real-world object size. Nature Human Behaviour, 3,
140--147. Collette, F., Van der Linden, M., Laureys, S., Delfiore, G.,
Degueldre, C., Luxen, A., et al. (2005). Exploring the unity and
diversity of the neural substrates of executive functioning. Human Brain
Mapping, 25, 409--423. Collin, G., Sporns, O., Mandl, R.C.W. & van den
Heuvel, M.P. (2014). Structural and functional aspects relating to costs
and benefit of rich club organisation in the human cerebral cortex.
Cerebral Cortex, 24, 2258--2267. Collins, A.M. & Loftus, E.F. (1975). A
spreading-activation theory of semantic processing. Psychological
Review, 82, 407--428. Collins, W.M. & Daniel, F. (2018). The impact of
reading at rapid rates on inference generation. Journal of Research in
Reading, 41, 564--581. Colman, A.M. (2015). Oxford Dictionary of
Psychology (4th edn). Oxford: Oxford University Press. Colomb, C. &
Ginet, M. (2012). The cognitive interview for use with adults: An
empirical test of an alternative mnemonic and of a partial protocol.
Applied Cognitive Psychology, 26, 35--47. Colombo, L., Fudio, S. &
Mosna, G. (2009). Phonological and working memory mechanisms involved in
written

References spelling. European Journal of Cognitive Psychology, 21,
837--861. Coltheart, M. (2001). Assumptions and methods in cognitive
neuropsychology. In B. Rapp (ed.), The handbook of cognitive
neuropsychology: What deficits reveal about the human mind (pp. 3--21).
Hove, UK: Psychology Press. Coltheart, M. (2010). Lessons from cognitive
neuropsychology for cognitive science: A reply to Patterson and Plaut
(2009). Topics in Cognitive Science, 2, 3--11. Coltheart, M. (2015).
Language processing: Revisiting Marshall and Newcombe (1973). In M.W.
Eysenck & D. Groome (eds), Cognitive Psychology: Revisiting the classic
studies (pp. 189--202). London: Sage. Coltheart, M. & Ulicheva, A.
(2018). Why is non-word reading so variable in adult skilled readers?
PeerJ, 6 (Article no. 34879). Coltheart, M., Rastle, K., Perry, C.,
Langdon, R. & Ziegler, J. (2001). DRC: A dual-route cascaded model of
visual word recognition and reading aloud. Psychological Review, 108,
204--256. Colvin, M.K. & Gazzaniga, M.S. (2007). Split-brain cases. In
M. Velmans & S. Schneider (eds), The Blackwell Companion to
Consciousness (pp. 181--193). Oxford: Blackwell. Colvin, M.K., Dunbar,
K. & Grafman, J. (2001). The effects of frontal lobe lesions on goal
achievement in the water jug task. Journal of Cognitive Neuroscience,
13, 1129--1147. Cona, G., Arcara, G., Tarantino, V. & Bisiacchi, P.S.
(2015). Does predictability matter? Effects of cue predictability on
neurocognitive mechanisms underlying prospective memory. Frontiers in
Human Neuroscience, 9 (Article no. 188). Cona, G., Bisiacchi, P.S. &
Scapazza, C. (2016). Effects of cue focality on the neural mechanisms of
prospective memory: A meta-analysis of neuroimaging studies. Scientific
Reports, 6 (Article no. 25983). Conway, A.R.A., Cowan, N. & Bunting,
M.F. (2001). The cocktail party phenomenon revisited: The importance of
working memory capacity. Psychonomic Bulletin & Review, 8, 331--335.
Conway, B.R., Eskew, R.T., Martin, P.R. & Stockman, A. (2018). A tour of
contemporary colour vision research. Vision Research, 151, 2--6. Conway,
M.A. (2005). Memory and the self. Journal of Memory and Language, 53,
594--628. Conway, M.A. (2009). Episodic memories. Neuropsychologia, 47,
2305--2313. Conway, M.A. & Pleydell-Pearce, C.W. (2000). The
construction of autobiographical memories in the self-memory system.
Psychological Review, 107, 262--288. Conway, M.A., Loveday, C. & Cole,
S.N. (2016). The remembering-imagining system. Memory Studies, 9,
256--265.

839

Conway, M.A., Wang, Q., Hanyu, K. & Haque, S. (2005). A cross-cultural
investigation of autobiographical memory. Journal of Cross-Cultural
Psychology, 36, 739--749. Conway, P., Goldstei-Greenwood, J., Polacek,
D. & Greene, J.D. (2018). Sacrificial utilitarian judgements do reflect
concern for the greater good: Clarification via process dissociation and
the judgements of philosophers. Cognition, 179, 241--265. Cook, A.E. &
Myers, J.L. (2004). Processing discourse rules in scripted narratives:
The influences of context and world knowledge. Journal of Memory and
Language, 50, 268--288. Cook, A.E. & O'Brien, E.J. (2017). Fundamentals
of inferencing during reading. Language and Linguistics Compass, 11
(Article no. e12246). Cook, G.I., Rummel, J. & Dummel, S. (2015). Toward
an understanding of motivational influences on prospective memory using
value-added intentions. Frontiers in Human Neuroscience, 9 (Article no.
278). Copeland, D.E. & Radvansky, G.A. (2004). Working memory and
syllogistic reasoning. Quarterly Journal of Exerimental Psychology, 57A,
1437--1457. Corbetta, M. & Shulman, G.L. (2002). Control of goaldirected
and stimulus-driven attention in the brain. Nature Reviews Neuroscience,
3, 201--215. Corbetta, M. & Shulman, G.L. (2011). Spatial neglect and
attention networks. Annual Review of Neuroscience, 34, 569--599.
Corbetta, M., Patel, G. & Shulman, G.I. (2008). The reorienting system
of the human brain: From environment to theory of mind. Neuron, 58,
306--324. Corkin, S. (1968). Acquisition of motor skill after bilateral
medial temporal-lobe excision. Neuropsychologia, 6, 255--265. Corkin, S.
(1984). Lasting consequences of bilateral medial temporal lobectomy --
Clinical course and experimental findings in HM. Seminars in Neurology,
4, 249--259. Corley, M., Brocklehurst, P.H. & Moat, H.S. (2011). Error
biases in inner and overt speech: Evidence from tongue twisters. Journal
of Experimental Psychology: Learning, Memory, and Cognition, 37,
162--175. Cormack, L.K., Czuba, T.B., Knöll, J. & Huk, A.C. (2017).
Binocular mechanisms of 3D motion processing. Annual Review of Vision
Science, 3, 297--318. Cormier, D.C., Bulut, O., McGrew, K.S. & Frison,
J. (2016). The role of Cattell-Horn-Carroll (CHC) cognitive abilities in
predicting writing achievement during the school-age years. Psychology
in the Schools, 53, 787--803. Corner, A., Hahn, U. & Oaksford, M.
(2011). The psychological mechanism of the slippery slope argument.
Journal of Memory and Language, 64, 133--152. Cosentino, S., Chut, D.,
Libon, D., Moore, P. & Grossman, M. (2006). How does the brain support
script

840

References

comprehension? A study of executive processs and semantic knowledge in
dementia. Neuropsychology, 20, 307--318. Coste, C.P. & Kleinschmidt, A.
(2016). Cingulo-opercular network activity maintains alertness.
NeuroImage, 128, 264--272. Costello, F.J. & Keane, M.T. (2000).
Efficient creativity: Constraint-guided conceptual combination.
Cognitive Science, 24, 299--349. Cowen, A.S. & Keltner, D. (2017).
Self-report captures 27 distinct categories of emotion bridged by
continuous gradients. Proceedings of the National Academy of Sciences,
114, E7900--E7909. Cowen, A.S. & Keltner, D. (2018). Clarifying the
conceptualization, dimensionality, and structure of emotion: Response to
Barrett and colleagues. Trends in Cognitive Sciences, 22, 274--276.
Cowley, M.B. (2015). Hypothesis falsification in the 2-4-6 number
sequence test: Introducing imaginary counterparts. Philosophy of Mind
eJournal, 8, 3--44. Cowley, M.B. & Byrne, R.M.J. (2005). When
falsification is the only path to truth. In B.G. Bara, L. Barsalou & M.
Bucciarelli (eds), Proceedings of the Twenty-Seventh Annual Conference
of the Cognitive Science Societ (pp. 512--517). Mahwah, NJ: Erlbaum.
Cowley, S.J. & Harvey, M.I. (2016). The illusion of common ground. New
Ideas in Psychology, 42, 56--63. Cox, W.T.L. & Devine, P.G. (2016).
Experimental research on shooter bias: Ready (or relevant) for
application in the courtroom? Journal of Applied Research in Memory and
Cognition, 5, 236--238. Craik, F.I.M. (2002). Levels of processing:
Past, present . . . and future? Memory, 10, 305--318. Craik, F.I.M. &
Lockhart, R.S. (1972). Levels of processing: A framework for memory
research. Journal of Verbal Learning and Verbal Behavior, 11, 671--684.
Craik, F.I.M. & Tulving, E. (1975). Depth of processing and the
retention of words in episodic memory. Journal of Experimental
Psychology: General, 104, 268--294. Crawford, J.R., Smith, G., Maylor,
E.A., Della Sala, S. & Logie, R.H. (2003). The Prospective and
Retrospective Memory Questionnaire (PRMQ): Normative data and latent
structure in a large non-clinical sample. Memory, 11, 261--275.
Craycraft, N.N. & Brown-Schmidt, S. (2018). Compensating for an
inattentive audience. Cognitive Science, 42, 1509--1528. Creem, S.H. &
Proffitt, D.R. (2001). Grasping objects by their handles: A necessary
interaction between cognition and action. Journal of Experimental
Psychology: Human Perception and Performance, 27, 218--228. Crescentini,
C., Seyed-Allaei, S., Vallesi, A. & Shallice, T. (2012). Two networks
involved in producing and realising plans. Neuropsychologia, 50,
1521--1535.

Crible, L. (2017). Discourse markers and (dis)fluencies in English and
French: Variation and combination in the DisFrEn corpus. International
Journal of Corpus Linguistics, 22, 242--269. Crisp, J., Howard, D. &
Lambon Ralph, M.A. (2011). More evidence for a continuum between
phonological and deep dyslexia: Novel data from three measures of direct
orthography-to-phonology translation. Aphasiology, 25, 615--641.
Cristea, I.A., Kok, R.N. & Cuijpers, P. (2015). Efficacy of cognitive
bias modification interventions in anxiety and depression:
Meta-analysis. British Journal of Psychiatry, 206, 7--16. Croskerry, P.
(2018). Medical decision making. In L.J. Ball & V.A. Thompson (eds),
Routledge International Handbook of Thinking and Reasoning
(pp. 109--129). Abingdon, Oxon.: Routledge. Crupi, V., Elia, F., Aprà,
F. & Tentori, K. (2018). Double conjunction fallacies in physicians'
probability judgement. Medical Decision Making, 38, 756--760. Cruse, D.,
Chennu, S., Chatelle, C., Bekinschtein, T.A., Fernandez-Espejo, D.,
Pickard, J.D., et al. (2011). Bedside detection of awareness in the
vegetative state. Lancet, 378, 2088--2094. Cryder, C.E., Lerner, J.S.,
Gross, J.J. & Dahl, R.E. (2008). Misery is not miserly: Sad and
self-focused individuals spend more. Psychological Science, 19,
525--530. Crystal, D. (1997). A Dictionary of Linguistics and Phonetics
(4th edn). Cambridge, MA: Blackwell. Crystal, D. (2005). Speaking of
writing and writing of speaking. Longman's Language Review, 1, 5--8.
Curiel, J.M. & Radvansky, G.A. (2014). Spatial and character situation
model updating. Journal of Cognitive Psychology, 26, 205--212. Curot,
J., Busigny, T., Valton, L., Denuelle, M., Vignal, J.-P., Maillard, L.,
et al. (2017). Memory scrutinized through electrical brain stimulation:
A review of 80 years of experiential phenomena. Neuroscience and
Biobehavioral Reviews, 78, 161--177. Cutler, A. & Butterfield, S.
(1992). Rhythmic cues to speech segmentation: Evidence from juncture
misperception. Journal of Memory and Language, 31, 218--236. Cuttler, C.
& Graf, P. (2009a). Checking-in on the memory deficit and meta-memory
deficit theories of compulsive checking. Clinical Psychology Review, 29,
393--409. Cuttler, C. & Graf, P. (2009b). Sub-clinical compulsive
checkers show impaired performance on habitual, event- and time-cued
episodic prospective memory tasks. Journal of Anxiety Disorders, 23,
813--823. Cvejic, E., Kim, J. & Davis, C. (2012). Recognising prosody
across modalities, face areas and speakers: Examining perceivers'
sensitivity to variable realisations of visual prosody. Cognition, 122,
442--453.

References Dąbrowska, E. (2018). Experience, aptitude and individual
differences in native language ultimate attainment. Cognition, 178,
222--235. Dagher, A., Owen, A.M., Boecker, H. & Brooks, D.J. (1999).
Mapping the network for planning: A correlational PET activation study
with the Tower of London task. Brain, 122, 1973--1987. Dalgleish, T. &
Werner-Seidler, A. (2014). Disruptions in autobiographical memory
processing in depression and the emergence of memory therapeutics.
Trends in Cognitive Sciences, 18, 596--604. Dalgleish, T., Hill, E.,
Golden, A.-M.J., Morant, N. & Dunn, B.D. (2011). The structure of past
and future lives in depression. Journal of Abnormal Psychology, 120,
1--15. Dalrymple, K.A., Kingstone, A. & Handy, T.C. (2009).
Event-related potential evidence for a dual-locus model of global/local
processing. Cognitive Neuropsychology, 26, 456--470. Danckert, J. &
Ferber, S. (2006). Revisiting unilateral neglect. Neuropsychologia, 44,
987--1006. Dando, C.J., Ormerod, T.C., Wilcock, R. & Milne, R. (2011).
When help becomes hindrance: Unexpected errors of omission and
commission in eyewitness memory resulting from changes in temporal order
at retrieval? Cognition, 121, 416--421. Dandolo, L.C. & Schwabe, L.
(2018). Time-dependent memory transformation along the hippocampal
anterior axis. Nature Communications, 9 (Article no. 1205). Danek, A.H.
& Wiley, J. (2017). What about false insights? Deconstructing the Aha!
experience along its multiple dimensions for correct and incorrect
solutions separately. Frontiers in Psychology, 7 (Article no. 2077).
Danek, A.H., Fraps, T., von Műller, A., Grothe, B. & Öllinger, M.
(2014). Working wonders? Investigating insight with magic tricks.
Cognition, 130, 174--185. Daneman, M. & Carpenter, P.A. (1980).
Individual differences in working memory and reading. Journal of Verbal
Learning and Verbal Behavior, 19, 450--466. Darling, S. & Havelka, J.
(2010). Visuospatial bootstrapping: Evidence for binding of verbal and
spatial information in working memory. Quarterly Journal of Experimental
Psychology, 63, 239--245. Darling, S., Allen, R.J. & Havelka, J. (2017).
Visuo-spatial bootstrapping: When visuo-spatial and verbal memory work
together. Current Directions in Psychological Science, 26, 3--9. Das,
T., Hwang, J.J. & Poston, K.L. (2019). Episodic recognition memory and
the hippocampus in Parkinson's disease: A review. Cortex, 113, 191--209.
D'Avanzato, C., Joormann, J., Siemer, M. & Gotlib, I.H. (2013). Emotion
regulation and anxiety: Examining diagnostic specificity and stability
of strategy use. Cognitive Therapy & Research, 37, 968--980.

841

Davies, B.L. (2007). Grice's Cooperative Principle: Meaning and
rationality. Journal of Pragmatics, 39, 2308--2331. Davies, M. (2010).
Double dissociation: Understanding its role in cognitive
neuropsychology. Mind & Language, 25, 500--540. Davies-Thompson, J.,
Pancaroglu, R. & Barton, J. (2014). Acquired prosopagnosia: Structural
basis and processing impairments. Frontiers in Bioscience, E6, 159--174.
Davis, J.I., Senghas, A., Brandt, F. & Ochsner, K.N. (2010). The effects
of BOTOX injections on emotional experience. Emotion, 10, 433--440.
Davis, M. (2018). Frederic Bartlett: A question of priority. Quarterly
Journal of Experimental Psychology, 71, 1030--1031. Dawes, R.M. (1988).
Rational Choice in an Uncertain World. San Diego, CA: Harcourt Brace
Jovanovich. Dawson, E., Gilovich, T. & Regan, D.T. (2002). Motivated
reasoning and performance on the Wason selection task. Personality and
Social Psychology Bulletin, 28, 1379--1387. Day, M.V. & Ross, M. (2014).
Predicting confidence in flashbulb memories. Memory, 22, 232--242.
Deady, D.K., North, N.T., Allan, D., Smith, M.J.L. & O'Carroll, R.E.
(2010). Examining the effect of spinal cord injury on emotional
awareness, expressivity and memory for emotional material. Psychology,
Health & Medicine, 15, 406--419. Dean, M., Kibris, O. & Masatlioglu, Y.
(2017). Limited attention and status quo bias. Journal of Economic
Theory, 169, 93--127. Debelak, R., Egle, J., Köstering, L. & Kaller,
C.P. (2016). Assessment of planning ability: Psychometric analyses on
the unidimensionality and construct validity of the Tower of London task
(TOL-F). Neuropsychology, 30, 346--360. de Bode, S., Smets, L., Mathern,
G.W. & Dubinsky, S. (2015). Complex syntax in the isolated right
hemisphere: Receptive grammatical abilities after cerebral
hemispherectomy. Epilepsy & Behavior, 51, 33--39. Dębska, A. &
Rączaszek-Leonardi, J. (2018). What makes us more egocentric in
communication? Discourse Processes, 55, 1--11. DeCaro, M.S., van
Stockum, C.A. & Wieth, M.B. (2016). When higher working memory hinders
insight. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 42, 39--49. DeCaro, M.S., van Stockum, C.A. & Wieth, M.B.
(2017). The relationship between working memory and insight depends on
moderators: Reply to Chuderski and Justrzêbski (2017). Journal of
Experimental Psychology: Learning, Memory, and Cognition, 43,
2005--2010. Deffenbacher, K.A., Bornstein, B.H., Penrod, S.D. & McGorty,
E.K. (2004). A meta-analytic review of the effects of high stress on
eyewitness memory. Law and Human Behavior, 28, 687--706.

842

References

de Gardelle, V., Sackur, J. & Kouider, S. (2009). Perceptual illusions
in brief visual presentations. Consciousness and Cognition, 18,
569--577. de Gardelle, V., Waszczuk, M., Egner, T. & Summerfield, C.
(2013). Concurrent repetition enhancement and suppression responses in
extrastriate visual cortex. Cerebral Cortex, 23, 2235--2244. Degno, F.,
Loberg, O., Zang, C.L., Zhang, M.M., Donnelly, N. & Liversedge, S.P.
(2019). Parafoveal previews and lexical frequency in natural reading:
Evidence from eye movements and fixation-related potentials. Journal of
Experimental Psychology: General, 148, 453--473. de Graaf, T.A., Hsieh,
P.-J. & Sack, A.T. (2012). The "correlates" in neural correlates of
consciousness. Neuroscience and Biobehavioral Reviews, 16, 191--197. De
Groot, A.D. (1965). Thought and Choice in Chess. The Hague, Netherlands:
Mouton. de Haan, E.H.F., Jackson, S.R. & Schenk, T. (2018). Where are we
now with "what" and "how"? Cortex, 98, 1--7. de Haan, B., Karnath, H.-O.
& Driver, J. (2012). Mechanisms and anatomy of unilateral extinction
after brain injury. Neuropsychologia, 50, 1045--1053. Dehaene, S. &
Changeux, J.P. (2011). Experimental and theoretical approaches to
conscious processing. Neuron, 70, 200--227. Delaney, P.F., Ericsson,
K.A. & Knowles, M.E. (2004). Immediate and sustained effects of planning
in a problemsolving task. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 30, 1219--1234. de la Rosa, S., Schillinger,
F.L., Bülthoff, H.H., Schultz, J. & Uludag, K. (2016). fMRI adapation
between action observation and action execution reveals cortical areas
with mirror neuron properties in human BA 44/45. Frontiers in Human
Neuroscience, 10 (Article no. 78). Del Cul, A., Dehaene, S., Reyes, P.,
Bravo, E. & Slachevsky, A. (2009). Causal role of prefrontal cortex in
the threshold for access to consciousness. Brain, 132, 2531--2540. Del
Guidice, M. & Ellis, B.J. (2015). Evolutionary foundations of
developmental psychopathology. In D. Ciccetti (ed.), Developmental
Psychopathology, Vol. 2: Developmental neuroscience (3rd edn)
(pp. 1--58). New York: Wiley. Dell, G.S. (1986). A spreading-activation
theory of retrieval in sentence production. Psychological Review, 93,
283--321. Dell, G.S. (2013). Cascading and feedback in interactive
models of production: A reflection of forward modelling? Behavioral and
Brain Sciences, 36, 351--352. Dell, G.S. & Caramazza, A. (2008).
Introduction to special issue on computational modelling in cognitive
neuropsychology. Cognitive Neuropsychology, 25, 131--135. Dell, G.S. &
Oppenheim, G.M. (2015). Insights for speech production planning from
errors in inner speech. In M.A. Redford (ed.), The Handbook of Speech
Production (pp. 404--418). Hoboken, NJ: Wiley-Blackwell.

Dell, G.S., Burger, L.K. & Svec, W.R. (1997). Language production and
serial order: A functional analysis and a model. Psychological Review,
104, 123--147. Dell, G.S., Nozari, N. & Oppenheim, G.M. (2014). Word
production: Behavioural and computational considerations. In M.
Goldrick, V. Ferreira & M. Miozzo (eds), The Oxford Handbook of Language
Production. Oxford: Oxford University Press. Dell, G.S., Oppenheim, G.M.
& Kitttredge, A.K. (2008). Saying the right word at the right time:
Syntagmatic and paradigmatic interference in sentence production.
Language and Cognitive Processes, 23, 583--608. DeLong, K.A., Urbach,
T.P. & Kutas, M. (2005). Probabilisltic word activation during language
comprehension inferred from electrical brain activity. Nature
Neuroscience, 8, 1117--1121. DeLucia, P.R. (2013). Effects of size on
collision perception and implications for perceptual theory and
transportation safety. Current Directions in Psychological Science, 22,
199--204. del Prete, F., Hanczakowski, M., Bajo, M.T. & Mazzoni, G.
(2015). Inhibitory effects of thought substitution in the think/no-think
task: Evidence from independent cues. Memory, 23, 507--517. de Manzano,
O. & Ullén, F. (2018). Same genes, different brains: Neuroanatomical
differences between monozygotic twins discordant for musical training.
Cerebral Cortex, 28, 387--394. De Martino, B., Camerer, C.F. & Adolphs,
R. (2010). Amydala damage eliminates monetary loss aversion. Proceedings
of the National Academy of Sciences, 107, 3788--3792. Demertzi, A.,
Soddu, A. & Laureys, S. (2013). Consciousness supporting networks.
Current Opinion in Neurobiology, 23, 239--244. DeMiguel, V., Garlappi,
L. & Budescu, D.V. (2009). Optimal versus naïve diversification: How
inefficient is the 1/N portfolio strategy? Review of Financial Studies,
22, 1915--1953. Demiray, B. & Janssen, S.M.J. (2015). The
self-enhancement function of autobiographical memory. Applied Cognitive
Psychology, 29, 49--60. De Neys, W. (2006). Dual processing in
reasoning: Two systems but one reasoner. Psychological Science, 17,
428--433. De Neys, W. (2012). Bias and conflict: A case for logical
intuitions. Perspectives on Psychological Science, 7, 28--38. De Neys,
W. (2014). Conflict detection, dual processes, and logical intuitions:
Some clarifications. Thinking & Reasoning, 20, 169--187. De Neys, W.,
Cromheeke, S. & Osman, M. (2011). Feeling we're biased: Autonomic
arousal and reasoning conflict. Cognitive, Affective & Behavioral
Neuroscience, 12, 123--130.

References De Neys, W. & Verschueren, N. (2006). Working memory capacity
and a notorious brain teaser -- The case of the Monty Hall dilemma.
Experimental Psychology, 53, 123--131. De Neys, W., Moyens, E. &
Vansteenwegen, D. (2010). Feeling we're biased: Autonomic arousal and
reasoning conflict. Cognitive, Affective & Behavioral Neuroscience, 12,
123--130. De Neys, W., Schaeken, W. & d'Ydewalle, G. (2005). Working
memory and everyday conditional reasoning: Retrieval and inhibition of
stored counterexamples. Thinking & Reasoning, 11, 349--381. den Ouden,
D.-B., Dickey, M.W., Anderson, C. & Christianson, K. (2016). Neural
correlates of early-closure garden-path processing: Effects of prosody
and plausibility. Quarterly Journal of Experimental Psychology, 69,
926--949. Derryberry, D. & Reed, M.A. (2002). Anxiety-related
attentional biases and their regulation by attentional control. Journal
of Abnormal Psychology, 111, 225--236. De Salvo, S., Caminiti, F.,
Bonanno, L., De Cola, M.C., Corallo, F., Caizzone, A., et al. (2015).
Neurolophysiological assessment for evaluating residual cognition in
vegetative and minimally conscious state patients: A pilot study.
Functional Neurology, 30, 237--244. de Schotten, M.T. & Shallice, T.
(2017). Identical, similar or different? Is a single brain model
sufficient? Cortex, 86, 172--175. Destrebecqz, A., Peigneux, P.,
Laureys, S., Degueldre, C., Del Fiorem, G., Aerts, J., et al. (2005).
The neural correlates of implicit and explicit sequence learning:
Interacting networks revealed by the process dissociation procedure.
Learning and Memory, 12, 480--490. Deutsch, J.A. & Deutsch, D. (1963).
Attention: Some theoretical considerations. Psychological Review, 93,
283--321. De Vries, J.V. (1970). Perspective. (Original work published
in 1604). De Vries, M., Holland, R.W., Corneille, O., Rondeel, E.J.E. &
Witteman, C.L.M. (2012). Mood effects on dominated choices: Positive
mood induces departures from logical rules. Journal of Behavioral
Decision Making, 25, 74--81. Dew, I.T.Z. & Cabeza, R. (2011). The porous
boundaries between explicit and implicit memory: Behavioural and neural
evidence. Annals of the New York Academy of Sciences, 1224, 174--190.
Dewar, M.T., Cowan, N. & Della Sala, S. (2007). Forgetting due to
retroactive interference: A fusion of Müller and Pizecker's (1900) early
insights into everyday forgetting and recent research on retrograde
amnesia. Cortex, 43, 616--634. Diana, R.A. (2017). Parahippocampal
cortex processes the non-spatial context of an event. Cerebral Cortex,
27, 1808--1816.

843

Diana, R.A., Yonelinas, A.P. & Ranganath, C. (2007). Imaging
recollection and familiarity in the medial temporal lobe: A
three-component model. Trends in Cognitive Sciences, 11, 379--386.
Diano, M., Celeghin, A., Bagnis, A. & Tamietto, M. (2017). Amygdala
response to emotional stimuli without awareness: Facts and
interpretations. Frontiers in Psychology, 7 (Article no. 2029). Diao,
L., Qi, S., Xu, M., Li, Z., Ding, C., Chen, A., et al. (2016). Neural
signature of reward-modulated unconscious inhibitory control.
International Journal of Psychophysiology, 107, 1--8. Dick, F., Bates,
E., Wulfeck, B., Utman, J.A., Dronkers, N. & Gernsbacher, M.A. (2001).
Language deficits, localization, and grammar: Evidence for a
distributive model of language breakdown in aphasic patients and
neurologically intact individuals. Psychological Review, 108, 759--788.
Dijksterhuis, A. & Nordgren, L.F. (2006). A theory of unconscious
thought. Perspectives on Psychological Science, 1, 95--180.
Dijksterhuis, A. & Strick, M. (2016). A case for thinking without
consciousness. Perspectives on Psychological Science, 11, 117--132.
Dijkstra, K. & Post, L. (2015). Mechanisms of embodiment. Frontiers in
Psychology, 6 (Article no. 1525). Dijkstra, N., Bosch, S.E. & van
Gerven, M.A.J. (2017a). Vividness of visual imagery depends on the
neural overlap with perception in visual areas. Journal of Neuroscience,
37, 1367--1373. Dijkstra, N., Mostert, P., de Lange, F.P., Bosch, S. &
van Gerven, M.A.J. (2018). Differential temporal dynamics during visual
imagery and perception. eLIFE, 7 (Article no. e33904). Dijkstra, N.,
Zeidman, P., Ondobaka, S., van Gerven, M.A.J. & Friston, K. (2017b).
Distinct top-down and bottom-up brain connectivity during visual
perception and imagery. Scientific Reports, 7 (Article no. 5677). Di
Lollo, V. (2018). Attention is a sterile concept; iterative re-entry is
a fertile substitute. Consciousness and Cognition, 64, 45--49. Ding, S.,
Cueva, C.J., Tsodyks, M. & Qian, N. (2017). Visual perception as
retrospective Bayesian decoding from high- to low-level features.
Proceedings of the National Association of Sciences, 43, E9115--E9124.
Dion, K.L. & Dion, K.K. (1976). The Honi phenomenon revisited: Factors
underlying the resistance to perceptual distortion of one's partner.
Journal of Personality and Social Psychology, 33, 170--177. Di Russo,
F., Aprile, T., Spitoni, G. & Spinelli, D. (2008). Impaired visual
processing of contralesional stimuli in neglect patients: A
visual-evoked potential study. Brain, 131, 842--854.

844

References

Dismukes, R.K. (2012). Prospective memory in workplace and everyday
situations. Current Directions in Psychological Science, 21, 215--220.
Dismukes, R.K. & Nowinski, J.L. (2006). Prospective memory, concurrent
task management, and pilot error. In A. Kramer, D. Wiegmann & A. Kirlik
(eds), Attention: From theory to practice (pp. 223--238). Oxford: Oxford
University Press. Di Stasi, L.L. & Guardini, P. (2007). Perceiving
affordances in virtual environments: Visual guidance of virtual stair
climbing. Perception, 36 (Suppl. S), 186. Ditto, P.H., Scepansky, J.A.,
Munro, G.D., Apanovitch, A.M. & Lockhart, L.K. (1998). Motivated
sensitivity to preference inconsistent information. Journal of
Personality and Social Psychology, 75, 53--69. Dodhia, R.M. & Dismukes,
K.R. (2009). Interruptions create prospective memory tasks. Applied
Cognitive Psychology, 23, 73--89. Döhring, J., Stoldt, A., Witt, K.,
Schönfeld, R., Deuschl, G., Born, J., et al. (2017). Motor skill
learning and offlinechanges in TGA patients with acute hippocampal CA1
lesions. Cortex, 89, 156--168. Dolcos, F., Katsumi, Y., Weymar, M.,
Moore, M., Tsukiura, T. & Dolcos, S. (2017). Emerging directions in
emotional episodic memory. Frontiers in Psychology, 8 (Article no.
1867). Domeier, M., Sachse, P. & Schäfer, B. (2018). Motivational
reasons for biased decisions: The sunk-cost effect's instrumental
rationality. Frontiers in Psychology, 9 (Article no. 815). Domini, F.,
Shah, R. & Caudek, C. (2011). Do we perceive a flattened world on the
monitor screen? Acta Psychologica, 138, 359--366. Domurat, A.,
Kowalczuk, O., Idzikowska, K., Borzymowska, Z. & Nowak-Przygodzka, M.
(2015). Bayesian probability estimates are not necessary to make choices
satisfying Bayes' rule in elementary situations. Frontiers in
Psychology, 6, 1--14. Donovan, I., Pratt, J. & Shomstein, S. (2017).
Spatial attention is necessary for object-based attention: Evidence from
temporal-order judgements. Attention, Perception & Psychophysics, 79,
753--764. Doré, B.P., Silvers, J.A. & Ochsner, K.N. (2016). Toward a
personalized science of emotion regulation. Social and Personality
Psychology Compass, 10, 171--187. Dosenbach, N.U.F., Fair, D.A., Cohen,
A.L., Schlaggar, B.L. & Petersen, S.E. (2008). A dual-networks
architecture of top-down control. Trends in Cognitive Sciences, 12,
99--105. Douglass, A.B. & Steblay, N.K. (2006). Memory distortion in
eyewitnesses: A meta-analysis of the post-identification feedback
effect. Applied Cognitive Psychology, 20, 859--869.

Downing, P.E., Chan, A.W.Y., Peelen, M.V., Dodds, C.M. & Kanwisher, N.
(2006). Domain specificity in visual cortex. Cerebral Cortex, 16,
1453--1461. Doyon, J., Gabitov, E., Vahdat, S., Lungu, O. & Boutin, A.
(2018). Current issues related to motor sequence learning in humans.
Current Opinion in Behavioral Sciences, 20, 89--97. Dreyer, F.R., Frey,
D., Arana, S., von Saldern, S., Picht, T., Vajkoczy, P., et al. (2015).
Is the motor system necessary for processing action and abstract emotion
words? Evidence from focal brain lesions. Frontiers in Psychology, 6
(Article no. 1661). Dronkers, N.F., Ivanova, M.V. & Baldo, J.V. (2017).
What do language disorders reveal about brain-language relationships?
From classic models to network approaches. Journal of the International
Neuropsychological Society, 23, 741--754. Dror, I.E., Charlton, D. &
Péron, A.E. (2006). Contextual information renders experts vulnerable to
making erroneous identifications. Forensic Science International, 156,
74--78. Dror, I.E., Wertheim, K., Fraser-Mackenzie, P. & Walajtys, J.
(2012). The impact of human-technology co-operation and distributed
cognition in forensic science: Biasing effects of AFIS contextual
information on human experts. Journal of Forensic Sciences, 57,
343--352. Drummond, L. & Shomstein, S. (2010). Object-based attention:
Shifting or uncertainty? Attention, Perception & Psychophysics, 72,
1743--1755. Drury, J.E., Baum, S.R., Valertote, H. & Steinhauer, K.
(2016). Punctuation and implicit prosody in silent reading: An ERP study
investigating English gardenpath sentences. Frontiers in Psychology, 7
(Article no. 1375). Dubarry, A.-S., Llorens, A., Trébuchon, A., Carron,
R., Liégeois-Chauvel, C., Bénar, C.-G., et al. (2017). Estimating
parallel processing in a language task using single-trial intracerebral
electroencephalography. Psychological Science, 28, 414--426. Duchaine,
B. & Yovel, G. (2015). A revised neural framework for face processing.
Annual Review of Vision Science, 1, 393--416. Dudai, Y. & Edelson, M.G.
(2016). Personal memory: Is it personal, is it memory? Memory Studies,
9, 275--283. Dudukovic, N.M., Marsh, E.J. & Tversky, B. (2004). Telling
a story or telling it straight: The effects of entertaining versus
accurate retellings on memory. Applied Cognitive Psychology, 18,
125--143. Duffau, H. (2017). A two-level model of inter-individual
anatomo-functional variability of the brain and its implications for
neurosurgery. Cortex, 86, 303--313. Duffy, S.A. & Pisoni, D.B. (1992).
Comprehension of synthetic speech produced by rule: A review and
theoretical interpretation. Language and Speech, 35, 351--389.

References Dufour, S., Bruneilliere, A. & Frauenfelder, U.H. (2013).
Tracking the time course of word-frequency effects in auditory word
recognition with event-related potentials. Cognitive Science, 37,
489--507. Dugué, L., Merriam, E.P., Heeger, D.J. & Carrasco, M. (2018).
Specific visual subregions of TPJ mediate reorienting of spatial
attention. Cerebral Cortex, 28, 2375--2390. Dummel, S., Rummel, J. &
Voss, A. (2016). Additional information is not ignored: New evidence for
information integration and inhibition in take-the-best decisions. Acta
Psychologica, 163, 167--184. Dunbar, K. (1993). Concept discovery in a
scientific domain. Cognitive Science, 17, 397--434. Dunbar, K. (1995).
How scientists really reason: Scientific reasoning in real-world
laboratories. In R.J. Sternberg & J.E. Davidson (eds), The Nature of
Insight (pp. 365--395). Cambridge, MA: MIT Press. Dunbar, K. &
Blanchette, I. (2001). The analogical paradox: Why analogy is so easy in
naturalistic settings, yet so difficult in the psychological laboratory.
In D. Genter, K. Holyoak & B. Kokinov (eds), Analogy: Perspectives from
Cognitive Science (pp. 313--334). Cambridge, MA: MIT Press. Duncan, J. &
Humphreys, G.W. (1989). A resemblance theory of visual search.
Psychological Review, 96, 433--458. Duncan, J. & Humphreys, G.W. (1992).
Beyond the search surface: Visual search and attentional engagement.
Journal of Experimental Psychology: Human Perception & Performance, 18,
578--588. Duncan, J., Bundesen, C., Olson, A., Humphreys, G., Chavda, S.
& Shibuya, H. (1999). Systematic analysis of deficits in visual
attention. Journal of Experimental Psychology: General, 128, 450--478.
Duncker, K. (1945). On problem solving. Psychological Monographs, 58
(Whole No. 270). Dunlosky, J., Rawson, K.A., Marsh, E.J., Nathan, M.J. &
Willingham, D.T. (2013). Improving students' learning with effective
learning techniques: Promising directions from cognitive and educational
psychology. Psychological Science in the Public Interest, 14, 4--58.
Dunn, J.C. (2008). The dimensionality of the remember-know task: A
state-trace analysis. Psychological Review, 115, 426--446. Dunning, D.
(2011). Chapter five -- The Dunning Kruger effect: On being ignorant of
one's own ignorance. Advances in Experimental Social Psychology, 44,
247--296. Duss, S.B., Reber, T.P., Hänggi, J., Schwab, S., Wiest, R.,
Muri, R.M., et al. (2014). Unconscious relational encoding depends on
hippocampus. Brain, 137, 3355--3370. Dux, P.E., Tombu, M.N., Harrison,
S., Rogers, B.P., Tong, F. & Marois, R. (2009). Training improves
multitasking performance by increasing the speed of information
processing in human prefrontal cortex. Neuron, 63, 127--138.

845

Dyer, J.S. (2016). Multi-attribute utility theory (MAUT). International
Series in Operations Research and Management Science, 233, 285--314.
Eagle, M.N., Gallese, V. & Migone, P. (2007). Intentional attunement:
Mirror neurons and the neural underpinnings of interpersonal relations.
Journal of the American Psychoanalytic Association, 55, 131--176.
Easterbrook, J.A. (1959). The effect of emotion on cue utilisation and
the organisation of behaviour. Psychological Review, 66, 183--201.
Eaton, E., Marshall, J. & Pring, T. (2011). Mechanisms of change in the
evolution of jargon aphasia. Aphasiology, 25, 1543--1561. Ebbinghaus, H.
(1885/1913). Über das Gedächtnis (Leipzig: Dunker) \[translated by H.
Ruyer & C.E. Bussenius\]. New York: Teacher College, Columbus
University. Ecker, U.K.H., Brown, G.D.A. & Lewandowsky, S. (2015).
Memory without consolidation: Temporal distinctiveness explains
retroactive interference. Cognitive Science, 39, 1570--1593. Edelson,
M.G., Sharot, T., Dolan, R.J. & Dudai, Y. (2011). Following the crowd:
Brain substrates of long-term memory conformity. Science, 333, 108--111.
Egly, R., Driver, J. & Rafal, R.D. (1994). Shifting visual attention
between objects and locations: Evidence from normal and parietal lesion
subjects. Journal of Experimental Psychology: General, 123, 161--177.
Eherenfreund-Hager, A. & Taubman-Ben-Ari, O. (2016). The effect of
affect induction and personal variables on young drivers' willingness to
drive recklessly. Transportation Research Part F, 41, 138--149.
Eherenfreund-Hager, A., Taubman-Ben-Ari, O., Toledo, T. & Farah, H.
(2017). The effect of positive and negative emotions on young drivers: A
simulator study. Transportation Research Part F, 49, 236--243. Ehinger,
K.A., Hidalgo-Sotelo, B., Torraiba, A. & Oliva, A. (2009). Modelling
search for people in 900 scenes: A combined source model of eye
guidance. Visual Cognition, 17, 945--978. Eich, E. (1995). Searching for
mood-dependent memory. Psychological Science, 6, 67--75. Eich, E. &
Metcalfe, J. (1989). Mood-dependent memory for internal versus external
events. Journal of Experimental Psychology: Learning, Memory &
Cognition, 15, 443--455. Eichenbaum, H. (2015). Amnesia: Revisiting
Scoville and Milner's (1957) research on HM. In M.W. Eysenck & D. Groome
(eds), Cognitive Psychology: Revisiting the classic studies
(pp. 71--85). London: Sage. Eil, D. & Lien, J.W. (2014). Staying ahead
and getting even: Risk attitudes of experienced poker players. Games and
Economic Behavior, 87, 50--69. Eimer, M. & Schröder, E. (1998). ERP
effects of intermodal attention and cross-modal links in spatial
attention. Psychophysiology, 35, 317--328.

846

References

Eimer, M., Gosling, A. & Duchaine, B. (2012). Electrophysiological
markers of covert face recognition in developmental prosopagnosia.
Brain, 135, 542--554. Einstein, G.O. & McDaniel, M.A. (2005).
Prospective memory: Multiple retrieval processes. Current Directions in
Psychological Science, 14, 286--290. Ekroll, V., Sayim, B., Van der
Hallen, R. & Wagemans, J. (2016). Illusory visual completion of an
object's invisible backside can make your finger feel shorter. Current
Biology, 26, 1029--1033. Ekroll, V., Sayim, B. & Wagermans, J. (2017).
The other side of magic: The psychology of perceiving hidden things.
Perspectives on Psychological Science, 12, 91--106. Eldar, E., Niv, Y. &
Cohen, J.D. (2016). Neural gain and breadth versus focus in perceptual
processing. Psychological Science, 27, 1632--1643. Elder, J.H. &
Goldberg, R.M. (2002). Ecological statistics of Gestalt laws for the
perceptual organisation of contours. Journal of Vision, 2, 324--353.
Elliott, D., Lyons, J., Hayes, S.J., Burkitt, J.J., Roberts, J.W.,
Grierson, L.E.M., et al. (2017). The multiple process model of
goal-directed reaching revisited. Neuroscience and Biobehavioral
Reviews, 72, 95--110. Ellis, A.W. & Young, A.W. (1988). Human Cognitive
Neuropsychology. Hove, UK: Psychology Press. Ellis, J.J., Glaholt, M.G.
& Reingold, E.M. (2011). Eye movements reveal solution knowledge prior
to insight. Consciousness and Cognition, 20, 768--776. Elqayam, S.
(2018). The new paradigm in psychology of reasoning. In L.J. Ball &
V.A.Thompson (eds), Routledge International Handbook of Thinking and
Reasoning (pp. 130--150). Abingdon, Oxon.: Routledge. Elqayam, S. &
Evans, J.St.B.T. (2011). Subtracting "ought" from "is": Descriptivism
versus normatism in the study of human thinking. Behavioral and Brain
Sciences, 34, 233--248. Elsey, J.W.B., van Ast, V.A. & Kindt, M. (2018).
Human memory reconsolidation: A guiding framework and critical review of
the evidence. Psychological Bulletin, 144, 797--848. Elward, R.L. &
Vargha-Khadem, F. (2018). Semantic memory in developmental amnesia.
Neuroscience Letters, 680, 23--30. Endres, T. & Renkl, A. (2015).
Mechanisms behind the testing effect: An empirical investigation of
retrieval practice in meaningful learning. Frontiers in Psychology, 6
(Article no. 1054). Endress, A.D. & Potter, M.C. (2014). Large capacity
temporary visual memory. Journal of Experimental Psychology: General,
143, 548--565. Endress, A.D. & Szabó, S. (2017). Interference and memory
capacity limitations. Psychological Review, 124, 551--571. Engbert, R.,
Nuthmann, A., Richter, E.M. & Kliegl, R. (2005). SWIFT: A dynamical
model of saccade

generation during reading. Psychological Review, 112, 777--813. Engel,
P.J.H. (2008). Tacit knowledge and visual expertise in medical
diagnostic reasoning: Implications for medical education. Medical
Teacher, 30, e184--e188. Engel, S., Shapiro, L.P. & Love, T. (2018).
Proformantecedent linking in individuals with agrammatic aphasia: A test
of the intervener hypothesis. Journal of Neurolinguistics, 48, 79--94.
Engle, R.W. & Kane, M.J. (2004). Executive attention, working memory
capacity and a two-factor theory of cognitive control. In B. Ross (ed.),
The Psychology of Learning and Motivation (pp. 145--199). New York:
Elsevier. Engstrom, J., Markkula, G., Victor, T. & Merat, N. (2017).
Effects of cognitive load on driving performance: The cognitive control
hypothesis. Human Factors, 59, 734--764. Enz, K.F., Pillemer, D.B. &
Johnson, K.M. (2016). The relocation bump: Memories of middle adulthood
are organised around residential moves. Journal of Experimental
Psychology: General, 145, 935--940. Erez, J., Cusack, R., Kendall, W. &
Barense, M.D. (2016). Conjunctive coding of complex object features.
Cerebral Cortex, 26, 2271--2282. Ericsson, K.A. (2017). Expertise and
individual differences: The search for the structure and acquisition of
experts' superior performance. Wiley Interdisciplinary Reviews:
Cognitive Science, 8, 1--6. Ericsson, K.A. & Chase, W.G. (1982).
Exceptional memory. American Scientist, 70, 607--615. Ericsson, K.A. &
Kintsch, W. (1995). Long-term working memory. Psychological Review, 102,
211--245. Eriksen, C.W. & St. James, J.D. (1986). Visual attention
within and around the field of focal attention: A zoom lens model.
Perception & Psychophysics, 40, 225--240. Eriksson, J., Larsson, A.,
Ahlströn, K.R. & Nyberg, L. (2006). Similar frontal and distinct
posterior cortical regions mediate visual and auditory perceptual
awareness. Cerebral Cortex, 17, 760--765. Esteves-Sorenson, C. &
Perretti, F. (2012). Micro-costs: Inertia in television viewing. The
Economic Journal, 122, 867--902. Etchells, D.B., Brooks, J.L. &
Johnston, R.A. (2017). Evidence for view-invariant face recognition
units in unfamiliar face learning. Quarterly Journal of Experimental
Psychology, 70, 874--889. Etkin, A. & Schatzberg, A.F. (2011). Common
abnormalities and disorder-specific compensation during implicit
regulation of emotional processing in generalised anxiety and major
depressive disorders. American Journal of Psychiatry, 168, 968--978.
Etkin, A., Büchel, C. & Gross, J.J. (2015). The neural basis of emotion
regulation. Nature Reviews Neuroscience, 16, 693--700.

References Eustache, F., Viard, A. & Desgranges, B. (2016). The MNESIS
model: Memory systems and processes, identity and future thinking.
Neuropsychologia, 87, 96--109. Evans, J.St.B.T. (2006). The
heuristic-analytic theory of reasoning: Extension and evaluation.
Psychonomic Bulletin & Review, 13, 378--395. Evans, J.St.B.T. (2016).
Reasoning, biases and dual processes: The lasting impact of Wason
(1960). Quarterly Journal of Experimental Psychology, 69, 2076--2092.
Evans, J.St.B.T. (2018). Dual-process theories. In L.J. Ball & V.A.
Thompson (eds), Routledge International Handbook of Thinking and
Reasoning (pp. 151--166). Abingdon, Oxon.: Routledge. Evans, J.St.B.T. &
Curtis-Holmes, J. (2005). Rapid responding increases belief bias:
Evidence for dual-process theories of reasoning. Thinking & Reasoning,
11, 382--389. Evans, J.St.B.T. & Over, D.E. (2010). Heuristic thinking
and human intelligence: A commentary on Marewski, Gaissmaier and
Gigerenzer. Cognitive Processing, 11, 171--175. Evans, J.St.B.T. &
Stanovich, K.E. (2013a). Dual-process theories of higher cognition:
Advancing the debate. Perspectives on Psychological Science, 8,
223--241. Evans, J.St.B.T. & Stanovich, K.E. (2013b). Theory and
metatheory in the study of dual processing: Reply to comments.
Perspectives on Psychological Science, 8, 263--271. Evans, J.St.B.T.,
Thompson, V.A. & Over, D.E. (2015). Uncertain deduction and conditional
reasoning. Frontiers in Psychology, 6 (Article no. 398). Evans, N. &
Levinson, S. (2009). The myth of language universals: Language diversity
and its importance for cognitive science. Behavioral and Brain Sciences,
32, 429--492. Evans, S., McGettigan, C., Agnew, Z.K., Rosen, S. & Scott,
S.K. (2016). Getting the cocktail party started: Masking effects in
speech perception. Journal of Cognitive Neuroscience, 28, 483--500.
Everaert, J., Duyck, W. & Koster, E.H.W. (2014). Attention,
interpretation, and memory biases in subclinical depression: A
proof-of-principle test of the combined biases hypothesis. Emotion, 14,
331--340. Everaert, J., Grahek, I. & Koster, E.H.W. (2017a). Individual
differences in cognitive control over emotional material modules
cognitive biases linked to depressive symptoms. Cognition and Emotion,
31, 736--746. Everaert, J., Koster, E.H.W. & Derakshan, N. (2012). The
combined cognitive bias hypothesis in depression. Clinical Psychology
Review, 32, 413--424. Everaert, J., Podina, I.R. & Koster, E.H.W.
(2017b). A comprehensive meta-analysis of interpretation biases in
depression. Clinical Psychology Review, 58, 33--48. Everett, D.L.
(2005). Cultural constraints on grammar and cognition in Piraha. Current
Anthropology, 46, 621--646. Eysenck, M.W. (1979). Depth, elaboration,
and distinctiveness. In L.S. Cermak & F.I.M. Craik (eds), Levels of

847

Processing in Human Memory (pp. 89--118). Hillsdale, NJ: Lawrence
Erlbaum Associates. Eysenck, M.W. (1992). Anxiety: The cognitive
perspective. Hove, UK: Psychology Press. Eysenck, M.W. (2015). Auditory
attention: Beyond Cherry's (1953) cocktail party problem. In M.W.
Eysenck & D. Groome (eds), Cognitive Psychology: Revisiting the classic
studies (pp. 13--23). London: Sage. Eysenck, M.W. & Brysbaert, M.
(2018). Fundamentals of Cognition (3rd edn). Abingdon, Oxon.: Psychology
Press. Eysenck, M.W. & Derakshan, N. (2011). New perspectives in
attentional control theory. Personality and Individual Differences, 50,
955--960. Eysenck, M.W. & Eysenck, M.C. (1980). Effects of processing
depth, distinctiveness, and word frequency on retention. British Journal
of Psychology, 71, 263--274. Eysenck, M.W. & Fajkowska, M. (2018).
Anxiety and depression: Toward overlapping and distinctive features.
Cognition and Emotion, 32, 1391--1400. Eysenck, M.W. & Groome, D. (eds)
(2015a). Cognitive Psychology: Revisiting the classic studies. London:
Sage. Eysenck, M.W. & Groome, D. (2015b). Memory systems: Beyond
Tulving's (1972) episodic and semantic memory. In M.W. Eysenck & D.
Groome (eds), Cognitive Psychology: Revisiting the classic studies
(pp. 105--116). London: Sage. Eysenck, M.W. & Holmes, A. (in press).
Anxiety, depression and cognitive dysfunction. In P. Corr (ed.), The
Cambridge Handbook of Personality Psychology (2nd edn). Cambridge:
Cambridge University Press. Eysenck, M.W., Derakshan, N., Santos, R. &
Calvo, M.G. (2007). Anxiety and cognitive performance: Attentional
control theory. Emotion, 7, 336--353. Eysenck, M.W., Macleod, C. &
Mathews, A. (1987). Cognitive functioning and anxiety. Psychological
Research, 49, 189--195. Eysenck, M.W., Mogg, K., May, J., Richards, A. &
Mathews, A. (1991). Bias in interpretation of ambiguous sentences
related to threat in anxiety. Journal of Abnormal Psychology, 100,
144--150. Eysenck, M.W., Payne, S. & Santos, R. (2006). Anxiety and
depression: Past, present, and future events. Cognition & Emotion, 20,
274--294. Fabbro, F., Skrap, M. & Agliotti, S. (2000). Pathological
switching between languages after frontal lesions in a bilingual
patient. Journal of Neurology, Neuroscience, and Psychiatery, 68,
650--652. Fama, R., Pitel, A.-L. & Sullivan, E.V. (2012). Anterograde
episodic memory in Korsakoff syndrome. Neuropsychology Review, 22,
93--104. Farag, C., Troiani, V., Bonner, M., Powers, C., Avants, B.,
Gee, J., et al. (2010). Hierarchical organization of scripts: Converging
evidence from fMRI and fronto-temporal degeneration. Cerebral Cortex,
20, 2453--2463.

848

References

Farah, M.J. (1991). Cognitive neuropsychology: Patterns of co-occurrence
among the associative agnosias: Implications for visual object
representation. Cognitive Neuropsychology, 8, 1--19. Farah, M.J. (1994).
Specialisations within visual object recognition: Clues from
prosopagnosia and alexia. In M.J. Farah & G. Ratcliff (eds), The
Neuropsychology of High-Level Vision: Collected Tutorial Essays
(pp. 133--146). Hillsdale, NJ: Lawrence Erlbaum Associates. Farmer,
C.M., Klauer, S.G., McClafferty, J.A. & Guo, F. (2015). Relationship of
near-crash/crash risk to time spent on a cell phone while driving.
Traffic Injury Prevention, 16, 792--800. Farmer, G.D., Janssen, C.P.,
Nguyen, A.T. & Brumby, D.P. (2018). Dividing attention between tasks:
Testing whether explicit payoff functions elicit optimal dual-task
performance. Cognitive Science, 42, 820--849. Farmer, M.E. & Klein, R.M.
(1995). The evidence for a temporal processing deficit linked to
dyslexia: A review. Psychonomic Bulletin & Review, 2, 460--493.
Faroqui-Shah, Y. & Friedman, L. (2015). Production of verb tense in
agrammatic aphasia: A meta-analysis and further data. Behavioural
Neurology, (Article no. ID983870). Fatania, J. & Mercer, T. (2017).
Non-specific retroactive interference in children and adults. Advances
in Cognitive Psychology, 13, 314--322. Fath, A.J., Lind, M. & Bingham,
G.P. (2018). Perception of time to contact of slow- and fast-moving
objects using monocular and binocular motion information. Attention,
Perception & Psychphysics, 80, 1584--1590. Fawcett, J.M., Peace, K.A. &
Greve, A. (2016). Looking down the barrel of a gun: What do we know
about the weapon focus effect? Journal of Applied Research in Memory and
Cognition, 5, 257--263. Fawcett, J.M., Russell, E.J., Peace, K.A. &
Christie, J. (2013). Of guns and geese: A meta-analytic review of the
"weapon focus" literature. Psychology, Crime & Law, 19, 35--66. Fazekas,
P. & Overgaard, M. (2018). Perceptual consciousness and cognitive
access: An introduction. Philosophical Transactions of the Royal Society
B, 373 (Article no. 201170340). Fazio, L.K., Brashier, N.M., Payne, B.K.
& Marsh, E.J. (2015). Knowledge does not protect against illusory truth.
Journal of Experimental Psychology: General, 144, 993--1002. Fecher, B.,
Friesike, S. & Hebing, M. (2015). What drives academic data sharing?
PLoS ONE, 10 (Article no. e0118053). Fedor, A., Szathmáry, E. &
Őllinger, M. (2015). Problem solving stages in the five square problem.
Frontiers in Psychology, 6 (Article no. 1050).

Fedorenko, E., Scott, T.L., Brunner, P., Coon, W.G., Pritchett, B.,
Schalk, G., et al. (2016). Neural correlate of the construction of
sentence meaning. Proceedings of the National Association of Sciences,
113, E6256--E6262. Fedzechkina, M., Chu, B. & Jaeger, T.F. (2018). Human
information processing shapes language change. Psychological Science,
29, 72--82. Feeser, M., Prehn, K., Kazzer, P., Mungee, A. & Bajhouj, M.
(2014). Transcranial direct current stimulation enhances cognitive
control during emotion regulation. Brain Stimulation, 7, 105--112.
Feinstein, J.S. (2013). Lesion studies of human emotion and feeling.
Current Opinion in Neurobiology, 23, 304--309. Feist, G.J. (2008). The
Psychology of Science and the Origins of the Scientific Mind. New Haven,
CT: Yale University Press. Feldman, A.G. (2016). Active sensing without
efference copy: Referent control of perception. Journal of
Neurophysiology, 116, 960--976. Feldman, G. & Albarracín, D. (2017).
Norm theory and the action-effect: The role of social norms in regret
following action and inaction. Journal of Experimental Social
Psychology, 69, 111--120. Feldman, J. (2013). The neural binding
problem(s). Cognitive Neurodynamics, 7, 1--11. Felleman, D.J. & Van
Essen, D.C. (1991). Distributed hierarchical processing in the primate
cerebral cortex. Cerebral Cortex, 1, 1--47. Ferber, R. (1995).
Reliability and validity of slip-of-thetongue corpora: A methodological
note. Linguistics, 33, 1169--1190. Ferbinteanu, J. (2019). Memory
systems 2018 -- Towards a new paradigm. Neurobiology of Learning and
Memory, 157, 61--78. Fernandez, K.C., Jazaieri, H. & Gross, J.J. (2016).
Emotion regulation: A transdiagnostic perspective on a new RDoC domain.
Cognitive Therapy and Research, 40, 426--440. Ferrari, P.F., Gerbella,
M., Coudé, G. & Rozzi, S. (2017a). Two different mirror neuron networks:
The sensorimotor (hand) and limbi (face) pathways. Neuroscience, 358,
300--315. Ferrari, V., Codispoti, M. & Bradley, M.M. (2017b). Repetition
and ERPs during emotional scene processing: A selective review.
International Journal of Psychophysiology, 111, 170--177. Ferreira, F.
(2003). The misinterpretation of non-canonical sentences. Cognitive
Psychology, 47, 164--203. Ferreira, F. & Lowder, M.W. (2016).
Prediction, information structure, and good-enough language processing.
Psychology of Learning and Motivation, 65, 217--247. Ferreira, F. &
Swets, B. (2002). How incremental is language production? Evidence from
the production of utterances requiring the computation of arithmetic
sums. Journal of Memory and Language, 46, 57--84.

References Ferreira, F., Bailey, K.G.D. & Ferraro, V. (2002). Goodenough
representations in language comprehension. Current Directions in
Psychological Science, 11, 11--15. Ferreira, V.S. (2019). A mechanistic
framework for explaining audience design in language production. Annual
Review of Psychology, 70, 29--51. Ferreira, V.S. & Griffin, Z.M. (2003).
Phonological influences on lexical (mis)selection. Psychological
Science, 14, 86--90. Ferrer, R.A., Maclay, A., Litvak, P.M. & Lerner,
J.S. (2017). Revisiting the effects of anger on risk-tasking: Empirical
and meta-analytic evidence for differences between males and females.
Journal of Behavioral Decision Making, 30, 516--526. Ffytche, D.H.,
Howard, R.J., Brammer, M.J., Woodruff, D.P. & Williams, S. (1998). The
anatomy of conscious vision: An fMRI study of visual hallucinations.
Nature Neuroscience, 1, 738--742. Fiedler, K. & von Sydow, M. (2015).
Heuristics and biases: Beyond Tversky and Kahneman's (1974) judgment
under uncertainty. In M.W. Eysenck & D. Groome (eds), Cognitive
Psychology: Revisiting the classic studies (pp. 146--161). London: Sage.
Fiedler, K., Brinkmann, B., Betsch, T. & Wild, B. (2000). A sampling
approach to biases in conditional probability judgments: Beyond
base-rate neglect and statistical format. Journal of Experimental
Psychology: General, 129, 1--20. Filmer, H.L., Lyons, M., Mattingley,
J.B. & Dux, P.E. (2017). Anodal tDCS applied during multitasking
training leads to transferable performance gains. Scientific Reports, 7
(Article no. 12988). Fine, A.B., Jaeger, T.F., Farmer, T.A. & Qian, T.
(2013). Rapid expectation adaptation during syntactic comprehension.
PLoS ONE, 8 (Article no. e77661). Finn, E.S., Shen, X., Scheinost, D.,
Rosenberg, M.D., Huang, J., Chun, M.M., et al. (2015). Functional
connectome fingerprinting: Identifying individuals using patterns of
brain connectivity. Nature Reviews Neuroscience, 18, 1664--1671.
Firestone, C. & Scholl, B.J. (2016). Cognition does not affect
perception: Evaluating the evidence for "top-down" effects. Behavioral
and Brain Sciences, 39 (Article no. e229). Fischer, R., Fröber, K. &
Dreisbach, G. (2018). Shielding and relaxation in multitasking: Prospect
of reward counteracts relaxation of task shielding in multitasking. Acta
Psychologica, 191, 112--123. Fischer, J. & Whitney, D. (2014). Serial
dependence in visual perception. Nature Neuroscience, 17, 738--746.
Fischer, P. & Greitemeyer, T. (2010). A new look at selective-exposure
effects: An integrative model. Current Directions in Psychological
Science, 19, 384--389.

849

Fischer, R. & Plessow, F. (2015). Efficient multitasking: Parallel
versus serial processing of multiple tasks. Frontiers in Psychology, 6
(Article no. 1366). Fischer-Baum, S., Kook, J.H., Lee, Y., Ramos-Nunez,
A. & Vannucci, M. (2018). Individual differences in the neural and
cognitive mechanisms of single word reading. Frontiers in Human
Neuroscience, 12 (Article no. 271). Fisk, J., Ellis, J.A. & Reynolds,
S.A. (2019). A test of the CaR-FA-X mechanisms and depression in
adolescents. Memory, 27, 455--464. Fitousi, D. & Wenger, M.J. (2013).
Variants of independence in the perception of facial identity and
expression. Journal of Experimental Psychology: Human Perception and
Performance, 39, 133--155. Fivush, R. (2010). The development of
autobiographical memory. Annual Review of Psychology, 62, 2--24. Fleck,
J.I. & Weisberg, R.W. (2013). Insight versus analysis: Evidence for
diverse methods in problem solving. Journal of Cognitive Psychology, 25,
436--463. Flegal, K.E. & Anderson, M.C. (2008). Overthinking skilled
motor performance: Or why those who teach can't do. Psychonomic Bulletin
& Review, 15, 927--932. Flevaris, A.V. & Robertson, L.C. (2016). Spatial
frequency selection and integration of global and local information in
visual processing: A selective review and tribute to Shlomo Bentin.
Neuropsychologia, 83, 192--200. Flinker, A. & Knight, R.T. (2018).
Broca's area in comprehension and production, insights intracranial
studies in humans. Opinion in Behavioral Sciences, 21, 170--175. Flinker
A., Korzeniewska A., Shestyuk, A.Y., Franaszczuk, P.J., Dronkers, N.F.,
Knight, R.T., et al. (2015). Redefining the role of Broca's area in
speech. Proceedings of the National Association of Sciences, 112,
2871--2875. Fodor, J.D. (1998). Learning to parse? Journal of
Psycholinguistic Research, 27, 285--319. Foerde, K. & Poldrack, R.A.
(2009). Procedural learning in humans. In L.R. Squire (ed.),
Encylopaedia of Neuroscience (Vol. 7; pp. 1083--1091). New York:
Academic Press. Foland-Ross, L.C. & Gotlib, I.H. (2012). Cognitive and
neural aspects of information processing in major depressive disorder:
An integrative perspective. Frontiers in Psychology, 3 (Article no.
489). Follmer, D.J. (2018). Executive function and reading
comprehension: A meta-analytic review. Educational Psychologist, 53,
42--60. Fontaine, J.R.J., Scherer, K.R. & Soriano, C. (eds) (2013).
Components of Emotional Meaning: A sourcebook. Oxford: Oxford University
Press. Ford, J.H., Addis, D.R. & Giovanello, K.S. (2011). Differential
neural activity during search of specific and general autobiographical
memories elicited by music cues. Neuropsychologia, 49, 2514--2526.

850

References

Forster, S. & Lavie, N. (2008). Failures to ignore entirely irrelevant
distractors: The role of load. Journal of Experimental Psychology:
Applied, 14, 73--83. Fossett, T.R.D., McNeil, M.R., Pratt, S.R.,
Tompkins, C.A. & Shuster, L.I. (2016). The effect of speaking rate on
serial-order sound-level errors in normal healthy controls and persons
with aphasia. Aphasiology, 30, 74--95. Foster, D.H. (2011). Colour
constancy. Vision Research, 51, 674--700. Foster, D.H. (2018). The
Verriest lecture: Colour vision in an uncertain world. Journal of the
Optical Society of America, 35, B192--B201. Foster, D.H. & Nascimento,
S.M.C. (1994). Relational colour constancy from invariant
cone-excitation ratios. Proceedings of the Royal Society of London
Series B -- Biological Sciences, 257, 115--121. Foster, J.D., Reidy,
D.E., Misra, T.A. & Goff, J.S. (2011). Narcissism and stock market
investing: Correlates and consequences of cocksure investing.
Personality and Individual Differences, 50, 816--821. Foulsham, T.
(2015). Eye movements and their functions in everyday tasks. Eye, 29,
196--199. Foulsham, T. & Kingstone, A. (2017). Are fixations in static
natural scenes a useful predictor of attention in the real world?
Canadian Journal of Experimental Psychology, 71, 172--181. Fowlkes,
C.C., Martin, D.R. & Malik, J. (2007). Local figure-ground cues are
valid for natural images. Journal of Vision, 7 (Article no. 2). Fox,
C.J., Hanif, H.M., Iaria, G., Duchaine, B.C. & Barton, J.J.S. (2011).
Perceptual and anatomic patterns of selective deficits in facial
identity and expression processing. Neuropsychologia, 49, 3188--3200.
Frank, M.C., Everett, D.L., Fedorenko, E. & Gibson, E. (2008). Number as
a cognitive technology: Evidence from Pirahã language and cognition.
Cognition, 108, 819--824. Franklin, S., Turner, J., Lambon Ralph, M.A.,
Morris, J. & Bailey, P.J. (1996). A distinctive case of word meaning
deafness? Cognitive Neuropsychology, 13, 1139--1162. Franz, V.H. &
Gegenfurtner, K.R. (2008). Grasping visual illusions: Consistent data
and no dissociation. Cognitive Neuropsychology, 25, 920--950. Fraser H.
(2018a). Thirty years is long enough: It's time to create a process that
ensures covert recordings used as evidence in court are interpreted
reliably and fairly. Journal of Judicial Administration, 27, 95--104.
Fraser, H. (2018b). "Assisting" listeners to hear words that aren't
here: Dangers in using police transcripts of indistinct covert
recordings. Australian Journal of Forensic Sciences, 50, 129--139.
Frässle, S., Summer, J., Jansen, A., Naber, M. & Einhäuser, W. (2014).
Binocular rivalry: Frontal activity relates to

introspection and action but not to perception. Journal of Neuroscience,
34, 1738--1747. Frauenfelder, U.H., Segui, J. & Dijkstra, T. (1990).
Lexical effects in phonemic processing: Facilitatory or inhibitory?
Journal of Experimental Psychology: Human Perception & Performance, 16,
77--91. Frazier, L. & Rayner, K. (1982). Making and correcting errors
during sentence comprehension: Eye movements in the analysis of
structurally ambiguous sentences. Cognitive Psychology, 14, 178--210.
Frazier, L., Carlson, K. & Clifton, C. (2006). Prosodic phrasing is
central to language comprehension. Trends in Cognitive Sciences, 10,
244--249. Frederick, S. (2005). Cognitive reflection and decision
making. Journal of Economic Perspectives, 19, 25--42. Fredrickson, B.L.
& Branigan, C. (2005). Positive emotions broaden the scope of attention
and thought-action repertoires. Cognition & Emotion, 19, 313--332.
Freed, E.M., Hamilton, S.T. & Long, D.L. (2017). Comprehension in
proficient readers: The nature of individual variation. Journal of
Memory and Language, 97, 135--153. Freeman, J. & Simoncelli, E.P.
(2011). Metamers of the ventral stream. Nature Neuroscience, 14,
1195--1201. Freud, E., Culham, J.C., Plaut, D.C. & Behrmann, M. (2017a).
The large-scale organisation of shape processing in the ventral and
dorsal pathways. ELIFE, 6 (Article no. e27576). Freud, E., Ganel, T.,
Shelef, I., Hammer, M.D., Avidan, G. & Behrmann, M. (2017b).
Three-dimensional representations of objects in dorsal cortex are
dissociable from those in ventral cortex. Cerebral Cortex, 27, 422--434.
Freud, E., Plaut, D.C. & Behrmann, M. (2016). "What" is happening in the
dorsal visual pathway. Trends in Cognitive Sciences, 20, 773--784.
Freuenberger, D. & Roeham, D. (2017). The costs of being certain: Brain
potential evidence for linguistic preactivation in sentence processing.
Psychophysiology, 54, 824--832. Frick-Horbury, D. & Guttentag, R.E.
(1998). The effects of restricting hand gesture production on lexical
retrieval and free recall. American Journal of Psychology, 111, 43--62.
Fried, I., Haggard, P., He, B.J. & Schurger, A. (2017). Volition and
action in the human brain: Processes, pathologies, and reasons. Journal
of Neuroscience, 37, 10842--10847. Friedman, N.P. & Miyake, A. (2017).
Unity and diversity of executive functions: Individual differences as a
window on cognitive structure. Cortex, 86, 186--204. Friedman, N.P.,
Miyake, A., Young, S.E., DeFries, J.C., Corley, R.P. & Hewitt, J.K.
(2008). Individual differences in executive functions are almost
entirely genetic in origin. Journal of Experimental Psychology: General,
137, 201--225.

References Friedman-Hill, S.R., Robertson, L.C. & Treisman, A. (1995).
Parietal contributions to visual feature binding: Evidence from a
patient with bilateral lesions. Science, 269, 853--855. Friedrich, C.K.
& Kotz, S.A. (2007). Event-related potential evidence of form and
meaning coding during online speech recognition. Journal of Cognitive
Neuroscience, 19, 594--604. Friedrich, T.E., Hunter, P.V. & Elias, L.J.
(2018). The trajectory of pseudoneglect in adults: A systematic review.
Neuropsychology Review, 28, 436--452. Friesen, L.K. (2013). The
structure of consciousness. Unpublished Ph.D. thesis, University of
Massachusetts -- Amherst. Frijda, N.H. (2013). Comment: The why, when,
and how of appraisal. Emotion Review, 5, 169--170. Frisson, S., Harvey,
D.R. & Staub, A. (2017). No prediction error cost in reading: Evidence
from eye movements. Journal of Memory and Language, 95, 200--214.
Froyen, V., Feldman, J. & Singh, M. (2015). Bayesian hierarchical
grouping: Perceptual grouping as mixture estimation. Psychological
Review, 122, 575--597. Fugelsang, J.A., Stein, C.B., Green, A.E. &
Dunbar, K.N. (2004). Theory and data interactions of the scientific
mind: Evidence from the molecular and the cognitive laboratory. Canadian
Journal of Experimental Psychology, 58, 86--95. Fukumura, K. & van
Gompel, R.P.G. (2012). Producing pronouns and definite noun phrases: Do
speakers use the addressee's discourse model? Cognitive Science, 36,
1289--1311. Funnell, M., Metcalfe, J. & Tsapkini, K. (1996). In the mind
but not in the tongue: Feeling of knowing in anomic patient H.W. In L.M.
Reder (ed.), Implicit Memory and Metacognition (pp. 171--194).
Hillsdale, NJ: Erlbaum. Futrell, R., Steams, L., Everett, D.L.,
Piantadosi, S.T. & Gibson, E. (2016). A corpus investigation of
syntactic embedding in Piraha. PLoS ONE, 11 (Article no. e0145289).
Gable, P.A. & Harmon-Jones, E. (2010a). The effect of low versus high
approach-motivated positive affect on memory for peripherally versus
centrally presented information. Emotion, 10, 599--603. Gable, P.A. &
Harmon-Jones, E. (2010b). The blues broaden, but the nasty narrows:
Attentional consequences of negative affects low and high in
motivational intensity. Psychological Science, 21, 211--215. Gable,
P.A., Browning, L. & Harmon-Jones, E. (2015a). Affect, motivation, and
cognitive scope. In T.S. Braver (ed.), Motivation and Cognitive Control
(pp. 164--187). London: Routledge. Gable, P.A., Poole, B.D. &
Harmon-Jones, E. (2015b). Anger perceptually and conceptually narrows
cognitive scope. Journal of Personality and Social Psychology, 109,
163--174.

851

Gabrieli, J.D.E., Fleischman, D., Keane, M., Reminger, S. & Morrell, F.
(1995). Double dissociation between memory systems underlying explicit
and implicit memory in the human brain. Psychological Science, 6,
76--82. Gaillard, R., Dehaene, S., Adam, C., Clémenceau, S., Hasboun,
D., Baulac, M., et al. (2009). Converging intracranial markers of
conscious access. PLoS Biology, 7 (Article no. e1000061). Gainotti, G. &
Ciaraffa, F. (2013). Is "object-centred neglect" a homogeneous entity?
Brain and Cognition, 81, 18--23. Gale, M. & Ball, L.J. (2012). Contrast
class cues and performance facilitation in a hypothesis-testing task:
Evidence for an iterative counterfactual model. Memory & Cognition, 40,
408--419. Gallagher, S. & Trigg, D. (2016). Agency and anxiety:
Delusions of control and loss of control in schizophrenia and
agoraphobia. Frontiers in Human Neuroscience, 10 (Article no. 459).
Gallese, V. & Sinigaglia, C. (2014). Understanding action with the motor
system. Behavioral and Brain Sciences, 37, 199--200. Gallese, V.,
Fadiga, L., Fogassi, L. & Rizzolatti, G. (1996). Action recognition in
the premotor cortex. Brain, 119, 593--609. Galletti, C. & Fattori, P.
(2018). The dorsal visual stream revisited: Stable circuits or dynamic
pathways? Cortex, 98, 203--217. Gallivan, J.P., Chapman, C.S., Wolpert,
D.M. & Flanagan, J.R. (2018). Decision-making in sensori-motor control.
Nature Reviews Neuroscience, 19, 519--534. Galotti, K.M. (2002). Making
Decisions That Matter: How people face important life choices. Mahwah,
NJ: Lawrence Erlbaum Associates. Galotti, K.M. (2007). Decision
structuring in important reallife choices. Psychological Science, 18,
320--325. Galotti, K.M. & Tinkelenberg, C.E. (2009). Real-life decision
making: Parents choosing a first-grade placement. American Journal of
Psychology, 122, 455--468. Galton, F. (1883). Inquiries into Human
Faculty and its Development. London: Macmillan. Gambetti, E. &
Giusberti, F. (2012). The effect of anger and anxiety traits on
investment decisions. Journal of Economic Psychology, 33, 1059--1069.
Gandhi, T., Acharya, S. & Shukla, S. (2016). Anton's syndrome -- The
neurologic mystery of denial. Medical Science, 20, 161--163. Gangemi,
A., Bourgeois-Gironde, S. & Mancini, F. (2015). Feelings of error in
reasoning -- In search of a phenomenon. Thinking & Reasoning, 21,
383--396. Ganong, W.F. (1980). Phonetic categorisation in auditory word
perception. Journal of Experimental Psychology: Human Perception &
Performance, 6, 110--125. Gao, X. & Jiang, T. (2018). Sensory
constraints on perceptual simulation during sentence reading. Journal

852

References

of Experimental Psychology: Human Perception and Performance, 44,
848--855. Garcea, F.E. & Mahon, B.Z. (2012). What is in a tool concept?
Dissociating manipulation knowledge from function knowledge. Memory &
Cognition, 40, 1303--1313. Gardiner, J.M., Brandt, K.R., Baddeley, A.D.,
VarghaKhadem, F. & Mishkin, M. (2008). Charting the acquisition of
semantic knowledge in a case of developmental amnesia. Neuropsychologia,
46, 2865--2868. Garg, N., Williams, L.A. & Lerner, J.S. (2018). The
miseryis-not-miserly effect revisited: Replication despite opportunities
for compensatory consumption. PLoS ONE, 13 (Article no. e199433).
Garner, K.G. & Dux, P.E. (2015). Training conquers multi-tasking costs
by dividing task representations in the fronto-parietal-subcortical
system. Proceedings of the National Academy of Sciences, 112,
14372--14377. Garrard, P., Carroll, E., Vinson, D. & Vigliocco, G.
(2004). Dissociation of lexical syntax and semantics: Evidence from
focal cortical degeneration. Neurocase, 10, 353--362. Garrard, P.,
Maloney, L.M., Hodges, J.R. & Patterson, K. (2005). The effects of very
early Alzheimer's disease on the characteristics of writing by a
renowned author. Brain, 128, 250--260. Garrett, B. (2011). Convicting
the Innocent: Where criminal prosecutions go wrong. Cambridge, MA:
Harvard University Press. Garrett, M. (1980). Levels of processing in
sentence production. In B. Butterworth (ed.), Language Production
(pp. 177--220). London: Academic Press. Garrod, S. & Terras, M. (2000).
The contribution of lexical and situational knowledge to resolving
discourse roles: Bonding and resolution. Journal of Memory and Language,
42, 526--544. Garson, J. (2016). Connectionism. In E.N. Zalta (ed.), The
Stanford Encyclopedia of Philosophy (online). Stanford, CA: Metaphysics
Research Lab, Stanford University. Gaskell, M.G. & Marslen-Wilson, W.D.
(2002). Representation and competition in the perception of spoken
words. Cognitive Psychology, 45, 220--266. Gathercole, S.E. & Baddeley,
A.D. (1993). Phonological working memory: A critical building-block for
reading development and vocabulary acquisition. European Journal of
Psychology of Education, 8, 259--272. Gauld, A. & Stephenson, G.M.
(1967). Some experiments relating to Bartlett's theory of remembering.
British Journal of Psychology, 58, 39--50. Gauthier, I. & Tarr, M.J.
(2016). Visual object recognition: Do we (finally) know more now than we
did? Annual Review of Vision Science, 2, 377--396. Gauvin, H.S., De
Baene, W., Brass, M. & Hartsuiker, R.J. (2016). Conflict monitoring in
speech processing: An fMRI study of error detection in speech production
and perception. NeuroImage, 126, 96--105.

Gavilán, J.M., Rivera, D., Guasch, M., Demestre, J. & Garcia-Albea, J.E.
(2017). Exploring the effects of visual frame and matching direction on
the vertical-horizontal illusion. Perception, 46, 1339--1355. Gawronski,
B. & Beer, J.S. (2017). What makes moral dilemma judgements
"utilitarian" or "deontological"? Social Neuroscience, 12, 626--632.
Gawronski, B., Armstrong, J., Conway, P., Friesdorf, R. & Hütter, M.
(2017). Consequences, norms, and generalised inaction in moral dilemmas:
The CNI model of moral decision making. Journal of Personality and
Social Psychology, 112, 343--376. Gazzaniga, M.S. (1992). Nature's Mind.
London: Basic Books. Gazzaniga, M.S. (2013). Shifting gears: Seeking new
approaches for mind/brain mechanisms. Annual Review of Psychology, 64,
1--20. Gazzaniga, M.S. & Ledoux, J.E. (1978). The Integrated Mind.
London: Basic Books. Gazzaniga, M.S., Ivry, R.B. & Mangun, G.R. (2008).
Cognitive Neuroscience: The biology of the mind (3rd edn). New York:
W.W. Norton. Gegenfurtner, A., Kok, E., van Geel, K., de Bruin, A.,
Jarodzka, H., Szulewski, A., et al. (2017). The challenges of studying
visual expertise in medical image diagnosis. Medical Education, 51,
97--104. Gegenfurtner, A., Lehtinen, E. & Säljö, R. (2011). Expertise
differences in the comprehension of visualisations: A meta-analysis of
eye-tracking research in professional domains. Educational Psychology
Review, 23, 523--552. Geiselman, R.E. & Fisher, R.P. (1997). Ten years
of cognitive interviewing. In D.G. Payne & F.G. Conrad (eds),
Intersections in Basic and Applied Memory Research (pp. 291--310).
Mahwah, NJ: Lawrence Erlbaum Associates. Geisler, W.S., Perry, J.S.,
Super, B.J. & Gallogly, D.P. (2001). Edge co-occurrence in natural
images predicts contour grouping performance. Vision Research, 41,
711--724. Gelbard-Sagiv, H., Faivre, N., Mudrik, L. & Koch, C. (2016).
Low-level awareness accompanies "unconscious" highlevel processing
during continuous flash suppression. Journal of Vision, 16, 1--16. Geng,
J.J., DiQuattro, N.E. & Helm, J. (2017). Distractor probability changes
the shapes of attentional template. Journal of Experimental Psychology:
Human Perception and Performance, 43, 1993--2007. Genon, S., Reid, A.,
Langner, R., Amunts, K. & Eickhoff, S.B. (2018). How to characterise the
function of a brain region. Trends in Cognitive Sciences, 22, 350--364.
Genty, E., Neumann, C. & Zuberbühler, K. (2015). Bonobos modify
communication signals according to recipient familiarity. Scientific
Reports, 5 (Article no. 16442). George, T. & Wiley, J. (2016).
Forgetting the literal: The role of inhibition in metaphor
comprehension. Journal

References of Experimental Psychology: Learning, Memory, and Cognition,
42, 1324--1330. Geraerts, E. (2012). Cognitive underpinnings of
recovered memories of childhood abuse. True and false recovered
memories: Toward a reconciliation of the debate. Nebraska Symposium on
Motivation, 58, 175--191. Geraerts, E., Schooler, J.W., Merckelbach, H.,
Jelicic, M., Hunter, B.J.A. & Ambadar Z. (2007). Corroborating
continuous and discontinuous memories of childhood sexual abuse.
Psychological Science, 18, 564--568. Germine, L., Cashdollar, N., Duzel,
E. & Duchaine, B. (2011). A new selective developmental deficit:
Impaired object recognition with normal face recognition. Cortex, 47,
598--607. Gerrig, R.J. & O'Brien, E.J. (2005). The scope of memorybased
processing. Discourse Processes, 39, 225--242. Gerwing, J. & Allison, M.
(2011). The flexible semantic integration of gestures and words:
Comparing face-to-face and telephone dialogues. Gesture, 11, 308--329.
Geskin, J. & Behrmann, M. (2018). Congenital prosopagnosia without
object agnosia? A literature review. Cognitive Neuropsychology, 35,
4--54. Geurten, M. & Willems, S. (2017). The learned interpretation of
fluency in amnesia. Neuropsychologia, 101, 10--16. Ghafur, R.D., Suri,
G. & Gross, J.J. (2018). Emotion regulation choice: The role of
orienting attention and action readiness. Current Opinion in Behavioral
Sciences, 19, 31--35. Gheysen, F., Van Opstal, F., Roggeman, C., Van
Waelvelde, H. & Fias, W. (2011), The neural basis of implicit perceptual
sequence learning. Frontiers in Human Neuroscience, 5 (Article no. 137).
Ghose, G.M. & Ts'o, D.Y. (2017). Integration of colour, orientation, and
size functional domains in the ventral pathway. Neurophotonics, 4
(Article no. 031216). Ghosh, V.E. & Gilboa, A. (2014). What is a memory
schema? A historical perspective on current neuroscience literature.
Neuropsychologia, 53, 104--114. Ghosh, V.E., Moscovitch, M., Colella,
B.M. & Gilboa, A. (2014). Schema representation in patients with
ventromedial PFC lesions. Journal of Neuroscience, 34, 12057--12070.
Gibbs, R.W. (2013). The real complexities of psycholinguistic research
on metaphor. Language Sciences, 40, 45--52. Gibson, J.J. (1950). The
Perception of the Visual World. Boston, MA: Houghton Mifflin. Gibson,
J.J. (1966). The Senses Considered as Perceptual Systems. Boston, MA:
Houghton Mifflin. Gibson, J.J. (1979). The Ecological Approach to Visual
Perception. Boston, MA: Houghton Mifflin. Gibson, E., Tan, C., Futrell,
R., Mahowald, K., Konieczny, L., Hemworth, B. & Fedorenko, E. (2017).
Don't underestimate the benefits of being misunderstood. Psychological
Science, 28, 703--712.

853

Gick, M.L. & Holyoak, K.J. (1980). Analogical problem solving. Cognitive
Psychology, 12, 306--355. Gigerenzer, G. (2014). Risk Savvy: How to make
good decisions. New York: Viking. Gigerenzer, G. & Gaissmaier, W.
(2011). Heuristic decision making. Annual Review of Psychology, 62,
451--482. Gigerenzer, G. & Garcia-Retamero, R. (2017). Cassandra's
regret: The psychology of not wanting to know. Psychological Review,
124, 179--196. Gigerenzer, G. & Hoffrage, U. (1995). How to improve
Bayesian reasoning without instruction -- Frequency formats.
Psychological Review, 102, 684--704. Gigerenzer, G. & Hoffrage, U.
(1999). Overcoming difficulties in Bayesian reasoning. Psychological
Review, 102, 684--704. Gilaie-Dotan, S. (2016a). Which visual functions
depend on intermediate visual regions? Insights from a case of
developmental visual form agnosia. Neuropsychologia, 83, 179--191.
Gilaie-Dotan, S. (2016b). Visual motion serves but is not under the
purview of the dorsal pathway. Neuropsychologia, 89, 378--392.
Gilaie-Dotan, S., Saygin, A.P., Lorenzi, L.J., Egan, R., Rees, G. &
Behrmann, M. (2013). The role of human ventral visual cortex in motion
perception. Brain, 136, 2784--2798. Gilbert, C.D. & Li, W. (2013).
Top-down influences on visual processing. Nature Reviews Neuroscience,
14, 350--363. Gilboa, A. & Marlatte, H. (2017). Neurobiology of schemas
and schema-mediated memory. Trends in Cognitive Sciences, 21, 618--631.
Gilhooly, K.J. (2018). Incubation, problem solving and creativity. In
L.J. Ball & V.A. Thompson (eds), The Routledge International Handbook of
Thinking and Reasoning (pp. 204--217). Abingdon, Oxon.: Routledge.
Giorgetta, C., Grecucci, A., Bonini, N., Coricelli, G., Demarchi, G.,
Braun, C., et al. (2013). Waves of regret: An MEG study of emotion and
decision-making. Neuropsychologia, 51, 38--51. Girshick, A.R. & Banks,
M.S. (2009). Probabilistic combination of slant information: Weighted
averaging and robustness as optimal percepts. Journal of Vision, 9,
1--20. Glennerster, A., Tscheang, L., Gilson, S.J., Fitzgibbon, A.W. &
Parker, A.J. (2006). Humans ignore motion and stereo cues in favour of a
fictional stable world. Current Biology, 16, 428--432. Glöckner, A.,
Hilbig, B.E., Henninger, F. & Fielder, S. (2016). The reversed
description-experience gap: Disentangling sources of presentation format
in risky choice. Journal of Experimental Psychology: General, 145,
486--508. Glöckner, A., Hilbig, B.E. & Jekel, M. (2014). What is
adaptive about adaptive decision making? A parallel constraint
satisfaction account. Cognition, 133, 641--666.

854

References

Glover, S. (2004). Separate visual representations in the planning and
control of action. Behavioral and Brains Sciences, 27, 3--78. Glover,
S., Wall, M.B. & Smith, A.T. (2012). Distinct cortical networks support
the planning and online control of reaching-to-grasp in humans. European
Journal of Neuroscience, 35, 909--915. Gobet, F. (2016). Understanding
Expertise: A multidisciplinary approach. London: Palgrave. Gobet, F. &
Clarkson, G. (2004). Chunks in expert memory: Evidence for the magical
number four ... or is it two? Memory, 12, 732--747. Gobet, F. & Ereku,
M.H. (2014). Checkmate to deliberate practice: The case of Magnus
Carlsen. Frontiers in Psychology, 5 (Article no. 878). Gobet, F. & Lane,
P. (2015). Human problem solving: Beyond Newell, Shaw, and Simon's
(1958) theory of human problem solving. In M.W. Eysenck & D. Groome
(eds), Cognitive Psychology: Revisiting the classic studies (pp.
133--145). London: Sage. Gobet, F. & Simon, H.A. (2000). Five seconds or
sixty? Presentation time in expert memory. Journal of Experimental
Psychology: Learning, Memory and Cognition, 29, 1082--1094. Gobet, F. &
Waters, A.J. (2003). The role of constraints in expert memory. Journal
of Experimental Psychology: Learning, Memory & Cognition, 29,
1082--1094. Godden, D.R. & Baddeley, A.D. (1975). Context dependent
memory in two natural environments: On land and under water. British
Journal of Psychology, 66, 325--331. Godden, D.R. & Baddeley, A.D.
(1980). When does context influence recognition memory? British Journal
of Psychology, 71, 99--104. Godefroy, O., Azouvi, P., Robert, P.,
Roussel, M., LeGall, D. & Meulemans, T. (2010). Dysexecutive syndrome:
Diagnostic criteria and validation study. Annals of Neurology, 68,
855--864. Godwin, D., Barry, R.L. & Marois, R. (2015). Breakdown of the
brain's functional network modularity with awareness. Proceedings of the
National Academy of Sciences of the United States of America, 112,
3799--3804. Goel, V. (2010). Neural basis of thinking: Laboratory
problems versus real-world problems. Wiley Interdisciplinary Reviews --
Cognitive Science, 1, 613--621. Goel, V. & Grafman, J. (1995). Are the
frontal lobes implicated in "planning" functions? Interpreting data from
the Tower of Hanoi. Neuropsychologia, 33, 623--642. Goel, V. & Grafman,
J. (2000). The role of the right prefrontal cortex in ill-structured
problem solving. Cognitive Neuropsychology, 17, 415--436. Goel, V. &
Waechter, R. (2018). Inductive and deductive reasoning: Integrating
insights from philosophy, psychology, and neuroscience. In L.J. Ball &
V.A. Thompson (eds), Routledge International Handbook of Thinking

and Reasoning (pp. 218--247). Abingdon, Oxon.: Routledge. Goel, V.,
Tierney, M., Sheesley, L., Bartolo, A., Vartanian, O. & Grafman, J.
(2007). Hemispheric specialisation in human prefrontal cortex for
resolving certain and uncertain inferences. Cerebral Cortex, 17,
2245--2250. Goel, V., Vartanian, O., Bartolo, A., Hakim, L., Ferraro,
A.M., Isella, V., et al. (2013). Lesions to the right prefrontal cortex
impair real-world planning through premature commitments.
Neuropsychologia, 51, 713--724. Goh, W.D. & Lu, S.H.X. (2012). Testing
the myth of encoding-retrieval match. Memory & Cognition, 40, 28--39.
Goldberg, A., Russell, M. & Cook, A. (2003). The effect of computers on
student writing: A meta-analysis of studies from 1992 to 2002. Journal
of Technology, Learning, and Assessment, 2, 1--52. Goldberg, I.I.,
Harel, M. & Malach, R. (2006). When the brain loses its self: Prefrontal
inactivation during sensorimotor processing. Neuron, 50, 329--339.
Goldenberg, G., Mullbacher, W. & Nowak, A. (1995). Imagery without
perception: A case study of anosognosia for cortical blindness.
Neuropsychologia, 33, 1373--1382. Goldinger, S.D. & Azuma, T. (2003).
Puzzle-solving science: The quixotic quest for units in speech
perception. Journal of Phonetics, 31, 305--320. Goldrick, M. (2006).
Limited interaction in speech production: Chronometric, speech error,
and neuropsychological evidence. Language and Cognitive Processes, 21,
817--855. Goldrick, M., Keshet, J., Gustafson, E., Heller, J. & Needle,
J. (2016). Automatic analysis of slips of the tongue: Insights into the
cognitive architecture of speech production. Cognition, 148, 31--39.
Goldstein, D.G. & Gigerenzer, G. (2002). Models of ecological
rationality: The recognition heuristic. Psychological Review, 109,
75--90. Gollwitzer, P. (2014). Weakness of the will: Is a quick fix
possible? Motivation and Emotion, 38, 305--322. Golumbic, E.Z., Cogan,
G.B., Schroeder, C.E. & Poeppel, D. (2013). Visual input enhances
selective speech envelope tracking in auditory cortex at a "cocktail
party". Journal of Neuroscience, 33, 1417--1426. Gómez, A.T., Lupón, N.,
Cardna, G. & Aznar-Casanova, J.A. (2012). Visual mechanisms governing
the perception of autostereograms. Clinical and Experimental Optometry,
95, 146--152. Gomulicki, B.R. (1956). Recall as an abstractive process.
Acta Psychologica, 12, 77--94. Gong, L., Wang, J., Yang, X., Li, X., Gu,
C., Wang, M., et al. (2016). Dissociation between conceptual and
perceptual implicit memory: Evidence from patients with frontal and
occipital lobe lesions. Frontiers in Human Neuroscience, 9 (Article no.
722).

References Gontar, P., Schneider, S.A.E., Schmidt-Molt, C., Bollin, C. &
Bengler, K. (2017). Hate to interrupt you, but... Analysing turn-arounds
from a cockpit perspective. Cognitive Technology & Work, 19, 837--853.
Goodale, M.A. & Milner, A.D. (1992). Separate visual pathways for
perception and action. Trends in Neurosciences, 15, 20--25. Goodale,
M.A. & Milner, A.D. (2018). Two visual pathways -- Where have they taken
us and where will they lead in future? Cortex, 98, 283--292. Goodale,
M.A., Meenan, J.P., Bülthoff, H.H., Nicolle, D.A., Murphy, K.J. &
Racicot, C.I. (1994). Separate neural pathways for the visual analysis
of object shape in perception and prehension. Current Biology, 4,
604--610. Goodhew, S.C., Shen, E. & Edwards, M. (2016). Selective
spatial enhancement: Attentional spotlight size impacts spatial but not
temporal perception. Psychonomic Bulletin & Review, 23, 1144--1149.
Goodroe, S.C., Stames, J. & Brown, T.I. (2018). The complex nature of
hippocampal-striatal interactions in spatial navigation. Frontiers in
Human Neuroscience, 12 (Article no. 250). Goolkasian, P. & Woodberry, C.
(2010). Priming effects with ambiguous figures. Attention, Perception &
Psychophysics, 72, 168--178. Gottfredson, L.S. (1997). Why g matters:
The complexities of everyday life. Intelligence, 24, 79--132. Grabner,
R.H., Stern, E. & Neubauer, A. (2007). Individual differences in chess
expertise: A psychometric investigation. Acta Psychologica, 124,
398--420. Graesser, A.C., Millis, K.K. & Zwaan, R.A. (1997). Discourse
comprehension. Annual Review of Psychology, 48, 163--1899. Graesser,
A.C., Singer, M. & Trabasso, T. (1994). Constructing inferences during
narrative text comprehension. Psychological Review, 101, 371--395. Graf,
P. (2012). Prospective memory: Faulty brain, flaky person. Canadian
Psychology, 53, 7--13. Grafton, B., MacLeod, C., Rudaizky, D., Holmes,
E.A., Salemink, C., Fox, E., et al. (2017). Confusing procedures with
process when appraising the impact of cognitive bias modification on
emotional vulnerability. British Journal of Psychiatry, 211, 266--271.
Graham, S.A. & Fisher, S.E. (2013). Decoding the genetics of speech and
language. Current Opinion in Neurobiology, 23, 43--51. Grainger, J.
(2018). Orthographic processing: A "mid-level" vision of reading: The
44th Sir Frederic Bartlett lecture. Quarterly Journal of Experimental
Psychology, 71, 335--359. Granzier, J.J.M., Brenner, E. & Smeets, J.B.J.
(2009a). Reliable identification by colour under natural conditions.
Journal of Vision, 9, 1--9.

855

Gras, D., Tardieu, H. & Nicolas, S. (2012). Predictive inference
activation: Interest of a Stroop-like task. Swiss Journal of Psychology,
71, 141--148. Gray, R. (2011). Looming auditory collision warnings for
driving. Human Factors, 53, 63--74. Gray, R., Ho, C. & Spence, C.
(2014). A comparison of different informative vibrotactile forward
collision warnings: Does the warning need to be linked to the collision
event? PLoS ONE, 9 (Article no. e87070). Graziano, M.S.A. (2016).
Consciousness engineered. Journal of Consciousness Studies, 23, 98--115.
Graziano, M.S.A. & Kastner, S. (2011). Human consciousness and its
relationship to social neuroscience: A novel hypothesis. Cognitive
Neuroscience, 2, 98--113. Green, A.E. (2016). Creativity, within reason:
Semantic distance and dynamic state creativity in relational thinking
and reasoning. Current Directions in Psychological Science, 25, 28--35.
Greenberg, D.L., Keane, M.M., Ryan, L.R. & Verfaillie, M. (2009).
Impaired category fluency in medial temporal lobe amnesia: The role of
episodic memory. Journal of Neuroscience, 29, 10900--10908. Greenberg,
J.H. (1963). Some universals of grammar with particular reference to the
order of meaningful elements. In J.H. Greenberg (ed.), Universals of
Language (pp. 58--90). Cambridge, MA: MIT Press. Greene, J.D. (2014).
Moral Tribes: Emotion, reason and the gap between us and them.
Bloomsbury, UK: Atlantic Books. Greene, J.D., Morelli, S.A., Lowenberg,
K., Nvstrom, L.E. & Cohen, J.D. (2008). Cognitive load selectively
interferes with utilitarian moral judgment. Cognition, 107, 1144--1154.
Greene, J.D., Nystrom, L.E., Engell, A.D., Darley, J.M. & Cohen, J.D.
(2004). The neural bases of cognitive conflict and control in moral
judgment. Neuron, 44, 389--400. Grice, H.P. (1975). Logic and
conversation. In P. Cole & J.L. Morgan (eds), Syntax and Semantics, III:
Speech acts (pp. 41--58). New York: Academic Press. Grice, H.P. (1989).
Studies in the Way of Words. Cambridge, MA: Harvard University Press.
Griffiths, J.D., Marslen-Wilson, W.D., Stramatakis, E.A. & Tyler, L.K.
(2013). Functional organisation of the neural language system: Dorsal
and ventral pathways are critical for syntax. Cerebral Cortex, 20,
139--147. Grill-Spector, K., Weiner, K.S., Kay, K. & Gomez, J. (2017).
The functional neuroanatomy of human face perception. Annual Review of
Vision Science, 3, 167--196. Griskevicius, V., Shiota, M.N. & Neufeld,
S.L. (2010). Influence of different positive emotions on persuasive
processing: A functional evolutionary approach. Emotion, 10, 190--206.
Grisoni, L., Miller, T.M. & Pulvermüller, F. (2017). Neural correlates
of semantic prediction and resolution in sentence processing. Journal of
Neuroscience, 37, 4848--4858.

856

References

Groopman, J. (2007). How Doctors Think. New York: Houghton Mifflin.
Gross, J.J. (2015). Emotion regulation: Current status and future
prospects. Psychological Inquiry, 26, 1--26. Gross, J.J. & Thompson,
R.A. (2007). Emotion regulation: Conceptual foundations. In J.J. Gross
(ed.), Handbook of Emotion Regulation (pp. 3--24). New York: Guilford
Press. Gross, S. (2018). Perceptual consciousness and cognitive access
from the perspective of capacity-unlimited working memory. Philosophical
Transactions of the Royal Society B, 373 (Article no. 2017.0343).
Grossman, E.D., Battelli, L. & Pascual-Leone, A. (2005). Repetitive TMS
over STSp disrupts perception of biological motion. Vision Research, 45,
2847--2853. Grossnickle, E.M., Dumas, D., Alexander, P.A. & Baggetta, P.
(2016). Individual differences in the process of relational reasoning.
Learning and Instruction, 42, 141--159. Grot, S., Leclerc, M.-E. & Luck,
D. (2018). Examining the neural correlates of active and passive forms
of verbal-spatial binding in working memory. Biological Psychology, 136,
67--75. Guan, C.Q., Ye, F., Wagner, R.W., Meng, W. & Leary, C.K. (2014).
Text comprehension mediates morphological awareness, syntactic
processing, and working memory in predicting Chinese written composition
performance. Journal of Educational Psychology, 106, 779--798. Gueliaï,
B., Langus, A. & Nespor, M. (2014). Prosody in the hands of the speaker.
Frontiers in Psychology, 5 (Article no. 700). Guida, A., Gobet, F. &
Nicolas, S. (2013). Functional cerebral reorganisation: A signature of
expertise? Re-examining Guida, Gobet, Tardieu, and Nicolas' (2012)
two-stage framework. Frontiers in Human Neuroscience, 7 (Article no.
590). Guida, A., Gobet, F., Tardieu, H. & Nicolas, S. (2012). How
chunks, long-term working memory and templates offer a cognitive
explanation for neuroimaging data on expertise acquisition: A two-stage
framework. Brain and Cognition, 79, 221--244. Güllich, A. (2017).
International medallists' and nonmedallists' developmental sport
activities -- A matchedpairs analysis. Journal of Sports Sciences, 35,
2281--2288. Gustavson, D.E., Miyake, A., Hewitt, J.K. & Friedman, N.P.
(2015). Understanding the cognitive and genetic underpinnings of
procrastination: Evidence for shared genetic influences with goal
management and executive function abilities. Journal of Experimental
Psychology: General, 144, 1063--1079. Gutchess, A.H. & Park, D.C.
(2006). The fMRI environment can impair memory performance in young and
elderly adults. Brain Research, 1099, 133--140.

Gutierrez-Sigut, E., Vergara-Martínez, M. & Perea, M. (2017). Early use
of phonological codes in deaf readers: An ERP study. Neuropsychologia,
106, 261--279. Gvion, A. & Friedmann, N. (2016). A principled relation
between reading and naming in acquired and developmental anomia: Surface
dyslexia following impairment in the phonological output lexicon.
Frontiers in Psychology, 7 (Article no. 340). Gwilliams, L., Linzen, T.,
Poeppel, D. & Marantz, A. (2018). In spoken word recognition, the future
predicts the past. Journal of Neuroscience, 38, 7585--7599. Haak, K.V. &
Beckmann, C.F. (2018). Objective analysis of the topological
organisation of the human cortical visual connectome suggests three
visual pathways. Cortex, 98, 73--83. Haber, R.N. & Levin, C.A. (2001).
The independence of size perception and distance perception. Perception
& Psychophysics, 63, 1140--1152. Hafenbrädl, S., Waeger, D., Marewski,
J.N. & Gigerenzer, G. (2016). Applied decision making with
fast-and-frugal heuristics. Journal of Applied Research in Memory and
Cognition, 5, 215--231. Hagoort, P. (2017). The core and beyond in the
languageready brain. Neuroscience and Biobehavioral Reviews, 81,
194--204. Hagoort, P., Hald, L., Bastiaansen, M. & Petersson, K.M.
(2004). Integration of word meaning and world knowledge in language
comprehension. Science, 304, 438--441. Hahn, B., Ross, T.J. & Stein,
E.A. (2006). Neuroanatomical dissociations between bottom-up and
top-down processes of visuospatial selective attention. NeuroImage, 32,
842--853. Hahn, S., Andersen, G.J. & Saidpour, A. (2003). Static scene
analysis for the perception of heading. Psychological Science, 14,
543--548. Hahn, U. (2014). The Bayesian boom: Good thing or bad?
Frontiers in Psychology, 5 (Article no. 765). Hahn, U. & Hornikx, J.
(2016). A normative framework for argument quality: Argumentation
schemes with a Bayesian foundation. Synthese, 193, 1833--1873. Hahn, U.
& Oaksford, M. (2007). The rationality of informal argumentation: A
Bayesian approach to reasoning fallacies. Psychological Review, 114,
704--732. Hahn, U. & Oaksford, M. (2014). The Fallacies Explained.
Oxford: Oxford University Press. Haider, H., Eichler, A. & Lange, T.
(2011). An old problem: How can we distinguish between conscious and
unconscious knowledge acquired in an implicit learning task?
Consciousness and Cognition, 20, 658--672. Haigh, M., Wood, J.S. &
Stewart, A.J. (2016). Slippery slope arguments imply opposition to
change. Memory & Cognition, 44, 819--836.

References Halle, M. & Stevens, K. (1962). Speech recognition: A model
and a programme for research. IRE Transactions on Information Theory, 8,
155--159. Hambrick, D.Z. & Tucker-Drob, E.M. (2015). The genetics of
music accomplishment: Evidence for gene-environment correlation and
interaction. Psychonomic Bulletin & Review, 22, 112--120. Hambrick,
D.Z., Burgoyne, A.P., Macnamara, B.N. & Ullén, F. (2018). Toward a
multifactorial model of expertise: Beyond born versus made. Annals of
the New York Academy of Sciences, 1423 (SI), 284--295. Hambrick, D.Z.,
Burgoyne, A.P. & Oswald, F.L. (in press). Domain-general models of
expertise: The role of cognitive ability. In P. Ward, J.M. Schragen, J.
Gore & E. Roth (eds), Oxford Handbook of Expertise: Research and
application. Oxford: Oxford University Press. Hamlin, J.K. (2017). Is
psychology moving in the right direction? An analysis of the evidentiary
value movement. Perspectives on Psychological Science, 12, 690--693.
Hamm, J.P. & McMullen, P.A. (1998). Effects of orientation on the
identification of rotated objects depend on the level of identity.
Journal of Experimental Psychology: Human Perception and Performance,
24, 413--426. Han, S.W. & Marois, R. (2013). The source of dual-task
limitations: Serial or parallel processing of multiple response
selections? Attention, Perception, & Psychophysics, 75, 1395--1405. Han,
S., Lerner, J. & Keltner, D. (2007). Feelings and consumer decision
making: The appraisal-tendency framework. Journal of Consumer
Psychology, 17, 158--168. Han, Z.Z. & Bi, Y.C. (2009). Reading
comprehension without phonological mediation: Further evidence from a
Chinese aphasic individual. Science in China Series C -- Life Sciences,
52, 492--499. Hanley, J.R. (2011). An appreciation of Bruce and Young's
(1986) serial stage model of face naming after 25 years. British Journal
of Psychology, 102, 915--930. Hanley, J.R. & McDonnell, V. (1997). Are
reading and spelling phonologically mediated? Evidence from a patient
with a speech production impairment. Cognitive Neuropsychology, 14,
3--33. Hanley, J.R. & Sotiropoulos, A. (2018). Developmental surface
dysgraphia without surface dyslexia. Cognitive Neuropsychology, 35,
333--341. Hannula, D.E. & Greene, A.J. (2012). The hippocampus
re-evaluated in unconscious learning and memory: At a tipping point?
Frontiers in Human Neuroscience, 6 (Article no. 80), 1--20. Hannula,
D.E., Tranel, D. & Cohen, N.J. (2006). The long and the short of it:
Relational memory impairments in amnesia, even at short lags. Journal of
Neuroscience, 26, 8352--8359.

857

Hansen, T., Olkkonen, M., Walter, S. & Gegenfurtner, K.R. (2006). Memory
modulates colour appearance. Nature Neuroscience, 9, 1367--1368. Haque,
S., Vaphiades, M.S. & Lueck, D.J. (2018). The visual agnosias and
related disorders. Journal of NeuroOphthalmology, 38, 379--392. Harada,
Y., Hakoda, Y., Kuroki, D. & Mitsudo, H. (2015). The presence of a
weapon shrinks the functional field of view. Applied Cognitive
Psychology, 29, 592--599. Hardt, O., Nader, K. & Nadel, L. (2013). Decay
happens: The role of active forgetting in memory. Trends in Cognitive
Sciences, 17, 111--120. Hardwicke, T.E., Taqi, M. & Shanks, D.R. (2016).
Postretrieval new learning does not reliably induce human memory
updating via reconsolidation. Proceedings of the National Academy of
Sciences, 113, 5206--5211. Hareli, S. & Weiner, B. (2002). Dislike and
envy as antecedents of pleasure at another's misfortune. Motivation and
Emotion, 26, 257--277. Harley, T.A. (2010). Talking the Talk: Language,
psychology and science. Hove, UK: Psychology Press. Harley, T.A. (2012).
Why the earth is almost flat: Imaging and the death of cognitive
psychology. Cortex, 48, 1371--1372. Harley, T.A. (2013). The Psychology
of Language: From data to theory (4th edn). Hove, UK: Psychology Press.
Harley, T.A. & McAndrew, S. (2015). Who killed psycholinguistics? Beyond
Chomsky's classic review of Skinner's Verbal Behaviour. In M.W. Eysenck
& D. Groome (eds), Cognitive Psychology: Revisiting the classic studies
(pp. 179--188). London: Sage. Harley, T.A. & Bown, H.E. (1998). What
causes a tip-of-the tongue state? Evidence for lexical neighbourhood
effects in speech production. British Journal of Psychology, 89, 151--
174. Harm, M.W. & Seidenberg, M.S. (2004). Computing the meanings of
words in reading: Co-operative division of labour between visual and
phonological processes. Psychological Review, 111, 662--720. Harris,
A.J.L., Hahn, U., Madsen, J.K. & Hsu, A.S. (2016). The appeal to expert
opinion: Quantitative support for a Bayesian network approach. Cognitive
Science, 40, 1496--1533. Harris, A.J.L., Hsu, A.S. & Madsen, J.K.
(2012). Because Hitler did it! Quantitative tests of Bayesian
argumentation using ad hominem. Thinking & Reasoning, 18, 311--343.
Harris, P.R., Griffin, D.W. & Murray, S. (2008). Testing the limits of
optimistic bias: Event and person moderators in a multilevel framework.
Journal of Personality and Social Psychology, 95, 1225--1237. Harrison,
H.S., Turvey, M.T. & Frank, T.D. (2016). Affordance-based
perception-action dynamics: A model of visually guided braking.
Psychological Review, 123, 305--323.

858

References

Harrison, T.L., Shipstead, Z. & Engle, R.W. (2015). Why is working
memory capacity related to matrix reasoning tasks? Memory & Cognition,
43, 389--396. Hart, W., Albarracin, D., Eagly, A.H., Brechan, I.,
Lindberg, M.J. & Merrill, L. (2009). Feeling validated versus being
correct: A meta-analysis of selective exposure to information.
Psychological Bulletin, 135, 555--588. Hartwigsen, G. (2018). Flexible
redistribution in cognitive networks. Trends in Cognitive Sciences, 22,
687--698. Harvey, L.O. (1986). Visual memory: What is remembered? In F.
Klix & H. Hagendorf (eds), Human Memory and Cognitive Capabilities
(pp. 179--186). The Hague, Netherlands: Elsevier. Haskell, T.R.,
Thornton, R. & MacDonald, M.C. (2010). Experience and grammatical
agreement: Statistical learning shapes number agreement production.
Cognition, 114, 151--164. Hassabis, D., Kumaran, D., Vann, S.D. &
Maguire, E.A. (2007). Patients with hippocampal amnesia cannot imagine
new experiences. Proceedings of the National Academy of Sciences, USA,
104, 1726--1731. Hassin, R.R. (2013). Yes it can: On the functional
abilities of the human unconscious. Perspectives on Psychological
Science, 8, 195--207. Hasson, U., Egidi, G., Marelli, M. & Willems, R.M.
(2018). Grounding the neurobiology of language in first principles: The
necessity of non-language-centric explanations for language
comprehension. Cognition, 180, 135--157. Hata, K. (2016). On the
importance of the multimodal approach to discourse markers: A pragmatic
view. International Review of Pragmatics, 8, 36--54. Hauk, O.,
Johnsrude, I. & Pulvermüller, F. (2004). Somatotopic representation of
action words in human motor and premotor cortex. Neuron, 41, 301--307.
Häuser, K.I., Titone, D.A. & Baum, S.R. (2016). The role of the
ventro-lateral prefrontal cortex in idiom comprehension: An rTMS study.
Neuropsychologia, 91, 360--370. Hayes, J.R. (2012). Modelling and
remodelling writing. Written Communication, 29, 369--388. Hayes, J.R. &
Bajzek, D. (2008). Understanding and reducing the knowledge effect:
Implications for writers. Written Communication, 25, 104--118. Hayes,
J.R. & Chenoweth, N. (2006). Is working memory involved in the
transcribing and editing of texts? Written Communication, 23, 135--141.
Hayes, J.R. & Flower, L.S. (1980). Identifying the organisation of
writing processes. In L.W. Gregg & E.R. Steinberg (eds), Cognitive
Processes in Writing (pp. 3--30). Mahwah, NJ: Erlbaum. Hayes, J.R. &
Flower, L.S. (1986). Writing research and the writer. American
Psychologist, 41, 1106--1113. Hayes, J.R., Flower, L.S., Schriver, K.,
Stratman, J. & Carey, L. (1985). Cognitive Processes in Revision
(Technical

Report No. 12). Pittsburgh, PA: Carnegie Mellon University. Hayward,
W.G. & Tarr, M.J. (2005). Visual perception II: High-level vision. In K.
Lamberts & R.L. Goldstone (eds), The Handbook of Cognition (pp. 43--70).
London: Sage. Heck, D.W. & Erdfelder, E. (2017). Linking process and
measurement models of recognition-based decisions. Psychological Review,
124, 442--471. Hegdé, J. (2008). Time course of visual perception:
Coarseto-fine processing and beyond. Progress in Neurobiology, 84,
405--439. Hegdé, J. (2018). Neural mechanisms of high-level vision.
Comprehensive Physiology, 8, 902--953. Hegdé, J. & Van Essen, D.C.
(2000). Selectivity for complex shapes in primate visual area V2.
Journal of Neuroscience, 20, RC61. Heimler, B., Weisz, H. & Collignon,
O. (2014). Revisiting the adaptive and maladaptive effects of
cross-modal plasticity. Neuroscience, 283, 44--63. Held, R.T., Cooper,
E.A. & Banks, M.S. (2012). Blur and disparity are complementary cues to
depth. Current Biology, 22, 426--431. Heller, D., Parisien, C. &
Stevenson, S. (2016). Perspectivetaking behaviour as the probabilistic
weighing of multiple domains. Cognition, 149, 104--120. Hellmann, J.H.,
Echterhoff, G., Kopietz, R., Niemeier, S. & Memon, A. (2011). Talking
about visually perceived events: Communication effects on eyewitness
memory. European Journal of Social Psychology, 41, 658--671. Henderson,
E.N. (1903). A study of memory for connected trains of thought.
Psychological Review, Series of Monograph Supplements, 5, 1--93.
Henderson, J.M. & Hollingworth, A. (1999). High-level scene perception.
Annual Review of Psychology, 50, 243--271. Henke, K. (2010). A model for
memory systems based on processing modes rather than consciousness.
Nature Reviews Neuroscience, 11, 523--532. Henry, M.L., Beeson, P.M.,
Alexander, G.E. & Rapcsak, S.Z. (2012). Written language impairments in
primary progressive aphasia: A reflection of damage to central semantic
and phonological processes. Journal of Cognitive Neuroscience, 24,
261--275. Henry, M.L., Wilson, S.M., Babiak, M.C., Mandelli, M.L.,
Beeson, P.M., Miller, Z.A., et al. (2016). Phonological processing in
primary progressive aphasia. Journal of Cognitive Neuroscience, 28,
210--222. Hepner, C., McCloskey, M. & Rapp, B. (2017). Do reading and
spelling share orthographic representations? Evidence from developmental
dysgraphia. Cognitive Neuropsychology, 34, 119--143. Herholz, S.C. &
Zatorre, R.J. (2012). Musical training as a framework for brain
plasticity, behaviour, function, and structure. Neuron, 76, 486--502.

References Herholz, S.C., Coffey, E.B.J., Pantev, C. & Zatorre, R.J.
(2016). Dissociation of neural networks for predisposition and for
training-related plasticity in auditory-motor learning. Cerebral Cortex,
26, 3125--3134. Hering, E. (1878). Zur Lehre vom Lichtsinn. Vienna,
Austria: Gerold. Herlihey, T.A. & Rushton, S.K. (2012). The role of
discrepant retinal motion during walking in the realignment of
egocentric space. Journal of Vision, 12, 1--11. Herrera, S., Montorio,
I., Cabrera, I. & Botelia, J. (2017). Memory bias for threatening
information related to anxiety: An updated meta-analytic review. Journal
of Cognitive Psychology, 29, 832--854. Hertwig, R., Pachur, T. &
Kurzenhauser, S. (2005). Judgements of risk frequencies: Test of
possible cognitive mechanisms. Journal of Experimental Psychology:
Learning, Memory and Cognition, 31, 621--642. Hesse, C., Franz, V.H. &
Schenk, T. (2016). Pointing and anti-pointing in Müller-Lyer figures:
Why illusions need to be scaled. Journal of Experimental Psychology:
Human Perception and Performance, 42, 90--102. Hesse, C., Schenk, T. &
Deubel, H. (2012). Attention is needed for action control: Further
evidence from grasping. Vision Research, 71, 37--43. Hesselmann, G.
(2013). Dissecting visual awareness with fMRI. The Neuroscientist, 19,
495--508. Hesselmann, G. & Moors, P. (2015). Definitely maybe: Can
unconscious processes perform the same functions as conscious processes?
Frontiers in Psychology, 6 (Article no. 584). Hesselmann, G., Darcy, N.,
Rothkirch, M. & Sterzer, P. (2018). Investigating masked priming along
the "vision-for-perception" and "vision-for-action" dimensions of
unconscious priming. Journal of Experimental Psychology: General, 147,
1641--1659. Hesselmann, G., Flandin, G. & Dehaene, S. (2011). Probing
the cortical network underlying the psychological refractory period: A
combined EEG-fMRI study. NeuroImage, 56, 1608--1621. Hesselmann, G.,
Naccache, L., Cohen, L. & Dehaene, S. (2013). Splitting of the P3
component during dual-task processing in a patient with posterior
callosal section. Cortex, 49, 730--747. Heutink, J., de Haan, G.,
Marsman, J.-B., van Dijk, M. & Cordes, C. (2018). The effect of target
speed on perception of visual motion direction in a patient with
akinetopsia. Cortex, (Epub 15 December 2018). Heyman, T., Brunins, A.,
Hutchison, K.A. & Storms, G. (2018). The (un)reliability of item-level
semantic priming effects. Behavior Research Methods, 50, 2173--2183.
Heywood, C.A. & Cowey, A. (1999). Cerebral achromatopsia. In G.W.
Humphreys (ed.), Case Studies in the Neuropsychology of Vision
(pp. 17--40). Hove, UK: Psychology Press.

859

Hibberd, D.L., Jamson, S.L. & Carsten, O.M.J. (2013). Mitigating the
effects of in-vehicle distractions through use of the psychological
refractory period paradigm. Accident Analysis and Prevention, 50,
1096--1103. Hicks, J.L., Marsh, R.L. & Cook, G.I. (2005). Task
interference in time-based, event-based, and dual intention prospective
memory conditions. Journal of Memory and Language, 53, 430--444. Higham,
P.A., Blank, H. & Luna, K. (2017). Effects of post-warning specificity
on memory performance and confidence in the eyewitness misinformation
paradigm. Journal of Experimental Psychology: Applied, 23, 417--432.
Hilbert, M. (2012). Toward a synthesis of cognitive biases: How noisy
information processing can bias human decision making. Psychological
Bulletin, 138, 211--237. Hilger, K., Ekman, M., Fiebach, C.J. & Basten,
U. (2017). Efficient hubs in the intelligent brain: Nodal efficiency of
hub regions in the salient network is associated with general
intelligence. Intelligence, 60, 10--25. Hilliard, C. & Cook, S.W.
(2016). Bridging gaps in common ground: Speakers design their gestures
for their listeners. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 42, 91--102. Himmelbach, M., Boehme, R. &
Karnath, H.-O. (2012). 20 years later: A second look on DF's motor
behaviour. Neuropsychologia, 50, 139--144. Hirsch, C.R., Clark, D.M. &
Mathews, A. (2006). Imagery and interpretations in social phobia:
Support for the combined cognitive biases hypothesis. Behavior Therapy,
37, 223--236. Hirst, W. & Phelps, E.A. (2016). Flashbulb memories.
Current Directions in Psychological Science, 25, 36--41. Hirst, W.,
Phelps, E.A., Meksin, R., Vaidya, C.J., Buckner, R.L., Budson, A.E., et
al. (2015). A ten-year follow-up of a study of memory for the attack of
September 11, 2001: Flashback memories and memories for flashbulb
events. Journal of Experimental Psychology: General, 144, 604--623.
Hitchcock, C., Mueller, V., Hammond, E., Rees, C., WernerSeidler, A. &
Dalgleish, T. (2016). The effects of autobiographical memory flexibility
(MemFlex) training: An uncontrolled trial in individuals in remission
from depression. Journal of Behavioral Therapy and Experimental
Psychiatry, 52, 92--98. Ho, C. & Spence, C. (2005). Assessing the
effectiveness of various auditory cues in capturing a driver's visual
attention. Journal of Experimental Psychology: Applied, 11, 157--174.
Hobbs, S. & Burman, J.T. (2009). Is the "cognitive revolution" a myth?
The Psychologist, 22, 812--814. Hobeika, L., Diard-Decoeuf, C., Garcin,
B., Levy, R. & Volle, E. (2016). General and specialised brain
correlates for analogical reasoning: A meta-analysis of

860

References

functional imaging studies. Human Brain Mapping, 37, 1953--1969.
Hodgson, C. & Lambon Ralph, M.A. (2008). Mimicking aphasic semantic
errors in normal speech production: Evidence from a novel experimental
paradigm. Brain and Language, 104, 89--101. Hofer, F. & Schwaninger, A.
(2005). Using threat image projection data for assessing individual
screeners performance. WIT Transactions on the Built Environment, 82,
417--426. Hoffman, P., Lambon Ralph, M.A. & Woollams, A.M. (2015).
Triangulation of the neurocomputational architecture underpinning
reading aloud. Proceedings of the National Academy of Sciences, 112,
E3719--E3728. Hoffrage, U., Hafenbrädle, S. & Marewski, J.N. (2018). The
fast-and-frugal heuristics programme. In L.J. Ball & V.A. Thompson
(eds), Routledge International Handbook of Thinking and Reasoning
(pp. 325--345). Abingdon, Oxon.: Routledge. Hoffrage, U., Krauss, S.,
Martignon, L. & Gigerenzer, G. (2015). Natural frequencies improve
Bayesian reasoning in simple and complex inference tasks. Frontiers in
Psychology, 6 (Article no. 1473). Holan, A.D. (2015). All politicians
lie, some lie more than others. New York Times, 11 December. Holland,
A.C. & Kensinger, E.A. (2010). Emotion and autobiographical memory.
Physics of Life Reviews, 7, 88--131. Holland, R.W., de Vries, M.,
Hermsen, B. & van Knippenberg, A. (2012). Mood and the
attitude-behaviour link: The happy act on impulse, the sad think twice.
Social Psychological and Personality Science, 3, 356--364. Holler, J. &
Wilkin, K. (2011). An experimental investigation of how addressee
feedback affects co-speech gestures accompanying speakers' responses.
Journal of Pragmatics, 43, 3622--3536. Hollingworth, A. & Henderson,
J.M. (2002). Accurate visual memory for previously attended objects in
natural scenes. Journal of Experimental Psychology: Human Perception &
Performance, 28, 113--136. Hollingworth, A., Maxcey-Richard, A.M. &
Vecera, S.P. (2012). The spatial distribution of attention within and
across objects. Journal of Experimental Psychology: Human Perception and
Performance, 38, 135--151. Holmes, V.M. (1988). Hesitations and sentence
planning. Language and Cognitive Processes, 3, 323--361. Holyoak, K.J. &
Stamenković, D. (2018). Metaphor comprehension: A critical review of
theories and evidence. Psychological Bulletin, 144, 641--671. Holzgrefe,
J., Wellmann, C., Petrone, C., Truckenbrodt, H., Hohle, B. &
Wartenburger, I. (2013). Brain response to prosodic boundary cues
depends on boundary position. Frontiers in Psychology, 4 (Article no.
421). Hommel, B. (1998). Automatic stimulus-response translation in
dual-task performance. Journal of Experimental

Psychology: Human Perception and Performance, 24, 1368--1384. Hornikx,
J., Harris, A.J.L. & Boekema, J. (2018). How many laypeople holding a
popular opinion are needed to counter an expert opinion? Thinking &
Reasoning, 24, 117--128. Hortensius, R., Terburg, D., Morgan, B., Stein,
D.J., van Honk, J. & de Gelder, B. (2017). The dynamic consequences of
amygdala damage on threat processing in Urbach-Wiethe disease: A
commentary on Pishamazi et al. (2016). Cortex, 88, 192--197. Horton, C.,
D'Zmura, M. & Srinivasan, R. (2013). Suppression of competing speech
through entrainment of cortical oscillations. Journal of
Neurophysiology, 109, 3082--3093. Horton, W.S. & Gerrig, R.J. (2005).
Conversational common ground and memory processes in language
production. Discourse Processes, 40, 1--35. Horton, W.S. & Gerrig, R.J.
(2016). Revisiting the memory-based processing approach to common
ground. Topics in Cognitive Science, 8, 780--795. Horton, W.S. & Keysar,
B. (1996). When do speakers take into account common ground? Cognition,
59, 91--117. Hosking, S.G. & Crassini, B. (2010). The effects of
familiar size and object trajectories on time-to-contact judgments.
Experimental Brain Research, 203, 541--552. Houdé, O. & Borst, G.
(2015). Evidence for an inhibitorycontrol theory of the reasoning brain.
Frontiers in Human Neuroscience, 9 (Article no. 148). Houston, A.I.,
Fawcdett, T.W., Mallpress, J.M. & McNamara, J.M. (2014). Clarifying the
relationship between prospect theory and risk-sensitive foraging theory.
Evolution and Human Behavior, 35, 502--507. Howard, R.W. (2009).
Individual differences in expertise development over decades in a
complex intellectual domain. Memory & Cognition, 37, 194--209. Howe,
M.L. (2019). Unravelling the nature of early (autobiographical) memory.
Memory, 27, 115--121. Howe, M.L. & Courage, M.L. (1997). The emergence
and early development of autobiographical memory. Psychological Review,
104, 499--523. Howe, P.D.L. & Carter, O.L. (2016). Hallucinations and
mental imagery demonstrate top-down effects on visual perception.
Behavioral and Brain Sciences, 39 (Article no. e248). Howe, P.D. &
Leiserowitz, A. (2013). Who remembers a hot summer or a cold winter? The
asymmetric effects of beliefs about global warming on perceptions of
local conditions in the U.S. Global Environmental Change, 23,
1488--1500. Howe, P.D.L. & Webb, M.E. (2014). Detecting unidentified
changes. PLoS ONE, 9 (Article no. e84490). Howes, A., Warren, P.A.,
Farmer, G., El-Deredy, W. & Lewis, R.L. (2016). Why contextual
preference reversals

References maximise expected value. Psychological Review, 123, 368--391.
Huang, J., Pickering, M.J., Yang, J., Wang, S. & Branigan, H.P. (2016).
The independence of syntactic processing in Mandarin: Evidence from
structural priming. Journal of Memory and Language, 91, 81--98. Huang,
Y. & Rao, R.P.N. (2011). Predictive coding. Wiley Interdisciplinary
Reviews -- Cognitive Science, 2, 580--593. Hubel, D.H. & Wiesel, T.N.
(1962). Receptive fields, binocular interaction and functional
architecture in the cat's visual cortex. Journal of Physiology, 160,
106--154. Hubel, D.H. & Wiesel, T.N. (1979). Brain mechanisms of vision.
Scientific American, 249, 150--162. Huberdeau, D.M., Krakauer, J.W. &
Haith, A.M. (2015). Dual-process decomposition in human sensori-motor
adaptation. Current Opinion in Neurobiology, 33, 71--77. Huber-Huber, C.
& Ansorge, U. (2018). Unconscious conflict adaptation without
feature-repetitions and response time carry-over. Journal of
Experimental Psychology: Human Perception and Performance, 44, 169--175.
Huettig, F. (2015). Four central questions about prediction in language
processing. Brain Research, 1626, 118--135. Huettig, F. & Mani, N.
(2016). Is prediction necessary to understand language? Probably not.
Language, Cognition and Neuroscience, 31, 19--31. Huff, M., Maurer,
A.E., Brich, I., Pagenkopf, A., Wickelmaier, F. & Papenmeier, F. (2018).
Construction and updating of event models in auditory event processing.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 44,
307--320. Huettel, S.A. (2012). Event-related fMRI in cognition.
NeuroImage, 62, 1152--1156. Hugenberg, K., Young, S.G., Bernstein, M.J.
& Sacco, D.F. (2010). The categorisation individuation model: An
integrative account of the other-race recognition deficit. Psychological
Review, 117, 1168--1187. Huijser, S., van Vugt, M.K. & Taatgen, N.A.
(2018). The wandering self: Tracking distracting self-generated thought
in a cognitively demanding context. Consciousness and Cognition, 58,
170--185. Hulleman, J. & Olivers, C.N.L. (2017). The impending demise of
the item in visual search. Behavioral and Brain Sciences, 40 (Article
no. e132), 1--20. Hung, C.P., Kreiman, C., Poggio, T. & DiCarlo, J.J.
(2005). Fast readout of object identity from macaque inferior temporal
cortex. Science, 310, 863--866. Hunt, R.R. & Smith, R.E. (2014). How
distinctive processing enhances hits and reduces false alarms. Journal
of Memory and Language, 75, 45--57. Huntsinger, J.R. (2012). Does
positive affect broaden and negative affect narrow attentional scope? A
new answer to an old question. Journal of Experimental Psychology:
General, 141, 595--600.

861

Huntsinger, J.R., Isbell, L.M. & Clore, G.L. (2014). The affective
control of thought: Malleable, not fixed. Psychological Bulletin, 121,
600--618. Huppert, J.D. (2008). Anxiety disorders and depression
comorbidity. In M.M. Antony & M.B. Stein (eds), Oxford Handbook of
Anxiety and Related Disorders (pp. 5726--5587). Oxford: Oxford
University Press. Hurme, M., Koivisto, M., Revonsuo, A. & Railo, H.
(2017). Early processing in primary visual cortex is necessary for
unconscious vision while late processing is necessary only for conscious
vision in neurologically healthy humans. NeuroImage, 150, 230--238.
Hurme, M., Koivisto, M., Revonsuo, A. & Railo, H. (2019). V1 activity
during feedforward and early feedback processing is necessary for both
conscious and unconscious motion perception. NeuroImage, 185, 313--321.
Hurvich, L.M. & Jameson, D. (1957). An opponent process theory of colour
vision. Psychological Review, 64, 384--390. Huth, A.G., Lee, T.,
Nishimoto, S., Bilenko, N.Y., Vu, A.T. & Gallant, J.L. (2016). Decoding
the semantic content of natural movies from human brain activity.
Frontiers in Systems Neuroscience, 10 (Article no. 81). Hyde, K.L.,
Lerch, J., Norton, A., Forgeard, M., Winner, E., Evans, A.C., et
al. (2009). Musical training shapes structural brain development.
Journal of Neuroscience, 29, 3019--3025. Hyman, I., Boss, S., Wise, B.,
McKenzie, K. & Caggiano, J. (2009). Did you see the unicycling clown?
Inattentional blindness while walking and talking on a cell phone.
Applied Cognitive Psychology, 24, 597--607. Ihlebaek, C., Løve, T.,
Eilertsen, D.E. & Magnussen, S. (2003). Memory for a staged criminal
Event witnessed live and on video. Memory, 11, 310--327. Indefrey, P.
(2011). The spatial and temporal signatures of word production
components: A critical update. Frontiers in Psychology, 2 (Article no.
255). Indefrey, P. & Levelt, W.J.M. (2004). The spatial and temporal
signatures of word production components. Cognition, 92, 101--144.
Inman, C.S., James, G.A., Vytal, K. & Hamann, S. (2018). Changes in
large-scale functional network organisation during autobiographical
memory retrieval. Neuropsychologia, 110, 208--224. Insausti, R., Annese,
J., Amaral, D.G. & Squire, L.R. (2013). Human amnesia and the medial
temporal lobe illuminated by neuropsychological and neurohistological
findings for patient E.P. Proceedings of the National Academy of
Sciences of the United States of America, 110, E1953--E1962. Ioannides,
A.A., Popescu, M., Otsuka, A., Bezerianos, A. & Liu, L. (2003).
Magnetoencephalographic evidence of the interhemispheric asymmetry in
echoic memory

862

References

lifetime and its dependence on handedness and gender. NeuroImage, 19,
1061--1075. Ipser, A., Agolli, B., Bajraktari, A., Al-Alawi, F.,
Djaafara, N. & Freeman, E.D. (2017). Sight and sound persistently out of
synch: Stable individual differences in audiovisual synchronization
revealed by implicit measures of lip-voice integration. Scientific
Reports, 7 (Article no. 46413). Irish, M. & Piguet, O. (2013). The
pivotal role of semantic memory in remembering the past and imagining
the future. Frontiers in Behavioral Neuroscience, 7 (Article no. 27).
Irish, M. & Piolino, P. (2016). Impaired capacity for prospection in the
dementias -- Theoretical and clinical implications. British Journal of
Clinical Psychology, 55, 45--68. Irish, M., Bunk, S., Tu, S.C.,
Kamminga, J., Hodges, J.R., Hornberger, M., et al. (2016). Preservation
of episodic memory in semantic dementia: The importance of regions
beyond the medial temporal lobes. Neuropsychologia, 81, 50--60.
Ishibashi, R., Mima, T., Fukuyama, H. & Pobric, G. (2018). Facilitation
of function and manipulation knowledge of tools using transcranial
direct current stimulation (tDCS). Frontiers of Integrative
Neuroscience, 11 (Article no. 37). Itkonen, T., Pekkanen, J. & Lappi, O.
(2015). Driver gaze behaviour is different in normal curve driving and
when looking at the tangent point. PLoS One, 10 (Article no. e0135505).
Ittelson, W.H. (1951). Size as a cue to distance: Static localisation.
American Journal of Psychology, 64, 54--67. Itzhak, I. & Baum, S.R.
(2015). Misleading bias-driven expectations in referential processing
and the facilitative role of contrastive accent. Journal of
Psycholinguistic Research, 44, 623--650. Iyilikci, E.A. & Amado, S.
(2018). The uncertainty appraisal enhances the prominent deck in the
Iowa gambling task. Motivation and Emotion, 42, 1--16. Izard, C.E.
(2007). Basic emotions, natural kinds, emotion schemas, and a new
paradigm. Perspectives on Psychological Science, 2, 260--280. Jaarsma,
T., Jarokzka, H., Nap, M., van Merrienboer, J.J.G. & Boshuizen, H.P.A.
(2014). Expertise under the microscope: Processing histopathological
slides. Medical Education, 48, 292--300. Jack, F. & Hayne, H. (2010).
Childhood amnesia: Empirical evidence for a two-stage phenomenon.
Memory, 18, 831--844. Jack, F., MacDonald, S., Reese, E. & Hayne, H.
(2009). Maternal reminiscing style during early childhood predicts the
age of adolescents' earliest memories. Child Development, 80, 496--505.
Jacobs, A., Pinto, J. & Shiffrar, M. (2004). Experience, context, and
the visual perception of human movement.

Journal of Experimental Psychology: Human Perception and Performance,
30, 833--835. Jacobs, R.A. (2002). What determines visual cue
reliability? Trends in Cognitive Sciences, 6, 345--350. Jacoby, L.L.,
Bishara, A.J., Hessels, S. & Toth, J.P. (2005). Aging, subjective
experience, and cognitive control: Dramatic false remembering by older
adults. Journal of Experimental Psychology: General, 134, 131--148.
Jacoby, L.L., Debner, J.A. & Hay, J.F. (2001). Proactive interference,
accessibility bias, and process dissociations: Valid subjective reports
of memory. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 27, 686--700. Jacoby, L.L., Wahlheim, C.N. & Kelley, C.M.
(2015). Memory consequences of looking back to notice change:
Retroactive and proactive facilitation. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 41, 1282--1297. Jacquemot,
C., Dupoux, E. & Bachoud-Lévi, A.-C. (2011). Is the word-length effect
linked to subvocal rehearsal? Cortex, 47, 484--493. Jaeger, T.F. &
Snider, N.E. (2013). Alignment as a consequence of expectation
adaptation: Syntactic priming is affected by the prime's prediction
error given both prior and recent experience. Cognition, 127, 57--83.
Jain, A.K. & Duin, R.P.W. (2004). Pattern recognition. In R.L. Gregory
(ed.), The Oxford Companion to the Mind (pp. 698--703). Oxford: Oxford
University Press. Jäkel, F., Singh, M., Wichmann, F.A. & Herzog, M.H.
(2016). An overview of quantitative approaches in Gestalt perception.
Vision Research, 126, 3--8. Jalbert, A., Neath, I., Bireta, T.J. &
Surprenant, A.M. (2011). When does length cause the word length effect?
Journal of Experimental Psychology: Learning, Memory, and Cognition, 37,
338--353. James, D., Friedman, D., Louie, C. & O'Meara, T. (2018).
Dissecting the Monty Hall anomaly. Economic Inquiry, 56, 1817--1826.
James, E.L., Lau-Zhu, A., Clark, I.A., Visser, R.M., Hagenaars, M.A. &
Holmes, E.A. (2016). The trauma film paradigm as an experimental
psychopathology model of psychological trauma: Intrusive memories and
beyond. Clinical Psychology Review, 47, 106--142. James, K.H. (2017).
The importance of handwriting experience on the development of the
literate brain. Current Directions in Psychological Science, 26,
502--508. James, T.W., Culham, J., Humphrey, G.K., Milner, A.D. &
Goodale, M.A. (2003). Ventral occipital lesions impair object
recognition but not object-directed grasping: An fMRI study. Brain, 126,
2463--2475. James, W. (1890). The Principles of Psychology. New York:
Holt, Rinehard & Winston. Janczyk, M., Renas, S. & Durst, M. (2018).
Identifying the locus of compatibility-based backward crosstalk:

References Evidence from an extended PDP paradigm. Journal of
Experimental Psychology: Human Perception and Performance, 44, 261--276.
Janelle, C.M., Singer, R.N. & Williams, A.M. (1999). External
distraction and attentional narrowing: Visual search evidence. Journal
of Sport & Exercise Psychology, 21, 70--91. Jans, B., Peters, J.C. & de
Weerd, P. (2010). Visual spatial attention to multiple locations at
once: The jury is still out. Psychological Review, 117, 637--684.
Jansma, J.M., Ramsey, N.F., Slagter, H.A. & Kahn, R.S. (2001).
Functional anatomical correlates of controlled and automatic processing.
Journal of Cognitive Neuroscience, 13, 730--743. Janssen, P., Verhoef,
B.-E. & Premereur, E. (2018). Functional interactions between the
macaque dorsal and ventral visual pathways during three-dimensional
object vision. Cortex, 98, 218--227. Jantzen, M.G., Large, E.W. & Magne,
C. (2016). Editorial: Overlap of neural systems for processing language
and music. Frontiers in Psychology, 7 (Article no. 876). Jared, D.
(2002). Spelling-sound consistency and regularity effects in word
naming. Journal of Memory and Language, 46, 723--750. Jared, D. &
O'Donnell, K. (2017). Skilled adult readers activate the meanings of
high-frequency words using phonology: Evidence from eye tracking. Memory
& Cognition, 45, 334--346. Jarosz, A.F., Colflesh, G.J.H. & Wiley, J.
(2012). Uncorking the muse: Alcohol intoxication facilitates creative
problem. Consciousness and Cognition, 21, 487--493. Jefferies, E., Sage,
K. & Lambon Ralph, M.A. (2007). Do deep dyslexia, dysphasia, and
dysgraphia share a common phonological impairment? Neuropsychologia, 45,
1553--1570. Jeneson, A. & Squire, L.R. (2012). Working memory, longterm
memory, and medial temporal lobe function. Learning & Memory, 19,
15--25. Jenkins, R. & Burton, A.M. (2011). Stable face representations.
Philosophical Transactions of the Royal Society B: Biological Sciences,
366, 1671--1683. Jenkins, R., White, D., van Montfort, X. & Burton, A.M.
(2011). Variability in photos of the same face. Cognition, 121,
313--323. Jensen, M.S., Yao, R., Street, W.N. & Simons, D.J. (2011).
Change blindness and inattentional blindness. Wiley Interdisciplinary
Reviews: Cognitive Science, 2, 529--546. Jiahui, G., Yang, H. &
Duchaine, B. (2018). Developmental prosopagnosics have widespread
selectivity reductions across category-selective visual cortex.
Proceedings of the National Academy of Sciences, 115, E6418--E6427.
Jiang, Y., Costello, P., Fang, F., Huang, M. & He, S. (2006). A
gender-and sexual orientation-dependent spatial attentional effect of
invisible images. Proceedings of the

863

National Academy of Sciences of the United States of America, 103,
17048--17052. Jiménez, L. & Vázquez, G.A. (2011). Implicit sequence
learning and contextual cueing do not compete for central cognitive
resources. Journal of Experimental Psychology: Human Perception and
Performance, 37, 222--235. Joanisse, M.F. & McClelland, J.L. (2015).
Connectionist perspectives on language learning, representation and
processing. Wiley Interdisciplinary Reviews -- Cognitive Science, 6,
235--247. Jobard, G., Vigneau, M., Simon, G. & Tzurio-Mazoyer, N.
(2011). The weight of skill: Interindividual variability of reading
related brain activation patterns in fluent readers. Journal of
Neurolinguistics, 24, 113--132. Johannessen, K.B. & Berntsen, D. (2010).
Current concerns in involuntary and voluntary autobiographical memories.
Consciousness and Cognition, 19, 847--860. Johansson, G. (1973). Visual
perception of biological motion and a model for its analysis. Perception
& Psychophysics, 14, 201--211. Johansson, G. (1975). Visual motion
perception. Scientific American, 232, 76--89. Johansson, G., van
Hofsten, C. & Jansson, G. (1980). Event perception. Annual Review of
Psychology, 31, 27--64. John, L.K., Loewenstein, G. & Prelec, D. (2012).
Measuring the prevalence of questionable research practices with
incentives for truth telling. Psychological Science, 23, 524--532.
Johnson, M.K., Hashtroudi, S. & Lindsay, D.S. (1993). Source monitoring.
Psychological Bulletin, 114, 3--28. Johnson-Laird, P.N. (1983). Mental
Models: Towards a cognitive science of language, inference and
consciousness. Cambridge: Cambridge University Press. Johnson-Laird,
P.N., Goodwin, G.P. & Khemlani, S.S. (2018). Mental models and
reasoning. In L.J. Ball & V.A. Thompson (eds), Routledge International
Handbook of Thinking and Reasoning (pp. 346--365). Abingdon, Oxon.:
Routledge. Johnson-Laird, P.N., Khemlani, S.S. & Goodwin, G.P. (2015).
Logic, probability, and human reasoning. Trends in Cognitive Sciences,
19, 201--214. Jolicoeur, P., Gluck, M.A. & Kosslyn, S.M. (1984).
Pictures and names: Making the connection. Cognitive Psychology, 16,
243--275. Jones, E.B. & Sharpe, L. (2017). Cognitive bias modification:
A review of meta-analyses. Journal of Affective Disorders, 223,
175--183. Jones, P.R. (2016). A tutorial on cue combination and signal
detection theory: Using changes in sensitivity to evaluate how observers
integrate sensory information. Journal of Mathematical Psychology, 73,
117--139. Jones, S.P., Dwyer, D.M. & Lewis, M.B. (2017). The utility of
multiple synthesised views in the recognition of

864

References

unfamiliar faces. Quarterly Journal of Experimental Psychology, 70,
906--918. Jongman, S.R., Roelofs, A. & Scheper, A.R. (2017). Picture
naming in typically developing and language-impaired children: The role
of sustained attention. International Journal of Language &
Communication Disorders, 52, 323--333. Jonides, J., Lewis, R.L., Nee,
D.E., Lustig, C., Berman, M.G. & Moore, K.S. (2008). The mind and brain
of short-term memory. Annual Review of Psychology, 59, 193--224.
Joormann, J. & Tanovic, E. (2015). Cognitive vulnerability to
depression: Examining cognitive control and emotion regulation. Current
Opinion in Psychology, 4, 86--92. Joormann, J., Yoon, K.L. & Zetsche, U.
(2007). Cognitive inhibition in depression. Applied & Preventive
Psychology, 12, 128--139. Josselyn, S.A. & Frankland, P.W. (2012).
Infantile amnesia: A neurogenic hypothesis. Learning & Memory, 19,
423--433. Joyce, J. (1922/1960). Ulysses. London: Bodley Head. Jun, S.A.
(2010). The implicit prosody hypothesis and overt prosody in English.
Language and Cognitive Processes, 25, 1201--1233. Juphard, A., Vidal,
J.R., Perrone-Bertolotti, M., Minotti, L., Kahane, P., Lachaux, J.-P.,
et al. (2011). Direct evidence for two different neural mechanisms for
reading familiar and unfamiliar words: An intra-cerebral EEG study.
Frontiers in Human Neuroscience, 5 (Article no. 101). Just, M.A. &
Carpenter, P.A. (1992). A capacity theory of comprehension.
Psychological Review, 114, 678--703. Just, M.A., Carpenter, P.A.,
Keller, T.A., Emery, L., Zajac, H. & Thlborn, K.R. (2001).
Interdependence of non-overlapping cortical systems in dual cognitive
tasks. NeuroImage, 14, 417--426. Juskenaite, A., Quinette, P., Laisney,
M., Eustache, M.L., Desgranges, B., Viader, F., et al. (2016). Preserved
self-evaluation in amnesia supports access to the self through
introspective computation. Frontiers in Human Neuroscience, 10 (Article
no. 462). Kaakinen, J.K. & Hyönä, J. (2007). Perspective effects in
repeated reading: An eye movement study. Memory & Cognition, 35,
1323--1336. Kahan, D.M. (2012). Why we are poles apart on climate
change. Nature, 488, 255. Kahan, D.M. (2015). Climate-science
communication and the measurement problem. Advances in Political
Psychology, 36, 1--43. Kahan, D.M., Peters, E., Wittlin, M., Slovic, P.,
Ouellette, L.L., Braman, D., et al. (2012). The polarising impact of
science literacy and numeracy on perceived climate change risks. Nature
Climate Change, 2, 732--735. Kahane, G., Everett, J.A.C., Earp, B.D.,
Farias, M. & Savulescu, J. (2015). "Utilitarian" judgments in
sacrificial moral dilemmas do not reflect impartial concern for the
greater good. Cognition, 134, 193--209.

Kahneman, D. (2003). A perspective on judgment and choice: Mapping
bounded rationality. American Psychologist, 58, 697--720. Kahneman, D.
(2011). Thinking, Fast and Slow. New York: Farrar, Strauss and Giroux.
Kahneman, D. & Tversky, A. (1972). Subjective probability -- Judgment of
representativeness. Cognitive Psychology, 3, 430--454. Kahneman, D. &
Tversky, A. (1973). On the psychology of prediction. Psychological
Review, 80, 237--251. Kahneman, D. & Tversky, A. (1979). Prospect
theory: An analysis of decision under risk. Econometrica, 47, 263--291.
Kahneman, D. & Tversky, A. (1984). Choices, values and frames. American
Psychologist, 39, 341--350. Kaiser, E., Runner, J.T., Sussman, R.S. &
Tanenhaus, M.K. (2009). Structural and semantic constraints on the
resolution of pronouns and reflexives. Cognition, 112, 55--80. Kaiser,
D. & Cichy, R.M. (2018). Typical visual field locations facilitate
access to awareness for everyday objects. Cognition, 180, 118--122.
Kaland, N., Moller-Nielsen, A., Smith, L., Mortensen, E.L., Callesen, K.
& Gotlien, D. (2005). The Strange Stories test: A replication study of
children and adolescents with Asperger syndrome. European Child &
Adolescent Psychiatry, 14, 73--82. Kandasamy, N., Garfinkel, S.N., Page,
L., Hardy, B., Critchley, H.D., Gurnell, M., et al. (2016).
Interoceptive ability predicts survival on a London trading floor.
Scientific Reports, 6 (Article no. 32986). Kandil, F.I., Rotter, A. &
Lappe, M. (2009). Driving is smoother and more stable when using the
tangent point. Journal of Vision, 9, 1--11. Kane, J. & Webster, G.A.
(2013). Heuristics and biases that help and hinder scientists: Toward a
psychology of scientific judgement and decision making. In G. Feist & M.
Gorman (eds), Handbook of the Psychology of Science (pp. 437--459). New
York: Springer. Kanizsa, G. (1976). Subjective contours. Scientific
American, 234, 48--52. Kanwisher, N., McDermott, J. & Chun, M.M. (1997).
The fusiform face area: A module in human extrastriate cortex
specialised for face perception. Journal of Neuroscience, 17,
4302--4311. Kaplan, S., Bekhor, S. & Shiftan, Y. (2011). Development and
estimation of a semi-compensatory choice model based on explicit choice
protocols. Annals of Regional Science, 47, 51--80. Karimi, H. &
Ferreira, F. (2016). Good-enough linguistic representations and online
cognitive equilibrium in language processing. Quarterly Journal of
Experimental Psychology, 69, 1013--1040. Karlen, Y. (2017). The
development of a new instrument to assess metacognitive strategy
knowledge about academic

References writing and its relation to self-regulated writing and
writing performance. Journal of Writing Research, 9, 61--86. Karlsson,
J., van den Broek, P., Helder, A., Hickendorff, M., Koornneef, A. & van
Leijenhorst, L. (2018). Profiles of young readers: Evidence from
thinking aloud while reading narrative and expository texts. Learning
and Individual Differences, 67, 105--116. Kasselimis, D.S.,
Angelopoulou, G., Kolovos, G., Daskalaki, A., Peppas, C., Tavernarakis,
A., et al. (2017). Pure word deafness due to herpes simplex
encephalitis. Journal of the Neurological Sciences, 372, 11--13. Kassin,
S.M., Dror, I.E. & Kukucka, J. (2013). The forensic confirmation bias:
Problems, perspectives, and proposed solutions. Journal of Applied
Research in Memory and Cognition, 2, 42--52. Katidioti, I. & Taatgen,
N.A. (2014). Choice in multitasking how delays in the primary task turn
a rational into an irrational multitasker. Human Factors, 56, 728--736.
Katti, H., Peelen, M.V. & Arun, S.P. (2017). How do targets,
non-targets, and scene context influence real-world object detection?
Attention, Perception & Psychophysics, 79, 2021--2036. Kauffmann, L.,
Chauvin, A., Guyader, N. & Peyrin, C. (2015). Rapid scene
categorisation: Role of spatial frequency order, accumulation mode and
luminance contrast. Vision Research, 107, 49--57. Kay, K., Naselaris,
T., Prenger, R.J. & Gallant, J.L. (2008). Identifying natural images
from human brain activity. Nature, 452, 352--355. Kazanas, S.A. &
Altarriba, J. (2015). The survival advantage: Underlying mechanisms and
extant limitations. Evolutionary Psychology, 13, 360--396. Keane, M.
(1987). On retrieving analogs when solving problems. Quarterly Journal
of Experimental Psychology, 39A, 29--41. Keating, J., Affleck-Brodie,
C., Wiegland, R. & Morcom, A.M. (2017). Aging, working memory capacity
and the proactive control of recollection: An event-related potential
study. PloS ONE, 12 (Article no. e0180367). Kelber, A., Yovanovich, C. &
Olsson, P. (2017). Thresholds and noise limitations of colour vision in
dim light. Philosophical Transactions of the Royal Society B, 372
(Article no. 2016.0065). Kellogg, R.T. (2001). Competition for working
memory among writing processes. American Journal of Psychology, 114,
175--191. Kellogg, R.T. & Mueller, S. (1993). Performance amplification
and process restructuring in computer-based writing. International
Journal of Man-Machine Studies, 39, 33--49. Kellogg, R.T. & Whiteford,
A.P. (2012). The development of writing expertise. In E.L. Grigorenko,
E. Mambrino & D.D. Preiss (eds), Writing: A mosaic of new perspectives
(pp. 109--124). Hove, UK: Psychology Press.

865

Kellogg, R.T., Olive, T. & Piolat, A. (2007). Verbal, visual, and
spatial working memory in written language production. Acta
Psychologica, 124, 382--397. Kellogg, R.T., Whiteford, A.P., Turner,
C.E., Cahill, M. & Mertens, A. (2013). Working memory in written
composition: An evaluation of the 1996 model. Journal of Writing
Research, 5, 159--190. Kemeny, F., Demeter, G., Racsmány, M., Valálik,
I. & Lukács, A. (2018). Impaired sequential and partially compensated
probabilistic skill learning in Parkinson's disease. Journal of
Neuropsychology (Epub 08 June 2018). Kendeou, P., Smith, E.R. & O'Brien,
E.J. (2013). Updating during reading comprehension: Why causality
matters. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 39, 854--865. Kenealy, P.M. (1997). Mood-state-dependent
retrieval: The effects of induced mood on memory reconsidered. Quarterly
Journal of Experimental Psychology, 50A, 290--317. Kenett, Y.N., Levi,
E., Anaki, D. & Faust, M. (2017). The semantic distance task:
Quantifying semantic distance with semantic network path length. Journal
of Experimental Psychology: Learning, Memory, and Cognition, 43,
1470--1489. Kent, S.C. & Wanzek, J. (2016). The relationship between
component skills and writing quality and production across developmental
levels: A meta-analysis of the last 25 years. Review of Educational
Research, 86, 570--601. Kersten, A.W., Meissner, C.A., Lechugs, J.,
Schwartz, B.L., Albrechtsen, J.S. & Iglesias, A. (2010). English
speakers attend more strongly than Spanish speakers to manner of motion
when classifying novel objects and events. Journal of Experimental
Psychology: General, 139, 638--653. Kessler, Y. & Moscovitch, M. (2013).
Strategic processing in long-term repetition priming in the lexical
decision task. Memory, 21, 366--376. Keys, D.J. & Schwartz, B. (2007).
"Leaky" rationality: How research on behavioural decision making
challenges normative standards of rationality. Perspectives on
Psychological Science, 2, 162--180. Keysar, B., Barr, D.J., Balin, J.A.
& Branner, J.S. (2000). Taking perspective in conversation: The role of
mutual knowledge in comprehension. Psychological Science, 11, 32--38.
Keysers, C., Paracampo, R. & Gazzola, V. (2018). What neuromodulation
and lesion studies tell us about the function of the mirror neuron
system and embodied cognition. Current Opinion in Psychology, 24,
35--40. Khemlani, S.S. & Johnson-Laird, P.N. (2012). Theories of the
syllogism: A meta-analysis. Psychological Bulletin, 138, 427--457.
Khemlani, S.S. & Johnson-Laird, P.N. (2017). Illusions in reasoning.
Minds and Machines, 27, 11--35.

866

References

Khemlani, S.S., Orenes, I. & Johnson-Laird, P.N. (2012). Negation: A
theory of its meaning, representation, and use. Journal of Cognitive
Psychology, 24, 541--559. Kidd, E., Donnelly, S. & Christiansen, M.H.
(2018). Individual differences in language acquisition and processing.
Trends in Cognitive Sciences, 22, 154--169. Kilpatrick, F.P. & Ittelson,
W.H. (1953). The size-distance invariance hypothesis. Psychological
Review, 60, 223--231. Kim, D., Stephens, J.D.W. & Pitt, M.A. (2012). How
does context play a part in splitting words apart: Production and
perception of word boundaries in casual speech. Journal of Memory and
Language, 66, 509--529. Kim, E.J., Suh, M.K., Lee, B., Park, K.C., Ku,
B.D., Chung, C.S., et al. (2009). Transcortical sensory aphasia
following a left frontal lobe infarction probably due to anomalously
represented language areas. Journal of Clinical Neuroscience, 16,
1482--1485. Kim, H. (2017a). Brain regions that show repetition
suppression and enhancement: A meta-analysis of 137 neuroimaging
experiments. Human Brain Mapping, 38, 1894--1913. Kim, N.-G. (2017b). A
binocular information source for size perception. Frontiers in
Psychology, 8 (Article no. 2078). Kim, N.-G. (2018). Independence of
size and distance in binocular vision. Frontiers in Psychology, 9
(Article no. 988). Kim, P.Y. & Mayhorn, C.B. (2008). Exploring students'
prospective memory inside and outside the lab. American Journal of
Psychology, 121, 241--254. Kim, S. & Voss, J.L. (2019). Large-scale
network interactions supporting item-context memory formation. PloS ONE,
14 (Article no. e0210167). Kim, S., Carello, C. & Turvey, M.T. (2016).
Size and distance are perceived independently in an optical tunnel:
Evidence for direct perception. Vision Research, 125, 1--11. Kimchi, R.,
Yeshurun, Y., Spehar, B. & Pirkner, Y. (2016). Perceptual organisation,
visual attention, and objecthood. Vision Research, 126, 34--51. King,
B.R., Fogel, S.M., Albouy, G. & Doyon, J. (2013a). Neural correlates of
the age-related changes in motor sequence learning and motor adaptation
in older adults. Frontiers in Human Science, 7 (Article no. 142). King,
J.-R., Sitt, J.D., Faugeras, F., Rohaut, B., El Karoui, I., Cohen, L.,
et al. (2013b). Information sharing in the brain indexes consciousness
in non-communicative patients. Current Biology, 23, 1914--1919.
Kingston, J., Levy, J., Rysling, A. & Staub, A. (2016). Eye movement
evidence for an immediate Ganong effect. Journal of Experimental
Psychology: Human Perception and Performance, 42, 1969--1988. Kintsch,
W. (1988). The role of knowledge in discourse comprehension: A
construction-integration model. Psychological Review, 95, 163--182.

Kintsch, W. (1992). A cognitive architecture for comprehension. In H.L.
Pick, P. van den Broek & D.C. Knill (eds), Cognition: Conceptual and
methodological issues (pp. 143--163). Washington, DC: American
Psychological Association. Kintsch, W. (1998). Comprehension: A Paradigm
for Cognition. New York: Cambridge University Press. Kintsch, W. (2000).
Metaphor comprehension: A computational theory. Psychonomic Bulletin &
Review, 7, 257--266. Kintsch, W., Welsch, D., Schmalhofer, E. & Zimny,
S. (1990). Sentence memory: A theoretical analysis. Journal of Memory
and Language, 29, 133--159. Kircanski, K. & Gotlib, I.H. (2015).
Processing of emotional information in major depressive disorder: Toward
a dimensional understanding. Emotion Review, 7, 256--264. Kizilirmak,
J.M., Sarrger, V., Kehl, J., Őllinger, M., FoltaSchoofs, K. &
Richardson-Klavehn, A. (2018). Feelingsof-warmth increase more abruptly
for verbal riddles solved with in contrast to without Aha! experience.
T.W., Mendez, M.F., Frontiers in Psychology, 9 (Article no. 1404).
Klargaard, S.K., Starrfelt, R. & Gerlach, C. (2018). Inversion effects
for faces and objects in developmental prosopagnosia: A case series
analysis. Neuropsychologia, 113, 52--60. Klauer, K.C., Beller, S. &
Hütter, M. (2010). Conditional reasoning in context: A dual-source model
of probabilistic inference. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 36, 298--323. Klauer, K.C. & Zhao, Z.
(2004). Double dissociations in visual and spatial short-term memory.
Journal of Experimental Psychology: General, 133, 355--381. Klauer,
K.C., Musch, J. & Naumer, B. (2000). On belief bias in syllogistic
reasoning. Psychological Review, 107, 852--884. Klaus, J., Mädebach, A.,
Oppermann, F. & Jeseniak, J.D. (2017). Planning sentences while doing
other things at the same time: Effects of concurrent verbal and
visuo-spatial working memory load. Quarterly Journal of Experimental
Psychology, 70, 811--831. Klein, C. (2014). Reliability in cognitive
neuroscience: A metameta analysis. Philosophical Psychology, 28,
606--613. Klein, G. (1998). Sources of Power: How people make decisions.
Cambridge, MA: MIT Press. Klein, G. (2008). Naturalistic decision
making. Human Factors, 50, 456--460. Klein, G., Calderwood, R. &
Clinton-Cirocco, A. (2010). Rapid decision making on the fire ground:
The original study plus a postscript. Journal of Cognitive Engineering
and Decision Making, 4, 186--209. Kliegl, O. & Bäuml, K-H.T. (2016).
Retrieval practice can insulate items against intralist interference:
Evidence from the list-length effect, output interference, and
retrievalinduced forgetting. Journal of Experimental Psychology:
Learning, Memory and Cognition, 42, 202--214.

References Kliegl, O., Pastötter, B. & Bäuml, K.-H.T. (2015). The
contribution of encoding and retrieval processes to proactive
interference. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 41, 1778--1780. Kloeters, S., Hartmann, C.J., Pundmann, V.D.,
Schnitzler, A., Sudmeyer, M. & Lange, J. (2017). Impaired perception of
human movements in Parkinson's disease. Behavioural Brain Research, 317,
88--94. Klooster, N.B. & Duff, M.C. (2015). Remote semantic memory is
impoverished in hippocampal amnesia. Neuropsychologia, 79, 42--52.
Klumpp, H., Bhaumik, R., Kinney, K.L. & Fitzgerald, J.M. (2018).
Principal component analysis and neural predictors of emotion
regulation. Behavioural Brain Research, 338, 128--133. Knoblich, G.,
Ohlsson, S., Haider, H. & Rhenius, D. (1999). Constraint relaxation and
chunk decomposition in insight. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 25, 1534--1555. Knoblich, G., Ohlsson,
S. & Raney, G.E. (2001). An eye movement study of insight problem
solving. Memory & Cognition, 29, 1000--1009. Knol, H., Huys, R.,
Sarrazin, J.-C., Spiegler, A. & Jirsa, V.K. (2017). Ebbinghaus figures
that deceive the eye do not necessarily deceive the hand. Scientific
Reports, 7 (Article no. 3111). Knowlton, B.J. & Foerde, K. (2008).
Neural representations of non-declarative memories. Current Directions
in Psychological Science, 17, 107--111. Ko, Y. & Lau, H. (2012). A
detection theoretic explanation of blindsight suggests a link between
conscious perception and metacognition. Philosophical Transactions of
the Royal Society B, 367, 1401--1411. Kocab, A., Senghas, A. & Snedeker,
J. (2016). The emergence of temporal language in Nicaraguan Sign
Language. Cognition, 156, 147--163. Kocagoncu, E., Clarke, A., Devereux,
B.J. & Tyler, L.K. (2017). Decoding the cortical dynamics of
sound-meaning mapping. Journal of Neuroscience, 37, 1312--1319. Koch, C.
& Tsuchiya, N. (2012). Attention and consciousness: Related yet
different. Trends in Cognitive Sciences, 16, 103--105. Koch, C.,
Massimini, M., Boly, M. & Tononi, G. (2016). Neural correlates of
consciousness: Progress and problems. Nature Reviews Neuroscience, 17,
307--321. Koch, I., Poljac, E., Müller, H. & Kiesel, A. (2018).
Cognitive structure, flexibility, and plasticity in human multitasking
-- An integrative review of dual-task and task-switching research.
Psychological Bulletin, 144, 557--583. Koehler, D.J. & James, G. (2009).
Probability matching in choice under uncertainty: Intuition versus
deliberation. Cognition, 113, 123--127.

867

Koellinger, P. & Treffers, T. (2015). Joy leads to overconfidence, and a
simple countermeasure. PloS ONE, 10 (Article no. e0143263). Kohn, N.,
Eickhoff, S.B., Scheller, M., Laird, A.R., Fox, P.T. & Habel, U. (2014).
Neural networks of cognitive emotion regulation -- An ALE meta-analysis
and MACM analysis. NeuroImage, 87, 345--355. Koivisto, M. & Grassini, S.
(2016). Neural processing around 200 ms after stimulus-onset correlates
with subjective visual awareness. Neuropsychologia, 84, 235--243.
Koivisto, M., Kastrati, G. & Revonsuo, A. (2014). Recurrent processing
enhances visual awareness but is not necessary for fast categorisation
of natural scenes. Journal of Cognitive Neuroscience, 26, 223--231.
Koivisto, M., Railo, H., Revonsuo, A., Vanni, S. & SalminenVaparanta, N.
(2011). Recurrent processing in V1/V2 contributes to categorisation of
natural scenes. Journal of Neuroscience, 31, 2488--2492. Koivisto, M. &
Rientamo, E. (2016). Unconscious vision spots the animal but not the
dog: Masked priming of natural scenes. Consciousness and Cognition, 41,
10--23. Kok, P., Mostert, P. & de Lange, F.P. (2017). Prior expectations
induce pre-stimulus sensory templates. Proceedings of the National
Academy of Sciences of the United States of America, 114, 10473--10478.
Kondziella, D., Friberg, C.K., Frokjaer, V.G., Fabricius, M. & Møller,
K. (2016). Preserved consciousness in vegetative and minimal conscious
states: Systematic review and meta-analysis. Journal of Neurology,
Neurosurgery and Psychiatry, 87, 485--492. Konishi, M. & Smallwood, J.
(2016). Shadowing the wandering mind: How understanding the
mind-wandering state can inform our appreciation of conscious
experience. Wiley Interdisciplinary Reviews -- Cognitive Science, 7,
233--246. Koole, S.L., Webb, T.L. & Sheeran, P.L. (2015). Implicit
emotion regulation: Feeling better without knowing why. Current Opinion
in Psychology, 3, 6--10. Koornneef, A. & Reuland, E. (2016). On the
shallow processing (dis)advantage: Grammar and economy. Frontiers in
Psychology, 7 (Article no. 82). Kopiske, K.K., Cesanek, E., Campagnoli,
C. & Domini, F. (2017). Adaptation effects in grasping the Müller-Lyer
illusion. Vision Research, 136, 21--31. Koppel, J. & Berntsen, D.
(2015). The peaks of life: The differential temporal location of the
reminiscence bump across disparate cueing methods. Journal of Applied
Research in Memory and Cognition, 4,66--80. Koppel, J. & Berntsen, D.
(2016). The reminiscence bump without memories: The distribution of
imagined wordcued and important autobiographical memories in a
hypothetical 70-year-old. Consciousness and Cognition, 44, 89--102.

868

References

Koppenol-Gonzalez, G.V., Bouwmeester, S. & Boonstra, A.M. (2010).
Understanding planning ability measured by the Tower of London: An
evaluation of its internal structure by latent variable modelling.
Psychological Assessment, 22, 923--934. Kornell, N., Bjork, R.A. &
Garcia, M.A. (2011). Why tests appear to prevent forgetting: A
distribution-based bifurcation model. Journal of Memory and Language,
65, 85--97. Kosslyn, S.M. (1994). Image and Brain: The resolution of the
imagery debate. Cambridge, MA: MIT Press. Kosslyn, S.M. (2005). Mental
images and the brain. Cognitive Neuropsychology, 22, 333--347. Kosslyn,
S.M. & Thompson, W.L. (2003). When is early visual cortex activated
during visual mental imagery? Psychological Bulletin, 129, 723--746.
Koster, E.H.W., Hoorelbeke, K., Onraedt, T., Owens, M. & Derakshan, N.
(2017). Cognitive control interventions for depression: A systematic
review of findings from training studies. Clinical Psychology Review,
53, 79--92. Kotseruba, I. & Tsotsos, J. (2018). A review of 40 years of
cognitive architecture research: Core cognitive abilities and practical
applications. Artificial Intelligence Review, 1--78. Kouider, S., de
Gardelle, V., Sackur, J. & Dupoux, E. (2010). How rich is consciousness?
The partial awareness hypothesis. Trends in Cognitive Sciences, 14,
301--307. Kounios, J. & Beeman, M. (2014). The cognitive neuroscience of
insight. Annual Review of Psychology, 65, 71--93. Kourtzi, Z. & Connor,
C.E. (2011). Neural representations for object perception: Structure,
category, and adaptive coding. Annual Reviews of Neuroscience, 34,
45--67. Kovacs, G. & Schweinberger, S.R. (2016). Repetition suppression
-- An integrative view. Cortex, 80, 1--4. Kovacs, K. & Conway, A.R.A.
(2016). Process overlap theory: A unified account of the general factor
of intelligence. Psychological Inquiry, 27, 151--177. Kovera, M.B.,
Bull, M. & Evelo, A.J. (2017). The case for double-blind lineup
administration. Psychology, Public Policy and Law, 23, 421--437. Kraft,
J.M. & Brainard, D.H. (1999). Mechanisms of colour constancy under
nearly natural viewing. Proceedings of the National Academy of the
United States of America, 96, 307--312. Kragel, J.E. & Polyn, S.M.
(2016). Decoding episodic retrieval processes: Fronto-parietal and
medial temporal lobe contributions to free recall. Journal of Cognitive
Neuroscience, 28, 125--139. Kraus, N. & Slater, J. (2016). Beyond words:
How humans communicate through sound. Annual Review of Psychology, 67,
83--103. Krauss, S. & Wang, X.T. (2003). The psychology of the Monty
Hall problem: Discovering psychological

mechanisms for solving a tenacious brain teaser. Journal of Experimental
Psychology: General, 132, 3--22. Kravitz, D.J. & Behrmann, M. (2011).
Space-, object-, and feature-based attention interact to organise visual
scenes. Attention, Perception & Psychophysics, 73, 2434--2447. Kravitz,
D.J., Saleem, K.S., Baker, C.I., Ungerleider, L.G. & Mishkin, M. (2013).
The ventral visual pathway: An expanded neural framework for the
processing of object quality. Trends in Cognitive Sciences, 17, 26--49.
Krawczyk, D.C. (2012). The cognition and neuroscience of relational
reasoning. Brain Research, 1428, 13--23. Krawczyk D.C., Morrison, R.G.,
Viskontas, I., Holyoak, K.J., Chow, T.W., Mendez, M.F., et al. (2008).
Distraction during relational reasoning: The role of prefrontal cortex
in interference control. Neuropsychologia, 46, 2020--2032. Kretz, D. &
Krawczyk, D.C. (2014). Expert analogy use in a naturalistic setting.
Frontiers in Psychology, 5 (Article no. 1333). Kriengwatana, B., Terry,
J., Chládková, K. & Escudero, P. (2016). Speaker and accent are handled
differently: Evidence in native and non-native listeners. PLoS ONE, 11
(Article no. e0156870). Króliczak, G., Heard, P., Goodale, M.A. &
Gregory, R.L. (2006). Dissocations of perception and action unmasked by
the hollow-face illusion. Brain Research, 1080, 9--16. Kroll, J.F. &
Navarro-Torres, C. (2018). Bilingualism. In J.T. Wixted & S.L.
Thompson-Schill (eds), Stevens' Handbook of Experimental Psychology and
Cognitive Neuroscience, Vol. 3: Language and thought (4th edn)
(pp. 245--274). New York: Wiley. Kruger, J.M. & Dunning, D. (1999).
Unskilled and unaware of it: How difficulties in recognising one's own
incompetence lead to inflated self-assessments. Journal of Personality
and Social Psychology, 77, 1121--1134. Kruglanski, A.W. & Gigerenzer, G.
(2011). Intuitive and deliberate judgments are based on common
principles. Psychological Review, 118, 97--109. Krupinski, E.A., Graham,
A.R. & Weinstein, R.S. (2013). Characterising the development of visual
search expertise in pathology residents viewing whole slide images.
Human Pathology, 44, 357--364. Krynski, T.R. & Tenenbaum, J.B. (2007).
The role of causality in judgment under uncertainty. Journal of
Experimental Psychology: General, 136, 430--450. Kubricht, J.R., Lu, H.
& Holyoak, K.J. (2017). Individual differences in spontaneous analogical
transfer. Memory & Cognition, 45, 576--588. Kugler, T., Connolly, T. &
Ordonez, L.D. (2012). Emotion, decision and risk: Betting on gambles
versus betting on people. Journal of Behavioral Decision Making, 25,
123--134. Kuhn, G. & Findlay, J.M. (2010). Misdirection, attention and
awareness: Inattentional blindness reveals temporal

References relationship between eye movements and visual awareness.
Quarterly Journal of Experimental Psychology, 63, 136--146. Kuhn, G. &
Martinez, L.M. (2012). Misdirection -- Past, present, and the future.
Frontiers in Human Neuroscience, 5, 172. Kuhn, G., Teszka, R., Tenaw, N.
& Kingstone, A. (2016). Don't be fooled! Attentional responses to social
cues in a face-to-face and video magic trick reveals greater topdown
control for overt than covert attention. Cognition, 146, 136--142.
Kulatunga-Moruzi, C., Brooks, L.R. & Norman, G.R. (2004). Using
comprehensive feature lists to bias medical diagnosis. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 30, 563--572.
Kulatunga-Moruzi, C., Brooks, L.R. & Norman, G.R. (2011). Teaching
post-training: Influencing diagnostic strategy with instructions at
test. Journal of Experimental Psychology: Applied, 17, 195--209. Kundel,
H.L. & Nodine, C.F. (1975). Interpreting chest radiographs without
visual search. Radiology, 116, 527--532. Kundel, H.L., Nodine, C.F.,
Conant, E.F. & Weinstein, S.P. (2007). Holistic components of image
perception in mammogram interpretation: Gaze tracking study. Radiology,
242, 396--402. Kuperberg, G.R. & Jaeger, T.F. (2016). What do we mean by
prediction in language comprehension? Language, Cognition and
Neuroscience, 31, 32--59. Kuperberg, G.R., Paczynski, M. & Ditman, T.
(2011). Establishing causal coherence across sentences: An ERP study.
Journal of Cognitive Neuroscience, 23, 1230--1246. Kuppens, P. (2013).
Comment: Appraisal affords flexibility to emotion in more ways than one.
Emotion Review, 5, 176--179. Kuppens, P., Van Mechelen, I., Smits,
D.J.M. & De Broeck, P. (2003). The appraisal basis of anger:
Specificity, necessity and sufficiency of components. Emotion, 3,
254--269. Kurby, C.A. & Zacks, J.M. (2012). Starting from scratch and
building brick by brick. Memory & Cognition, 40, 812--826. Kurt, S.,
Deutscher, A., Crook, J.M., Ohl, F.W., Budinger, E., Moeller, C.K., et
al. (2008). Auditory cortical contrast enhancing by global
winner-take-all inhibitory interactions. PLoS ONE, 3 (Article no.
31735). Kvavilashvili, L. & Ellis, J.A. (2004). Ecological validity and
twenty years of real-life/laboratory controversy in memory research: A
critical (and historical) review. History and Philosophy of Psychology,
6, 59--80. Kwon, M., Shim, W.H., Kim, S.J. & Kim, J.S. (2017).
Transcortical sensory aphasia after left Frontal lobe infarction: Loss
of functional connectivity. European Neurology, 78, 15--21. Kwon, Y.,
Choi, S. & Lee, Y. (2016). Early use of orthographic information in
spoken word recognition:

869

Event-related potential evidence from the Korean language.
Psychophysiology, 53, 544--552. Lacey, S., Stilla, R., Deshpande, G.,
Zhao, S., Stephens, C., McCormick, K., et al. (2017). Engagement of the
left extrastriate body area during body-part metaphor comprehension.
Brain & Language, 166, 1--18. Lacroix, A.N., Diaz, A.F. & Rogalsky, C.
(2015). The relationship between the neural computations for speech and
music is context-dependent: An activation likelihood estimate study.
Frontiers in Psychology, 6 (Article no. 1138). Laeng, B., Bloem, I.M.,
D'Ascenzo, S. & Tommasi, L. (2014). Scrutinising visual images: The role
of gaze in mental imagery and memory. Cognition, 131, 263--283.
Lafer-Sousa, R., Conway, B.R. & Kanwisher, N.G. (2016). Colour-based
regions of the ventral visual pathway lie between face- and
place-selective regions in humans, as in macaques. Journal of
Neuroscience, 36, 1682--1697. Laganaro, M., Morand, S. & Schnider, A.
(2009). Time course of evoked-potential changes in different forms of
anomia in aphasia. Journal of Cognitive Neuroscience, 21, 1499--1510.
Lahmer, M., Glatz, C., Seibold, V.C. & Chuang, L.L. (2018). Looming
auditory collision warnings for semi-automated driving: An ERP study.
AutomototiveUI'18: Proceedings of the 10th ACM International Conference
on Automotive Interfaces and Interactive Vehicular Applications, 23--25
September 2018, 310--319. Lai, C.S.L., Fisher, S.E., Hurst, J.A.,
Vargha-Khadem, E. & Monaco, A.P. (2001). A forkhead-domain gene is
mutated in a severe speech and language disorder. Nature, 413, 519--523.
Laird, J.E., Lebiere, C. & Rosenbloom, P.S. (2017). A standard model of
the mind: Toward a common computational framework across artificial
intelligence, cognitive science, neuroscience, and robotics. AI
Magazine, 38, 1--19. Lakatos, I. (1978). The Methodology of Scientific
Research Programmes: Philosophical papers, Vol. 1. Cambridge: Cambridge
University Press. Lambe, K.A., O'Reilly, G., Kelly, B.D. & Curristan, S.
(2016). Dual-process cognitive interventions to enhance diagnostic
reasoning: A systematic review. BMJ Quality & Safety, 25, 808--820.
Lambon Ralph, M.A. (2014). Neurocognitive insights on conceptual
knowledge and its breakdown. Philosophical Transactions of the Royal
Society B, 369 (Article no. 20120392). Lambon Ralph, M.A., Jefferies,
E., Patterson, K. & Rogers, T.T. (2017). The neural and computational
bases of semantic cognition. Nature Reviews Neuroscience, 18, 42--55.
Lambon Ralph, M.A., Patterson, K. & Plaut, D.C. (2011). Finite case
series or infinite single-case studies?

870

References

Comments on "Case series investigations in cognitive neuropsychology" by
Schwartz and Dell (2010). Cognitive Neuropsychology, 28, 466--474.
Lamme, V.A.F. (2006). Towards a true neural stance on consciousness.
Trends in Cognitive Sciences, 10, 494--501. Lamme, V.A.F. (2010). How
neuroscience will change our view on consciousness. Cognitive
Neuroscience, 1, 204--240. Lamme, V.A.F. (2018). Challenges for theories
of consciousness: Seeing or knowing, the missing ingredient and how to
deal with panpsychism. Philosophical Transactions of the Royal Society
B, 373 (Article no. 2017.0344). Lamy, D., Salti, M. & Bar-Haim, Y.
(2009). Neural correlates of subjective awareness and unconscious
processing: An ERP study. Journal of Cognitive Neuroscience, 21,
1435--1446. Land, E.H. (1986). Recent advances in retinex theory. Vision
Research, 26, 7--21. Land, M. (2009). Lee's tau operator. Perception,
38, 853--854. Land, M.F. & Lee, D.N. (1994). Where we look when we
steer. Nature, 369, 742--744. Landin-Romero, R., Tan, R., Hodges, J.R. &
Kufor, F. (2016). An update on semantic dementia: Genetics, imaging, and
pathology. Alzheimer's Research & Therapy, 8, 1--9. Landy, M.S., Banks,
M.S. & Knill, D.C. (2011). Ideal-observer models of cue utilisation. In
J. Trommershäuser, J. Körding & M.S. Landy (eds), Sensory Cue
Integration (pp. 5--29). Oxford: Oxford University Press. Langenburg,
G., Champod, C. & Wertheim, P. (2009). Testing for potential contextual
bias during the verification stage of the ACE-V methodology when
conducting fingerprint comparisons. Journal of Forensic Sciences, 54,
571--582. Langer, M.S. & Siciliano, R.A. (2015). Are blur and disparity
complementary cues to depth? Vision Research, 107, 15--21. Langille, D.,
Asbridge, M., Kisely, S. & Wilson, K. (2012). Risk of depression and
multiple sexual risk-taking behaviours in adolescents in Nova Scotia,
Canada. Sex Health, 9, 254--260. Lappi, O. & Mole, C.D. (2018).
Visuo-motor control, eye movements, and steering: A unified approach for
incorporating feedback, feedforward, and internal models. Psychological
Bulletin, 144, 981--1001. Lappi, O., Pekkanen, J. & Itkonen, T.H.
(2013). Pursuit eye-movements in curve driving differentiate between
future path and tangent point models. PloS ONE, 8 (Article no. e68326).
Lappi, O., Rinkkala, P. & Pekkanen, J. (2017). Systematic observation of
an expert driver's gaze strategy -- An on-road case study. Frontiers in
Psychology, 8 (Article no. 620). Lasaponara, S., D'Onofrio, M., Pinto,
M., Dragone, A., Menicagli, D., Bueti, D., et al. (2018). EEG correlates
of

preparatory orienting, contextual updating, and inhibition of sensory
processing in left spatial neglect. Journal of Neuroscience, 38,
3792--3808. Latorella, K.A. (1998). Effects of modality on interrupted
flight deck performance: Implications for data link. Proceedings of the
Human Factors and Ergonomics Society 42nd Annual Meeting, Vols. 1 and 2,
87--91. Chicago, IL. Lau, J.Y.F. (2015). Commentary: A glass half full
or half empty? Cognitive bias modification for mental health problems in
children and adolescents -- Reflections on the meta-analysis by Cristea
et al. (2015). Journal of Child Psychology and Psychiatry, 56, 735--737.
Laukkonen, R.E. & Tangen, J.M. (2018). How to detect insight moments in
problem solving experiments. Frontiers in Psychology, 9 (Article no.
282). Launder, D. & Perry, C. (2014). A study identifying factors
influencing decision making in dynamic emergencies like urban fire and
rescue settings. International Journal of Emergency Services, 3,
144--161. Lavie, N. (2005). Distracted and confused? Selective attention
under load. Trends in Cognitive Sciences, 9, 75--82. Lavie, N. (2010).
Attention, distraction, and cognitive control under load. Current
Directions in Psychological Science, 19, 143--148. Lawrence, A., Thomas,
R.P. & Dougherty, M.R. (2018). Integrating fast and frugal heuristics
with a model of memory-based cue generation. Journal of Behavioral
Decision Making, 31, 487--507. Lawson, R.R., Gayle, J.O. & Wheaton, L.A.
(2017). Novel behavioural indicator of explicit awareness reveals
temporal course of fronto-parietal neural network facilitation during
motor learning. PLoS ONE, 12 (Article no. e0175176). Le, X.,
Lancvashire, I., Hirst, G. & Jokel, R. (2011). Longitudinal detection of
dementia through lexical and syntactic changes in writing: A case study
of three British novelists. Literary and Linguistic Computing, 26,
435--461. Leach, F.R. & Plaks, J.E. (2009). Regret for errors of
commission in the distant term versus near term: The role of level of
abstraction. Personality and Social Psychology Bulletin, 35, 221--229.
Leding, J.K. & Toglia, M.P. (2018). Adaptive memory: Survival processing
and social isolation. Evolutionary Psychology, 16, 1--9. Lee, C.Y.,
Tsai, J.-L., Su, E.C.-I., Tzeng, O.J.L. & Hung, D. (2005). Consistency,
regularity, and frequency effects in naming Chinese characters. Language
and Linguistics, 6, 75--107. Lee, D.N. (1976). A theory of visual
control of braking based on information about time-to-collision.
Perception, 5, 1497--1501. Lee, D.N. (2009). General tau theory:
Evolution to date. Perception, 38, 837--850.

References Lee, E.K., Brown-Schmidt, S. & Watson, D.G. (2013). Ways of
looking ahead: Hierarchical planning in language production. Cognition,
129, 544--562. Lee, H., Heller, A.S., van Reekum, C.M., Nelson, B. &
Davidson, R.J. (2012a). Amygdala-prefrontal coupling underlies
individual differences in emotion regulation. NeuroImage, 62,
1575--1581. Lee, J.-S., Mathews, A., Shergill, S., Chan, D.K.Y., Majeed,
N. & Yiend, J. (2015). How can we enhanced cognitive bias modification
techniques? The effects of prospective cognition. Journal of Behavior
Therapy and Experimental Psychiatry, 49, 120--127. Lee, P. (1996). The
Whorf Theory Complex: A critical reconstruction. New York: John
Benjamins. Lee, R.J., Dawson, K.A. & Smithson, H.E. (2012b). Slow
updating of the achromatic point after a change in illumination. Journal
of Vision, 12, 1--22. Lee, W.E., Wadsworth, M.E.J. & Hotopf, M. (2006).
The protective role of trait anxiety: A longitudinal cohort study.
Psychological Medicine, 36, 345--351. Légal, J.-B., Chekroun, P.,
Coiffard, V. & Gabarrot, F. (2017). Beware of the gorilla: Effect of
goal priming on inattentional blindness. Consciousness and Cognition,
55, 165--171. Lehar, S. (2008). The constructive aspect of visual
perception: A Gestalt field theory principle of visual reification
suggests a phase conjugate mirror principle of perceptual computation.
Retrieved from http://cns-alumni.bu. edu/-
slehar/ConstructiveAspect/ConstructiveAspect. html. Lehle, C. & Hübner,
R. (2009). Strategic capacity sharing between two tasks: Evidence from
tasks with the same and with different task sets. Psychological
Research, 73, 707--726. Lehle, C., Steinhauser, M. & Hübner, R. (2009).
Serial or parallel processing in dual tasks: What is more effortful?
Psychophysiology, 46, 502--509. Leinenger, M. (2014). Phonological
coding during reading. Psychological Bulletin, 140, 1534--1555. Lench,
H.C. & Darbor, K.E. (2014). Negative affective reactions reduce
perceived likelihood of risk. Motivation and Emotion, 38, 569--577.
Lench, H.C. & Levine, L.J. (2005). Effects of fear on risk and control
judgments and memory: Implications for health promotion messages.
Cognition and Emotion, 19, 1049--1069. Lench, H.C., Flores, S.A. &
Bench, S.W. (2011). Discrete emotions predict changes in cognition,
judgment, experience, behaviour, and physiology: A meta-analysis of
experimental emotion elicitations. Psychological Bulletin, 137,
834--855. Lenton, A.P. & Francesconi, M. (2010). How humans cognitively
manage an abundance of mate options. Psychological Science, 21,
528--533.

871

Lenton, A.P. & Stewart, A. (2008). Changing her ways: The number of
options and mate-standard strength impact mate choice strategy and
satisfaction. Judgment and Decision Making Journal, 3, 501--511.
Lenton-Brym, A., Kurczek, J., Rosenbaum, R.S. & Sheldon, S. (2017). A
new method for assessing the impact of medial temporal lobe amnesia on
the characteristics of generated autobiographical events.
Neuropsychologia, 85, 35--43. Leonard, C.J., Balestreri, A. & Luck, S.J.
(2015). Interactions between space-based and feature-based attention.
Journal of Experimental Psychology: Human Perception and Performance,
41, 11--16. Leonard, M.K., Baud, M.O., Sjerps, M.J. & Chang, E.F.
(2016). Perceptual restoration of masked speech in human cortex. Nature
Communications, 7 (Article no. 13619). Leopold, D.A. (2012). Primary
visual cortex: Awareness and blindsight. Annual Review of Neuroscience,
35, 91--109. LePort, A.K.R., Mattfield, A.T., Dickinson-Anson, H.,
Fallon, J.H., Stark, C.E.L., Kruggel, F., et al. (2012). Behavioural and
neuroanatomical investigation of highly superior autobiographical
memory. Neurobiology of Learning and Memory, 98, 78--92. LePort, A.K.R.,
Stark, S.M., McGaugh, J.L. & Stark, C.E.L. (2016). Highly superior
autobiographical memory: Quality and quantity of retention over time.
Frontiers in Psychology, 6 (Article no. 2017). Lerner, J.S. & Keltner,
D. (2000). Beyond valence: Toward a model of emotion-specific influences
on judgment and choice. Cognition and Emotion, 14, 473--493. Lerner,
J.S. & Keltner, D. (2001). Fear, anger, and risk. Journal of Personality
and Social Psychology, 81, 146--159. Lerner, J.S. & Tiedens, L.Z.
(2006). Portrait of the angry decision maker: How appraisal tendencies
shape anger's influence on cognition. Journal of Behavioral Decision
Making, 19, 115--137. Lerner, J.S., Gonzalez, R.M., Small, D.A. &
Fischhoff, B. (2003). Effects of fear and anger on perceived risks of
terrorism: A national field experiment. Psychological Science, 14,
144--150. Lerner, J.S., Li, Y. & Weber, E.U. (2013). The financial costs
of sadness. Psychological Science, 24, 72--79. Lerner, J.S., Valdesolo,
P. & Kassam, K.S. (2015). Emotion and decision making. Annual Review of
Psychology, 66, 799--823. Lev-Ari, S. (2014). Comprehending non-native
speakers: Theory and evidence for adjustment in manner of processing.
Frontiers in Psychology, 5 (Article no. 1546). Levelt, W.J.M. (1983).
Monitoring and self-repair in speech. Cognition, 14, 41--104. Levelt,
W.J.M., Roelofs, A. & Meyer, A.S. (1999). A theory of lexical access in
speech production. Behavioral and Brain Sciences, 22, 1--38.

872

References

Levin, D.T., Drivdahl, S.B., Momen, N. & Beck, M.R. (2002). False
predictions about the detectability of visual changes: The role of
beliefs about attention, memory, and the continuity of attended objects
in causing change blindness blindness. Consciousness & Cognition, 11,
507--527. Levin, I.P. & Gaeth, G.J. (1988). How consumers are affected
by the framing of attribute information before and after consuming the
product. Journal of Consumer Research, 15, 374--378. Levine, D.N.,
Calvanio, R. & Popovics, A. (1982). Language in the absence of inner
speech. Word, 15, 19--44. Levine, L.J. & Edelstein, R.S. (2009). Emotion
and memory narrowing: A review and goal-relevance approach. Cognition &
Emotion, 23, 833--875. Levis, J. & Barriuso, T.A. (2011). Non-native
speakers' pronunciation errors in spoken and read English. Proceedings
of Pronunciation in Second Language Learning and Teaching, 3, 187--194.
Leviston, Z., Walker, I. & Morwinski, S. (2013). Your opinion on climate
change might not be as common as you think. Nature Climate Change, 3,
334--337. Lewis, P.A., Critchley, H.D., Smith, A.P. & Dolan, R.J.
(2005). Brain mechanisms for mood congruent memory facilitation.
NeuroImage, 25, 1214--1223. Levy, C.M. & Ransdell, S. (1995). Is writing
as difficult as it seems? Memory & Cognition, 23, 767--779. Levy, D.A.,
Stark, C.E.L. & Squire, L.R. (2004). Intact conceptual priming in the
absence of declarative memory. Psychological Science, 17, 228--235. Li,
O., Jackson, T. & Chen, H. (2011). Attentional and memory biases among
weight dissatisfied young women: Evidence from a dichotic listening
paradigm. Cognitive Therapy and Research, 35, 9312--9314. Li, P.,
Dunham, Y. & Carey, S. (2009). Of substance: The nature of language
effects on entity construal. Cognitive Psychology, 58, 487--524.
Liberman, A.M., Cooper, F.S., Shankweiler, D.S. & StuddertKennedy, M.
(1967). Perception of the speech code. Psychological Review, 74,
431--461. Libet, B., Gleason, C.A., Wright, E.W. & Pearl, D.K. (1983).
Time of conscious intention to act in relation to onset of cerebral
activity (readiness potential): The unconscious initiation of a freely
voluntary act. Brain, 106, 623--642. Lichtenstein, S., Slovic, P.,
Fischhoff, B., Layman, M. & Coombs, J. (1978). Judged frequency of
lethal events. Journal of Experimental Psychology: Human Learning and
Memory, 4, 551--578. Liden, C., Krüger, O., Schwarz, L., Erb, M.,
Karatzki, B., Scheffler, K., et al. (2016). Neurobiology of knowledge
and misperception of lyrics. NeuroImage, 134, 12--21. Liebenthal, E. &
Möttönen, R. (2018). An interactive model of auditory-motor speech
perception. Brain and Language, 187, 33--40.

Lieberman, P. (1963). Some effects of semantic and grammatical context
on the production and perception of speech. Language & Speech, 6,
172--187. Lief, H. & Fetkewicz, J. (1995). Retractors of false memories:
The evolution of pseudo-memories. Journal of Psychiatry & Law, 23,
411--436. Lieto, A., Lebiere, C. & Oltramari, A. (2018). The knowledge
level in cognitive architectures: Current limitations and possible
developments. Cognitive Systems Research, 48, 39--55. Limpo, T. & Alves,
R.A. (2018). Effects of planning strategies on writing dynamics and
final texts. Acta Psychologica, 188, 97--109. Lin, S., Keysar, B. &
Epley, N. (2010). Reflexively mindblind: Using theory of mind to
interpret behaviour requires effortful attention. Journal of
Experimental Social Psychology, 46, 551--556. Lindholm, T. &
Christianson, S.A. (1998). Intergroup biases and eyewitness testimony.
Journal of Social Psychology, 138, 710--723. Lindquist, K.A., Gendron,
M., Barrett, L.F. & Dickerson, B.C. (2014). Emotion perception, but not
affect perception, is impaired with semantic memory loss. Emotion, 14,
375--387. Lindquist, K.A., Satpute, A.B., Wager, T.D., Weber, J. &
Barrett, L.F. (2016). The brain basis of positive and negative affect:
Evidence from a meta-analysis of the human neuroimaging literature.
Cerebral Cortex, 26, 1910--1922. Lindquist, K.A., Wager, T.D., Kober,
H., Bliss-Moreau, E. & Barrett, L.F. (2012). The brain basis of emotion:
A meta-analytic review. Behavioral and Brain Sciences, 35, 121--143.
Lindsay, D.S., Allen, B.P., Chan, J.C.K. & Dahl, L.C. (2004). Eyewitness
suggestibility and source similarity: Intrusions of details from one
event into memory reports of another event. Journal of Memory and
Language, 50, 96--111. Lingnau, A. & Petris, S. (2013). Action
understanding within and outside the motor system: The role of task
difficulty. Cerebral Cortex, 23, 1342--1350. Linhares, A., Freitas,
A.E.T.A., Mendes, A. & Silva, J.S. (2012). Entanglement of perception
and reasoning in the combinatorial game of chess: Differential errors of
strategic reconstruction. Cognitive Systems Research, 13, 72--86.
Linkovski, O., Kalanthroff, E., Henik, A. & Anholt, G. (2013). Did I
turn off the stove? Good inhibitory control can protect from influences
of repeated checking. Journal of Behavior Therapy and Experimental
Psychiatry, 44, 30--36. Linnell, K.J. & Caparos, S. (2011). Perceptual
and cognitive load interact to control the spatial focus of attention.
Journal of Experimental Psychology: Human Perception and Performance,
37, 1643--1648.

References List, A. & Robertson, L.C. (2007). Inhibition of return and
object-based attentional selection. Journal of Experimental Psychology:
HumanPerception and Performance, 33, 1322--1334. Litvak, P.M., Lerner,
J.S., Tiedens, L.Z. & Shonk, K. (2010). Fuel in the fire: How anger
impacts judgement and decision-making. In M. Potegal, G. Stemmler & C.
Spielberger (eds), International Handbook of Anger: Constituent and
concomitant biological, psychological, and social processes
(pp. 287--310). New York: Springer. Liu, H.N., Li, X.W., Han, B.X. &
Liu, X.Q. (2017). Effects of cognitive bias modification on social
anxiety: A meta-analysis. PLoS ONE, 12 (Article no. e0175107). Liu, S.
(2014). Formulaic language: An analytical review. International Journal
of Linguistics and Communication, 2, 1--11. Livingstone, M.S. (2000). Is
it warm? Is it real? Or just low spatial frequency? Science, 290, 1299.
Loft, S. & Remington, R.W. (2010). Prospective memory and task
interference in a continuous monitoring dynamic display task. Journal of
Experimental Psychology: Applied, 16, 145--157. Loft, S., Chapman, M. &
Smith, R.E. (2016). Reducing prospective memory error and costs in
simulated air traffic control: External aids, extending practice, and
removing perceived memory requirements. Journal of Experimental
Psychology: Applied, 22, 272--284. Loft, S., Smith, R.E. & Remington,
R.W. (2013). Minimising the disruptive effects of prospective memory in
simulated air traffic control. Journal of Experimental Psychology:
Applied, 19, 254--265. Loftus, E.F. (1979). Eyewitness Testimony.
Cambridge, MA: Harvard University Press. Loftus, E.F. (1992). When a lie
becomes memory's truth: Memory distortion after exposure to
misinformation. Current Directions in Psychological Science, 13,
145--147. Loftus, E.F. & Davis, D. (2006). Recovered memories. Annual
Review of Clinical Psychology, 2, 469--498. Loftus, E.F. & Palmer, J.C.
(1974). Reconstruction of automobile destruction: An example of the
interaction between language and memory. Journal of Verbal Learning and
Verbal Behavior, 13, 585--589. Loftus, E.F., Miller, D.G. & Burns, H.J.
(1978). Semantic integration of verbal information into a visual memory.
Journal of Experimental Psychology: Human Learning and Memory, 4,
19--31. Logačev, P. & Vasishth, S. (2016). A multiple-channel model of
task-dependent ambiguity resolution in sentence comprehension. Cognitive
Science, 40, 266--298. Logan, G.D. (1988). Toward an instance theory of
automatisation. Psychological Review, 9, 492--527. Logan, G.D. (2018).
Automatic control: How experts act without thinking. Psychological
Review, 125, 453--485.

873

Logan, G.D., Taylor, S.E. & Etherton, J.L. (1999). Attention and
automaticity: Toward a theoretical integration. Psychological Research,
62, 165--181. Logie, R.H. (1995). Visuo-Spatial Working Memory. Hove,
UK: Erlbaum. Logie, R.H. (1999). Working memory. Psychologist, 12,
174--178. Logie, R.H. (2015). Working memory: Beyond Baddeley and Hitch.
In M.W. Eysenck & D. Groome (eds), Cognitive Psychology: Revisiting the
classic studies (pp. 86--104). London: Sage. Logie, R.H. (2016).
Retiring the central executive. Quarterly Journal of Experimental
Psychology, 69, 2093--2109. Long, G.M. & Toppino, T.C. (2004). Enduring
interest in perceptual ambiguity: Alternating views of reversible
figures. Psychological Bulletin, 130, 748--768. Long, M.R., Horton,
W.S., Rohde, H. & Sorace, A. (2018). Individual differences in switching
and inhibition predict perspective-taking across the lifespan.
Cognition, 170, 25--30. Loukusa, S., Mäkinen, L., Kuusikko-Gauffin, S.,
Ebeling, H. & Leinonen, E. (2018). Assessing social-pragmatic
inferencing skills in children with autism spectrum disorder. Journal of
Communication Disorders, 73, 91--105. Lourenço, J.S., Hill, J.H. &
Maylor, E.A. (2015). Too easy? The influence of task demands conveyed
tacitly on prospective memory. Frontiers in Human Neuroscience, 9, 242.
Love, J. & McKoon, G. (2011). Rules of engagement: Incomplete and
complete pronoun resolution. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 37, 874--887. Lovell, P.G., Bloj, M. &
Harris, J.M. (2012). Optimal integration of shading and binocular
disparity for depth perception. Journal of Vision, 12, 1--18. Lovett, A.
& Forbus, K. (2017). Modelling visual problem solving as analogical
reasoning. Psychological Bulletin, 124, 60--90. Lu, H., Tjan, B.S. &
Liu, Z. (2017). Human efficiency in detecting and discriminating
biological motion. Journal of Vision, 17, 1--14. Lu, S.A., Wickens,
C.D., Prinet, J.C., Hutchins, S.D., Sarter, N. & Sebok, A. (2013).
Supporting interruption management and multi-modal interface design:
Three meta-analyses of task performance as a function of interrupting
task modality. Human Factors: The Journal of the Human Factors and
Ergonomics Society, 55, 697--726. Luan, M. & Li, H. (2017). Good enough
-- Compromise between desirability and feasibility: An alternative
perspective on satisficing. Journal of Experimental Social Psychology,
70, 110--116. Luber, B. & Lisanby, S.H. (2014). Enhancement of human
cognitive performance using transcranial magnetic stimulation (TMS).
NeuroImage, 85, 961--970.

874

References

Luchins, A.S. (1942). Mechanisation in problem solving: The effect of
Einstellung. Psychological Monographs, 54 (Article no. 248). Ludwig, K.,
Sterzer, P., Kathmann, N. & Hesselmann, G. (2016). Differential
modulation of visual object processing in dorsal and ventral stream by
stimulus visibility. Cortex, 83, 113--123. Luk, K.K.S., Xiao, W.S. &
Cheung, H. (2012). Cultural effects on perspective taking in
Chinese-English bilinguals. Cognition, 124, 350--355. Luke, S.G. (2018).
Influences on and consequences of parafoveal preview in reading.
Attention, Perception, & Psychophysics, 80, 1675--1682. Luke, S.G. &
Christianson, K. (2016). Limits on lexical prediction during reading.
Cognitive Psychology, 88, 22--60. Lupyan, G. (2016). Not even wrong: The
"It's just X" fallacy. Behavioral and Brain Sciences, 39, 40--41.
Lupyan, G. (2017). Changing what you see by changing what you know: The
role of attention. Frontiers in Psychology, 8 (Article no. 553). Luria,
A.R. (1968). The Mind of a Mnemonist. New York: Basic Books. Lustig, C.,
Konkel, A. & Jacoby, L.L. (2004). Which route to recovery? Controlled
retrieval and accessibility bias in retroactive interference.
Psychological Science, 15, 729--735. Lyn, H., Greenfield, P.M.,
Savage-Rumbaugh, S., GillespieLynch, K. & Hopkins, W.D. (2011). Nonhuman
primates do declare! A comparison of declarative symbol and gesture use
in two children, two bonobos and a chimpanzee. Language & Communication,
31, 63--74. Lyn, H., Russell, J.L., Leevens, D.A., Bard, K.A., Boysen,
S.T., Schaeffer, J.A., et al. (2014). Apes communicate about absent and
displaced objects: Methodology matters. Animal Cognition, 17, 85--94.
McClain, R. & Goldrick, M. (2018). The neurocognitive mechanisms of
speech production. In S.L. ThompsonSchill (ed.), Stevens' Handbook of
Experimental Psychology and Cognitive Neuroscience, Vol. 3: Language and
thought: Developmental and social psychology (4th edn; pp. 319--356).
New York: Wiley. MacDonald, M.C. (2013). How language production shapes
language form and comprehension. Frontiers in Psychology, 4 (Article no.
226). MacDonald, M.C. (2016). Speak, act, remember: The
language-production basis of serial order and maintenance in verbal
memory. Current Directions in Psychological Science, 25, 47--53.
MacDonald, M.C., Just, M.A. & Carpenter, P.A. (1992). Working memory
constraints on the processing of syntactic ambiguity. Cognitive
Psychology, 24, 56--98. MacDonald, M.C., Pearlmutter, N.J. & Seidenberg,
M.S. (1994). The lexical nature of syntactic ambiguity resolution.
Psychological Review, 101, 676--703.

Mace, J.H. (2003). Study-test awareness can enhance priming on an
implicit memory task: Evidence from a wordcompletion task. American
Journal of Psychology, 116, 257--279. Macerollo, A., Bose, S.,
Ricciardi, L., Edwards, M.J. & Kilner, J.M. (2015). Linking differences
in action perception with differences in action execution. Social,
Cognitive and Affective Neuroscience, 10, 1121--1127. MacGregor, J.N.,
Ormerod, T.C. & Chronicle, E.P. (2001). Information processing and
insight: A process model of performance on the nine-dot and related
problems. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 27, 176--201. Mack, A., Erol, M., Clarke, J. & Bert, J.
(2016). No iconic memory without attention. Consciousness and Cognition,
40, 1--8. MacLeod, A.K. (2016). Prospection, well-being and memory.
Memory Studies, 9, 266--274. MacLeod, C. & Clarke, P. (2015). The
attentional bias modification approach to anxiety intervention. Clinical
Psychological Science, 3, 58--78. Macnamara, B.N., Hambrick, D.Z. &
Oswald, F.L. (2014). Deliberate practice and performance in music,
games, sports, education, and professions: A meta-analysis.
Psychological Science, 25, 1608--1618. Macnamara, B.N., Hambrick, D.Z. &
Moreau, D. (2016a). How important is deliberate practice? Perspectives
on Psychological Science, 11, 355--358. Macnamara, B.N., Moreau, D. &
Hambrick, D.Z. (2016b). The relationship between deliberate practice and
performance in sports: A meta-analysis. Perspectives on Psychological
Science, 11, 333--350. McNeil, M.R., Hula, W.D. & Sung, J.E. (2010). The
role of memory and attention in aphasic language performance. In J.
Guendouzi, F. Loncke & M. Williams (eds), The Handbook of
Psycholinguistics and Cognitive Processes: Perspectives in communication
disorders (pp. 567--592). Hove, UK: Psychology Press. Macoir, J. &
Bernier, J. (2002). Is surface dysgraphia tied to semantic impairment?
Evidence from a case of semantic dementia. Brain and Cognition, 48,
452--457. MacPherson, S.E. (2018). Definition: Dual-tasking and
multitasking. Cortex, 106, 313--314. Mãdebach, A., Jescheniak, J.D.,
Schriefers, H. & Oppermann, F. (2011). Ease of processing constrains the
activation flow in the conceptual-lexical system during speech planning.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 37,
649--660. Madore, K.P., Szpunar, K.K., Addis, D.R. & Schacter, D.L.
(2016). Episodic specificity induction impacts activity in a core brain
network during construction of imagined future experiences. Proceedings
of the National Academy of Sciences, 113 (Article no. 38).

References Madore, K.P., Thakral, P.P., Beaty, R.E., Addis, D.R. &
Schacter, D.L. (2019). Neural mechanisms of episodic retrieval support
divergent creative thinking. Cerebral Cortex, 29, 150--166. Madsen, H.B.
& Kim, J.H. (2016). Ontogeny of memory: An update on 40 years of work on
infantile amnesia. Behavioural Brain Research, 298, 4--14. Maffei, C.,
Capasso, R., Cazzolli, G., Colosimo, C., Dell'Acqua, F., Piludu, F., et
al. (2017). Pure word deafness following left temporal damage:
Behavioural and neuroanatomical evidence from a new case. Cortex, 97,
240--254. Magalhães, P. & White, K.G. (2016). The sunk-cost effect
across species: A review of persistence in a course of action due to
prior investment. Journal of the Experimental Analysis of Behavior, 105,
339--361. Magnuson, J.S. & Nusbaum, H.C. (2007). Acoustic differences,
listener expectations, and the perceptual accommodation of talker
variability. Journal of Experimental Psychology: Human Perception and
Performance, 33, 391--409. Maguire, E.A., Nannery, R. & Spiers, H.J.
(2006). Navigation around London by a taxi driver with bilateral
hippocampal lesions. Brain, 129, 2894--2907. Mahowald, K., James, A.,
Futrell, R. & Gibson, E. (2016). A meta-analysis of syntactic priming in
language production. Journal of Memory and Language, 91, 5--27. Maier,
N.R.F. (1931). Reasoning in humans II: The solution of a problem and its
appearance in consciousness. Journal of Comparative Psychology, 12,
181--194. Maiworm, M., Bellantoni, M. & Spence, C. (2012). When
emotional valence modulates audiovisual integration. Attention,
Perception & Psychophysics, 74, 1302--1311. Makovski, T. (2017). The
open-object illusion: Size perception is greatly influenced by object
boundaries. Attention, Perception & Psychophysics, 79, 1282--1289.
Mallow, J., Bernarding, J., Luchtmann, M., Bethmann, A. & Brechmann, A.
(2015). Superior memorisers employ different neural networks for
encoding and recall. Frontiers in Systems Neuroscience, 9 (Article no.
128). Mallpress, D.E.W., Fawcett, T.W., Houston, A.I. & McNamara, J.M.
(2015). Risk attitudes in a changing environment: An evolutionary model
of the fourfold pattern of risk preferences. Psychological Bulletin,
122, 364--375. Mamede, S., Schmidt, H.G., Rikers, R.M.J.P., Custers,
E.J.F.M., Splinter, T.A.W. & van Saase, J.L.C.M. (2010a). Conscious
thought beats deliberation without attention in diagnostic
decision-making: At least when you are an expert. Psychological
Research, 74, 586--592. Mamede, S., van Gog, T., van den Berge, K.,
Rikers, R.M.J.P., van Saase, J.L.C.M., van Guldener, C., et al. (2010b).
Effect of availability bias and reflective reasoning on diagnostic
accuracy among internal medicine

875

residents. Journal of the American Medical Association, 304, 1198--1203.
Manassi, M., Liberman, A., Kosovicheva, A., Zhang, K. & Whitney, D.
(2018). Serial dependence in position occurs at the time of perception.
(2018). Serial dependence in position occurs at the time of perception.
Psychonomic Bulletin & Review, 25, 2245--2253. Mandel, D.R. (2014). Do
framing effects reveal irrational choice? Journal of Experimental
Psychology: General, 143, 1185--1198. Manning, D., Barker-Mill, S.C.,
Donovan, T. & Crawford, T. (2006). Time-dependent observer errors in
pulmonary nodule detection. British Journal of Radiology, 79, 342--346.
Manns, J.R., Hopkins, R.O. & Squire, L.R. (2003). Semantic memory and
the human hippocampus. Neuron, 38, 127--133. Margolin, S.J., Driscoll,
C., Toland, M.J. & Kegler, J.L. (2013). E-readers, computer screens, or
paper: Does reading comprehension change across media platforms? Applied
Cognitive Psychology, 27, 512--519. Marien, H., Custers, R., Hassin,
R.R. & Aarts, H. (2012). Unconscious goal activation and the hijacking
of the executive function. Journal of Personality and Social Psychology,
103, 399--415. Marinelli, L., Quartarone, A., Hallett, M., Frazzitta, G.
& Ghilardi, M.F. (2017). The many facets of motor learning and their
relevance for Parkinson's disease. Clinical Neurophysiology, 128,
1127--1141. Marinsek, N.L. & Gazzaniga, M.S. (2016). A split-brain
perspective on illusionism. Journal of Consciousness Studies, 23,
149--159. Mark, V. (1996). Conflicting communicative behaviour in a
split-brain patient: Support for dual consciousness. In S. Hameroff, A.
Kaszniak & A. Scott (eds), Toward a Science of Consciousness: The first
Tucson discussions and debates (pp. 189--196). Cambridge, MA: MIT Press.
Markovits, H., Brisson, J. & de Chantal, P.-L. (2017). Logical reasoning
versus information processing in the dualstrategy model of reasoning.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 43,
72--80. Markovits, H., Brunet, M.-L., Thompson, V. & Brisson, J. (2013).
Direct evidence for a dual-process model of deductive inference. Journal
of Experimental Psychology: Learning, Memory, and Cognition, 39,
1213--1222. Markowitsch, H.J. & Kessler, J. (2000). Massive impairment
in executive functions with partial preservation of other cognitive
functions: The case of a young patient with severe degeneration of the
prefrontal cortex. Experimental Brain Research, 133, 94--102. Marques,
J.F., Raposo, A. & Almeida, J. (2013). Structural processing and
category-specific deficits. Cortex, 49, 266--275.

876

References

Marques, L.M., Lapenta, O.M., Costa, T.L. & Boggio, P.S. (2016).
Multisensory integration processes underlying speech perception as
revealed by the McGurk illusion. Language, Cognition and Neuroscience,
31, 1115--1129. Marr, D. (1982). Vision: A computational investigation
into the human representation and processing of visual information. San
Francisco: W.H. Freeman. Marrero, H., Gámez, E. & Díaz, J.M. (2016). Do
people reason when they accept tricky offers? A case of approach and
avoidance motivated reasoning. Journal of Economic Psychology, 57,
26--38. Marsh, E.J. & Roediger, H.L. (2012). Episodic and
autobiographical memory. In A.F. Healy & R.W. Proctor (eds), Handbook of
Psychology, Vol. 4: Experimental psychology (2nd edn; pp. 472--494). New
York: Wiley. Marslen-Wilson, W.D. (1987). Functional parallelism in
spoken word-recognition. Cognition, 25, 71--102. Marslen-Wilson, W.D.
(1990). Activation, competition, and frequency in lexical access. In
G.T.M. Altmann (ed.), Cognitive Models of Speech Processing
(pp. 148--172). Cambridge, MA: MIT Press. Marslen-Wilson, W.D. & Tyler,
L.K. (1980). The temporal structure of spoken language comprehension.
Cognition, 6, 1--71. Martin, C.D., Branzi, F.M. & Bar, M. (2018).
Prediction is production: The missing link between language production
and comprehension. Scientific Reports, 8 (Article no. 1079). Martin,
D.H. & Barry, C. (2012). Writing nonsense: The interaction between
lexical and sublexical knowledge in the priming of non-word spelling.
Psychonomic Bulletin & Review, 19, 691--698. Martin, R.C., Miller, M. &
Vu, H. (2004). Lexical-semantic retention and speech production: Further
evidence from normal and brain-damaged participants for a phrasal scope
of planning. Cognitive Neuropsychology, 21, 625--644. Martinez, A.,
Anilo-Vento, L., Sereno, M.I., Frank, L.R., Buxton, R.B., Dubowitz,
D.J., et al. (1999). Involvement of striate and extrastriate visual
cortical areas in spatial attention. Nature Neuroscience, 2, 364--369.
Mashour, G.A. & Hudetz, A.G. (2018). Neural correlates of
unconsciousness in large-scale brain networks. Trends in Neurosciences,
41, 150--160. Mather, G. (2009). Foundations of Sensation and Perception
(2nd edn). Hove, UK: Psychology Press. Mather, G. (2015). Computational
approaches to perception: Beyond Marr's (1982) computational approach to
vision. In M.W. Eysenck & D. Groome (eds), Cognitive Psychology:
Revisiting the classic studies (pp. 38--46). London: Sage. Mather, M.,
Cacioppo, J.T. & Kanwisher, N. (2013). How fMRI can inform cognitive
theories. Perspectives on Psychological Science, 8, 108--113.

Mathews, A. (2012). Effects of modifying the interpretation of emotional
ambiguity. Journal of Cognitive Psychology, 24, 92--105. Mathy, F. &
Feldman, J. (2012). What's magic about magic numbers: Chunking and data
compression in short-term memory. Cognition, 122, 346--362. Mattys, S.L.
(2004). Stress versus co-articulation: Toward an integrated approach to
explicit speech segmentation. Journal of Experimental Psychology: Human
Perception and Performance, 30, 397--408. Mattys, S.L., Brooks, J. &
Cooke, M. (2009). Recognising speech under a processing load:
Dissociating energetic from informational factors. Cognitive Psychology,
59, 203--243. Mattys, S.L., Davis, M.H., Bradlow, A.R. & Scott, S.K.
(2012). Speech recognition in adverse conditions: A review. Language and
Cognitive Processes, 27, 953--978. Mattys, S.L., White, L. & Melhorn,
J.F. (2005). Integration of multiple speech segmentation cues: A
hierarchical framework. Journal of Experimental Psychology: General,
134, 477--500. Maule, A.J. & Hodgkinson, G.P. (2002). Heuristics, biases
and strategic decision making. The Psychologist, 15, 69--71. Mauss,
I.B., Cook, C.L., Cheng, J.Y.J. & Gross, J.J. (2007). Individual
differences in cognitive reappraisal: Experiential and physiological
responses to an anger provocation. International Journal of
Psychophysiology, 66, 116--124. Mayberry, E.J., Sage, K. & Lambon Ralph,
M.A. (2011). At the edge of semantic space: The breakdown of coherent
concepts in semantic dementia is constrained by typicality and severity
but not modality. Journal of Cognitive Neuroscience, 23, 2240--2251.
Mayer, K.M., Vuong, G.C. & Thornton, I.M. (2015). Do people "pop out"?
PLoS ONE, 10 (Article no. e0139618). Mayor, J., Gomez, P., Chang, F. &
Lupyan, G. (2014). Connectionism coming of age: Legacy and future
challenges. Frontiers in Psychology, 5 (Article no. 187). Mazzi, C.,
Bagattini, C. & Savazzi, S. (2016). Blind-sight vs. degraded-sight:
Different measures tell a different story. Frontiers in Psychology, 7
(Article no. 901). McBride, P.M. & Workman, R.A. (2017). Is prospective
memory unique? A comparison of prospective and retrospective memory.
Psychology of Learning and Motivation, 67, 213--238. McCabe, D.P.,
Roediger, H.L., McDaniel, M.A., Balota, D.A. & Hambrick, D.Z. (2010).
The relationship between working memory capacity and executive
functioning: Evidence for a common executive attention construct.
Neuropsychology, 24, 222--243. McCaffrey, T. (2012). Innovation relies
on the obscure: A key to overcoming the classic problem of functional
fixedness. Psychological Science, 23, 215--218.

References McCarthy, R. & Warrington, E.K. (1984). A two-route model of
speech production. Brain, 107, 463--485. McClelland, J.L. (1979). On the
time relations of mental processes: An examination of systems of
processes in cascade. Psychological Review, 86, 287--330. McClelland,
J.L. & Elman, J.L. (1986). The TRACE model of speech perception.
Cognitive Psychology, 18, 1--86. McClelland, J.L. & Rumelhart, D.E.
(1981). An interactive activation model of context effects in letter
perception. Part 1. An account of basic findings. Psychological Review,
88, 375--407. McClelland, J.L., Mirman, D., Bolger, D.J. & Khaitan, P.
(2014). Interactive activation and mutual constraint satisfaction in
perception and cognition. Cognitive Science, 38, 1139--1189. McClelland,
J.L., Rumelhart, D.E. & The PDP Research Group (1986). Parallel
Distributed Processing: Vol. 2. Psychological and biological models.
Cambridge, MA: MIT Press. McCormick, C., Claramelli, E., de Luca, F. &
Maguire, E.A. (2018). Comparing and contrasting the cognitive effects of
hippocampal and ventromedial prefrontal cortex damage: A review of human
lesion studies. Neuroscience, 374, 295--318. McCright, A.M.,
Marquart-Pyatt, S.T., Shwom, R.L., Brechin, S.R. & Allen, S. (2016).
Ideology, capitalism, and climate: Explaining public views about climate
change in the United States. Energy Research & Social Science, 21,
180--189. McCrudden, M.T., Barnes, A., McTigue, E.M., Welch, C. &
MacDonald, E. (2017). The effect of perspective-taking on reasoning
about strong and weak belief-relevant arguments. Thinking & Reasoning,
23, 115--133. McDaniel, M.A., LaMontagne, P., Beck, S.M., Scullin, M.K.
& Braver, T.S. (2013). Dissociable neural routes to successful
prospective memory. Psychological Science, 24, 1791--1800. McDaniel,
M.A., Umanath, S., Einstein, G.O. & Waldum, E.R. (2015). Dual pathways
to prospective remembering. Frontiers in Human Neuroscience, 3 (Article
no. 392). McDermott, J.H. (2009). The cocktail party problem. Current
Biology, 19, R1024--R1027. McDermott, R., Fowler, J.H. & Smirnov, O.
(2008). On the evolutionary origin of prospect theory preferences. The
Journal of Politics, 70, 335--350. McDonald, J.L. (2008). Differences in
the cognitive demands of word order, plural, and subject-verb agreement
constructions. Psychonomic Bulletin & Review, 15, 980--984. McDowell, M.
& Jacobs, P. (2017). Meta-analysis of the effect of natural frequencies
on Bayesian reasoning. Psychological Review, 143, 1273--1312.
McEachrane, M. (2009). Emotion, meaning, and appraisal theory. Theory &
Psychology, 19, 33--53.

877

McFall, T.A. (2016). Loss aversion on the links: Penalised pro golfers
fall prey to decision bias. International Journal of Applied Behavioral
Economics, 5, 24--40. McGlone, M.S. & Manfredi, D.A. (2001).
Topic-vehicle interaction in metaphor comprehension. Memory & Cognition,
29, 1209--1219. McGregor, S.J. & Howes, A. (2002). The role of attack
and defence semantics in skilled players' memory for chess positions.
Memory & Cognition, 29, 1209--1219. McGugin, R.W., van Gulick, A.E.,
Tamber-Rosenau, B.J., Ross, D.A. & Gauthier, I. (2015). Expertise
effects in face-selective areas are robust to clutter and diverted
attention but not to competition. Cerebral Cortex, 25, 2610--2622.
McGugin, R.W., Newton, A.T., Gore, J.C. & Gauthier, I. (2014). Robust
expertise effects in right FFA. Neuropsychologia, 63, 135--144. McGugin,
R.W., Ryan, K.F., Tamber-Rosenau, B.J. & Gautheir, I. (2018). The role
of experience in the faceselective response in right FFA. Cerebral
Cortex, 28, 2071--2084. McGurk, H. & MacDonald, J. (1976). Hearing lips
and seeing voices. Nature, 264, 746--748. McKeeff, T.J., McGugin, R.W.,
Tong, F. & Gauthier, I. (2010). Expertise increases the functional
overlap between face and object perception. Cognition, 117, 335--360.
McKeefry, D.J., Burton, M.P., Vakrou, C., Barrett, B.T. & Morland, A.B.
(2008). Induced deficits in speed perception by transcranial magnetic
stimulation of human cortical areas V5/MT and V3A. Journal of
Neuroscience, 28, 6848--6857. McKone, E., Kanwisher, N. & Duchaine, B.C.
(2007). Can generic expertise explain special processing for faces?
Trends in Cognitive Sciences, 11, 8--15. McKoon, G. & Ratcliff, R.
(1992). Inference during reading. Psychological Review, 99, 440--466.
McKoon, G. & Ratcliff, R. (2017). Adults with poor reading skills and
the inferences they make during reading. Scientific Studies of Reading,
21, 292--309. McLaughlin, K., Remy, M. & Schmidt, H.G. (2008). Is
analytic information processing a feature of expertise in medicine?
Advances in Health Sciences Education, 13, 123--128. McLeod, P. (1977).
A dual-task response modality effect: Support for multiprocessor models
of attention. Quarterly Journal of Experimental Psychology, 29,
651--667. McNally, R.J. & Geraerts, E. (2009). A new solution to the
recovered memory debate. Perspectives on Psychological Science, 4,
126--134. McNamara, D.S. & Magliano, J. (2009). Toward a comprehensive
model of comprehension. In B. Ross (ed.), The Psychology of Learning and
Motivation, Vol. 51 (pp. 297--384). Burlington, MA: Academic Press.

878

References

McNerney, M.W., Goodwin, K.A. & Radvansky, G.A. (2011). A novel study: A
situation model analysis of reading times. Discourse Processes, 48,
453--474. McQueen, J.M. & Huettig, F. (2012). Changing only the
probability that spoken words will be distorted changes how they are
recognised. Journal of the Acoustical Society of America, 131, 509--517.
McQueen, J.M. (1991). The influence of the lexicon on phonetic
categorisation: Stimulus quality in word-final ambiguity. Journal of
Experimental Psychology: Human Perception & Performance, 17, 433--443.
McRae, K., Jacobs, S.E., Ray, R.D., John, O.P. & Gross, J.J. (2012).
Individual differences in reappraisal ability: Links to reappraisal
frequency, well-being, and cognitive control. Journal of Research in
Personality, 46, 2--7. McVay, J.C. & Kane, M.J. (2012). Drifting from
low to "D'oh!": Working memory capacity and mind wandering predict
extreme reaction times and executive control errors. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 38, 525--549.
Meador, K.J., Loring, D.W., Lee, G.P., Nichols, M.E., Moore, E.E. &
Figueroa, R.E. (1997). Level of consciousness and memory during the
intracarotid sodium amobarbital procedure. Brain and Cognition, 33,
178--188. Medimorec, S. & Risko, E.F. (2017). Pauses in written
composition: On the importance of where writers pause. Reading and
Writing, 30, 1267--1285. Meehan, T.P., Bressler, S.L., Tang, W.,
Astafiev, S.V., Sylvester, C.M., Shulman, G.L., et al. (2017). Top-down
cortical interactions in visuo-spatial attention. Brain Structure and
Function, 222, 3127--3145. Megreya, A.M., Sandford, A. & Burton, A.M.
(2013). Matching face images taken on the same day or months apart: The
limitations of photo ID. Applied Cognitive Psychology, 27, 700--706.
Meiser, T. (2011). Much pain, little gain? Paradigm-specific models and
methods in experimental psychology. Perspectives on Psychological
Science, 6, 183--191. Melby-Lervåg, A., Lyster, S.-A.H. & Hulme, C.
(2012). Phonological skills and their role in learning to read: A
meta-analytic review. Psychological Bulletin, 138, 322--352. Melinger,
A., Branigan, H.P. & Pickering, M.J. (2014). Parallel processing in
language production. Language, Cognition and Neuroscience, 29, 663--683.
Melloni, L., Molina, C., Pena, M., Torres, D., Singer, W. & Rodriguez,
E. (2007). Synchronisation of neural activity across cortical areas
correlates with conscious perception. Journal of Neuroscience, 27,
2858--2865. Melloni, L., Schwiedrzik, C.M., Muller, N., Rodriguez, E. &
Singer, W. (2011). Expectations change the signatures and timing of
electrophysiological correlates of perceptual awareness. Journal of
Neuroscience, 31, 1386--1396.

Melnikoff, D.E. & Bargh, J.A. (2018). The mythical number two. Trends in
Cognitive Sciences, 22, 280--293. Melo, M., Scarpin, D.J., Amaro, E.,
Passos, R.B.D., Sato, J.R., Friston, K.J., et al. (2012). How doctors
generate diagnostic hypotheses: A study of radiological diagnosis with
functional magnetic resonance imaging. PLoS ONE, 6 (Article no. e28752).
Mély, D.A., Kim, J., McGill, M., Guo, Y. & Serre, T. (2016). A
systematic comparison between visual cues for boundary detection. Vision
Research, 120, 93--107. Memon, A., Meissner, C.A. & Fraser, J. (2010).
The cognitive interview: A meta-analytic review and study space analysis
of the past 25 years. Psychology, Public Policy and Law, 16, 340--372.
Menneer, T., Cave, K.R. & Donnelly, N. (2009). The cost of search for
multiple targets: Effects of practice and target similarity. Journal of
Experimental Psychology: Applied, 15, 125--139. Mennin, D.S., Fresco,
D.M., Ritter, M. & Heimberg, R.G. (2015). An open trial of emotion
regulation therapy for generalised anxiety disorder and co-occurring
depression. Depression and Anxiety, 32, 614--623. Mercier, H. (2016).
The argumentative theory: Predictions and empirical evidence. Trends in
Cognitive Sciences, 20, 689--700. Mercier, H. (2018). A related
proposal: An interactionist perspective on reason. Behavioral and Brain
Sciences, 41 (Article no. e53). Mercier, H., Boudry, M., Paglieri, F. &
Trouche, E. (2017). Natural-born arguers: Teaching how to make the best
of our reasoning abilities. Educational Psychologist, 52, 1--16.
Mesgarani, N. & Chang, E.F. (2012). Selective cortical representation of
attended speaker in multi-talker speech perception. Nature, 485,
233--237. Messina, I., Sambin, M., Beschoner, P. & Viviani, R. (2016).
Changing views of emotion regulation and neurobiological models of the
mechanism of action of psychotherapy. Cognitive, Affective and
Behavioral Neuroscience, 16, 571--587. Mesulam, M.M., Wieneke, C.,
Hurley, R., Rademaker, A., Thompson, C.K., Weintraub, S., et al. (2013).
Words and objects at the tip of the left temporal lobe in primary
progressive aphasia. Brain, 136, 601--618. Metcalfe, J. & Wiebe, D.
(1987). Intuition in insight and noninsight problem solving. Memory &
Cognition, 15, 238--246. Metzner, P., von der Malsberg, T., Vasishth, S.
& Rösler, F. (2017). The importance of reading naturally: Evidence from
combined recordings of eye movements and electric brain potentials.
Cognitive Science, 41, 1232--1263. Meyer, A.S. & Damian, M.F. (2007).
Activation of distractor names in the picture-picture interference
paradigm. Memory & Cognition, 35, 494--503.

References Meyer, A.S., Huettig, F. & Levelt, W.J.M. (2016). Same,
different, or closely related: What is the relationship between language
production and comprehension? Journal of Memory and Language, 89, 1--7.
Meyer, D.E. & Schvaneveldt, R.W. (1971). Facilitation in recognising
pairs of words: Evidence of a dependence between retrieval operations.
Journal of Experimental Psychology, 90, 227--234. Meyer, K.N., Du, F.,
Parks, E. & Hopfinger, J.B. (2018). Exogenous vs. endogenous attention:
Shifting the balance of fronto-parietal activity. Neuropsychologia, 111,
307--316. Mickes, L., Searle-Carlisle, T.M. & Wixted, J.T. (2013).
Rethinking familiarity: Remember/know judgments in free recall. Journal
of Memory and Language, 68, 333--349. Migo, E.M., Mayes, A.R. &
Montaldi, D. (2012). Measuring recollection and familiarity: Improving
the remember/know procedure. Consciousness and Cognition, 21,
1435--1455. Milivojevic, B. (2012). Object recognition can be viewpoint
dependent or invariant -- It's just a matter of time and task. Frontiers
in Computational Neuroscience, 6 (Article no. 27). Milivojevic, B.,
Hamm, J.P. & Corballis, M.C. (2011). About turn: How object orientation
affects categorisation and mental rotation. Neuropsychologia, 49,
3758--3767. Milkowski, M. (2016). Explanatory completeness and
idealisation in large brain simulations: A mechanistic perspective.
Synthese, 193, 1457--1478. Miller, G.A. (1956). The magic number seven,
plus or minus two: Some limits on our capacity for processing
information. Psychological Review, 63, 81--93. Miller, J., Brookie, K.,
Wales, S., Kaup., B. & Wallace, S. (2018). Embodied cognition: Is
activation of the motor cortex essential for understanding action verbs?
Journal of Experimental Psychology: Learning, Memory, and Cognition, 44,
335--370. Miller, J., Ulrich, R. & Rolke, B. (2009). On the optimality
of serial and parallel processing in the psychological refractory period
paradigm: Effects of the distribution of stimulus onset asymmetries.
Cognitive Psychology, 58, 273--310. Milner, A.D. (2012). Is visual
processing in the dorsal stream accessible to consciousness? Proceedings
of the Royal Society B, 279, 2289--2298. Milner, A.D. (2017). How do the
two visual streams interact with each other? Experimental Brain
Research, 235, 1297--1308. Milner, A.D. & Goodale, M.A. (1995). The
Visual Brain in Action. Oxford: Oxford University Press. Milner, A.D. &
Goodale, M.A. (2008). Two visual systems re-viewed. Neuropsychologia,
46, 774--785. Minervino, R.A., Olguín, V. & Trench, M. (2017). Promoting
interdomain analogical transfer: When creating a

879

problem helps to solve a problem. Memory & Cognition, 45, 221--232.
Miozzo, M., Shuster, V.P. & Fischer-Baum, S. (2018). How
modality-specific is morphology? Cognitive Neuropsychology, 35,
371--384. Mirković, J. & MacDonald, M.C. (2013). When singular and
plural are both grammatical: Semantic and morphophonological effects in
agreement. Journal of Memory and Language, 69, 277--298. Mirman, D.,
Chen, Q., Zhang, Y., Wang, Z., Faseyitan, O.K., Coslett, H.B., et
al. (2015). Neural organisation of spoken language revealed by
lesion-symptoms mapping. Nature Communications, 6 (Article no. 7762).
Mirman, D., Landrigan, J.-F. & Britt, A.E. (2017). Taxonomic and
thematic semantic systems. Psychological Bulletin, 113, 499--520.
Mirman, D., McClelland, L., Holt, L.L. & Magnuson, J.S. (2008). Effects
of attention on the strength of lexical influences on speech perception:
Behavioural experiments and computational mechanisms. Cognitive Science,
32, 398--417. Mischel, W. (2008). The toothbrush problem. APS Observer,
21, 11. Misra, M., Guo, T., Bobb, S.C. & Kroll, J.F. (2012). When
bilinguals choose a single word to speak: Electrophysiological evidence
for inhibition of the native language. Journal of Memory and Language,
67, 224--237. Mitchell, D.B. (2006). Nonconscious priming after 17
years. Psychological Science, 17, 925--929. Mitchell, D.J. & Cusack, R.
(2016). Semantic and emotional content of imagined representations in
human occipito-temporal cortex. Scientific Reports, 6 (Article no.
20232). Mitroff, S.R. & Biggs, A.T. (2014). The ultra-rare-item effect:
Visual search for exceedingly rare items is highly susceptible to error.
Psychological Science, 25, 284--289. Mittelstädt, V. & Miller, J.
(2017). Separating limits on preparation versus online processing in
multitasking paradigms: Evidence for resource models. Journal of
Experimental Psychology: Human Perception and Performance, 43, 89--102.
Mitterer, H. & Mattys, S.L. (2017). How does cognitive load influence
speech perception? An encoding hypothesis. Attention, Perception &
Psychophysics, 79, 344--351. Mitterer, H., Reinisch, E. & McQueen, J.M.
(2018). Allophones, not phonemes in spoken-word recognition. Journal of
Memory and Language, 98, 77--92. Miyake, A. & Friedman, N.P. (2012). The
nature and organisation of individual differences in executive
functions: Four general conclusions. Current Directions in Psychological
Science, 21, 8--14. Miyake, A., Friedman, N.P., Emerson, M.J., Witzki,
A.H., Howerter, A. & Wager, T. (2000). The unity and diversity of
executive functions and their contributions to

880

References

complex "frontal lobe" tasks: A latent variable analysis. Cognitive
Psychology, 41, 49--100. Mohamed, T. & Clifton, C. (2011). Processing
temporary syntactic ambiguity: The effect of contextual bias. Quarterly
Journal of Experimental Psychology, 64, 1797--1820. Moisala, M.,
Salmela, V., Hietajärvi, L., Salo, E., Carlson, S., Salonen, O., et
al. (2016). Media multitasking is associated with distractibility and
increased prefrontal activity in adolescents and young adults.
NeuroImage, 134, 113--121. Mole, C.D., Jersakova, R. & Kountouriotis,
G.K. (2018). Metacognitive judgements of perceptual-motor steering
performance. Quarterly Journal of Experimental Psychology, 71,
2223--2234. Mole, C.D., Kountouriotis, G., Billington, J. & Wilkie, R.M.
(2016). Optic flow speed modulates guidance level control: New insights
into two-level steering. Journal of Experimental Psychology: Human
Perception and Performance, 42, 1818--1838. Molenberghs, P., Sale, M.V.
& Mattingley, J.B. (2012). Is there a critical lesion site for
unilateral spatial neglect? A meta-analysis using activation likelihood
estimation. Frontiers in Human Neuroscience, 6 (Article no. 78). Momma,
S. & Phillips, C. (2018). The relationship between parsing and
generation. Annual Review of Linguistics, 4, 233--254. Monahan, P.J.
(2018). Phonological knowledge and speech comprehension. Annual Review
of Linguistics, 4, 421--447. Monti, M.M., Pickard, J.D. & Owen, A.M.
(2013). Visual cognition in disorders of consciousness: From V1 to
topdown attention. Human Brain Mapping, 34, 1245--1253. Monti, M.M.,
Vanhaudenhuyse, A., Coleman, M.R., Boly, M., Pickard, J.D., Tshibanda,
L., et al. (2010). Wilful modulation of brain activity in disorders of
consciousness. New England Journal of Medicine, 362, 579--589. Moore,
A.T. & Schwitzgebel, E. (2018). The experience of reading. Consciousness
and Cognition, 62, 57--68. Moore, J.W. (2016). What is the sense of
agency and does it matter? Frontiers in Psychology, 7 (Article no.
1272). Moore, R. (2015). A common intentional framework for ape and
human communication. Current Anthropology, 56, 70. Moore-Berg, S.,
Karpinski, A. & Plant, E.A. (2017). Quick to the draw: How suspect race
and socioeconomic status influences shooting decisions. Journal of
Applied Social Psychology, 47, 482--491. Moors, A. (2016). Automaticity:
Componential, causal, and mechanistic explanations. Annual Review of
Psychology, 67, 263--287. Moors, A. & De Houwer, J. (2006).
Automaticity: A theoretical and conceptual analysis. Psychological
Bulletin, 132, 297--326.

Morawetz, C., Holz, P., Bauedwig, J., Treue, S. & Dechent, P. (2007).
Split of attentional resources in human visual cortex. Visual
Neuroscience, 24, 817--826. Morcom, A.M. (2016). Mind over memory: Cuing
the aging brain. Current Directions in Psychological Science, 25,
143--150. Morewedge, C.K. & Kahneman, D. (2010). Associative processes
in intuitive judgement. Trends in Cognitive Sciences, 14, 435--440.
Moray, N. (1959). Attention in dichotic listening: Affective cues and
the influence of instructions. Quarterly Journal of Experimental
Psychology, 11, 56--60. Morey, C.C. (2018). The case against specialised
visualspatial short-term memory. Psychological Bulletin, 144, 849--883.
Morgan, C.A., Southwik, S., Steffian, G., Hazlett, G.A. & Loftus, E.F.
(2013). Misinformation can influence memory for recently experienced,
highly stressful events. International Journal of Law and Psychiatry,
36, 11--17. Morgan, P.H. & Patrick, J. (2013). Paying the price works:
Increasing goal-state access cost improves problem solving and mitigates
the effect of interruption. Quarterly Journal of Experimental
Psychology, 66, 160--178. Moro, V., Berlucchi, G., Lerch, J., Tomaiuolo,
F. & Aglioti, S.M. (2008). Selective deficit of mental visual imagery
with intact primary visual cortex and visual perception. Cortex, 44,
109--118. Morris, C.D., Bransford, J.D. & Franks, J.J. (1977). Levels of
processing versus transfer appropriate processing. Journal of Verbal
Learning and Verbal Behavior, 16, 519--533. Morrison, R.G., Holyoak,
K.J. & Truong, B. (2001). Working-memory modularity in analogical
reasoning. In J.D. Moore & K. Stenning (eds), Proceedings of the
Twenty-third Annual Conference of the Cognitive Science Society
(pp. 663--668). Mahway, NJ: Lawrence Erlbaum Associates. Moscovitch, M.
(2008). Commentary: A perspective on prospective memory. In M. Kliegel,
M.A. McDaniel & G.O. Einstein (eds), Prospective Memory: Cognitive,
neuroscience, developmental, and applied perspectives (pp. 309--320).
New York: Lawrence Erlbaum Associates. Moscovitch, M., Cabeza, R.,
Winocur, G. & Nadel, L. (2016). Episodic memory and beyond: The
hippocampus and neocortex in transformation. Annual Review of
Psychology, 67, 105--134. Moscovitch, M., Winocur, G. & Behrmann, M.
(1997). What is special about face recognition? Nineteen experiments on
a person with visual object agnosia and dyslexia but normal face
recognition. Journal of Cognitive Neuroscience, 9, 555--604. Moser,
J.S., Huppert, J.D., Foa, E.B. & Simons, R.F. (2012). Interpretation of
ambiguous social scenarios in social phobia and depression: Evidence
from event-related brain potentials. Biological Psychology, 89,
387--397.

References Mosing, M.A., Madison, G., Pedersen, N.L., Kuja-Halkola, R. &
Ullén, F. (2014). Practice does not make perfect: No causal effect of
music practice on music ability. Psychological Science, 25, 1795--1803.
Moss, J., Kotovsky, K. & Cagan, J. (2011). The effect of incidental
hints when problems are suspended before, during, or after an impasse.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 37,
140--148. Most, S.B. (2013). Settings sights higher: Category-level
attentional set modulates sustained inattentional blindness.
Psychological Research, 77, 139--146. Motley, M.T. (1980). Verifications
of "Freudian slips" and semantic prearticulatory editing via
laboratory-induced spoonerisms. In V.A. Fromkin (ed.), Errors in
Linguistic Performance: Slips of the tongue, ear, pen, and hand. New
York: Academic Press. Motta, M., Callaghan, T. & Sylvester, S. (2018).
Knowing but presuming more: Dunning-Kruger effects and the endorsement
of anti-vaccine policy attitudes. Social Science & Medicine, 211,
274--281. Mottaghy, F.M. (2006). Interfering with working memory in
humans. Neuroscience, 139, 85--90. Moulton, P.L., Petros, T.V., Apostal,
K.J., Park, R.V., Ronning, E.A., King, B.M., et al. (2005).
Alcoholinduced impairment and enhancement of memory: A test of the
interference theory. Physiology & Behavior, 85, 240--245. Moulton, S.T.
& Kosslyn, S.M. (2009). Imagining predictions: Mental imagery as mental
emulation. Philosophical Transactions of the Royal Society B: Biological
Sciences, 364, 1273--1280. Mousikou, P., Sadat, J., Lucas, R. & Rastle,
K. (2017). Moving beyond the monosyllable in models of skilled reading:
Mega-study of disyllabic non-word reading. Journal of Memory and
Language, 93, 169--192. Moxley, J.H., Ericsson, K.A., Charness, N. &
Krampe, R.T. (2012). The role of intuition and deliberative thinking in
experts' superior tactical decision-making. Cognition, 124, 72--78.
Moyes, J., Sari-Sarraf, N. & Gilbert, S. (2019). Characterising
monitoring processes in event-based prospective memory: Evidence from
pupillometry. Cognition, 184, 83--95. Mozuraitis, M., Chambers, C.G. &
Daneman, M. (2015). Privileged versus shared knowledge about object
identity in real-time referential processing. Cognition, 142, 148--165.
Mueller, K.D., Koscik, R.L., Hermann, B.P., Johnson, S.C. & Turkstra,
L.S. (2018). Declines in connected language are associated with very
early mild cognitive impairment: Results from the Wisconsin Registry for
Alzheimer's prevention. Frontiers in Aging Neuroscience, 9 (Article no.
437). Mueller, K.L., Murray, J.C., Michaelson, J.J., Christiansen, M.H.,
Reilly, S. & Tomblin, J.B. (2016). Common

881

genetic variants in FOXP2 are not associated with individual differences
in language development. PLoS ONE, 11 (Article no. e0152576). Müller,
N.G., Bartelt, O.A., Donner, T.H., Villringer, A. & Brandt, S.A. (2003).
A physiological correlate of the "zoom lens" of visual attention.
Journal of Neuroscience, 23, 3561--3565. Munding, D., Dubarry, A.-S. &
Alario, F.X. (2016). On the cortical dynamics of word production: A
review of the MEG evidence. Language, Cognition and Neuroscience, 31,
441--462. Murphy, C., Rueschemeyer, S.-A., Watson, D., Karapanagiotidis,
T., Smallwood, J. & Jefferies, E. (2017). Fractionating the anterior
temporal lobe: MVPA reveals differential responses to input and
conceptual modality. NeuroImage, 147, 19--31. Murphy, G.L. (2011).
Models and concepts. In E.M. Pothod & A.J. Wills (eds), Formal
Approaches in Categorisation (pp. 299--312). Cambridge: Cambridge
University Press. Murphy, G. & Greene, C.M. (2017). Load theory behind
the wheel: Perceptual and cognitive load effects. Canadian Journal of
Experimental Psychology, 71, 191--202. Murphy, G., Groeger, J.A. &
Greene, C.M. (2016). Twenty years of load theory -- Where are we now,
and where should we go next? Psychonomic Bulletin & Review, 23,
1316--1340. Murray, J.D. & Burke, K.A. (2003). Activation and encoding
of predictive inferences: The role of reading skill. Discourse
Processes, 35, 81--102. Murty, V.P., Ritchey, M., Adcock, R.A. & LaBar,
K.S. (2010). fMRI studies of successful emotional memory encoding: A
quantitative meta-analysis. Neuropsychologia, 48, 3459--3469. Musel, B.,
Chauvin, A., Guyader, N., Chokron, S. & Perin, C. (2012). Is
coarse-to-fine strategy sensitive to normal aging? PloS ONE, 7 (Article
no. e38493). Mustanski, B. (2007). The influence of state and trait
affect on HIV risk behaviours: A daily diary study of MSM. Health
Psychology, 26, 618--626. Muter, P. (1978). Recognition failure of
recallable words in semantic memory. Memory & Cognition, 6, 9--12.
Naccache, L. (2018). Why and how access consciousness can account for
phomenal consciousness. Philosophical Transactions of the Royal Society
B, 373 (Article no. 20170357). Naccache, L., Blandin, E. & Dehaene, S.
(2002). Unconscious masked priming depends on temporal attention.
Psychological Science, 13, 416--424. Nachar, R.A., Inaty, E., Bonnin,
P.J. & Alayli, Y. (2015). Breaking down Captcha using edge corners and
fuzzy logic segmentation/recognition technique. Security and
Communication Networks, 8, 3995--4012. Nahmais, E. (2015). Why we have
free will. Scientific American, 312 (January), 77--79.

882

References

Nairne, J.S. (2015a). Encoding and retrieval: Beyond Tulving and
Thomson's (1973) encoding specificity. In M.W. Eysenck & D. Groome
(eds), Cognitive Psychology: Revisiting the classic studies
(pp. 117--132). London: Sage. Nairne, J.S. (2015b). The three "Ws" of
episodic memory: What, when, and where. American Journal of Psychology,
128, 267--279. Nairne, J.S., Thompson, S.R. & Pandeirada, J.N.S. (2007).
Adaptive memory: Survival processing enhances retention. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 33, 263--273.
Namdar, G., Tzelgov, J., Algom, D. & Ganel, T. (2014). Grasping numbers:
Evidence for automatic influence of numerical magnitude on grip
aperture. Psychonomic Bulletin & Review, 21, 830--835. Nardo, D.,
Holland, R., Leff, A.P., Price, C.J. & Crinion, J.T. (2018). Less is
more: Neural mechanisms underlying anomia treatment in chronic aphasic
patients. Brain, 140, 3039--3054. Nascimento, S.M.C., de Almeida,
V.M.N., Fiadeiro, P.T. & Foster, D.H. (2004). Minimum-variance
cone-excitation ratios and the limits of relational colour constancy.
Visual Neuroscience, 21, 337--340. Nascimento, S.M.C., Amano, K. &
Foster, D.H. (2016). Spatial distributions of local illumination colour
in natural scenes. Vision Research, 120, 39--44. Naselaris, T., Olman,
C.A., Stansbury, D.E., Ugurbil, K. & Gallant, J.L. (2015). A voxel-wise
encoding model for early visual areas decodes mental images of
remembered scenes. NeuroImage, 105, 215--228. Navarrete, G. & Mandel,
D.R. (eds) (2016). Improving Bayesian reasoning: What works and why?
Frontiers in Psychology, 6, 1--207. Navarro, D.J. & Perfors, A.F.
(2011). Hypothesis generation, sparse categories, and the positive test
strategy. Psychological Review, 118, 120--134. Navon, D. (1977). Forest
before trees: The precedence of global features in visual perception.
Cognitive Psychology, 9, 353--383. Navon, D. & Miller, J. (2002).
Queuing or sharing? A critical evaluation of the single-bottleneck
notion. Cognitive Psychology, 44, 193--251. Nee, D.E., Brown, J.W.,
Askren, M.K., Berman, M.G., Demiralp, E., Krawitz, A., et al. (2013). A
meta-analysis of executive components of working memory. Cerebral
Cortex, 23, 264--282. Neely, J.H. (1977). Semantic priming and retrieval
from lexical memory: Roles of inhibitionless spreading activation and
limited capacity attention. Journal of Experimental Psychology: General,
106, 226--254. Neghavi, H.R. & Nyberg, L. (2005). Common fronto-parietal
activity in attention, memory, and consciousness: Shared demands on
integration? Consciousness and Cognition, 14, 390--425.

Neisser, U. (1996). Remembering as doing. Behavioral and Brain Sciences,
19, 203--204. Nelson, L.D., Simmons, J. & Simonsohn, U. (2018).
Psychology's renaissance. Annual Review of Psychology, 69, 511--534.
Neumann, M.F., End, A., Luttmann, S., Scheweinberger, S.R. & Wiese, H.
(2015). The own-age bias in face memory is unrelated to differences in
attention -- Evidence from event-related potentials. Cognitive,
Affective & Behavioral Neuroscience, 15, 180--194. Newell, A. & Simon,
H.A. (1972). Human Problem Solving. Englewood Cliffs, NJ: Prentice Hall.
Newell, A., Shaw, J.C. & Simon, H.A. (1958). Elements of a theory of
human problem solving. Psychological Review, 65, 151--166. Newell, B.R.
(2015). Decision making under risk: Beyond Kahneman and Tversky's (1979)
prospect theory. In M.W. Eysenck & D. Groome (eds), Cognitive
Psychology: Revisiting the classic studies (pp. 162--178). London: Sage.
Newell, B.R. (2011). Recognising the recognition heuristic for what it
is (and what it's not). Judgment and Decision Making, 6, 409--412.
Newell, B.R., Weston, N.J. & Shanks, D.R. (2003). Empirical tests of a
fast and frugal heuristic: Not everyone "takesthe-best". Organizational
Behavior and Human Decision Processes, 91, 82--96. Newman, I.R., Gibb,
M. & Thompson, V.A. (2017). Rulebased reasoning is fast and belief-based
reasoning can be slow: Challenging current explanations of belief-bias
and base-rate neglect. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 43, 1154--1170. Newman-Toker, D.E., Kerber, K.A.,
Hsieh, Y.-H., Pula, J.H., Omron, R., Tehrani, A.S.S., et al. (2013).
HINTS outperforms ABCD2 to screen for stroke in acute continuous vertigo
and dizziness. Academic Emergency Medicine, 20, 987--996. Newsome, M.R.
& Johnson-Laird, P.N. (2006). How falsity dispels fallacies. Thinking &
Reasoning, 12, 214--234. Newstead, S.E., Handley, S.J. & Buck, E.
(1999). Falsifying mental models: Testing the predictions of theories of
syllogistic reasoning. Memory & Cognition, 27, 344--354. Nguyen, K. &
McDaniel, M.A. (2016). The JOIs of text comprehension: Supplementing
retrieval practice to enhance inference performance. Journal of
Experimental Psychology: Applied, 22, 59--71. Nicolle, A., Fleming,
S.M., Bach, D.R., Driver, J. & Dolan, R.J. (2011). A regret-induced
status quo bias. Journal of Neuroscience, 31, 3320--3327. Niebergall,
R., Khayat, P.S., Treue, S. & Martinez-Trujillo, J.C. (2011). Multifocal
attention filters targets from distractors within and beyond primate MT
neurons' receptive field boundaries. Neuron, 72, 1067--1079.

References Niendam, T.A., Laird, A.R., Kimberly, L.R., Dean, Y.M.,
Glahn, D.C. & Carter, C.S. (2012). Meta-analytic evidence for a
superordinate cognitive control network subserving diverse executive
functions. Cognitive, Affective, and Behavioral Neuroscience, 12,
241--268. Nieuwenstein, M.R., Wierenga, T., Morey, R.D., Wicherts, J.M.,
Blom, T.N., Wagenmakers, E.-J., et al. (2015). On making the right
choice: A meta-analysis and large-scale replication attempt of the
unconscious thought advantage. Judgment and Decision Making, 10, 1--17.
Nieuwland, M.S. (2019). Do "early" brain responses reveal word form
prediction during language comprehension? A critical review.
Neuroscience and Biobehavioral Reviews, 96, 367--400. Nieuwland, M.S. &
van Berkum, J.J.A. (2006a). When peanuts fall in love: N400 evidence for
the power of discourse. Journal of Cognitive Neuroscience, 18,
1098--1111. Nieuwland, M.S. & van Berkum, J.J.A. (2006b). Individual
differences and contextual bias in pronoun resolution: Evidence from
ERPs. Brain Research, 1118, 155--116. Nieuwland, M.S., Politzer-Ahles,
S., Neyselaar, E., Segaert, K., Darley, E., Kazanina, N., et al. (2018).
Large-scale replication study reveals a limit on probabilistic
prediction in language comprehension. eLife, 7 (Article no. e33468).
Nijboer, M., Borst, J., van Rijn, H. & Taatgen, N. (2014). Single-task
fMRI overlap predicts concurrent multitasking interference. NeuroImage,
100, 60--74. Nijboer, M., Borst, J., van Rijn, H. & Taatgen, N. (2016a).
Contrasting single and multi-component workingmemory systems in dual
tasking. Cognitive Psychology, 86, 1--26. Nijboer, M., Taatgen, N.A.,
Brands, A., Borst, J.P. & van Rijn, H. (2013). Decision making in
concurrent multitasking: Do people adapt to task interference? PLoS ONE,
8 (Article no. e79583). Nisbett, R.E. & Wilson, T.D. (1977). Telling
more than we can know: Verbal reports on mental processes. Psychological
Review, 84, 231--259. Nitschke, K., Ruh, N., Kappler, S., Stahl, C. &
Kaller, C.P. (2012). Dissociable stages of problem solving (1): Temporal
characteristics revealed by eye-movement analyses. Brain and Cognition,
80, 160--169. Nodine, C. & Mello-Thoms, C. (2010). The Role of Expertise
in Radiologic Image Interpretation: Medical image perception and
techniques. New York: Cambridge University Press. Nooteboom, S.G. &
Quené, H. (2008). Self-monitoring and feedback: A new attempt to find
the main cause of lexical bias in phonological speech errors. Journal of
Memory and Language, 58, 837--861. Nooteboom, S.G. & Queué, H. (2013).
Heft hemisphere: Exchanges predominate in segmental speech errors.
Journal of Memory and Language, 68, 26--38.

883

Nooteboom, S.G. & Quené, H. (2017). Self-monitoring for speech errors:
Two-stage detection and repair with and without auditory feedback.
Journal of Memory and Language, 95, 19--35. Nørby, S. (2015). Why
forget? On the adaptive value of memory loss. Perspectives on
Psychological Science, 10, 551--578. Nordgren, L.F., Bos, M.W. &
Dijksterhuis, A. (2011). The best of both worlds: Integrating conscious
and unconscious thought best solves complex decisions. Journal of
Experimental Social Psychology, 47, 509--511. Norman, D.A. (1980).
Twelve issues for cognitive science. Cognitive Science, 4, 1--32.
Norris, D. (2013). Models of visual word recognition. Trends in
Cognitive Sciences, 17, 517--524. Norris, D. (2017). Short-term memory
and long-term memory are still different. Psychological Bulletin, 143,
992--1009. Norris, D. & Kinoshita, S. (2012). Reading through a noisy
channel: Why there's nothing special about the perception of
orthography. Psychological Review, 119, 517--545. Norris, D., McQueen,
J.M. & Cutler, A. (2003). Perceptual learning in speech. Cognitive
Psychology, 47, 204--238. Norris, D., McQueen, J.M., Cutler, A. &
Butterfeld, S. (1997). The possible-word constraint in the segmentation
of continuous speech. Cognitive Psychology, 34, 191--243. Nozari, N. &
Novick, J. (2017). Monitoring and control in language production.
Current Directions in Psychological Science, 26, 403--410. Nozari, N.,
Dell, G.S. & Schwartz, M.F. (2011). Is comprehension necessary for error
detection? Cognitive Psychology, 63, 1--33. Nurullah, A.S. (2015). Cell
phone conversation while driving. In Zheng Yan (ed.), Encylopaedia of
Mobile Phone Behaviour, Vol. III (pp. 1328--1339). Hershey, PA: IGI
Global. Nuttall, H.E., Kennedy-Higgins, D., Hogan, J., Devlin, J.T. &
Adank, P. (2016). The effect of speech distortion on the excitability of
articulatory motor cortex. NeuroImage, 128, 218--226. Nuzzo, R. (2015).
Fooling ourselves. Nature, 526, 182--185. Nyholm, S. (2018). The ethics
of crashes with self-driving cars: A roadmap, 1. Philosophy Compass, 13
(Article no. e12507). Oaksford, M. (1997). Thinking and the rational
analysis of human reasoning. The Psychologist, 10, 257--260. Oaksford,
M. (2015). Imaging deductive reasoning and the new paradigm. Frontiers
in Human Neuroscience, 9 (Article no. 101). Oaksford, M. & Hall, S.
(2016). On the source of human irrationality. Trends in Cognitive
Sciences, 20, 336--344. Oaksford, M., Chater, N., Gerainger, B. &
Larkin, J. (1997). Optimal data selection in the Reduced Array Selection

884

References

Test (RAST). Journal of Experimental Psychology: Learning, Memory, and
Cognition, 23, 441--458. Oatley, K. & Johnson-Laird, P.N. (1987).
Towards a cognitive theory of emotions. Cognition and Emotion, 1,
29--50. Oberauer, K., Lewandowsky, S., Awh, E., Brown, G.D.A., Conway,
A., Cowan, N., et al. (2018). Benchmarks for models of short-term and
working memory. Psychological Bulletin, 144, 885--958. O'Brien, E.J. &
Cook, A.E. (2014). Knowledge activation, integration, and validation
during narrative text comprehension. Discourse Processes, 51, 26--49.
O'Brien, E.J. & Cook, A.E. (2016). Coherence threshold and the
continuity of processing: The RI-Val model of comprehension. Discourse
Processes, 53, 326--338. O'Brien, G.E., McCloy, D.R., Kubota, E.C. &
Yeatman, J.D. (2018). Reading ability and phoneme categorisation.
Scientific Reports, 8 (Article no. 16842). Ochsner, K.N., Ray, R.R.,
Hughes, B., McRae, K., Cooper, J.C., Weber, J., et al. (2009). Bottom-up
and top-down processes in emotion generation: Common and distinct neural
mechanisms. Psychological Science, 20, 1322--1331. O'Craven, K.,
Downing, P. & Kanwisher, N. (1999). fMRI evidence for objects as the
units of attentional selection. Nature, 401, 584--587. Odinot, G.,
Wolters, G. & van Koppen, P.J. (2009). Eyewitness memory of a
supermarket robbery: A case study of accuracy and confidence after 3
months. Law and Human Behavior, 33, 506--514. Oeberst, A. & Blank, H.
(2012). Undoing suggestive influence on memory: The reversibility of the
eyewitness misinformation effect. Cognition, 125, 141--159. Oehler, A.,
Wendt, S., Wedlich, F. & Horn, M. (2018). Investors' personality
influences investment decisions: Experimental evidence on extraversion
and neuroticism. Journal of Behavioral Finance, 19, 30--48. Oh, H.,
Beck, J.M., Zhu, P., Sommer, M.A., Ferrari, S. & Egner, T. (2016).
Satisficing in split-second decision making is characterised by
strategic cue discounting. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 42, 1937--1956. Ohlsson, S. (1992). Information
processing explanations of insight and related phenomena. In M.T. Keane
& K.J. Gilhooly (eds), Advances in the Psychology of Thinking (Vol. 1;
pp. 1--44). London: Harvester Wheatsheaf. Ohlsson, S. (2011). Deep
Learning: How the mind overrides experience. Cambridge: Cambridge
University Press. Olguin, A., Bekinschtein, T.A. & Bozic, M. (2018).
Neural encoding of attended continuous speech under different types of
interference. Journal of Cognitive Neuroscience, 30, 1606--1619. Olive,
T. (2012). Writing and working memory: A summary of theories and
findings. In E.L. Grigorenko, E. Mambrino

& D.D. Preiss (eds), Writing: A mosaic of perspectives (pp. 125--140).
Hove, UK: Psychology Press. Olive, T. (2014). Toward a parallel and
cascading model of the writing system: A review of research on writing
processes' co-ordination. Journal of Writing Research, 6, 173--194.
Olive, T., Kellogg, R.T. & Piolat, A. (2008). Verbal, visual, and
spatial working memory demands during text composition. Applied
Psycholinguistics, 29, 669--687. Olive, T. & Passerault, J.-M. (2012).
The visuospatial dimension of writing. Written Communication, 29,
326--344. Oliveri, M. & Caltagirone, C. (2006). Suppression of
extinction with TMS in humans: From healthy controls to patients.
Behavioural Neurology, 17, 163--167. Olkoniemi, H., Ranta, H. &
Kaakinen, J.K. (2016). Individual differences in the processing of
written sarcasm and metaphor: Evidence from eye movements. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 42, 433--450.
Öllinger, M., Jones, G. & Knoblich, G. (2014). The dynamics of search,
impasse, and representational change provide a coherent explanation of
difficulty in the nine-dot problem. Psychological Research, 78,
266--275. Olson, A., Halloran, E. & Romani, C. (2015a). Target/error
overlap in jargonaphasia: The case for a one-source model, lexical and
non-lexical summation, and the special status of correct responses.
Cortex, 73, 158--179. Olson, J.A., Amlani, A.A., Raz, A. & Rensink, R.A.
(2015b). Influencing choice without awareness. Consciousness and
Cognition, 37, 225--236. Olson, J.A., Landry, M., Appourchaux, K. & Raz,
A. (2016). Simulated thought insertion: Influencing the sense of agency
using deception and magic. Consciousness and Cognition, 43, 11--26. Open
Science Collaboration (2015). Estimating the reproducibility of
psychological science. Science, 349 (Article no. aac4716). Ophir, E.,
Nass, C. & Wagner, A.D. (2009). Cognitive control in media multitaskers.
Proceedings of the National Association of Sciences, 106, 15583--15587.
Oppenheimer, D.M. (2004). Spontaneous discounting of availability in
frequency judgment tasks. Psychological Science, 15, 100--105.
Oppenheimer, D.M. & Monin, B. (2009). Investigations in spontaneous
discounting. Memory & Cognition, 37, 608--614. Orchard-Mills, E., Van
der Burg, E. & Alais, D. (2016). Crossmodal correspondence between
auditory pitch and visual elevation affects temporal ventriloquism.
Perception, 45, 409--424. O'Reilly, R.C., Wyatte, D., Herd, S., Mingus,
B. & Jilk, D.J. (2013). Recurrent processing during object recognition.
Frontiers in Psychology, 4 (Article no. 124). Ortega, J., Montañes, P.,
Barnhart, A. & Kuhn, G. (2018). Exploiting failures in metacognition
through magic:

References Visual awareness as a source of visual metacognition bias.
Consciousness and Cognition, 65, 152--168. Osiurak, F. & Badets, A.
(2016). Tool use and affordance: Manipulation-based versus
reasoning-based approaches. Psychological Review, 123, 534--568.
Osiurak, F., Rossetti, Y. & Badets, A. (2017). What is an affordance? 40
years later. Neuroscience and Biobehavioral Reviews, 77, 403--417.
Osman, M., Wilkinson, L., Beigi, M., Castaneda, C.S. & Jahanshahi, M.
(2008). Patients with Parkinson's disease learn to control complex
systems via procedural as well as non-procedural learning.
Neuropsychologia, 46, 2355--2363. Otworowska, M., Blokpoel, M., Sweers,
M., Wareham, T. & van Rooioj, I. (2018). Demons of ecological
rationality. Cognitive Science, 42, 1057--1065. Oudman, E., Nijboer,
T.C.W., Postma, A., Wijnin, J.W. & Van der Stigchel, S. (2015).
Procedural learning and memory rehabilitation in Korsakoff's syndrome --
A review of the literature. Neuropsychological Review, 25, 134--148.
Overgaard, M. & Mogensen, J. (2015). Reconciling current approaches to
blindsight. Consciousness and Cognition, 32, 33--40. Overgaard, M.,
Fehl, K., Mouridsen, K., Bergholt, B. & Cleermans, K. (2008). Seeing
without seeing? Degraded conscious vision in a blindsight patient. PLoS
One, 3 (Article no. e3028). Owen, A.M. (2013). Detecting consciousness:
a unique role for neuroimaging. Annual Review of Psychology, 64,
109--133. Pachur, T. & Spaar, M. (2015). Domain-specific preferences for
intuition and deliberation in decision making. Journal of Applied
Research in Memory and Cognition, 4, 303--311. Pachur, T., Hertwig, R. &
Steinmann, F. (2012a). How do people judge risks: Availability
heuristic, affect heuristic, or both? Journal of Experimental
Psychology: Applied, 18, 314--330. Pachur, T., Schulte-Mecklenbeck, M.,
Murphy, R.O. & Hertwig, R. (2018). Prospect theory reflects selective
allocation of attention. Journal of Experimental Psychology: General,
147, 147--169. Pachur, T., Todd, P.M., Gigerenzer, G., Schooler, L.J. &
Goldstein, D.G. (2012b). When is the recognition heuristic an adaptive
tool? In P.M. Todd, G. Gigerenzer & ABC Research Group (eds), Ecological
Rationality: Intelligence in the world (pp. 113--143). Oxford: Oxford
University Press. Painter, D.R., Dwyer, M.F., Kamke, M.R. & Mattingley,
J.S. (2018). Stimulus-driven cortical hyperexcitability in individuals
with Charles Bonnet hallucinations. Current Biology, 28, 3475--3480.
Pakhomov, S., Chacon, D., Wicklund, M. & Gundel, J. (2011). Computerised
assessment of syntactic complexity

885

in Alzheimer's disease: A case study of Iris Murdoch's writing. Behavior
Research Methods, 43, 136--144. Paller, K.A. (2017). Sleeping in a brave
new world: Opportunities for improving learning and clinical outcomes
through targeted memory reactivation. Current Directions in
Psychological Science, 26, 532--537. Palmer, S.E. (1975). The effects of
contextual scenes on the identification of objects. Memory & Cognition,
3, 519--526. Palmer, S.E. & Rock, I. (1994). Rethinking perceptual
organisation: The role of uniform connectedness. Psychonomic Bulletin &
Review, 1, 29--55. Palmeri, T.J., Love, B.C. & Turner, B.M. (2017).
Modelbased cognitive neuroscience. Journal of Mathematical Psychology,
76, 59--64. Palombo, D.J., Sheldon, S. & Levine, B. (2018). Individual
differences in autobiographical memory. Trends in Cognitive Sciences,
22, 583--597. Pan, S.C. & Rickard, T.C. (2018). Transfer of testenhanced
learning: Meta-analytic review and synthesis. Psychological Bulletin,
144, 710--756. Panouillères, M.T.N., Boyles, R., Chesters, J., Watkins,
K.E. & Möttonen, R. (2018). Facilitation of motor excitability during
listening to spoken sentences is not modulated by noise or semantic
coherence. R.M., Stark, C.E.L., Cortex, 103, 44--54. Papageorgiou, C.
(2006). Worry and rumination: Styles of persistent negative thinking in
anxiety and depression. In G.L.C. Davey & A. Wells (eds), Worry and its
Psychological Disorders: Theory, assessment, and treatment (pp. 21--40).
Chichester, UK: Wiley. Papagno, C., Comi, A., Riva, M., Bizzi, A.,
Vernice, M., Casarotti, A., et al. (2017). Mapping the brain network of
the phonological loop. Human Brain Mapping, 38, 3011--3024. Papesh, M.H.
& Goldinger, S.D. (2014). Infrequent identity mismatches are frequently
undetected. Attention, Perception & Psychophysics, 76, 1335--1349.
Papesh, M.H., Heisick, L.L. & Warner, K.A. (2018). The persistent
low-prevalence effect in unfamiliar face-matching: The roles of feedback
and criterion shifting. Journal of Experimental Psychology: Applied, 24,
416--430. Papo, D. (2015). How can we study reasoning in the brain?
Frontiers in Human Neuroscience, 9 (Article no. 222). Pappas, Z. & Mack,
A. (2008). Potentiation of action by undetected affordant objects.
Visual Cognition, 16, 892--915. Parker, S.M. & Serre, T. (2015).
Unsupervised invariance learning of transformation sequences in a model
of object recognition yield selectivity for non-accidental properties.
Frontiers in Computational Neuroscience, 9 (Article no. 115). Parker,
E.S., Cahill, L. & McGaugh, J.L. (2006). A case of unusual
autobiographical remembering. Neurocase, 12, 35--49.

886

References

Parketny, J., Towler, J. & Eimer, M. (2015). The activation of visual
face memory and explicit face recognition are delayed in developmental
prosopagnosia. Neuropsychologia, 75, 538--547. Parkinson, B. (2001).
Putting appraisal in context. In K.R. Scherer, A. Schorr & T. Johnstone
(eds), Appraisal Processes in Emotion: Theory, methods, research.
Oxford: Oxford University Press. Parkinson, B. (2011). How social is the
social psychology of emotion? British Journal of Social Psychology, 50,
405--413. Parkinson, B. (2015). Pushing and pulling the boundaries of
emotion regulation. Psychological Inquiry, 26, 93--98. Parkinson, B. &
Manstead, A.S.R. (2015). Current emotion research in social psychology:
Thinking about emotions and other people. Emotion Review, 7, 371--380.
Parks, C.M. (2013). Transfer-appropriate processing in recognition
memory: Perceptual and conceptual effects on recognition memory depend
on task demands. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 39, 1280--1286. Pashler, H. (1994). Dual-task
interference in simple tasks: Data and theory. Psychological Bulletin,
116, 220--244. Pastötter, B. & Bäuml, K-H.T. (2016). Reversing the
testing effect by feedback: Behavioural and electrophysiological
evidence. Cognitive and Affective Neuroscience, 16, 473--488. Patal,
E.Z., Gadian, D.G., Cooper, J.M., Dziecial, A.M., Mishkin, M. &
Vargha-Khadem, F. (2015). Extent of hippocampal atrophy predicts degree
of deficit in recall. Proceedings of the National Academy of Sciences,
112, 12830--12833. Patihis, L., Frenda, S.J., LePort, A.K.R., Petersen,
N., Nichols, R.M., Stark, C.E.L., et al. (2013). False memories in
highly superior autobiographical memory individuals. Proceedings of the
National Academy of Sciences, 110, 20947--20952. Patsenko, E.G. &
Altmann, E.M. (2010). How planful is routine behaviour? A
selective-attention model of performance in the Tower of Hanoi. Journal
of Experimental Psychology: General, 139, 95--116. Pattamadilok, C.,
Perre, L. & Ziegler, J.C. (2011). Beyond rhyme or reason: ERPs reveal
task-specific activation of orthography on spoken language. Brain and
Language, 116, 116--124. Patterson, K. & Lambon Ralph, M.A. (1999).
Selective disorders of reading? Current Opinion in Neurobiology, 9,
235--239. Patterson, K. & Plaut, D.C. (2009). "Shallow draughts
intoxicate the brain": Lessons from cognitive science for cognitive
neuropsychology. Topics in Cognitive Science, 1, 39--58. Patterson, K.,
Nestor, P.J. & Rogers, T.T. (2007). Where do you know what you know? The
representation of

semantic knowledge in the human brain. Nature Reviews Neuroscience, 8,
976--987. Patterson, R., Fournier, L., Pierce, B., Winterbottom, M. &
Tripp, L. (2009). Modelling the dynamics of recognition-primed decision
making. Proceedings of the 9th International Conference on Naturalistic
Decision Making. London, June. Pauker, E., Itzhak, I., Baum, S.R. &
Steinhauer, K. (2011). Effects of cooperating and conflicting prosody in
spoken English garden path sentences: ERP evidence for the boundary
deletion hypothesis. Journal of Cognitive Neuroscience, 23, 2731--2751.
Paulo, R.M., Albuquerque, P.B. & Bull, R. (2016). The enhanced cognitive
interview: Expressions of uncertainty, motivation and its relation with
report accuracy. Psychology, Crime & Law, 22, 366--381. Paulo, R.M.,
Albuquerque, P.B., Vitorino, F. & Bull, R. (2017). Enhancing the
cognitive interview with an alternative procedure to witness-compatible
questioning: Category clustering recall. Psychology, Crime & Law, 23,
967--982. Pavan, A., Ghin, F., Donato, R., Campana, G. & Mather, G.
(2017). The neural basis of form and form-motion integration from static
and dynamic translational Glass patterns: A rTMS investigation.
NeuroImage, 157, 555--560. Pavlova, M.A., Erb, M., Hagberg, G.E.,
Loureiro, J., Sokolov, A.N. & Scheffer, K. (2017). "Wrong way up":
Temporal and spatial dynamics of the networks for body motion processing
at 9.4 T. Cerebral Cortex, 27, 5318--5330. Payne, B.K. (2006). Weapon
bias: Split-second decisions and unintended stereotyping. Current
Perspectives in Psychological Science, 15, 287--291. Payne, J. (1976).
Task complexity and contingent processing in decision making: An
information search and protocol analysis. Organizational Behavior and
Human Performance, 16, 366--387. Payne, S.J. & Duggan, G.B. (2011).
Giving up problem solving. Memory & Cognition, 39, 902--913. Paynter,
C.A., Kotovsky, K. & Reder, L.M. (2010). Problemsolving without
awareness: An ERP investigation. Neuropsychologia, 48, 3137--3144.
Pearson, J. & Kosslyn, S.M. (2015). The heterogeneity of mental
representation: Ending the imagery debate. Proceedings of the National
Association of Sciences, 112, 10089--10092. Pearson, J., Clifford,
C.W.G. & Tong, F. (2008). The functional impact of mental imagery on
conscious perception. Current Biology, 18, 982--986. Peckham, A.D.,
McHugh, R.K. & Otto, M.W. (2010). A meta-analysis of the magnitude of
biased attention in depression. Depression and Anxiety, 27, 1135--1142.
Pedrazzini, E., Schnider, A. & Ptak, R. (2017). A neuroanatomical model
of space-based and object-centred

References processing in spatial neglect. Brain Structure and Function,
222, 3605--3613. Pellicano, A., Borghi, A.M. & Binkofski, F. (2017).
Editorial: Bridging the theories of affordances and limb apraxia.
Frontiers in Human Neuroscience, 11 (Article no. 148). Peltier, C. &
Becker, M.W. (2016). Decision processes in visual search as a function
of target prevalence. Journal of Experimental Psychology: Human
Perception and Performance, 42, 1466--1478. Penaloza, A.A. & Calvillo,
D.P. (2012). Incubation provides relief from artificial fixation in
problem solving. Creativity Research Journal, 24, 338--344. Peng, P.,
Barnes, M., Wang, C., Wang, W., Li, S., Swanson, H.L., et al. (2018). A
meta-analysis on the relation between reading and working memory.
Psychological Bulletin, 144, 48--76. Penhune, V.B. & Steele, C.J.
(2012). Parallel contributions of cerebellar, striatal and M1 mechanisms
to motor sequence learning. Behavioural Brain Research, 226, 579--591.
Pennycook, G. & Thompson, V.A. (2012). Reasoning with base rates is
routine, relatively effortless, and context dependent. Psychonomic
Bulletin & Review, 19, 528--534. Pennycook, G., Fugelsang, J.A. &
Koehler, D.J. (2015). What makes us think? A three-stage dual-process
model of analytic engagement. Cognitive Psychology, 80, 34--72. Perenin,
M.-T. & Vighetto, A. (1988). Optic ataxia: A specific disruption in
visuomotor mechanisms. 1. Different aspects of the deficit in reaching
for objects. Brain, 111, 643--674. Peretz, I. & Coltheart, M. (2003).
Modularity of music processing. Nature Neuroscience, 6, 688--691.
Perfetti, C. & Stafura, J. (2014). Word knowledge in a theory of reading
comprehension. Scientific Studies of Reading, 18, 22--37. Perfors, A.F.
& Navarro, D.J. (2009). Confirmation bias is rational when hypotheses
are sparse. Proceedings of the 31st. Annual Conference of the Cognitive
Science Society, Amsterdam, 2741--2746. Perkins, A.M., Leonar, A.M.,
Ettinger, U., Weaver, K., Dalton, J.A., Mehta, M.A., et al. (2013). A
dose of ruthlessness: Interpersonal moral judgment is hardened by the
anti-anxiety drug lorazepam. Journal of Experimental Psychology:
General, 142, 612--620. Perry, A., Stiso, J., Chang, E.F., Lin, J.J.,
Parvizi, J. & Knight, R.T. (2018). Mirroring in the human brain:
Deciphering the spatial-temporal patterns of the human mirror neuron
system. Cerebral Cortex, 28, 1039--1048. Perry, C., Ziegler, J.C. &
Zorzi, M. (2007). Nested incremental modelling in the development of
computational theories: The CDP+ model of reading aloud. Psychological
Review, 114, 273--315. Perry, C., Ziegler, J.C. & Zorzi, M. (2014). When
silent letters say more than a thousand words: An implementation

887

and evaluation of CDP++ in French. Journal of Memory and Language, 72,
98--115. Persaud, N. & Cowey, A. (2008). Blindsight is unlike normal
conscious vision: Evidence from an exclusion task. Consciousness and
Cognition, 17, 1050--1055. Persaud, N. & Lau, H. (2008). Direct
assessment of qualia in a blindsight participant. Consciousness and
Cognition, 17, 1046--1049. Persaud, N. & McLeod, P. (2008). Wagering
demonstrates subconscious processing in a binary exclusion task.
Consciousness and Cognition, 17, 565--575. Persaud, N., Davidson, M.,
Maniscalco, B., Mobbs, D., Passingham, R.E., Cowey, A., et al. (2011).
Awarenessrelated activity in prefrontal and parietal cortices in
blindsight reflects more than superior visual performance. NeuroImage,
58, 605--611. Persuh, M. & Melara, R.D. (2016). Barack Obama Blindness
(BOB): Absence of visual awareness to a single object. Frontiers in
Human Neuroscience, 10 (Article no. 118). Pessoa, L. (2017). A network
model of the emotional brain. Trends in Cognitive Sciences, 21,
257--371. Peters, M.A.K., Ro, T. & Lau, H. (2016). Who's afraid of
response bias? Neuroscience of Consciousness, 1 (Article no. niw001).
Petrone, C., Truckenbrodt, H., Wellmann, C., HolzgrefeLang, J.,
Wartenburger, I. & Höhle, B. (2017). Prosodic boundary cues in German:
Evidence from the production and perception of bracketed lists. Journal
of Phonetics, 61, 71--92. Pezdek, K. (2003). Event memory and
autobiographical memory for the events of September 11, 2001. Applied
Cognitive Psychology, 17, 1033--1045. Phillips, W.J., Hine, D.W. &
Thorsteinsson, E.B. (2010). Implicit cognition and depression: A
meta-analysis. Clinical Psychology Review, 30, 691--709. Piai, V., Riès,
S.K. & Swick, D. (2016). Lesions to lateral prefrontal cortex impair
lexical interference control in word production. Frontiers of Human
Neuroscience, 9 (Article no. 721). Piantadosi, S.T., Tily, H. & Gibson,
E. (2012). The communicative function of ambiguity in language.
Cognition, 122, 280--291. Pickel, K.L. (2009). The weapon focus effect
on memory for female versus male perpetrators. Memory, 17, 664--678.
Pickering, M.J. & Gambi, C. (2018). Predicting while comprehending
language: A theory and review. Psychological Bulletin, 144, 1002--1044.
Pickering, M.J. & Garrod, S. (2013). An integrated theory of language
production and comprehension. Behavioral and Brains Sciences, 36,
329--347. Pilkington, E., Keidel, J., Kendrick, L.T., Saddy, J.D., Sage,
K. & Robson, H. (2017). Sources of phoneme errors in repetition:
Perseverative, neologistic, and lesion patterns

888

References

in jargon aphasia. Frontiers in Human Neuroscience, 11 (Article no.
225). Pilz, K.S., Roggeveen, A.B., Creighton, S.E., Bennett, P.J. &
Sekuler, A.B. (2012). How prevalent is object-based attention? PloS ONE,
7 (Article no. e30693). Pinker, S. (1997). How the Mind Works. New York:
W.W. Norton. Pinna, D., Porcheddu, D. & Deiana, K. (2016). From grouping
to coupling: A new perceptual organisation in vision, psychology, and
biology. Frontiers in Psychology, 7 (Article no. 1051). Pinto, J.
(2006). Developing body representations: A review of infants' responses
to biological-motion displays. In G. Knoblich, M. Grosjean, J. Thornton
& M. Shiffrar (eds), Perception of the Human Body from the Inside Out
(pp. 305--322). Oxford: Oxford University Press. Pinto, Y., Neville,
D.A., Otten, M., Corballis, P.M., Lamme, V.A.F., de Haan, E.H.F., et
al. (2017). Split brain: Divided perception but undivided consciousness.
Brain, 140, 1231--1237. Pirogovsky-Turk, E., Filoteo, J.V., Litvan, I. &
Harrington, D.L. (2015). Structural MRI correlates of episodic memory
processes in Parkinson's disease without mild cognitive impairment.
Journal of Parkinson's Disease, 5, 971--981. Pisella, L., Binkofski, F.,
Lasek, K., Toi, L. & Rossetti, Y. (2006). No double dissociation between
optic ataxia and visual agnosia: Multiple sub-streams for multiple
visuo-manual integrations. Neuropsychologia, 44, 2734--2748. Pitts,
M.A., Lutsyshyna, L.A. & Hillyard, S.A. (2018). The relationship between
attention and consciousness: An expanded taxonomy and implications for
no-report paradigms. Philosophical Transactions of the Royal Society B,
373 (Article no. 21070348). Pitts, M.A., Lutsyshyna, L.A. & Hillyard,
S.A. (2019). Reply to Montemayor and Halajian. Philosophical
Transactions of the Royal Society B, 374 (Article no. 20190003). Plait,
P. (2016). A fantastic optical illusion: Just another brick in the wall?
Retrieved from www.slate.com/blogs/bad\_
astronomy/2016/05/18/sometimes_a_cigar_isn_t_just\_ a_cigar.html.
Planton, S., Jucla, M. Roux, F.-E. & Démonet, J.-F. (2013). The
"handwriting brain": A meta-analysis of neuroimaging studies of motor
versus orthographic processes. Cortex, 49, 2772--2787. Planton, S.,
Longcamp, M., Péran, P., Démonet, J.-F. & Jucla, M. (2017). How
specialised are writing-specific brain regions? An fMRI study of
writing, drawing and oral spelling. Cortex, 88, 66--80. Plaut, D.C.,
McClelland, J.L., Seidenberg, M.S. & Patterson, K.E. (1996).
Understanding normal and impaired word reading: Computational principles
in quasi-regular domains. Psychological Review, 103, 56--115.

Pleskac, T.J. (2012). Comparability effects in probability judgments.
Psychological Science, 23, 848--854. Pobric, G., Jefferies, E. & Lambon
Ralph, M.A. (2010a). Amodal semantic representations depend on both
anterior temporal lobes: Evidence from repetitive transcranial magnetic
stimulation. Neuropsychologia, 48, 1336--1342. Pobric, G., Jefferies, E.
& Lambon Ralph, M.A. (2010b). Category-specific versus category-general
semantic impairment induced by transcranial magnetic stimulation.
Current Biology, 20, 964--968. Poeppel, D. & Monahan, P.J. (2011).
Feedforward and feedback in speech perception: Revisiting analysis by
synthesis. Language and Cognitive Processes, 26, 935--951. Pohl, R.F.,
Michalkiewicz, M., Erdfelder, E. & Hilbig, B.E. (2017). Use of the
recognition heuristic depends on the domain's recognition validity, not
on the recognition validity of selected sets of objects. Memory &
Cognition, 45, 776--791. Poldrack, R.A. & Yarkoni, T. (2016). From brain
maps to cognitive ontologies: Informatics and the search for mental
structure. Annual Review of Psychology, 67, 587--612. Poldrack, R.A.,
Baker, C., Durnez, J., Gorgolewski, K.J., Matthews, P.M., Munafo, M.R.,
et al. (2017). Scanning the horizon: Towards transparent and
reproducible neuroimaging research. Nature Reviews Neuroscience, 18,
115--126. Pope, D.G. & Schweitzer, M.E. (2011). Is Tiger Woods loss
averse? Persistent bias in the face of experience, competition, and high
stakes. American Economic Review, 101, 129--157. Pope, S.M.,
Meguerditchian, A. & Hopkins, W.D. (2015). Baboons (Papio papio), but
not humans, break cognitive set in a visuo-motor task. Animal Cognition,
18, 1339--1346. Popov, V., Ostarek, M. & Tenison, C. (2018). Practices
and pitfalls in inferring neural representations. NeuroImage, 174,
340--351. Popper, K.R. (1968). The Logic of Scientific Discovery.
London: Hutchinson. Posner, M.I. (1980). Orienting of attention. The
VIIth Sir Frederic Bartlett lecture. Quarterly Journal of Experimental
Psychology, 32A, 3--25. Postle, B.R. (2006). Working memory as an
emergent property of the mind and brain. Neuroscience, 139, 23--38.
Pourtois, G., Vanlessen, N., Bakic, J. & Paul, K. (2017). Modulatory
effects of positive mood on cognition: Lessons from attention and error
monitoring. Current Directions in Psychological Science, 26, 495--501.
Power, M. & Dalgleish, T. (2008). Cognition and Emotion: From order to
disorder (2nd edn). Hove, UK: Psychology Press. Pozzulo, J.D., Crescini,
C. & Panton, T. (2008). Does methodology matter in eyewitness
identification research? The effect of live versus video exposure on
eyewitness

References identification of accuracy. International Journal of Law and
Psychiatry, 31, 430--437. Prado, J., Chadha, A. & Booth, J.R. (2011).
The brain network for deductive reasoning: A quantitative metaanalysis
of 28 neuroimaging studies. Journal of Cognitive Neuroscience, 23,
3483--3497. Prass, M., Grimsen, C., König, M. & Fahle, M. (2013).
Ultrarapid object categorisation: Effect of level, animacy and context.
PloS ONE, 8 (Article no. e68051). Prebble, S.C., Addis, D.R. & Tippett,
L.J. (2013). Autobiographical memory and sense of self. Psychological
Bulletin, 139, 815--840. Precht, L., Keinath, A. & Krems, J.F. (2017).
Identifying the main factors contributing to driving errors and traffic
violations -- Results from naturalistic driving data. Transportation
Research Part F, 49, 49--92. Principe, A., Calabria, M., Campo, A.T.,
Cruzat, J., Conesa, G., Costa, A., et al. (2017). Whole network,
temporal and parietal lobe contributions to the earliest phases of
language production. Cortex, 95, 238--247. Prull, M.W. & Yockelson, M.B.
(2013). Ault age-related differences in the misinformation effect for
contextconsistent and context-inconsistent objects. Applied Cognitive
Psychology, 27, 384--395. Purcell, J.J., Jiang, X. & Eden, G.F. (2017).
Shared orthographic neuronal representations for spelling and reading.
NeuroImage, 147, 554--567. Purdon, C. (2018). There is a lot more to
compulsions than meets the eye. Clinical Neuropsychiatry, 15, 291--298.
Putnam, A.L., Sungkhasettee, V.W. & Roediger, H.L. (2017). When
misinformation improves memory: The effects of recollecting change.
Psychological Science, 28, 36--46. Puvvada, K.C. & Simon, J.Z. (2017).
Cortical representations of speech in a multi-talker auditory scene.
Journal of Neuroscience, 37, 9189--9196. Pyc, M.A. & Rawson, K.A.
(2010). Why testing improves memory: Mediator effectiveness hypothesis.
Science, 330, 335. Pyc, M.A. & Rawson, K.A. (2012). Why is test-restudy
practice beneficial for memory? An evaluation of the mediator shift
hypothesis. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 38, 737--746. Pylyshyn, Z.W. (2002). Mental imagery: In
search of a theory. Behavioral and Brain Sciences, 25, 157--238. Qian,
Z., Garnsey, S. & Christianson, K. (2018). A comparison of online and
offline measures of good-enough processing in garden-path sentences.
Language, Cognition and Neuroscience, 33, 227--254. Qu, W., Dai, M.,
Zhao, W., Zhang, K. & Ge, Y. (2016). Expressing anger is more dangerous
than feeling angry when driving. PloS ONE, 11 (Article no. e0156948).
Quamme, J.R., Yonelinas, A.P. & Norman, K.A. (2007). Effect of
unitisation on associative recognition in amnesia. Hippocampus, 17,
192--200.

889

Quinlan, T., Loncke, M., Leijten, M. & Van Waes, L. (2012). Coordinating
the cognitive processes of writing: The role of the monitor. Written
Communication, 29, 345--368. Quiroga, R.Q., Reddy, L., Kreiman, G.,
Koch, C. & Fried, I. (2005). Invariant visual representation by single
neurons in the human brain. Nature, 435, 1102--1107. Rabovsky, M.,
Hansem, S.S. & McClelland, J.L. (2018). Modelling the N400 brain
potential as change in a probabilistic representation of meaning. Nature
Human Behaviour, 2, 693--705. Rabin, J., Houser, B., Talbert, C. &
Patel, R. (2016). Blueblack or white-gold? Early stage processing and
the colour of "The Dress". PLoS ONE, 11 (Article no. e 0161090). Race,
E., Burke, K. & Verfaellie, A. (2019). Repetition priming in amnesia:
Distinguishing associative learning at different levels of abstraction.
Neuropsychologia, 122, 98--104. Radach, R. & Kennedy, A. (2013). Eye
movements in reading: Some theoretical context. Quarterly Journal of
Experimental Psychology, 66, 429--452. Radomsky, A.S., Dugas, M.J.,
Alcolado, G.M. & Lavoie, S.L. (2014). When more is less: Doubt,
repetition, memory, metamemory, and compulsive checking in OCD.
Behaviour Research and Therapy, 59, 30--39. Radonjić, A. & Brainard,
D.H. (2016). The nature of instructional effects in colour constancy.
Journal of Experimental Psychology: Human Perception and Performance,
42, 847--865. Radvansky, G.A. & Zacks, J.M. (2011). Event perception.
Wiley Interdisciplinary Reviews: Cognitive Science, 2, 608--620.
Raghunathan, R. & Pham, M.T. (1999). All negative moods are not equal:
Motivational influences of anxiety and sadness on decision making.
Organizational Behavior and Human Decision Processes, 79, 56--77. Ragni,
M. & Knauff, M. (2013). A theory and a computational model of spatial
reasoning with preferred mental models. Psychological Review, 120,
561--588. Ragni, M., Kola, I. & Johnson-Laird, P.N. (2018). On selecting
evidence to test hypotheses: A theory of selection tasks. Psychological
Bulletin, 144, 779--796. Rahnev, D. & Denison, R. (2018). Suboptimality
in perceptual decision making. Behavioral and Brain Sciences, 41, 1--66.
Raichle, M.E. (2015). The brain's default mode network. Annual Review in
Neuroscience, 38, 433--447. Raizada, R.D.S. & Poldrack, R.A. (2007).
Selective amplification of stimulus differences during categorical
processing of speech. Neuron, 56, 726--740. Rajaram, S. (1993).
Remembering and knowing: Two means of access to the personal past.
Memory & Cognition, 21, 89--102.

890

References

Rakow, T. & Sylark, W.J. (2018). Judgement heuristics. In L.J. Ball &
V.A. Thompson (eds), Routledge International Handbook of Thinking and
Reasoning (pp. 451--471). Abingdon, Oxon.: Routledge. Ramsey, L.E.,
Siegel, J.S., Baldassarre, A., Metcalf, N.V., Zinn, K., Shulman, G.L.,
et al. (2016). Normalisation of network connectivity in hemispatial
neglect recovery. Annals of Neurology, 80, 127--141. Ramsey, R. (2018).
What are reaction time indices of automatic imitation measuring?
Consciousness and Cognition, 65, 240--254. Ranft, A., Golkowski, D.,
Kiel, T., Riedl, V., Kohl, P., Rohrer, G., et al. (2016). Neural
correlates of sevoflurance-induced unconsciousness identified by
simultaneous functional magnetic resonance imaging and
electroencephalography. Anesthesiology, 125, 861--872. Rao, K.V. &
Baddeley, A. (2013). Raven's matrices and working memory: A dual-task
approach. Quarterly Journal of Experimental Psychology, 66, 1881--1887.
Raposo, A. & Marques, J.F. (2013). The contribution of fronto-parietal
regions to sentence comprehension: Insights from the Moses illusion.
NeuroImage, 83, 431--437. Rapp, B. & Lipka, K. (2011). The literate
brain: The relationship between spelling and reading. Journal of
Cognitive Neuroscience, 23, 1180--1197. Rapp, B., Epstein, C. &
Tainturier, M.-J. (2002). The integration of information across lexical
and sublexical processes in spelling. Cognitive Neuropsychology, 19,
1--29. Rapp, B., Fischer-Baum, S. & Miozzo, M. (2015). Modality and
morphology: What we write may not be what we say. Psychological Science,
26, 892--902. Rashal, E., Yeshurun, Y. & Kimchi, R. (2017). Attentional
requirements in perceptual grouping depend on the processes involved in
the organisation. Attention, Perception & Psychophysics, 79, 2073--2087.
Rastle, K. & Brysbaert, M. (2006). Masked phonological priming effects
in English: Are they real? Do they matter? Cognitive Psychology, 53,
97--145. Raven, J., Raven, C. & Court, J.H. (1998). Manual for Raven's
Progressive Matrices and Vocabulary Scales. Section 4: The advanced
progressive matrices. San Antonio, TX: Harcourt Assessment. Ray, C. &
Huntsinger, J.R. (2017). Feeling and thinking: An affect-as-cognitive
feedback account. Social and Personality Psychology Compass, 11 (Article
no. e12314). Rayner, K. & Clifton, C. (2009). Language processing in
reading and speech perception is fast and incremental: Implications for
event related potential research. Biological Psychology, 80, 4--9.
Rayner, K., Li, X.S. & Pollatsek, A. (2007). Extending the E-Z model of
eye-movement control to Chinese readers. Cognitive Science, 31,
1021--1033.

Rayner, K., Pollatsek, A., Ashby, J. & Clifton, C. (2012). Psychology of
Reading (2nd edn). Hove, UK: Psychology Press. Rayner, K., White, S.J.,
Johnson, R.L. & Liversedge, S.P. (2006). Reading words with jubmled
lettres -- There is a cost. Psychological Science, 17, 192--193. Reber,
A.S. (1993). Implicit Learning and Tacit Knowledge: An essay on the
cognitive unconscious. Oxford: Oxford University Press. Reber, P.J.
(2013). The neural basis of implicit learning and memory: A review of
neuropsychological and neuroimaging research. Neuropsychologia, 51,
2026--2042. Reber, P.J., Knowlton, J.R. & Squire, L.R. (1996).
Dissociable properties of memory systems: Differences in the flexibility
of declarative and non-declarative knowledge. Behavioral Neuroscience,
110, 861--871. Recanzone, G.H. & Sutter, M.L. (2008). The biological
basis of audition. Annual Review of Psychology, 59, 119--142.
Redelmeier, C., Koehler, D.J., Liberman, V. & Tversky, A. (1995).
Probability judgment in medicine: Discounting unspecified alternatives.
Medical Decision Making, 15, 227--230. Redfern, A.S. & Benton, C.P.
(2017). Expressive faces confuse identity. i-Perception, 8 (Article no.
2041669517731115). Rees, G. (2007). Neural correlates of the contents of
visual awareness in humans. Philosophical Transactions of the Royal
Society B -- Biological Sciences, 362, 877--886. Reeves, A.J., Amano, K.
& Foster, D.H. (2008). Colour constancy: Phenomenal or projective?
Perception & Psychophysics, 70, 219--228. Regier, T. & Xu, Y. (2017).
The Sapir-Whorf hypothesis and inference under uncertainty. Wiley
Interdisciplinary Reviews -- Cognitive Science, 8 (Article no. UNSP
e1440). Rego, S., Avantes, J. & Magalhães, P. (2018). Is there a
sunk-cost effect in committed relationships? Current Psychology, 37,
508--519. Reichle, E.D. (2015). Computational models of reading: A
primer. Language and Linguistics Compass, 9, 271--284. Reichle, E.D.,
Pollatsek, A., Fisher, D.L. & Rayner, K. (1998). Towards a model of eye
movement control in reading. Psychological Review, 105, 125--157.
Reingold, E.M., Reichle, E.D., Glaholt, M.G. & Sheridan, H. (2012).
Direct lexical control of eye movements in reading: Evidence from a
survival analysis of fixation durations. Cognitive Psychology, 65,
177--206. Reingold, E.M., Sheridan, H. & Reichle, E.D. (2015). Direct
lexical and non-lexical control of fixation duration in reading. In A.
Pollatsek & R. Treiman (eds), Oxford Handbook of Reading (pp. 261--276).
Oxford: Oxford University Press. Reiss, J.P., Campbell, D.W., Leslie,
W.D., Paulus, M.P., Stroman, P.W., Polimeni, J.O., et al. (2005). The
role of the striatum in implicit learning: A functional magnetic
resonance imaging study. NeuroReport, 16, 1291--1295.

References Remez, R.E., Ferro, D.F., Dubowski, K.R., Meer, J., Broder,
R.S. & Davids, M.L. (2010). Is desynchrony tolerance adaptable in the
perceptual organisation of speech? Attention, Perception &
Psychophysics, 72, 2054--2058. Renna, M.E., Quintero, J.M., Soffer, A.,
Pino, M., Ader, L., Fresco, D.M., et al. (2018). A pilot study of
emotion regulation therapy for generalised anxiety and depression:
Findings from a diverse sample of young adults. Behavior Therapy, 49,
403--418. Renoult, L., Tanguay, A., Beaudry, M., Tavakoli, P., Rabipour,
S., Campbell, K., et al. (2016). Personal semantics: Is it distinct from
episodic and semantic memory? An electrophysiological study of memory
for autobiographical facts and repeated events in honour of Shlomo
Bentin. Neuropsychologia, 83, 242--256. Rens, N., Bode, B., Burianová,
H. & Cunnington, R. (2017). Proactive recruitment of fronto-parietal and
salience networks for voluntary decisions. Frontiers in Human
Neuroscience, 11 (Article no. 610). Rensink, R.A., O'Regan, J.K. &
Clark, J.J. (1997). To see or not to see? The need for attention to
perceive changes in scenes. Psychological Science, 8, 368--373. Resnik,
K., Bradbury, D., Barnes, G.R. & Leff, A.P. (2014). Between thought and
expression, a magnetoencephalography study of the "tip-of-the-tongue"
phenomenon. Journal of Cognitive Neuroscience, 26, 2210--2223.
Reverberi, C., Shallice, T., D'Agostini, S., Skrap, M. & Bonatti, L.L.
(2009). Cortical bases of elementary deductive reasoning: Inference,
memory and meta-deduction. Neuropsychologia, 47, 1107--1111. Reverberi,
D.J., Toraldo, A., D'Agostino, S. & Skrap, M. (2005). Better with
(lateral) prefrontal cortex? Insight problems solved by frontal
patients. Brain, 128, 2882--2890. Rhys, C.S., Ulbrich, C. & Ordin, M.
(2013). Adaptation to aphasia: Grammar, prosody and interaction.
Clinical Linguistics & Phonetics, 27, 46--71. Rice, G.E., Lambon Ralph,
M.A. & Hoffman, P. (2015). The roles of left versus right anterior
temporal lobes in conceptual knowledge: An ALE meta-analysis of 97
functional neuroimaging studies. Cerebral Cortex, 25, 4374--4391.
Richards, B.A. & Frankland, P.W. (2017). The persistence and transience
of memory. Neuron, 94, 1071--1084. Richler, J.J., Cheung, O.S. &
Gauthier, I. (2011). Holistic processing predicts face recognition.
Psychological Science, 22, 464--471. Richter, T. & Späth, P. (2006).
Recognition is used as one cue among others in judgment and decision
making. Journal of Experimental Psychology: Learning, Memory &
Cognition, 32, 150--162. Rickard, T.C. & Pan, S.C. (2018). A dual memory
theory of the testing effect. Psychonomic Bulletin & Review, 25,
847--869.

891

Riddoch, M.J., Humphreys, G.W., Hickman, J.C., Daly, A. & Colin, J.
(2006). I can see what you are doing: Action familiarity and affordance
promote recovery from extinction. Cognitive Neuropsychology, 23,
583--605. Riege, A.H. & Tiegen, K.H. (2017). Everybody will win, and all
must be hired: Comparing additivity neglect with the non-selective
superiority bias. Journal of Behavioral Decision Masking, 30, 95--106.
Riès, S.K. (2016). Serial versus parallel neurobiological processes in
language production: Comment on Munding, Dubarry, and Alario (2015).
Language, Cognition and Neuroscience, 31, 476--479. Rigoli, F., Przzulo,
G., Dolan, R. & Friston, K. (2017). A goal-directed Bayesian framework
for categorization. Frontiers in Psychology, 8 (Article no. 408).
Rimmele, U., Davachi, L. & Phelps, E.A. (2012). Memory for time and
place contributes to enhanced confidence in memories for emotional
events. Emotion, 12, 834--846. Rinck, M. & Becker, E.S. (2005). A
comparison of attentional biases and memory biases in women with social
phobia and major depression. Journal of Abnormal Psychology, 114,
62--74. Ritchie, S.J. (2017). Review of "The Rationality Quotient:
Toward a test of rational thinking" (K.E. Stanovich, R.F. West & M.E.
Toplak). Intelligence, 61, 46. Rizio, A.A. & Dennis, N.A. (2013). The
neural correlates of cognitive control: Successful remembering and
intentional forgetting. Journal of Cognitive Neuroscience, 25, 297--312.
Rizio, A.A. & Dennis, N.A. (2017). Recollection after inhibition: The
effects of intentional forgetting on the neural correlates of retrieval.
Cognitive Neuroscience, 8, 1--8. Rizzolatti, G. & Sinigaglia, C. (2016).
The mirror mechanism: A basic principle of brain function. Nature
Reviews Neuroscience, 17, 757--765. Robbins, T., Anderson, E., Barker,
D., Bradley, A., Fearneyhough, C., Henson, R., et al. (1996). Working
memory in chess. Memory & Cognition, 24, 83--93. Roberts, J., Burkitt,
J.J., Willemse, B., Ludzki, A., Lyons, J., Elliott, D., et al. (2013).
The influence of target context and early and late vision on
goal-directed reaching. Experimental Brain Research, 229, 525--532.
Robertson, D.J., Noyes, E., Dowsett, A.J., Jenkins, R. & Burton, A.M.
(2016). Face recognition by Metropolitan police super-recognisers. PLoS
ONE, 11 (Article no. e0150036). Robertson, I.H., Mattingley, J.B.,
Rorden, C. & Driver, J. (1998). Phasic alerting of neglect patients
overcomes their spatial deficit in visual awareness. Nature, 395,
169--172. Robertson, S.I. (2017). Problem Solving: Perspectives from
cognition and neuroscience (2nd edn). London: Routledge. Robin, J.
(2018). Spatial scaffold effects in event memory and imagination. Wiley
Interdisciplinary Reviews -- Cognitive Science, 9 (Article no. e1462).

892

References

Robin, J. & Moscovitch, M. (2017). Details, gist and schema:
Hippocampal-neocortical interactions underlying recent and remote
episodic and spatial memory. Current Opinion in Behavioral Sciences, 17,
114--123. Robin, J., Wynn, J. & Moscovitch, M. (2016). The spatial
scaffold: The effects of spatial context on memory for events. Journal
of Experimental Psychology: Learning, Memory, and Cognition, 42,
308--315. Robinson, B.L. & McAlpine, D. (2009). Gain control mechanisms
in the auditory pathway. Current Opinion in Neurobiology, 19, 402--407.
Robinson, G.A., Butterworth, B. & Cipolotti, L. (2015). "My mind is
doing it all": No "brake" to stop speech generation in jargon aphasia.
Cognitive and Behavioral Neurology, 28, 229--241. Robison, M.W. &
Unsworth, N. (2018). Cognitive and contextual correlates of spontaneous
and deliberate mind-wandering. Journal of Experimental Psychology:
Learning, Memory and Cognition, 44, 85--98. Rock, P.B., Harris, M.G. &
Yates, T. (2006). A test of the tau-dot hypothesis of braking control.
Journal of Experimental Psychology: Human Perception and Performance,
32, 1479--1484. Rodriguez, L.-F., Gutierrez-Garcia, J.O. & Ramos, F.
(2016). Modelling the interaction of emotion and cognition in autonomous
agents. Biologically Inspired Cognitive Architectures, 17, 57--70.
Roediger, H.L. (2008). Relativity of remembering: Why the laws of memory
vanished. Annual Review of Psychology, 59, 225--254. Roediger, H.L.
(2010). Reflections on intersections between cognitive and social
psychology: A personal exploration. European Journal of Social
Psychology, 40, 189--205. Roediger, H.L. & McDermott, K.B. (2013). Two
types of event memory. Proceedings of the National Academy of Sciences,
110, 20856--20857. Roediger, H.L. & Gallo, D.A. (2001). Levels of
processing: Some unanswered questions. In M. Naveh-Benjamin, M.
Moscovitch & H.L. Roediger (eds), Perspectives on Human Memory and
Cognitive Aging (pp. 28--47). New York: Psychology Press. Rogers, B.
(2016). Revisiting motion parallax as a source of 3-D information.
Perception, 45, 1267--1278. Rogers, B. & Graham, M.E. (1979). Motion
parallax as an independent cue for depth perception. Perception, 8,
125--134. Rogers, T.T. & Patterson, K. (2007). Object categorisations:
Reversals and explanations of the basic-level advantage. Journal of
Experimental Psychology: General, 136, 451--469. Rohde, H. & Ettlinger,
M. (2012). Integration of pragmatic and phonetic cues in spoken word
recognition. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 38, 967--983.

Rohde, M., van Dam, L.C.J. & Ernst, M.O. (2016). Statistically optimal
multisensory cue integration: A practical tutorial. Multisensory
Research, 29, 279--317. Rolls, E.T. & Mills, W.P.C. (2018).
Non-accidental properties, metric invariance, and encoding by neurons in
a model of ventral stream visual object recognition, VisNet.
Neurobiology of Learning and Memory, 152, 20--31. Rorden, C., Hjaltason,
H., Fillmore, P., Fridriksson, J., Kjartansson, O., Magnusdottir, S., et
al. (2012). Allocentric neglect strongly associated with egocentric
neglect. Neuropsychologia, 50, 1151--1157. Rosch, E., Mervis, C.B.,
Gray, W.D., Johnson, D.M. & Boyes-Braem, P. (1976). Basic objects in
natural categories. Cognitive Psychology, 8, 382--439. Rose, N.S.,
Craik, F.I.M. & Buchsbaum, B.R. (2015). Levels of processing in working
memory: Differential involvement of fronto-temporal networks. Journal of
Cognitive Neuroscience, 27, 522--532. Rose, S.B., Aristei, S., Melinger,
A. & Abdel Rahman, R. (2019). The closer they are, the more they
interfere: Semantic similarity of word distractors increases competition
in language production. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 45, 753--763. Rosenbaum, R.S., Kõhler, S.,
Schacter, D.L., Moscovitch, M., Westmacott, R., Black, S.E., et
al. (2005). The case of KC: Contributions of a memory-impaired person to
memory theory. Neuropsychologia, 43, 989--1021. Rosenbloom, P.S., Laird,
J.E. & Lebiere, C. (2017). Précis of "A standard model of the mind".
Advances in Cognitive Systems, 5, 1--4. Rosenholtz, R. (2016).
Capabilities and limitations of peripheral vision. Annual Review of
Vision Science, 2, 437--457. Rosenholtz, R. (2017a). What modern vision
science reveals about the awareness puzzle: Summary-statistic encoding
plus decision limits underlie the richness of visual perception and its
quirky failures. Vision Sciences Society Symposium on Summary Statistics
and Awareness, St. Pete Beach, FL, preprint arXiv:1706.02764.
Rosenholtz, R. (2017b). Capacity limits and how the visual system copes
with them. Electronic Imaging, 14, 8--23. Rosenholtz, R., Huang, J. &
Ehinger, K.A. (2012). Rethinking the role of top-down attention in
vision: Effects attributable to a lossy representation in peripheral
vision. Frontiers in Psychology, 3 (Article no. 13). Rosenholtz, R.,
Sharan, L. & Park, E. (2016). Why don't we see the gorilla? Looking in
the wrong places, attending to the wrong stuff, or doing the wrong task?
Journal of Vision, 16, 43. Rosenthal, G., Sporns, O. & Avidan, G.
(2017). Stimulusdependent dynamic reorganisation of the human face
processing network. Cerebral Cortex, 27, 4823--4834.

References Ross, C.T. (2015). A multi-level Bayesian analysis of racial
bias in police shootings at the county-level in the United States,
2011--2014. PLoS ONE, 10 (Article no. e0141854). Ross, D.A.,
Tamber-Rosenau, B.J., Palmeri, T.J., Zhang, J.D., Xu, Y.D. & Gauthier,
I. (2018). High-resolution functional magnetic resonance imaging reveals
configural processing of cars in right anterior fusiform face area of
car exprts. Journal of Cognitive Neuroscience, 30, 973--984. Ross, D.F.,
Ceci, S.J., Dunning, D. & Toglia, M.P. (1994). Unconscious transference
and mistaken identity: When a witness misidentifies a familiar but
innocent person. Journal of Applied Psychology, 79, 918--930. Rossetti,
Y. & Pisella, A. (2018). Optic ataxia: Beyond the dorsal stream cliché.
Handbook of Clinical Neurology, 151, 225--247. Rossetti, Y., Pisella, L.
& McIntosh, R.D. (2017). Rise and fall of the two visual systems theory.
Annals of Physical and Rehabilitation Medicine, 60, 130--140. Rossion,
B. & Curran, T. (2010). Visual expertise with pictures of cars
correlates with RT magnitude of the car inversion effect. Perception,
39, 173--183. Rossit, S., Harvey, M., Butler, S.H., Szymanek, L.,
Morand, S., Monaco, S. & McIntosh, R.D. (2018). Impaired peripheral
reaching and on-line corrections in patient DF: Optic ataxia with visual
form agnosia. Cortex, 98, 84--101. Rothkirch, M. & Hesselmann, G.
(2017). What we talk about when we talk about unconscious processing --
A plea for best practices. Frontiers in Psychology, 8 (Article no. 835).
Rounis, E., Maniscalco, B., Rothwell, J.C., Passingham, R.E. & Lau, H.
(2010). Theta-burst transcranial magnetic stimulation to the prefrontal
cortex impairs metacognitive visual awareness. Cognitive Neuroscience,
1, 165--175. Roussel, M., Lhommée, E., Narme, P., Czernecki, V., LeGall,
D., Krystkowiak, P., et al. (2017). Dysexecutive syndrome in Parkinson's
disease: The GREFEX study. Aging, Neuropsychology, and Cognition, 24,
496--507. Roux, S. & Bonin, P. (2016). "RED" matters when naming "CAR":
The cascading activation of non-target properties. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 42, 475--488.
Rowe, M.L. (2008). Child-directed speech: Relation to socioeconomic
status, knowledge of child development and child vocabulary skill.
Journal of Child Language, 35, 185--205. Rowland, C.A. (2014). The
effect of testing versus restudy on retention: A meta-analytic review of
the testing effect. Psychological Bulletin, 140, 1432--1463. Roy, D.F.
(1991). Improving recall by eyewitnesses through the cognitive
interview: Practical applications and

893

implications for the police service. The Psychologist, 4, 398--400.
Rubin, D.C. & Berntsen, D. (2003). Life scripts help to maintain
autobiographical memories of highly positive, but not negative, events.
Memory & Cognition, 31, 1--14. Rubin, D.C. & Schulkind, M.D. (1997). The
distribution of important and word-cued autobiographical memories in
20-, 35-, and 70-year-old adults. Psychology of Aging, 12, 524--535.
Rubin, D.C. & Wenzel, A.E. (1996). One hundred years of forgetting: A
quantitative description of retention. Psychological Bulletin, 103,
734--760. Rubin, D.C., Wetzler, S.E. & Nebes, R.D. (1986).
Autobiographical memory across the life span. In D.C. Rubin (ed.),
Autobiographical Memory (pp. 202--222). Cambridge: Cambridge University
Press. Rubin, G.D., Roos, J.E., Tall, M., Harrawood, B., Bag, S., Ly,
D.L., Seaman, D.M., et al. (2015). Characterising search, recognition,
and decision in the detection of lung nodules on CY scans. Radiology,
274, 276--286. Rubin, R.D., Brown-Schmidt, S., Duff, M.C., Tranel, D. &
Cohen, N.J. (2011). How do I remember that I know you know that I know?
Psychological Science, 22, 1574--1582. Ruffieux, N., Ramon, M., Lao, J.,
Colombo, F., Stacchi, L., Borruat, F.-X., et al. (2016). Residual
perception of biological motion in cortical blindness. Neuropsychologia,
93, 301--311. Rumelhart, D.E. & Ortony, A. (1977). The representation of
knowledge in memory. In R.C. Anderson, R.J. Spiro & W.E. Montague (eds),
Schooling and the Acquisition of Knowledge (pp. 99--135). Hillsdale, NJ:
Lawrence Erlbaum Associates. Rumelhart, D.E., McClelland, J.L. & The PDP
Research Group (eds) (1986). Parallel Distributed Processing, Vol. 1:
Foundations. Cambridge, MA: MIT Press. Rummel, J., Einstein, G.O. &
Rampey, H. (2012). Implementation-intention encoding in a prospective
memory task enhances spontaneous retrieval of intentions. Memory, 20,
803--817. Rummel, J., Smeekens, B. & Kane, M.J. (2017). Dealing with
prospective memory demands while performing an ongoing task: Shared
processing, increased on-task focus, or both? Journal of Experimental
Psychology: Learning, Memory and Cognition, 43, 1047--1062. Rusconi, E.,
Ferri, F., Viding, E. & Mithener-Nissen, T. (2015). XRIndex: A brief
screening tool for individual differences in security threat detection
in x-ray images. Frontiers in Human Neuroscience, 9 (Article no. 439).
Rustemeier, M., Schwabe, L. & Bellebaum, C. (2013). On the relationship
between learning strategy and feedback processing in the weather
prediction task -- Evidence from event-related potentials.
Neuropsychologia, 51, 695--703.

894

References

Rusting, C.L. & DeHart, T. (2000). Retrieving positive memories to
regulate negative mood: Consequences for mood-congruent memory. Journal
of Personality and Social Psychology, 78, 737--752. Ruthruff, E.,
Johnston, J.C. & Remington, R.W. (2009). How strategic is the central
bottleneck: Can it be overcome by trying harder? Journal of Experimental
Psychology: Human Perception and Performance, 35, 1368--1384. Ryskin,
R., Futrell, R., Kiran, S. & Gibson, E. (2018). Comprehenders model the
nature of noise in the environment. Cognition, 181, 141--150. Ryu, J. &
Lee, S.-H. (2018). Stimulus-tuned structure of correlated fMRI activity
in human visual cortex. Cerebral Cortex, 28, 693--712. Sabri, M.,
Humphries, C., Verber, M., Mangalathu, J., Desai, A., Binder, J.R., et
al. (2013). Perceptual demand modulates activation of human auditory
cortex in response to task-irrelevant sounds. Journal of Cognitive
Neuroscience, 25, 1553--1562. Sadeh, T., Ozubko, J.D., Winocur, G. &
Moscovitch, M. (2016). Forgetting patterns differentiate between two
forms of memory representation. Psychological Science, 27, 810--820.
Sadeh, T., Shohamy, D., Levy, D.R., Reggev, N. & Maril, A. (2011).
Cooperation between the hippocampus and the striatum during episodic
encoding. Journal of Cognitive Neuroscience, 23, 1597--1608. Saenen, L.,
Heyvaert, M., van Dooren, W. & Onghena, P. (2015). Inhibitory control in
a notorious brain teaser: The Monty Hall dilemma. ZDN Mathematics
Education, 47, 837--848. Sævland, W. & Norman, E. (2016). Studying
different tasks of implicit learning across multiple test sessions
conducted on the web. Frontiers in Psychology, 7 (Article no. 808).
Sakreida, K., Effnert, I., Thill, S., Menz, M.M., Jirak, D., Eickhoff,
C.R., et al. (2016). Affordance processing in segregated parieto-frontal
dorsal stream subpathways. Neuroscience and Biobehavioral Reviews, 69,
80--112. Sala, G. & Gobet, F. (2017). Experts' memory superiority for
domain-specific random material generalizes across fields of expertise:
A meta-analysis. Memory & Cognition, 45, 183--193. Sala, G., Foley, J.P.
& Gobet, F. (2017). The effects of chess instruction on pupils'
cognitive and academic skills: State of the art and theoretical
challenges. Frontiers in Psychology, 8 (Article no. 238). Salvucci, D.D.
& Taatgen, N.A. (2008). Threaded cognition: An integrated theory of
concurrent multitasking. Psychological Review, 115, 101--130. Salvucci,
D.D. & Taatgen, N.A. (2011). Toward a unified view of cognitive control.
Topics in Cognitive Science, 3, 227--230.

Sampson, M. & Faroqui-Shah, Y. (2011). Investigation of self-monitoring
in fluent aphasia with jargon. Aphasiology, 25, 505--528. Samuel, A.G.
(2011). Speech perception. Annual Review of Psychology, 62, 49--72.
Samuelson, W. & Zeckhauser, R.J. (1988). Status quo bias in decision
making. Journal of Risk and Uncertainty, 1, 7--59. Sanbonmatsu, D.M.,
Posavac, S.S., Behrends, A.A., Moore, S.M. & Uchino, B.N. (2015). Why a
confirmation strategy dominates psychological science. PLoS ONE, 10
(Article no. e01138197). Sanbonmatsu, D.M., Strayer, D.L., Biondi, F.,
Behrends, A.A. & Moore, S.M. (2016a). Cell-phone use diminishes
self-awareness of impaired driving. Psychonomic Bulletin & Review, 23,
617--623. Sanbonmatsu, D.M., Strayer, D.L., Biondi, F., Behrends, A.A.,
Ward, N. & Watson, J.M. (2016b). Why drivers use cell phones and support
legislation to restrict this practice. Accident Analysis and Prevention,
92, 22--33. Sanborn, A.N. & Chater, N. (2016). Bayesian brains without
probabilities. Trends in Cognitive Sciences, 20, 883--893. Sand, K.,
Habekost, T., Petersen, A. & Starrfelt, R. (2016). The word superiority
effect in central and peripheral vision. Visual Cognition, 24, 293--303.
Sandberg, K., Timmermans, B., Overgaard, M. & Cleeremans, A. (2010).
Measuring consciousness: Is one measure better than the others?
Consciousness and Cognition, 19, 1069--1078. Sandler, W., Meir, I.,
Padden, C. & Aronoff, M. (2005). The emergence of grammar: Syntactic
structure in a new language. Proceedings of the National Academy of
Sciences of the United States of America, 102, 2661--2665. Sanocki, T.,
Bowyer, K.W., Heath, M.D. & Sarkar, S. (1998). Are edges sufficient for
object recognition? Journal of Experimental Psychology: Human Perception
& Performance, 24, 340--349. Santangelo, V., Cavallina, C., Colucci, P.,
Santori, A., Macri, S., McGaugh, J.L. & Campolongo, P. (2018). Enhanced
brain activity associated with memory access in highly superior
autobiographical memory. Proceedings of the National Academy of
Sciences, 115, 7795--7800. Saposnik, G., Redelmeier, D., Ruff, C.C. &
Tobler, P.N. (2016). Cognitive biases associated with medical decisions:
A systematic review. BMC Medical Informatics and Decision Making, 16
(Article no. 138). Sari, D.A., Koster, E.H.W., Pourtois, G. & Derakshan,
N. (2016). Training working memory to improve attentional control in
anxiety: A proof-of-principle study using behavioural and
electrophysiological measures. Biological Psychology, 121, 203--212.
Sarri, M., Ruff, C.C., Rees, G. & Driver, J. (2010). Neural correlates
of visual extinction or awareness in a series of

References patients with right temporo-parietal damage. Cognitive
Neuroscience, 1, 16--25. Sato, K. & Matsushima, K. (2006). Effects of
audience awareness on procedural text writing. Psychological Reports,
99, 51--73. Savage, L.J. (1954). The Foundations of Statistics. New
York: Wiley. Savelsbergh, G.J.P., Pijpers, J.R. & van Santvoord, A.A.M.
(1993). The visual guidance of catching. Experimental Brain Research,
93, 148--156. Savitsky, K., Keysar, B., Epley, N., Carter, T. & Swanson,
A. (2011). The closeness-communication bias: Increased egocentrism among
friends versus strangers. Journal of Experimental Social Psychology, 47,
269--273. Saygin, A.P. (2007). Superior temporal and premotor brain
areas necessary for biological motion perception. Brain, 130,
2452--2461. Scalici, F., Caltagirone, C. & Caresimo, G.A. (2017). The
contribution of different prefrontal cortex regions to recollection and
familiarity: A review of fMRI data. Neuroscience and Biobehavioral
Reviews, 83, 240--251. Schacter, D.L. & Addis, D.R. (2007). The
cognitive neuroscience of constructive memory: Remembering the past and
imagining the future. Philosophical Transactions of the Royal Society B:
Biological Sciences, 362, 773--786. Schacter, D.L. & Church, B.A.
(1995). Implicit memory in amnesic patients: When is auditory priming
spared? Journal of the International Neuropsychological Society, 1,
434--442. Schacter, D.L., Addis, D.R., Hassabis, D., Martin, V.C.,
Spreng, R.N. & Szpunar, K.K. (2012). The future of memory: Remembering,
imagining, and the brain. Neuron, 76, 677--694. Schacter, D.L. & Madore,
K.P. (2016). Remembering the past and imagining the future: Identifying
and enhancing the contribution of episodic memory. Memory Studies, 9,
245--255. Schacter, D.L. & Tulving, E. (1994). What are the memory
systems of 1994? In D.L. Schacter & E. Tulving (eds), Memory Systems
(pp. 1--38). Cambridge, MA: MIT Press. Schacter, D.L., Church, B.A. &
Bolton, E. (1995). Implicit memory in amnesic patients: Impairment of
voice-specific impairment priming. Psychological Science, 6, 20--25.
Schad, D.J. & Engbert, R. (2012). The zoom lens of attention: Simulating
shuffled versus normal text reading using the SWIFT model. Visual
Cognition, 20, 391--421. Schartau, P.E.S., Dalgleish, T. & Dunn, B.D.
(2009). Seeing the bigger picture: Training in perspective broadening
reduces self-reported affect and psychophysiological response to
distressing films and autobiographical memories. Journal of Abnormal
Psychology, 118, 15--27. Schechter, E. (2012). The switch model of
split-brain consciousness. Philosophical Psychology, 25, 203--226.

895

Schenk, T. & McIntosh, R.D. (2010). Do we have independent visual
streams for perception and action? Cognitive Neuroscience, 1, 52--62.
Scherer, K.R. & Ellsworth, P.C. (2009). Appraisal theories. In D. Sander
& K.R. Scherer (eds), The Oxford Companion to Emotion and the Affective
Sciences (pp. 45--49). Oxford: Oxford University Press. Scherer, L.D.,
Shaffer, V.A., Caverly, T., Scherer, A.M., Zikmund-Fisher, B.J.,
Kullgren, J.T., et al. (2018). The role of the affect heuristic and
cancer anxiety in responding to negative information about medical
tests. Psychology & Health, 33, 292--312. Scherman, A.Z. (2013).
Cultural life script theory and the reminiscence bump: A re-analysis of
seven studies across cultures. Nordic Psychology, 65, 103--119.
Schiffer, F., Zaidel, E., Bogen, J. & Chasan-Taber, S. (1998). Different
psychological status in the two hemispheres of two split-brain patients.
Neuropsychiatry, Neuropsychology, and Behavioral Neurology, 11,
151--156. Schmidt, J.R. & Thompson, V.A. (2008). "At least one" problem
with "some" formal reasoning paradigms. Memory & Cognition, 36,
217--239. Schmidt, S., Tinti, C., Fantino, M., Mammarella, I.C. &
Cornoldi, C. (2013). Spatial representations in blind people: The role
of strategies and mobility skills. Acta Psychologica, 142, 43--50.
Schmidtmann, G., Jennings, B.J. & Kingdom, F.A.A. (2015). Shape
recognition: Convexities, concavities and things in between. Scientific
Reports, 5 (Article no. 17142). Schneider, W. & Shiffrin, R.M. (1977).
Controlled and automatic human information processing: I. Detection,
search, and attention. Psychological Review, 84, 1--66. Schnuerch, R.,
Kreitz, C., Gibbons, H. & Memmert, D. (2016). Not quite so blind:
Semantic processing despite inattentional blindness. Journal of
Experimental Psychology: Human Perception and Performance, 42, 459--463.
Scholte, H.S., Wittreveen, S.C., Soekreijse, H. & Lamme, V.A.F. (2006).
The influence of inattention on the neural correlates of scene
segregation. Brain Research, 1076, 106--115. Schotter, E.R., Angela, B.
& Rayner, K. (2012). Parafoveal processing in reading. Attention,
Perception & Psychophysics, 74, 5--35. Schouten, D.I., Pereira, S.I.R.,
Tops, M. & Louzada, F.M. (2017). State of the art on targeted memory
reactivation: Sleep your way to enhanced cognition. Sleep Medicine
Reviews, 32, 123--131. Schraagen, J.M. (2018). Naturalistic decision
making. In L.J. Ball & V.A. Thompson (eds), Routledge International
Handbook of Thinking and Reasoning (pp. 487--501). Abingdon, Oxon.:
Routledge. Schulz, D.P.A., Sahani, M. & Carandini, M. (2015). Five key
factors determining pairwise correlations in visual cortex. Journal of
Neurophysiology, 114, 1022--1033.

896

References

Schumacher, E.H., Seymour, T.L., Glass, J.M., Fencsik, D.E., Lauber,
E.J., Kieras, D.E., et al. (2001). Virtually perfect time sharing in
dual-task performance: Uncorking the central cognitive bottleneck.
Psychological Science, 12, 101--108. Schwark, J., Sandry, J., MacDonald,
J. & Dolgov, I. (2012). False feedback increases detection of
low-prevalence targets in visual search. Attention, Perception &
Psychophysics, 74, 1583--1589. Schwartz, B., Ward, A., Monterosso, J.,
Lyubormirsky, S., White, K. & Lehman, D.R. (2002). Maximising versus
satisficing: Happiness is a matter of choice. Journal of Personality and
Social Psychology, 83, 1178--1197. Schwartz, B.L. & Hashtroudi, S.
(1991). Priming is independent of skill learning. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 17,
1177--1187. Schwartz, J., Chapman, G., Brewer, N. & Bergus, G. (2004).
The effects of accountability on bias in physician decision making:
Going from bad to worse. Psychonomic Bulletin & Review, 11, 173--178.
Schwarz, N. & Clore, G.L. (1983). Mood, misattribution, and judgements
of well-being -- Informative and directive functions of affective
states. Journal of Personality and Social Psychology, 45, 513--523.
Schwartz, S., Vuilleumier, P., Hutton, C., Marouta, A., Dolan, R.J. &
Driver, J. (2005). Modulation of fMRI responses by load at fixation
during task-irrelevant stimulation in the peripheral visual field.
Cerebral Cortex, 15, 770--786. Schwartz, Z.P. & David, S.V. (2018).
Focal suppression of distractor sounds by selective attention in
auditory cortex. Cerebral Cortex, 28, 323--339. Schweinberger, S.R. &
Soukup, G.R. (1998). Asymmetric relationships among perceptions of
facial identity, emotion and facial speech. Journal of Experimental
Psychology: Human Perception and Performance, 24, 1748--1765. Schweizer,
T.A., Kan, K., Hung, Y., Tam, F., Naglie, G. & Graham, S.J. (2013).
Brain activity during driving with distraction: An immersive fMRI study.
Frontiers in Human Neuroscience, 7 (Article no. 53). Schweppe, J.,
Grice, M. & Rummer, R. (2011). What models of verbal working memory can
learn from phonological theory: Decomposing the phonological similarity
effect. Journal of Memory and Language, 64, 256--269. Schwieren, J.,
Barenberg, J. & Dutke, S. (2017). The testing effect in the psychology
classroom: A meta-analytic perspective. Psychology Learning and
Teaching, 16, 179--196. Scott-Phillips, T.C. (2015). Nonhuman primate
communication, pragmatics, and the origins of language. Current
Anthropology, 56, 56--66. Scoville, W.B. & Milner, B. (1957). Loss of
recent memory after bilateral hippocampal lesions. Journal of Neurology,
Neurosurgery & Psychiatry, 20, 11--21.

Scullin, M.K., McDaniel, M.A., Dasse, M.N., Lee, J.H., Kurinac, C.A.,
Tami, C., et al. (2018). Thought probes during prospective memory
encoding: Evidence for perfunctory processes. PLoS ONE, 13 (Article no.
e0198646). Scullin, M.K., McDaniel, M.A., Shelton, J.T. & Lee, J.H.
(2010). Focal/nonfocal cue effects in prospective memory: monitoring
diﬃculty or different retrieval processes? Journal of Experimental
Psychology: Learning, Memory, and Cognition, 36, 736--749. Scullin,
M.K., Kurinec, C.A. & Nguyen, K. (2017). The effects of implementation
intention strategies on prospective memory cue encoding. Journal of
Cognitive Psychology, 29, 929--938. Scully, I.D., Napper, L.E. &
Hupbach, A. (2017). Does reactivation trigger episodic memory change? A
meta-analysis. Neurobiology of Learning and Memory, 142, 99--107.
Searston, R.A., Tangen, J.M. & Eva, K.W. (2016). Putting bias into
context: The role of familiarity in identification. Law and Human
Behavior, 40, 50--64. Sebastianelli, L., Saltuari, L. & Nardone, R.
(2017). How the brain can rewire itself after an injury: The lesson from
hemispherectomy. Neural Regeneration Research, 12, 1426--1427. Sedgwick,
H.A. & Gillam, B. (2017). A non-modular approach to visual space
perception. Ecological Psychology, 29, 72--94. Segaert, K., Weber, K.,
de Lange, F.P., Petersson, K.M. & Hagoort, P. (2013). The suppression of
repetition enhancement: A review of fMRI studies. Neuropsychologia, 51,
59--66. Sekeres, M.J., Bonasia, K., St-Laurent, M., Pishdadian, S.,
Winocur, G., Grady, C., et al. (2016). Recovering and preventing loss of
detailed memory: Differential rates of forgetting for detail types in
episodic memory. Learning and Memory, 23, 72--82. Senghas, A., Kita, S.
& Őzyűrek, A. (2004). Children creating core properties of language:
Evidence from emerging sign language in Nicaruagua. Science, 305,
1779--1782. Seo, M.-G. & Barrett, L.F. (2007). Being emotional during
decision making -- Good or bad? An empirical investigation. Academy of
Management Journal, 50, 923--940. Seymour, K., Clifford, C.W.G.,
Logothetis, N.K. & Bartels, A. (2009). The coding of color, motion and
their conjunction in the human visual cortex. Current Biology, 19,
177--183. Seymour, K.J., Williams, M.A. & Rich, A.N. (2016). The
representation of colour across the human visual cortex: Distinguishing
chromatic signals contributing to object form versus surface colour.
Cerebral Cortex, 26, 1997--2008. Shallice, T. (2015). Cognitive
neuropsychology and its vicissitudes: The fate of Caramazza's axioms.
Cognitive Neuropsychology, 32, 385--411.

References Shallice, T. & Cipiolotti, L. (2018). The prefrontal cortex
and neurological impairments of active thought. Annual Review of
Psychology, 69, 157--180. Shallice, T. & Warrington, E.K. (1970).
Independent functioning of verbal memory stores: A neuropsychological
study. Quarterly Journal of Experimental Psychology, 22, 261--273.
Shallice, T. & Warrington, E.K. (1974). The dissociation between
long-term retention of meaningful sounds and verbal material.
Neuropsychologia, 12, 553--555. Shamma, S.A., Elhilali, M. & Micheyl, C.
(2011). Temporal coherence and attention in auditory scene analysis.
Trends in Neurosciences, 34, 114--123. Shanks, D.R. (2010). Learning:
From association to cognition. Annual Review of Psychology, 61,
273--301. Shanks, D.R. (2017). Regressive research: The pitfalls of post
hoc data selection in the study of unconscious mental processes.
Psychonomic Bulletin & Review, 24, 752--775. Shanks, D.R. & St. John,
M.F. (1994). Characteristics of dissociable human learning systems.
Behavioral and Brain Sciences, 17, 367--394. Sharan, L., Park, E. &
Rosenholtz, R. (2016). Difficulty detecting changes in complex scenes
depends in part upon the strengths and limitations of peripheral vision.
Unpublished manuscript, Massachusetts Institute of Technology,
Cambridge, MA. Share, D.L. (2008). On the Anglocentricities of current
reading research and practice: The perils of over-reliance on an
"outlier" orthography. Psychological Bulletin, 134, 584--615. Sharot, T.
& Yonelinas, A.P. (2008). Differential timedependent effects of emotion
on recollective experience and memory for contextual information.
Cognition, 106, 538--547. Sharot, T., Martorella, E.A., Delgado, M.R. &
Phelps, E.A. (2007). How personal experience modulates the neural
circuitry of memories of September 11. Proceedings of the National
Academy of Sciences of the United States of America, 104, 389--394.
Sharpe, D. (1997). Of apples and oranges, file drawers and garbage: Why
validity issues in meta-analysis will not go away. Clinical Psychology
Review, 17, 881--901. Sheffer, L., Loewen, P.J., Soroka, S., Walgrave,
S. & Sheafer, T. (2018). Non-representative representatives: An
experimental study of the decision making of elected politicians.
American Political Science Review, 112, 302--321. Shelton, J.R. &
Weinrich, M. (1997). Further evidence of a dissociation between output
phonological and orthographic lexicons: A case study. Cognitive
Neuropsychology, 14, 105--129. Shelton, J.T. & Christopher, E.A. (2016).
A fresh pair of eyes on prospective memory monitoring. Memory &
Cognition, 44, 837--845.

897

Shelton, J.T. & Scullin, M.K. (2017). The dynamic interplay between
bottom-up and top-down processes supporting prospective remembering.
Current Directions in Psychological Science, 26, 352--358. Shen, W.,
Olive, J. & Jones, D. (2008). Two protocols comparing human and machine
phonetic discrimination performance in conversational speech.
INTERSPEECH, 1630--1633. Shen, W., Tung, Y., Yuan, Y., Zhan, H., Liu,
Luo, J., et al. (2018). Feeling the insight: Uncovering somatic markers
of the "aha" experience. Applied Psychophysiology and Biofeedback, 43,
13--21. Sheppes, G., Scheibe, S., Suri, G., Radu, P., Blechert, J. &
Gross, J.J. (2014). Emotion regulation choice: A conceptual framework
and supporting evidence. Journal of Experimental Psychology: General,
143, 163--181. Sheridan, H. & Reichle, E.D. (2016). An analysis of the
time course of lexical processing during reading. Cognitive Science, 40,
522--553. Sheridan, H. & Reingold, E.M. (2013). A further examination of
the lexical-processing stages hypothesised by the E-Z Reader model.
Attention, Perception & Psychophysics, 75, 407--414. Sheridan, H. &
Reingold, E.M. (2017a). Chess players' eye movements reveal rapid
recognition of complex visual patterns: Evidence from a chess-related
visual search task. Journal of Vision, 4, 1--12. Sheridan, H. &
Reingold, E.M. (2017b). The holistic processing account of visual
expertise in medical image perception: A review. Frontiers in
Psychology, 8 (Article no. 1620). Shevell, S.K. & Martin, P.R. (2017).
Colour opponency: Tutorial. Journal of the Optical Society of America A,
34, 1099--1110. Shifferman, E. (2015). More than meets the fMRI: The
unethical apotheosis of neuroimages. Journal of Cognition and
Neuroethics, 3, 57--116. Shiffrar, M. & Thomas, J.P. (2013). Beyond the
scientific objectification of the human body: Differentiated analyses of
human motion and object motion. In M. Rutherford and V. Kuhlmeier (eds),
Social Perception: Detection and interpretation of animacy, agency, and
intention (pp. 83--108). Cambridge, MA: MIT Press/ Bradford Books.
Shiffrin, R.M. & Schneider, W. (1977). Controlled and automatic human
information processing: II. Perceptual learning, automatic attending,
and a general theory. Psychological Review, 84, 127--190. Shimizu, R.E.,
Wum A.D., Samra, J.K. & Knowlton, B.J. (2017). The impact of cerebellar
transcranial direct current stimulation (tDCS) on learning fine-motor
sequences. Philosophical Transactions of the Royal Society B, 372
(Article no. 20160050). Shiota, M.N., Campos, B., Oveis, C.,
Hertenstein, M.J., Simon-Thomas, E. & Keltner, D. (2017). Beyond

898

References

happiness: Building a science of discrete positive emotions. American
Psychologist, 72, 617--643. Shipstead, Z., Harrison, T.L. & Engle, R.W.
(2016). Working memory capacity and fluid intelligence: Maintenance and
disengagement. Perspectives on Psychological Science, 11, 771--799.
Shiv, B., Loewenstein, G. & Bechara, A. (2005). The dark side of emotion
in decision making: When individuals with decreased emotional reactions
make more advantageous decisions. Cognitive Brain Research, 23, 85--92.
Shomstein, S., Lee, J. & Behrmann, M. (2010). Top-down and bottom-up
attentional guidance: Investigating the role of the dorsal and ventral
parietal cortices. Experimental Brain Research, 206, 197--208. Shrem,
T., Murray, M.M. & Deouell, L.Y. (2017). Auditoryvisual integration
modulates location-specific repetition suppression of auditory
responses. Psychophysiology, 54, 1663--1675. Shrout, P.E. & Rodgers,
J.L. (2018). Psychology, science, and knowledge construction: Broadening
perspectives from the replication crisis. Annual Review of Psychology,
69, 487--510. Sides, A., Osherson, D., Bonni, N. & Viale, R. (2002). On
the reality of the conjunction fallacy. Memory & Cognition, 30,
191--198. Sidi, Y., Ophir, Y. & Ackerman, R. (2016). Generalising screen
inferiority -- Does the medium, screen versus paper, affect performance
even with brief tasks? Metacognition Learning, 11, 15--33. Sidi, Y.,
Shpigelman, M., Zalmanov, H. & Ackerman, R. (2017). Understanding
metacognitive inferiority on screen by exposing cues for depth of
processing. Learning and Instruction, 51, 61--73. Siebert, M.,
Markowitsch, H.J. & Bartel, P. (2003). Amygdala, affect and cognition:
Evidence from 10 patients with Urbach-Wiethe disease. Brain, 126,
2627--2637. Siegel, E.H., Sands, M.K., Van den Noortgate, W., Condon,
P., Chang, Y., Dy, J., et al. (2018). Emotion fingerprints or emotion
populations? A meta-analytic investigation of autonomic features of
emotion categories. Psychological Bulletin, 144, 343--393. Siegert, R.,
Weatherall, M., Taylor, K.D. & Abernethy, D. (2008). A meta-analysis of
performance on simple span and more complex working memory tasks in
Parkinson's disease. Neuropsychology, 22, 450--461. Sigurdardottir,
H.M., Fridriksdottir, L.E., Gudjonsdottir, S. & Kristjánsson, A. (2018).
Cognition, 175, 157--168. Silbert, L.J., Honey, C.J., Simony, E.,
Poeppel, D. & Hasson, U. (2014). Coupled neural systems underlie the
production and comprehension of naturalistic narrative speech.
Proceedings of the National Academy of Sciences, 111, E4687--E4696.
Simion, F., Regolin, L. & Bulf, H. (2008). A predisposition for
biological motion in the newborn baby. Proceedings

of the National Academy of Sciences of the United States of America,
105, 809--813. Simmons, J.P., Nelson, L.D. & Simonsohn, U. (2018).
Falsepositive citations. Perspectives on Psychological Science, 13,
255--259. Simmons, S.M., Hicks, A. & Caird, J.K. (2016). Safety-critical
event risk associated with cell phone tasks as measured in naturalistic
driving studies: A systematic review and meta-analysis. Accident
Analysis and Prevention, 67, 161--169. Simon, D., Krawczyk, D.C. &
Holyoak, K.J. (2004). Construction of preferences by constraint
satisfaction. Psychological Science, 15, 331--336. Simon, H.A. (1945).
Theory of games and economic behaviour. American Sociological Review,
50, 558--560. Simon, H.A. (1957). Models of Man: Social and rational.
New York: Wiley. Simon, H.A. (1966). Scientific discovery and the
psychology of problem solving. In H.A. Simon (ed.), Mind and Cosmos:
Essays in contemporary science and philosophy (pp. 22--40). Pittsburgh,
PA: University of Pittsburgh Press. Simon, H.A. (1974). How big is a
chunk? Science, 183, 482--488. Simon, H.A. (1990). Invariants of human
behaviour. Annual Review of Psychology, 41, 1--19. Simons, D.J. &
Chabris, C.F. (1999). Gorillas in our midst: Sustained inattentional
blindness for dynamic events. Perception, 28, 1059--1074. Simons, D.J. &
Chabris, C.F. (2011). What people believe about how memory works: A
representative survey of the US population. Public Library of Science
One, 6 (Article no. e22757). Simonson, I. & Staw, B.M. (1992).
De-escalation strategies: A comparison of techniques for reducing
commitment to losing courses of action. Journal of Applied Psychology,
77, 419--426. Sinai, M.J., Ooi, T.L. & He, Z.J. (1998). Terrain
influences the accurate judgment of distance. Nature, 395, 497--500.
Singer, W. & Gray, C.M. (1995). Visual feature integration and the
temporal correlation hypothesis. Annual Review of Neuroscience, 18,
555--586. Singmann, H., Klauer, K.C. & Beller, S. (2016). Probabilistic
conditional reasoning: Disentangling form and content with the
dual-source model. Cognitive Psychology, 88, 61--87. Sio, U.N. &
Ormerod, T.C. (2009). Does incubation enhance problem solving? A
meta-analytic review. Psychological Bulletin, 135, 94--120. Sio, U.N. &
Ormerod, T.C. (2015). Incubation and cueing effects in problem-solving:
Set aside the difficult problems but focus on the easy ones. Thinking &
Reasoning, 21, 113--129.

References Sitek, E.J., Narozanska, E., Barczak, A., Jasinska-Myga, B.,
Harciarek, M., Chodakowska-Zebrowska, M., et al. (2014). Agraphia in
patients with frontotemporal dementia and parkinsonism linked to
chromosome 17 with P301L MAPT mutation: Dysexecutive, aphasic, apraxic
or spatial phenomenon? Neurocase, 20, 69--86. Skinner, B.F. (1957).
Verbal Behaviour. New York: Appleton-Century-Crofts. Skinner, E.I. &
Femandes, M.A. (2007). Neural correlates of recollection and
familiarity: A review of neuroimaging and patient data.
Neuropsychologia, 45, 2163--2179. Skipper, J.I., Devlin, J.T. & Lametti,
D.R. (2017). The hearing ear is always found close to the speaking
tongue: Review of the role of the motor system in speech perception.
Brain & Language, 164, 77--105. Slevc, L.R., Martin, R.C., Hamilton,
A.C. & Joanisse, M.F. (2011). Speech perception, rapid temporal
processing, and the left hemisphere: A case study of unilateral pure
word deafness. Neuropsychologia, 49, 216--230. Slevc, L.R. & Okala, B.M.
(2015). Processing structure in language and music: A case for shared
reliance on cognitive control. Psychonomic Bulletin & Review, 22,
637--652. Slezak, P. (1991). Can images be rotated and inspected? A test
of the pictorial medium theory. Program of the Thirteenth Annual
Conference of the Cognitive Science Society, Chicago, IL, 55--60.
Slezak, P. (1995). The "philosophical" case against visual imagery. In
T. Caelli, P. Slezak & R. Clark (eds), Perspectives in Cognitive
Science: Theories, experiments and foundations (pp. 237--271). New York:
Ablex. Sliwinska, M.W. & Pitcher, D. (2018). TNS demonstrates that both
right and left superior temporal sulci are important for facial
expression recognition. NeuroImage, 183, 394--400. Sliwinska, M.W.,
Khadilkar, M., Campbell-Ratcliffe, J., Quevenco, F. & Devlin, J.T.
(2012). Early and sustained supramarginal gyrus contributions to
phonological processing. Frontiers in Psychology, 3 (Article no. 161).
Sloman, S., Rottenstreich, Y., Wisniewski, E., Hadjichristidis, C. &
Fox, C.R. (2004). Typical versus atypical unpacking and superadditive
probability judgment. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 30, 573--582. Small, D.A. & Lerner, J.S. (2008).
Emotional policy: Personal sadness and anger shape judgments about a
welfare case. Political Psychology, 29, 149--168. Smith, C.A. & Lazarus,
R.S. (1993). Appraisal components, core relational themes, and the
emotions. Cognition & Emotion, 7, 233--269. Smith, C.N., Frascino, J.C.,
Hopkins, R.O. & Squire, L.R. (2013). The nature of anterograde and
retrograde memory impairment after damage to the medial temporal lobe.
Neuropsychologia, 51, 2709--2714.

899

Smith, C.N., Jeneson, A., Frascino, J.C., Kiswan, C.B., Hopkins, R.O. &
Squire, L.R. (2014). When recognition memory is independent of
hippocampal function. Proceedings of the National Academy of Sciences of
the United States of America, 111, 9935--9940. Smith, E.E. & Jonides, J.
(1997). Working memory: A view from neuroimaging. Cognitive Psychology,
33, 5--42. Smith, E.R. & O'Brien, E.J. (2012). Tracking spatial
information during reading: A cue-based process. Memory & Cognition, 40,
791--801. Smith, R. & Lane, R.D. (2015). The neural basis of one's own
conscious and unconscious emotional states. Neuroscience and
Biobehavioral Reviews, 57, 1--29. Smith, R., Alkozei, A., Bao, J. &
Kilgore, W.D.S. (2018). Successful goal-directed memory suppression is
associated with increased inter-hemispheric co-ordination between right
and left fronto-parietal control networks. Psychological Reports, 121,
93--111. Smith, R.E., Hunt, R.R., McVay, J.C. & McConnell, M.D. (2007).
The cost of event-based prospective memory: Salient target events.
Journal of Experimental Psychology: Learning, Memory, and Cognition, 33,
734--746. Smith, T.J., Lamont, P. & Henderson, J.M. (2012). The penny
drops: Change blindness at fixation. Perception, 41, 490--492. Snell,
J., van Leipsig, S., Grainger, J. & Meeter, M. (2018). OB-1-reader: A
model of word recognition and eye movements in text reading.
Psychological Review, 125, 969--984. Snyder, J.J. & Bischof, W.F.
(2010). Knowing where we're heading -- When nothing moves. Brain
Research, 1323, 127--138. Snyder, K.M., Ashitaka, Shimada, H., Ulrich,
J.E. & Logan, G.D. (2014). What skilled typists don't know about the
QWERTY keyboard. Attention, Perception & Psychophysics, 76, 162--171.
Sohoglu, E., Peelle, J.E., Carlyon, R.P. & Davis, M.D. (2014). Top-down
influences of written text on perceived clarity of degraded speech.
Journal of Experimental Psychology: Human Perception and Performance,
40, 186--199. Sokol-Hessner, P., Camerer, C.F. & Phelps, E.A. (2013).
Emotion regulation reduces loss aversion and decreases amygdala
responses to losses. Social Cognitive and Affective Neuroscience, 8,
341--350. Sokolov, A.A., Zeidman, P., Erb, M., Ryvlin, P., Friston, K.J.
& Pavlova, M.A. (2018). Structural and effective brain connectivity
underlying biological motion detection. Proceedings of the National
Academy of Sciences of the United States of America, 115,
E12034--E12042. Solé, R.V. & Seoane, L.F. (2015). Ambiguity in language
networks. Linguistic Review, 32, 5--35. Söllner, A. & Bröder, A. (2016).
Toolbox or adjustable spanner? A critical comparison of two metaphors
for

900

References

adaptive decision making. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 42, 215--237. Solomon, S.H. & Thompson-Schill,
S.L. (2017). Finding features, figuratively. Brain & Language, 174,
61--71. Song, J.-H. (2017). Abandoning and modifying one action plan for
alternatives. Philosophical Transactions of the Royal Society B, 372
(Article no. 20160195). Song, J.-H. & Nakayama, K. (2008). Target
selection in visual search as revealed by movement trajectories. Vision
Research, 48, 853--861. Soni, M., Lambon Ralph, M.A., Noonan, K., Ehsan,
S., Hodgson, C. & Woollams, A.M. (2009). "L" is for tiger: Effects of
phonological (mis)cueing on picture naming in semantic aphasia. Journal
of Neurolinguistics, 22, 538--547. Soni, M., Lambon Ralph, M.A. &
Woollams, A.M. (2011). "W" is for bath: Can associative errors be cued?
Journal of Neuolinguistics, 24, 445--465. Sörqvist, P. (2010). High
working memory capacity attenuates the deviation effect but not the
duplex-mechanism account of auditory distraction. Memory & Cognition,
38, 651--658. Sörqvist, P., Dahlstrom, Ő., Karlsson, T. & Rönnberg, J.
(2016). Concentration: The neural underpinnings of how cognitive load
shields against distraction. Frontiers in Human Neuroscience, 10
(Article no. 221). Sotiropoulos, A. & Hanley, J.R. (2017). Developmental
surface and phonological dyslexic in both Greek and English. Cognition,
168, 205--216. Soto, D. & Silvanto, J. (2014). Reappraising the
relationship between working memory and conscious awareness. Trends in
Cognitive Sciences, 18, 520--525. Soto-Faraco, S. & Alsius, A. (2009).
Deconstructing the McGurk-MacDonald illusion. Journal of Experimental
Psychology: Human Perception and Performance, 35, 580--587. Sowden, S. &
Catmur, C. (2015). The role of the right temporo-parietal junction in
the control of imitation. Cerebral Cortex, 25, 1107--1113. Spanel, K.,
Wagner, K., Geiger, M.J., Ofer, I., SchulzeBonhage, A. & Metternich, B.
(2018). Flashbulb memories: Is the amygdala central: An investigation of
patients with amygdalar damage. Neuropsychologia, 111, 163--171. Spelke,
E.S., Hirst, W.C. & Neisser, U. (1976). Skills of divided attention.
Cognition, 4, 215--230. Spence, C. (2012). Drive safely with
neuroergonomics. Psychologist, 25, 664--667. Spence, C., Parise, C. &
Chen, Y.-C. (2011). The Colavita visual dominance effect. In M.M. Murray
and M. Wallace (eds), Frontiers in the Neural Bases of Multisensory
Processes (pp. 523--550). Boca Raton, FL: CRC Press.

Sperber, D. & Girotto, V. (2002). Use or misuse of the selection task?
Rejoinder to Fiddick, Cosmides, and Tooby. Cognition, 85, 277--290.
Sperling, G. (1960). The information that is available in brief visual
presentations. Psychological Monographs, 74, 1--29. Sperry, R.W. (1968).
Hemisphere deconnection and unity in conscious awareness. American
Psychologist, 23, 723--733. Spiers, H.J., Maguire, E.A. & Burgess, N.
(2001). Hippocampal amnesia. Neurocase, 7, 357--382. Spiers, M.V.
(2016). The head trauma amnesia cure. Neurology, 86, 2291--2294. Spille,
C. & Meyer, B.T. (2014). Identifying the human-machine differences in
complex binaural scenes: What can be learned from our auditory system.
15th Annual Conference of the International Speech Communication
association (Interspeech 2014), Singapore, Vols. 1--4, 626--630. Squire,
L.R. & Dede, A.J.O. (2015). Conscious and unconscious memory systems.
Cold Spring Harbor Perspectives in Biology, 7 (Article no. a021667).
Squire, L.R., Genzel, L., Wixted, J.T. & Morris, R.G. (2015). Memory
consolidation. Cold Spring Harbor Perspectives in Biology, 7 (Article
no. a021766). Squire, L.R., Slater, P.C. & Chace, P. (1975). Retrograde
amnesia temporal gradient in very long-term memory following
electroconvulsive therapy. Science, 187, 77--79. St. Jacques, P.L.,
Kragel, P.A. & Rubin, D.C. (2011). Dynamic neural networks supporting
memory retrieval. NeuroImage, 57, 608--616. St-Laurent, M., Moscovitch,
M. & McAndrews, M.P. (2016). The retrieval of perceptual memory details
depends on right hippocampal integrity and activation. Cortex, 84,
15--33. Stagg, C.J. & Nitsche, M.A. (2011). Physiological basis of
transcranial direct current stimulation. The Neuroscientist, 17, 37--53.
Stagg, C.J., Antal, A. & Nitsche, M.A. (2018). Physiology of
transcranial direct current stimulation. Journal of ECT, 34, 144--152.
Stanford Encylopedia of Philosophy (2013). Analogy. Retrieved from
http://plato.stanford.edu/entries/reason ing-analogy/. Stange, J.P.,
Hamlat, E.J., Hamilton, J.L., Abramson, L.Y. & Alloy, L.B. (2013).
Overgeneral autobiographical memory, emotional maltreatment, and
depressive symptoms in adolescence: Evidence of a cognitive
vulnerability-stress interaction. Journal of Adolescence, 36, 201--208.
Stanley, D.J. & Spence, J.R. (2014). Expectations for replications: Are
yours realistic? Perspectives on Psychological Science, 9, 305--318.
Stanley, T.D., Carter, E.C. & Doucouliagos, H. (2018). What
meta-analyses reveal about the replicability of psychological research.
Psychological Bulletin, 144, 1325--1346.

References Stanovich, K.E. (2012). On the distinction between
rationality and intelligence: Implications for understanding individual
differences in reasoning. In K.J. Holyoak & R.G. Morrison (eds), The
Oxford Handbook of Thinking and Reasoning (pp. 433--455). Oxford: Oxford
University Press. Stanovich, K.E. (2013). Why humans are (sometimes)
less rational than other animals: Cognitive complexity and the axioms of
rational choice. Thinking & Reasoning, 19, 1--26. Stanovich, K.E.
(2016). The comprehensive assessment of rational thinking. Educational
Psychologist, 51, 23--34. Stanovich, K.E. & Toplak, M.E. (2011).
Defining features versus incidental correlates of Type 1 and Type 2
processing. Mind & Society, 11, 3--13. Stanovich, K.E. & West, R.F.
(2007). Natural myside bias is independent of cognitive ability.
Thinking & Reasoning, 13, 225--247. Stanovich, K.E., West, R.F. &
Toplak, M.E. (2013). Myside bias, rational thinking, and intelligence.
Current Directions in Psychological Science, 22, 259--264. Staub, A.
(2015). The effect of lexical probability on eye movements in reading:
Critical review and theoretical interpretation. Language and Linguistics
Compass, 9, 311--327. Staudigl, T., Vollmar, C., Noachtar, S. &
Hanslmayr, S. (2015). Temporal-pattern similarity analysis reveals the
beneficial and detrimental effects of context reinstatement on human
memory. Journal of Neuroscience, 35, 5373--5384. Steblay, N.K. & Dysart,
J.E. (2016). Repeated eyewitness identification procedures with the same
suspect. Journal of Applied Research in Memory and Cognition, 5, 284
--289. Steblay, N.K. & Phillips, J.D. (2011). The not-sure response
option in sequential lineup practice. Applied Cognitive Psychology, 25,
768--774. Steblay, N.K., Dysart, J.E. & Wells, G.L. (2011). Seventytwo
tests of the sequential lineup superiority effect: A meta-analysis and
policy discussion. Psychology, Public Policy, and Law, 17, 99--139.
Steblay, N.K., Wells, G.L. & Douglass, A.B. (2014). The eyewitness post
identification feedback effect 15 years later: Theoretical and policy
implications. Psychology, Public Policy and Law, 20, 1--18. Steblay,
N.M. (1997). Social influence in eyewitness recall: A meta-analytic
review of line-up instruction effects. Law and Human Behavior, 21,
283--298. Steel, K.A., Baxter, D., Dogramaci, S., Cobley, S. & Ellem, E.
(2016). Can biological motion research provide insight on how to reduce
friendly fire incidents? Psychonomic Bulletin & Review, 23, 1429--1439.
Steiger, A. & Kühberger, A. (2018). A meta-analytic re-appraisal of the
framing effect. Zeitschrift für Psychologie, 226, 45--55.

901

Steinborn, M.B. & Huestegge, L. (2017). Phone conversation while
processing information: Chronometric analysis of load effects in
everyday-media multi-tasking. Frontiers in Psychology, 8 (Article no.
896). Steinhauer, K. & Friederici, A.D. (2001). Prosodic boundaries,
comma rules, and brain responses: The closure positive shift in ERPs as
a universal marker for prosodic phrasing in listeners and readers.
Journal of Psycholinguistic Research, 30, 267--295. Steinmetz, K.R.M.,
Knight, A.G. & Kensinger, E.A. (2016). Neutral details associated with
emotional events are encoded: Evidence from a cued recall paradigm.
Cognition and Emotion, 30, 1352--1360. Stephens, R.G., Dunn, J.C. &
Hayes, B.K. (2018). Are there two processes in reasoning? The
dimensionality of inductive and deductive inferences. Psychological
Review, 125, 218--244. Sternberg, R.J. (2011). Understanding reasoning:
Let's describe what we really think about. Behavioral and Brain
Sciences, 34, 269--270. Steyvers, M. & Hemmer, P. (2012). Reconstruction
from memory In naturalistic environments. In B.H. Ross (ed.), The
Psychology of Learning and Motivation, 56, 126--144. Stivers, T.,
Enfield, N.J., Brown, P., Englert, C., Hayashi, M., Heinemann, T., et
al. (2009). Universals and cultural variation in turn-taking in
conversation. Proceedings of the National Academy of Sciences of the
United States of America, 106, 10587--10592. Storm, J.F., Boly, M.,
Casali, M., Olcese, U., Pennartz, C.M.A. & Wilke, M. (2017).
Consciousness regained: Disentangling mechanisms, brain systems, and
behavioural responses. Journal of Neuroscience, 37, 10882--10893.
Strand, J.F., Brown, V.A., Brown, H.E. & Berg, J.J. (2018). Keep
listening: Grammatical context reduces but does not eliminate activation
of unexpected words. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 44, 962--973. Strayer, D.L. & Drews, F.A. (2007).
Cell-phone induced driver distraction. Current Directions in
Psychological Science, 16, 128--131. Strayer, D.L. & Fisher, D.L.
(2016). SPIDER: A framework for understanding driver distraction. Human
Factors, 58, 5--12. Strayer, D.L., Watson, J.M. & Drews, F.A. (2011).
Cognitive distraction while multitasking in the automobile. The
Psychology of Learning and Motivation, 54, 29--58. Strick, M.,
Dijksterhuis, A., Bos, M.W, Sjoerdsma, A. & Van Baaren, R.B. (2011). A
meta-analysis on unconscious thought effects. Social Cognition, 29,
738--762. Strijkers, K., Costa, A. & Pulvermüller, F. (2017). The
cortical dynamics of speaking: Lexical and phonological knowledge
simultaneously recruit the frontal and temporal cortex within 200 ms.
NeuroImage, 163, 206--219.

902

References

Strobach, T., Antonenko, D., Abarrin, M., Escher, M., Flöel, A. &
Schubert, T. (2018). Modulation of dual-task control with right
prefrontal transcranial direct current stimulation. Experimental Brain
Research, 236, 227--241. Strobach, T., Liepelt, R., Pashler, H.,
Frensch, P.A. & Schubert, T. (2013). Effects of extensive dual-task
practice on processing stages in simultaneous choice tasks. Attention,
Perception & Psychophysics, 75, 900--920. Strong, S.L., Silson, E.H.,
Gonws, A.D., Morland, A.R. & McKeefry, D.J. (2017). Differential
processing of the direction and focus of expansion of optic flow stimuli
in areas MST and V3A of the human visual cortex. Journal of
Neurophysiology, 117, 2209--2217. Studer, B., Manes, F., Humphreys, G.,
Robbins, T.W. & Clark, L. (2015). Risk-sensitive decision-making in
patients with posterior parietal and ventromedial prefrontal cortex
injury. Cerebral Cortex, 25, 1--9. Stupple, E.J.N. & Ball, L.J. (2008).
Belief-logic conflict resolution in syllogistic reasoning:
Inspection-time evidence for a parallel-process model. Thinking &
Reasoning, 14, 168--181. Stupple, E.J.N., Ball, L.J. & Ellis, D. (2013).
Matching bias in syllogistic reasoning: Evidence for a dual-process
account from response times and confidence ratings. Thinking &
Reasoning, 19, 54--77. Stuss, D.T. (2011). Functions of the frontal
lobes: Relation to executive functions. Journal of the International
Neuropsychological Society, 17, 759--765. Stuss, D.T. & Alexander, M.P.
(2007). Is there a dysexecutive syndrome? Philsophical Transactions of
the Royal Society of London. Series B: Biological Sciences, 362,
901--915. Sulin, R.A. & Dooling, D.J. (1974). Intrusion of a thematic
idea in retention of prose. Journal of Experimental Psychology, 103,
255--262. Summerfield, C. & Li, V. (2018). Perceptual sub optimality:
Bug or feature? Behavioral and Brain Sciences, 41, e22, 39. Suri, G.,
Whittaker, K. & Gross, J.J. (2015). Launching reappraisal: It's less
common than you might think. Emotion, 15, 73--77. Suter, R.S., Pachur,
T. & Hertwig, R. (2016). How affect shapes risky choice: Distorted
probability weighting versus probability neglect. Journal of Behavioral
Decision Making, 29, 437--449. Svenson, O., Salo, I. & Lindholm, T.
(2009). Post-decision consolidation and distortion of facts. Judgment
and Decision Making, 4, 397--407. Svoboda, E., McKinnon, M.C. & Levine,
B. (2006). The functional neuroanatomy of autobiographical memory: A
meta-analysis. Neuropsychologia, 44, 2189--2208. Sweller, J. & Levine,
M. (1982). Effects of goal specificity on means-ends analysis and
learning. Journal of Experimental Psychology: Learning, Memory &
Cognition, 8, 463--474.

Swets, B., Desmet, T., Clifton, C. & Ferreira, F. (2008).
Underspecification of syntactic ambiguities: Evidence from self-paced
reading. Memory & Cognition, 36, 201--216. Swets, B., Jacovina, M.E. &
Gerrig, R.J. (2013). Effects of conversational pressures on speech
planning. Discourse Processes, 50, 23--51. Sylvester, C.M., Corbetta,
M., Raichle, M.E., Rodebaugh, T.L., Schlaggar, B.L., Sheline, Y.I., et
al. (2012). Functional network dysfunction in anxiety and anxiety
disorders. Trends in Neurosciencces, 35, 528--535. Szczepanski, S. &
Knight, R.T. (2014). Insights into human behaviour from lesions to the
prefrontal cortex. Neuron, 83, 1002--1018. Taatgen, N.A. (2011).
Threaded cognition, a model of human multitasking. Talk at
Interdisciplinary Workshop on Cognitive Neuroscience, Educational
Research and Cognitive Modelling, March. Delmenhorst, Germany. Taatgen,
N.A. (2013). The nature and transfer of cognitive skills. Psychological
Review, 120, 439--471. Taatgen, N.A., van Vugt, M.K., Borst, J.P. &
Melhorn, K. (2016). Cognitive modelling at ICCM: State of the art and
future directions. Topics in Cognitive Science, 8, 259--263.
Tajadura-Jiménez, A., Banakou, D., Bianchi-Berthouze, N. & Slater, M.
(2018). Embodiment in a child-like talking virtual body influences
object size perception, self-identification, and subsequent real
speaking. Scientific Reports, 8 (Article no. 4854). Talarico, J.M. &
Rubin, D.C. (2003). Confidence, not consistency, characterises flashbulb
memories. Psychological Science, 14, 455--461. Talarico, J.M., Berntsen,
D. & Rubin, D.C. (2009). Positive emotions enhance recall of peripheral
details. Cognition & Emotion, 23, 380--398. Tambini, A., Rimmele, U.,
Phelps, E.A. & Davachi, L. (2017). Emotional brain states carry over and
enhance future memory formation. Nature Neuroscience, 20, 271--278.
Tamietto, M. & Morrone, M.C. (2016). Visual plasticity: Blindsight
bridges anatomy and function in the visual system. Current Biology, 26,
R70--R73. Tamietto, M., Castelli, L., Vighetti, S., Perozzo, P.,
Geminiani, G., Weiskrantz, L., et al. (2009). Unseen facial and bodily
expressions trigger fast emotional reactions. Proceedings of the
National Academy of Sciences of the United States of America, 106,
17661--17666. Tanaka, J.W. & Taylor, M.E. (1991). Object categories and
expertise: Is the basic level in the eye of the beholder? Cognitive
Psychology, 15, 121--149. Tang, D. & Schmeichel, B.J. (2014). Stopping
anger and anxiety: Evidence that inhibitory control predicts negative
emotional responding. Cognition & Emotion, 28, 132--142.

References Tanguay, A.N., Benton, L., Romio, L., Steens, C., Davidson,
P.S.R. & Renoult, L. (2018). The ERP correlates of self-knowledge: Are
assessments of one's past, present, and future traits closer to semantic
or episodic memory? Neuropsychologia, 110, 65--83. Tarenskeen, S.,
Broersma, M. & Geurts, B. (2015). Overspecification of colour, pattern,
and size: Salience, absoluteness, and consistency. Frontiers in
Psychology, 6 (Article no. 1703). Tarr, M.J. & Hayward, W.G. (2017). The
concurrent encoding of viewpoint-invariant and viewpoint-dependent
information in visual object recognition. Visual Cognition, 25,
108--121. Tassy, S., Ouillier, O., Duclos, Y., Coulon, O., Mancini, J.,
Deruelle, C., et al. (2012). Disrupting the right prefrontal cortex
alters moral judgment. Social and Affective Neuroscience, 7, 282--288.
Taylor, C.T., Cross, K. & Amir, N. (2016). Attentional control moderates
the relationship between social anxiety symptoms and attentional
disengagement from threatening information. Journal of Behavior Therapy
and Experimental Psychiatry, 50, 68--76. Taylor, J.A., Wojaczynski, G.J.
& Ivry, R.B. (2014). Trialby-trial analysis of intermanual transfer
during visuomotor adaptation. Journal of Neurophysiology, 106,
3157--3172. Taylor, T., Roman, L., McFeaters, K., Romoser, M., Borowsky,
A., Merritt, D.J., et al. (2015). Cell phone conversations impede latent
hazard anticipation while driving, with partial compensation by
self-regulation in more complex driving scenarios. Amherst: Arbella
Insurance Human Performance Lab, University of Massachusetts. Techer,
F., Jallais, C., Corson, Y., Moreau, F., Ndiaye, D., Piechnick, B., et
al. (2017). Attention and driving performance modulations due to anger
state: Contribution of electroenchephalograpic data. Neuroscience
Letters, 636, 134--139. Tentori, K., Chater, N. & Crupi, V. (2016).
Judging the probability of hypotheses versus the impact of evidence:
Which form of inductive accurate and time-consistent? Cognitive Science,
40, 758--778. Tentori, K., Crupi, V. & Russo, S. (2013). On the
determinants of the conjunction fallacy: Probability versus inductive
confirmation. Journal of Experimental Psychology: General, 142,
235--255. Terzi, A., Koedijk, K., Noussair, C.N. & Pownall, R. (2016).
Reference point heterogeneity. Frontiers in Psychology, 7 (Article no.
1347). Tetlock, P.E. (2002). Social functionalist frameworks for
judgment and choice: Intuitive politicians, theologians, and
prosecutors. Psychological Review, 109, 451--471. Tetlock, P.E. &
Boettger, R. (1994). Accountability amplifies the status quo effect when
change creates victims. Journal of Behavioral Decision Making, 7, 1--23.

903

Thagard, P. (2011). Critical thinking and informal logic:
Neuropsychological perspectives. Informal Logic, 31, 152--170. Thakral,
P.P., Kensinger, E.A. & Slotnick, S.D. (2016). Familiarity and priming
are mediated by overlapping neural substrates. Brain Research, 1632,
107--118. Theeuwes, J., Mathot, S. & Grainger, J. (2014). Object-centred
and IOR. Attention, Perception and Psychophysics, 76, 2249--2255.
Thibaut, M., Tran, T.-H.-C., Szaffarczyk, S. & Boucart, M. (2018).
Impact of age-related macular degeneration on object searchers in
realistic panoramic scenes. Clinical and Experimental Optometry, 101,
372--379. Thomas, B.C., Croft, K.E. & Tranel, D. (2011). Harming king to
save strangers: Further evidence for abnormally utilitarian moral
judgments after ventromedial prefrontal damage. Journal of Cognitive
Neuroscience, 23, 2186--2196. Thomas, C. & Didierjean, A. (2016).
Magicians fix your mind: How unlikely solutions block obvious ones.
Cognition, 154, 169--173. Thomas, L.E. & Lleras, A. (2009). Swinging
into thought: Directed movement guides insight in problem solving.
Psychonomic Bulletin & Review, 16, 719--723. Thompson, J. & Parasuraman,
R. (2012). Attention, biological motion, and action recognition.
NeuroImage, 59, 4--13. Thompson, M.B. & Tangen, J.M. (2014). The nature
of expertise in fingerprint matching: Experts can do a lot with a
little. PLoS ONE, 9 (Article no. e114759). Thompson, M.B., Tangen, J.M.
& McCarthy, D.J. (2014). Human matching performance of genuine crime
scene latent fingerprints. Law and Human Behavior, 38, 84--93. Thompson,
V.A., Evans, J.St.B.T. & Campbell, J.I.C. (2013a). Matching bias on the
selection task: It's fast and feels good. Thinking & Reasoning, 19,
431--452. Thompson, V.A., Pennycook, G., Trippas, D. & Evans, J.St.B.T.
(2018). Do smart people have better intuitions? Journal of Experimental
Psychology: General, 147, 945--961. Thompson, V.A., Turner, J.A.P. &
Pennycook, G. (2011). Intuition, reason, and metacognition. Cognitive
Psychology, 63, 107--140. Thompson, V.A., Turner, J.A.P., Pennycook, G.,
Ball, L.J., Brack, H., Ophir, Y., et al. (2013b). The role of answer
fluency and perceptual fluency as metacognitive cues for initiating
analytic thinking. Cognition, 128, 237--251. Thomsen, D.K. (2015).
Autobiographical periods: A review and central components of a theory.
Review of General Psychology, 19, 294--310. Thornton, T.L. & Gilden,
D.L. (2007). Parallel and serial processes in visual search.
Psychological Review, 114, 71--103.

904

References

Thorpe, S., Fize, D. & Marlot, C. (1996). Speed of processing in the
human visual system. Nature, 381, 520--522. Tierney, A., Dick, F.,
Deutsch, D. & Sereno, M. (2013). Speech versus song: Multiple
pitch-sensitive areas revealed by a naturally occurring musical
illusion. Cerebral Cortex, 23, 249--254. Tierney, A., Patel, A.D. &
Breen, M. (2018). Acoustic foundations of the speech-to-song illusion.
Journal of Experimental Psychology: General, 147, 888--904. Tijtgat, P.,
Mazyn, L., De Laey, C. & Lenoir, M. (2008). The contribution of stereo
vision to the control of braking. Accident Analysis and Prevention, 40,
719--724. Tindle, R. & Longstaff, M.G. (2015). Writing, reading, and
listening differentially overload working memory performance across the
serial position curve. Advances in Cognitive Psychology, 11, 147--155.
Tindle, R. & Longstaff, M.G. (2016). Investigating the lower level
demands of writing: Handwriting movements interfere with immediate
verbal serial recall. Journal of Cognitive Psychology, 28, 443--461.
Toba, M.N., Migliaccio, R., Batrancourt, B., Bourlon, C., Duret, C.,
Pradat-Diehl, P., et al. (2018a). Common brain networks for distinct
deficits in visual neglect: A combined structural and tractography MRI
approach. Neuropsychologia, 115, 167--178. Toba, M.N., Rabuffetti, M.,
Duret, C., Pradat-Diehl, P., Gainotti, G. & Bartolomeo, P. (2018b).
Component deficits of visual neglect: "Magnetic" attraction of attention
vs. impaired spatial working memory. Neuropsychologia, 109, 52--62.
Todorović, D. (2009). The effect of the observer vantage point on
perceived distortions in linear perspective images. Attention,
Perception, & Psychophysics, 71, 183--193. Toffolo, M.B.J., van den
Hout, M.A., Radomsky, A.S. & Engelhard, I.M. (2016). Check, check,
double check: Investigating memory deterioration within multiple
sessions of repeated checking. Journal of Behavior Therapy and
Experimental Psychiatry, 53, 59--67. Toli, A., Webb, T.L. & Hardy, G.E.
(2016). Does forming implementation intentions help people with mental
health problems to achieve goals? A meta-analysis of experimental
studies with clinical and analogue samples. British Journal of Clinical
Psychology, 55, 69--90. Tollestrup, P.A., Turtle, J.W. & Yuille, J.C.
(1994). Actual victims and witnesses to robbery and fraud: An archival
analysis. In D.F. Ross, J.D. Read & M.P. Toglia (eds), Adult Eyewitness
Testimony: Current trends and developments (pp. 144--160). New York:
Wiley. Tolman, E.C. (1948). Cognitive maps in rats and men.
Psychological Review, 55, 189--208. Tong, F. & Pratte, M.S. (2012).
Decoding patterns of human brain activity. Annual Review of Psychology,
63, 483--509. Tononi, G., Boly, M., Massimini, M. & Koch, C. (2016).
Integrated information theory: From consciousness to

its physical substrate. Nature Reviews Neuroscience, 17, 450--461.
Toplak, M.E., West, R.F. & Stanovich, K.E. (2011). The Cognitive
Reflection Test as a predictor of performance on heuristics-and-biases
tasks. Memory & Cognition, 39, 1275--1289. Toplak, M.E., West, R.F. &
Stanovich, K.E. (2014). Assessing miserly information processing: An
expansion of the Cognitive Reflection Test. Thinking & Reasoning, 20,
147--168. Toplak, M.E., West, R.F. & Stanovich, K.E. (2017). Realworld
correlates of performance on heuristics and biases tasks in a community
sample. Journal of Behavioral Decision Making, 30, 541--554. Trabasso,
T. & Sperry, L.L. (1985). Causal relatedness and importance of story
events. Journal of Memory and Language, 24, 595--611. Tranel, D.,
Damasio, A.R., Damasio, H. & Brandt, J.P. (1994). Sensori-motor skill
learning in amnesia: Additional evidence for the neural basis of
nondeclarative memory. Learning and Memory, 1, 165--179. Trapp, S. &
Bar, M. (2015). Prediction, context, and competition in visual
recognition. Annals of the New York Academy of Sciences, 1339, 190--198.
Travaglia, A., Bisaz, R., Sweet, E.S., Blitzer, R.D. & Alberini, C.M.
(2016). Infantile amnesia reflects a developmental critical period for
hippocampal learning. Nature Neuroscience, 19, 1225--1233. Travers, E.,
Rolison, J.J. & Feeney, A. (2016). The time course of conflict on the
Cognitive Reflection Test. Cognition, 150, 109--118. Traxler, M.J.
(2014). Trends in syntactic parsing: Anticipation, Bayesian estimation,
and good-enough parsing. Trends in Cognitive Sciences, 18, 605--611.
Treiman, R. (2017). Learning to spell: Phonology and beyond. Cognitive
Neuropsychology, 34, 83--93. Treiman, R. & Kessler, B. (2016). Choosing
between alternative spellings of sounds: The role of context. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 42,
1154--1159. Treisman, A.M. (1964). Verbal cues, language, and meaning in
selective attention. American Journal of Psychology, 77, 206--219.
Treisman, A.M. (1998). Feature binding, attention and object perception.
Philosophical Transactions of the Royal Society of London Series B:
Biological Sciences, 353, 1295--1306. Treisman, A.M. & Davies, A.
(1973). Divided attention to ear and eye. In S. Kornblum (ed.),
Attention and Performance, Vol. IV (pp. 101--117). London: Academic
Press. Treisman, A.M. & Gelade, G. (1980). A feature integration theory
of attention. Cognitive Psychology, 12, 97--136.

References Treisman, A.M. & Riley, J.G.A. (1969). Is selective attention
selective perception or selective response: A further test. Journal of
Experimental Psychology, 79, 27--34. Tremblay, P. & Dick, A.S. (2016).
Broca and Wernicke are dead, or moving past the classic model of
language neurobiology. Brain & Language, 162, 60--71. Trench, M.,
Olguín, V. & Minervino, R. (2016). Seek, and ye shall find: Differences
between spontaneous and voluntary analogical retrieval. Quarterly
Journal of Experimental Psychology, 69, 696--712. Tresilian, J.R.
(1999). Visually timed action: Time-out for "tau"? Trends in Cognitive
Sciences, 3, 407--408. Tressoldi, P.E., Sella, F., Coltheart, M. &
Umiltà, C. (2012). Using functional neuroimaging to test theories of
cognition: A selective survey of studies from 2007 to 2011 as a
contribution to the Decade of the Mind initiative. Cortex, 48,
1247--1250. Triesch, J., Ballard, D.H. & Jacobs, R.A. (2002). Fast
temporal dynamics of visual cue integration. Perception, 31, 421--434.
Trippas, D., Handley, S.J. & Verde, M.F. (2013). The SDT model of belief
bias: Complexity, time and cognitive ability mediate the effects of
believability. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 39, 1393--1402. Trippas, D., Handley, S.J., Verde, M.F. &
Morsanyi, K. (2016). Logic brightens my day: Evidence for implicit
sensitivity to logical validity. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 42, 1448--1457. Trippas, D., Pennycook,
G., Verde, M.F. & Handley, S.J. (2015). Better but still biased:
Analytic cognitive style and belief bias. Thinking & Reasoning, 21,
431--445. Trippas, D., Thompson, V.A. & Handley, S.J. (2017). When fast
logic meets slow belief: Evidence for a parallelprocessing model of
belief bias. Memory & Cognition, 45, 539--552. Troiani, V., Price, E.T.
& Schultz, R.T. (2014). Unseen fearful faces promote amygdala guidance
of attention. Social, Cognitive, and Affective Neuroscience, 9,
133--140. Trouche, E., Johansson, P., Hall, L. & Mercier, H. (2016). The
selective laziness of reasoning. Cognitive Science, 40, 2122--2136.
Trout, J.D. (2001). The biological basis of speech: What to infer from
talking to the animals. Psychological Review, 108, 523--549. Troy, A.S.,
Shallcross, A.J., Brunner, A. & Friedman, R. (2018). Cognitive
reappraisal and acceptance: Effects on emotion, physiology, and
perceived cognitive costs. Emotion, 18, 58--74. Troy, A.S., Shallcross,
A.J. & Mauss, I.B. (2013). A person-by-situation approach to emotion
regulation: Cognitive reappraisal can either help or hurt, depending on
the context. Psychological Science, 24, 2505--2514.

905

Tsang, S.N.H. & Chan, A.H.S. (2018). Tracking and discrete dual-task
performance for different visual spatial stimulus-response mappings with
focal and ambient vision. Applied Ergonomics, 67, 39--49. Tsano, S.H. &
Sharma, T. (2018). Rod monochromatism (achromatopsia). Atlas of
Inherited Retinal Diseases Advances in Experimental Medicine and
Biology, 1085, 119--123. Tsarfaty, R., Seddah, D., Kübler, S. & Nivre,
J. (2013). Parsing morphologically rich languages: Introduction to the
Special Issue. Computational Models, 39, 15--22. Tsujii, T. & Watanabe,
S. (2009). Neural correlates of dual-task effect on belief-bias
syllogistic reasoning: A near-infrared spectroscopy study. Brain
Research, 1287, 118--125. Tubau, E., Aguilar-Lleyda, D. & Johnson, E.D.
(2015). Reasoning and choice in the Monty Hall Dilemma (MHD):
Implications for improving Bayesian reasoning. Frontiers in Psychology,
6 (Article no. 353). Tuckey, M.R. & Brewer, N. (2003a). How schemas
affect eyewitness memory over repeated retrieval attempts. Applied
Cognitive Psychology, 7, 785--800. Tuckey, M.R. & Brewer, N. (2003b).
The influence of schemas, stimulus ambiguity, and interview schedule on
eyewitness memory over time. Journal of Experimental Psychology:
Applied, 9, 101--118. Tullett, A.M. & Inzlicht, M. (2010). The voice of
self-control: Blocking the inner voice increases impulsive responding.
Acta Psychologica, 135, 252--256. Tulving, E. (1972). Episodic and
semantic memory. In E. Tulving & W. Donaldson (eds), Organisation of
Memory (pp. 381--403). London: Academic Press. Tulving, E. (1979).
Relation between encoding specificity and levels of processing. In L.S.
Cermak & F.I.M. Craik (eds), Levels of Processing in Human Memory
(pp. 405--428). Hillsdale, NJ: Lawrence Erlbaum Associates. Tulving, E.
(2002). Episodic memory: From mind to brain. Annual Review of
Psychology, 53, 1--25. Turano, M.T., Marzi, T. & Viggiano, M.P. (2016).
Individual differences in face processing captured by ERPs.
International Journal of Psychophysiology, 101, 1--8. Turner, R. (2016).
Uses, misuses, new uses and fundamental limitations of magnetic
resonance imaging in cognitive science. Philosophical Transactions of
the Royal Society B -- Biological Sciences, 371 (Article no. 20150349).
Tustin, K. & Hayne, H. (2016). Early memories come in small packages:
Episodic memory in young children and adults. Developmental
Psychobiology, 58, 852--865. Tversky, A. (1972). Elimination by aspects:
A theory of choice. Psychological Review, 79, 281--299. Tversky, A. &
Kahneman, D. (1974). Judgement under uncertainty: heuristics and biases.
Science, 185, 1124--1130. Tversky, A. & Kahneman, D. (1981). The framing
of decisions and the psychology of choice. Science, 211, 453--458.

906

References

Tversky, A. & Kahneman, D. (1983). Extensional versus intuitive
reasoning: The conjunction fallacy in probability judgment.
Psychological Review, 91, 293--315. Tversky, A. & Kahneman, D. (1992).
Advances in prospect theory: Cumulative representation of uncertainty.
Journal of Risk and Uncertainty, 5, 297--323. Tversky, A. & Koehler,
D.J. (1994). Support theory: A non-extensional representation of
subjective probability. Psychological Review, 101, 547--567. Tversky, A.
& Shafir, E. (1992). The disjunction effect in choice under uncertainty.
Psychological Science, 3, 305--309. Twedt, E. & Parfitt, P.R. (2018).
Perception. In S. Dunn (ed.), Oxford Bibliographies in Psychology
(pp. 1--12). Oxford: Oxford University Press. Tweney, R.D., Doherty,
M.E., Worner, W.J., Pliske, D.B., Mynatt, C.R., Gross, K.A., et
al. (1980). Strategies for rule discovery in an inference task.
Quarterly Journal of Experimental Psychology, 32, 109--123. Tyler, C.W.
(2015). The vault of perception: Are straight lines seen as curved? Art
& Perception, 3, 117--137. Tyler, L.K., Voice, J. & Moss, H.E. (2000).
The interaction of meaning and sound in spoken word recognition.
Psychonomic Bulletin & Review, 7, 320--326. Tyszka, J.M., Kennedy, D.P.,
Adolphs, R. & Paul, L.K. (2011). Intact bilateral resting-state networks
in the absence of the corpus callosum. Journal of Neuroscience, 31,
15154--15162. Tzourio-Mazoyer, N., Josse, G., Crivello, F. & Mazoyer, B.
(2004). Interindividual variability in the hemispheric organisation for
speech. NeuroImage, 21, 422--435. Uchino, B.N., Thoman, D. & Byerly, S.
(2010). Inference patterns in social psychology: Looking back as we move
forward. Social and Personality Psychology Compass, 20, 417--427. Ucros,
C.G. (1989). Mood-state-dependent memory: A meta-analysis. Cognition &
Emotion, 3, 139--167. Uddén, J., Ingvar, M., Hagoort, P. & Petersson,
K.M. (2017). Broca's region: A causal role in implicit processing of
grammars with crossed non-adjacent dependences. Cognition, 164,
188--198. Uddin, L.Q. (2013). Complex relationships between structural
and functional brain complexity. Trends in Cognitive Sciences, 17,
600--602. Uddin, L.Q., Rayman, J. & Zaidel, E. (2005). Split-brain
reveals separate but equal self-recognition in the two cerebral
hemispheres. Consciousness and Cognition, 14, 633--640. Uddin, S.,
Heald, S.L.M., Van Hedger, S.C., Klos, S. & Nusbaum, H.C. (2018).
Understanding environmental sounds in sentence context. Cognition, 172,
134--143. Ueno, T., Meteyard, L., Hoffman, P. & Murayama, K. (2018). The
ventral anterior temporal lobe has a necessary role in exception word
reading. Cerebral Cortex, 28, 3035--3045.

Ullén, F., Hambrick, D.Z. & Mosing, M.A. (2016). Rethinking expertise: A
multifactorial gene-environment interaction model of expert performance.
Psychological Bulletin, 142, 427--446. Uncapher, M.R. & Wagner, A.D.
(2018). Minds and brains of media multitaskers: Current findings and
future directions. Proceedings of the National Association of Sciences,
115, 9889--9896. Unsworth, N. & McMillan, B.D. (2013). Mind wandering
and reading comprehension: Examining working memory capacity, interest,
motivation, and topic experience. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 39, 832--842. Unsworth, N., Brewer,
G.A. & Spillers, G.J. (2013). Focusing the search: Proactive and
retroactive interference and the dynamics of free recall. Journal of
Experimental Psychology: Learning, Memory and Cognition, 39, 1742--1756.
Unsworth, N., Redick, T.S., Spillers, G.J. & Brewer, G.A. (2012).
Variation in working memory capacity and cognitive control: Goal
maintenance and micro-adjustments of control. Quarterly Journal of
Experimental Psychology, 65, 326--355. Urbanski, M., Bréchemier, M.-L.,
Garcin, B., Bendetowicz, D., de Schotten, M.T., Foulon, C., et
al. (2016). Reasoning by analogy requires the left frontal pole:
Lesion-deficit mapping and clinical implications. Brain, 139,
1783--1799. Uttal, W.R. (2012). Reliability in Cognitive Neuroscience: A
meta-meta analysis. Cambridge, MA: MIT Press. Vadillo, M.A.,
Konstantinis, E. & Shanks, D.R. (2016). Underpowered samples, false
negatives, and unconscious learning. Psychonomic Bulletin & Review, 23,
87--102. Vahdat, S., Fogel, S., Benali, H. & Doyon, J. (2017).
Network-wide reorganization of procedural memory during NREM sleep
revealed by fMRI. eLIFE, 6 (Article no. e24987). Vaina, L.M. (1998).
Complex motion perception and its deficits. Current Opinion in
Neurobiology, 8, 494--502. Vaina, L.M., Lemaya, M., Beinfanga, D.C.,
Choia, A. & Nakayama, K. (1990). Intact "biological motion" and
"structure from motion" in a patient with impaired motion mechanisms: A
case study. Visual Neuroscience, 5, 353--359. Valentine, T., Pickering,
A. & Darling, S. (2003). Characteristics of eyewitness identification
that predict the outcome of real line-ups. Applied Cognitive Psychology,
17, 969--993. Valero-Cabré, A., Amengual, J.L., Stengel, C.,
Pascal-Leone, A. & Coubard, O.A. (2017). Transcranial magnetic
stimulation in basic and clinical neuroscience: A comprehensive review
of fundamental principles and novel insights. Neuroscience and
Biobehavioral Reviews, 83, 381--404.

References Vallée-Tourangeau, F., Euden, G. & Hearn, V. (2011).
Einstellung defused: Interactivity and mental set. Quarterly Journal of
Experimental Psychology, 64, 1889--1895. van Atteveldt, N., Murray,
M.M., Thut, G. & Schroeder, C.E. (2014). Multisensory integration:
Flexible use of general operations. Neuron, 81, 1240--1253. Van Belle,
G., Busigny, T., Lefèvre, P., Joubert, S., Felician, O., Gentile, F. &
Rossion, B. (2011). Impairment of holistic face perception following
right ocipito-temporal damage in prosopagnosia: Converging evidence from
gaze-contingency. Neuropsychologia, 49, 3145--3150. Van Berkum, J.J.A.,
Brown, C.M., Zwitserlood, P., Kooijman, V. & Hagoort, P. (2005).
Anticipating upcoming words in discourse: Evidence from ERPs and reading
times. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 31, 443--467. Van Bockstaele, B., Verschuere, B., Tibboel,
H., De Houwer, J., Crombez, G. & Koster, E.H.W. (2014). A review of
current evidence for the causal impact of attentional bias on fear and
anxiety. Psychological Bulletin, 140, 682--721. van den Berg, A.V. &
Brenner, E. (1994). Why two eyes are better than one for judgments of
heading. Nature, 371, 700--702. Van den Brink, D., Van Berkum, J.J.A.,
Bastiaansen, M.C.M., Tesink, C.M.J.Y., Kos, M., Buitelaar, J.K., et
al. (2012). Empathy matters: ERP evidence for inter-individual
differences in social language processing. Social Cognitive and
Affective Neuroscience, 7, 173--183. van den Broek, P. & Helder, A.
(2017). Cognitive processes in discourse comprehension: Passive
processes, reader-initiated processes, and evolving mental
representations. Discourse Processes, 54, 360--372. Vandenbroucke,
A.R.E., Fahrenfort, J.J., Meuwese, J.D.I., Scholte, H.S. & Lamme, V.A.F.
(2016). Prior knowledge about objects determines neural colour
representation in human visual cortex. Cerebral Cortex, 26, 1401--1408.
Van den Hout, M. & Kindt, M. (2004). Obsessive-compulsive disorder and
the paradoxical effects of perseverative behaviour on experienced
uncertainty. Journal of Behavior Therapy and Experimental Psychiatry,
35, 165--181. van der Hoort, B., Guterstam, A. & Ehrsson, H.H. (2011).
Being Barbie: The size of one's own body determines the perceived size
of the world. PLoS ONE, 6 (Article no. e20195). van der Schuur, W.A.,
Baumgartner, S.E., Sumter, S.R. & Valkenburg, P.M. (2015). The
consequences of media multitasking for youth: A review. Computers in
Human Behavior, 53, 204--215. Van der Steen, S., Samuelson, D. &
Thomson, J.M. (2017). The effect of keyboard-based word processing on
students with different working memory capacity during the

907

process of academic writing. Written Communication, 34, 280--305. van
der Weiden, A., Ruys, K.I. & Aarts, H. (2013). A matter of matching: How
goals and primes affect self-agency experiences. Journal of Experimental
Psychology: General, 142, 954--966. Van Dyke, J.A., Johns, C.L. &
Kukona, A. (2014). Low working memory capacity is only spuriously
related to poor reading comprehension. Cognition, 131, 373--403. van
Gaal, S. & Lamme, V.A.F. (2012). Unconscious highlevel information
processing: Implication for neurobiologial theories of consciousness.
The Neuroscientist, 18, 287--301. van Gaal, S., Ridderinkhof, K.R.,
Scholte, H.S. & Lamme, V.A.F. (2010). Unconscious activation of the
prefrontal no-go network. Journal of Neuroscience, 30, 4143--4150. van
Gompel, R.P.G., Pickering, M.J. & Traxler, M.J. (2000). Unrestricted
race: A new model of syntactic ambiguity resolution. In A. Kennedy, R.
Radach, D. Heller & J. Pytte (eds), Reading as a Perceptual Process
(pp. 621--648). Oxford: Elsevier. van Gompel, R.P.G. & Traxler, M.J.
(2001). Re-analysis in sentence processing: Evidence against
constraint-based and two-stage models. Journal of Memory and Language,
43, 225--258. van Harreveld, F., Wagenmakers, F.J. & van der Maas,
H.L.J. (2007). The effects of time pressure on chess skills: An
investigation into fast and slow responses underlying expert
performance. Psychological Research, 71, 591--597. van Kesteren, M.T.R.,
Fernández, G., Norris, D.G. & Hermans, E.J. (2010). Persistent
schema-dependent hippocampal-neocortical connectivity during memory
encoding and post-encoding rest in humans. Proceedings of the National
Academy of Sciences, USA, 107, 7550--7555. Vanlancker-Sidtis, D. (2004).
When only the right hemisphere is left: Studies in language and
communication. Brain and Language, 91, 199--211. Vanlessen, N., De
Raedt, R., Koster, E.H.W. & Pourtois, G. (2016). Happy heart, smiling
eyes: A systematic review of positive mood effects on broadening of
visuospatial attention. Neuroscience and Biobehavioral Reviews, 68,
816--837. Vannuscorps, G., Andres, M. & Pillon, A. (2013). When does
action comprehension need motor involvement? Evidence from upper limb
aplasia. Cognitive Neuropsychology, 30, 253--283. Vannuscorps, G.,
Dricot, L. & Pillon, A. (2016). Persistent sparing of action conceptual
processing in spite of increasing disorders of action production: A case
against motor embodiment of action concepts. Cognitive Neuropsychology,
33, 191--209.

908

References

van Orden, G.C. (1987). A rows is a rose: Spelling, sound and reading.
Memory & Cognition, 14, 371--386. van Petten, C. & Luka, B.J. (2012).
Prediction during language comprehension: Benefits, costs, and ERP
components. International Journal of Psychophysiology, 83, 176--190. van
Petten, C., Coulson, S., Rubin, S., Plante, E. & Parks, M. (1999). Time
course of word identification and semantic integration in spoken
language. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 25, 394--417. van Polanen, V. & Davare, M. (2015).
Interactions between dorsal and ventral streams for controlling skilled
grasp. Neuropsychologia, 79, 186--191. van Turennout, M., Hagoort, P. &
Brown, C.M. (1998). Brain activity during speaking: From syntax to
phonology in 40 milliseconds. Science, 280, 572--574. van Velzen, M.H.,
Nanetti, L. & de Deyn, P.P. (2014). Data modelling in corpus
linguistics: How low can we go? Cortex, 55, 192--201. Vaquero, L.,
Hartmann, K., Ripollés, P., Rojo, N., Sierpowska, J., Francois, C., et
al. (2016). Structural neuroplasticity in expert pianists depends on the
age of musical training onset. NeuroImage, 126, 106--119. Varakin, D.A.,
Levin, D.T. & Collins, K.M. (2007). Comparison and representation
failures both cause realworld change. Perception, 36, 737--749.
Vargha-Khadem, F., Gadian, D.G., Watkins, K.E., Connelly, A., Van
Paesschen, W. & Mishkin, M. (1997). Differential effects of early
hippocampal pathology on episodic and semantic memory. Science, 277,
376--380. Vasilev, M.R. & Angele, B. (2017). Parafoveal preview effects
from word N + 1 and word N + 2 during reading: A critical review and
Bayesian meta-analysis. Psychonomic Bulletin & Review, 24, 666--689.
Vendetti, M.S., Starr, A., Johnson, E.L., Modavi, K. & Bunge, S.A.
(2017). Eye movements reveal optimal strategies for analogical
reasoning. Frontiers in Psychology, 8 (Article no. 932). Vergauwe, E. &
Langerock, N. (2017). Attentional refreshing of information in working
memory: Increased immediate accessibility of just-refreshed
representations. Journal of Memory and Language, 96, 23--35. Vergauwe,
E., Barrouillet, P. & Camos, V. (2009). Visual and spatial working
memory are not dissociated after all: A time-based resource-sharing
account. Journal of Experimental Psychology: Learning, Memory, and
Cognition, 35, 1012--1028. Verleger, R., Binkofski, F., Friedrich, M.,
Sedlmeier, P. & Kömpf, D. (2011). Anarchic-hand syndrome: ERP
reflections of lost control over the right hemisphere. Brain and
Cognition, 77, 138--150.

Verschueren, N., Schaeken, W. & d'Ydewalle, G. (2005). A dual-process
specification of causal conditional reasoning. Thinking & Reasoning, 11,
239--278. Vesia, M. & Crawford, J.D. (2012). Specialisation of reach
function in human posterior parietal cortex. Experimental Brain
Research, 221, 1--18. Vetter, P., Grosbras, M.-H. & Muckli, L. (2015).
TMS over V5 disrupts motion prediction. Cerebral Cortex, 25, 1052--1059.
Vidal-Piñeiro, D., Sneve, M.H., Storsve, A.B., Roe, J.M., Walhovd, K.B.
& Fhell, A.M. (2018). Neural correlates of durable memories across the
adult lifespan: Brain activity at encoding and retrieval. Neurobiology
of Aging, 60, 20--33. Viggiano, M.P., Giovannelli, F., Borgheresi, A.,
Feurra, M., Berardi, N., Pizzorusso, T., et al. (2008). Disruption of
the prefrontal cortex function by rTMS produces a category-specific
enhancement of the reaction times during visual object identification.
Neuropsychologia, 46, 2725--2731. Vigliocco, G., Antonini, T. & Garrett,
M.F. (1997). Grammatical gender is on the top of Italian tongues.
Psychological Science, 8, 314--317. Virtue, S., Schutzenhofer, M. &
Tomkins, B. (2017). Hemispheric processing of predictive inferences
during reading: The influence of negatively emotional valenced stimuli.
Laterality, 22, 455--472. Visted, E., Vollestad, J., Nielsen, M.B. &
Schanche, E. (2018). Emotion regulation in current and remitted
depression: A systematic review and meta-analysis. Frontiers in
Psychology, 8 (Article no. 756). Viviani, R. (2013). Emotion regulation,
attention to emotion, and the ventral attentional network. Frontiers in
Human Neuroscience, 7 (Article no. 746). Võ, M.L.-H. & Wolfe, J.M.
(2012). When does repeated search in scenes involve memory? Looking at
versus looking for objects in scenes. Journal of Experimental
Psychology: Human Perception and Performance, 38, 23--41. Volden, J.
(2017). Autism spectrum disorder. In L. Cummings (ed.), Research in
Clinical Pragmatics: Perspectives in Pragmatics, Philosophy &
Psychology, 11, 59--83. Volz, L.J. & Gazzaniga, M.S. (2017). Interaction
in isolation: 50 years of insights from split-brain research. Brain,
140, 2051--2060. Volz, L.J., Hillyard, S.A., Miller, M.B. & Gazzaniga,
M.S. (2018). Unifying control over the body: Consciousness and
cross-cueing in split-brain patients. Brain, 141 (Article no. e15). Von
Neumann, J. & Morgenstern, O. (1944). Theory of Games and Economic
Behaviour. Princeton, NJ: Princeton University Press. Vossel, S., Geng,
J.J. & Fink, G.R. (2014). Dorsal and ventral attention system: Distinct
neural circuits but collaborative roles. The Neuroscientist, 20,
150--159.

References Vousden, J.I. & Maylor, E.A. (2006). Speech errors across the
lifespan. Language and Cognitive Processes, 21, 48--77. Vranić, A.,
Jelić, M. & Tonković, M. (2018). Functions of autobiographical memory in
younger and older adults. Frontiers in Psychology, 9 (Article no. 219).
Vuilleumier, P., Armony, J.L., Clarke, K., Husain, M., Driver, J. &
Dolan, R.J. (2002a). Neural response to emotional faces with and without
awareness: Event-related fMRI in a parietal patient with visual
extinction and spatial neglect. Neuropsychologia, 40, 2156--2166.
Vuilleumier, P., Schwartz, S., Clarke, K., Husain, M. & Driver, J.
(2002b). Testing memory for unseen visual stimuli in patients with
extinction and spatial neglect. Journal of Cognitive Neuroscience, 14,
875--886. Wachtel, P.L. (1973). Psychodynamics, behaviour therapy and
the implacable experimenter: An inquiry into the consistency of
personality. Journal of Abnormal Psychology, 82, 324--334. Wagemans, J.,
Elder, J.H., Kubovy, M., Palmer, S.E., Peterson, M.A., Singh, M., et
al. (2012a). A century of Gestalt psychology in visual perception: I.
Perceptual grouping and figure-ground organisation. Psychological
Bulletin, 138, 1172--1217. Wagemans, J., Feldman, J., Gepshtein, S.,
Kimchi, R., Poemerantz, J.R. & van der Helm, P.A. (2012b). A century of
Gestalt psychology in visual perception: II. Conceptual and theoretical
foundations. Psychological Bulletin, 138, 1218--1252. Wagman, J.B.,
Caputo, S.E. & Suffregen, T.A. (2016). Hierarchical nesting of
affordances in a tool use task. Journal of Experimental Psychology:
Human Perception and Performance, 42, 1627--1642. Wagner, A.D.,
Schacter, D.L., Rotte, M., Koutstaal, W., Maril, A.M., Dale, B.R., et
al. (1998). Building memories: Remembering and forgetting of verbal
experiences as predicted by brain activity. Science, 281, 1188--1191.
Wagner, V., Jescheniak, J.D. & Schriefers, H. (2010). On the flexibility
of grammatical advance planning: Effects of cognitive load on multiple
lexical access. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 36, 423--440. Wagoner, B. (2013). Bartlett's concept of
schema in reconstruction. Theory & Psychology, 23, 553--575. Waldum,
E.R. & McDaniel, M.A. (2016). Why are you late? Investigating the role
of time management in timebased prospective memory. Journal of
Experimental Psychology: General, 145, 1049--1061. Wallas, G. (1926).
The Art of Thought. London: J. Cape. Wallis, G. (2013). Toward a unified
model of face and object recognition in the human visual system.
Frontiers in Psychology, 4 (Article no. 497). Wallisch, P. (2017).
Illumination assumptions account for individual differences in the
perceptual interpretation of

909

a profoundly ambiguous stimulus in the colour domain: "The dress".
Journal of Vision, 17, 1--14. Walsh, J.J., McNally, M., Shariah, A.,
Butt, A.A. & Eysenck, M.W. (2015). Interpretive bias, repressive coping,
and trait anxiety. Anxiety, Stress and Coping, 28, 617--633. Walter, S.,
Keitel, C. & Müller, M.M. (2016). Sustained splits of attention within
versus across visual hemifields produce distinct spatial gain profiles.
Journal of Cognitive Neuroscience, 28, 111--124. Walton, D. (2010). Why
fallacies appear to be better arguments than they are. Informal Logic,
30, 159--184. Walton, D. (2017). The slippery slope argument in the
ethical debate on genetic engineering of humans. Science and Engineering
Ethics, 23, 1507--1528. Wang, M., Rieger, M.O. & Hens, T. (2017). The
impact of culture on loss aversion. Journal of Behavioral Decision
Making, 30, 270--281. Wang, P., Gauthier, I. & Cottrell, G. (2016). Are
face and object recognition independent? A neurocomputational modelling
exploration. Journal of Cognitive Neuroscience, 28, 558--574. Wang, S.,
Fukuchi, M., Koch, C. & Tsuchiya, N. (2012). Spatial attention is
attracted in a sustained fashion toward singular points in the optic
flow. PLoS ONE, 7 (Article no. e41040). Wang, X.T. (1996).
Domain-specific rationality in human choices: Violations of utility
axioms and social contexts. Cognition, 60, 31--63. Wang, Y. & Xuebing,
L. (2017). Temporal course of implicit emotion regulation during a
priming-identify task: An ERP study. Scientific Reports, 7 (Article no.
41941). Ward, E.J. & Scholl, B.J. (2015). Inattentional blindness
reflects limitations on perception, not memory: Evidence from repeated
failures of awareness. Psychonomic Bulletin & Review, 22, 722--727.
Ward, J. (2006). The Student's Guide to Cognitive Neuroscience. Hove,
UK: Psychology Press. Ward, J. (2015). The Student's Guide to Cognitive
Neuroscience (3rd edn). Hove, UK: Psychology Press. Waris, O., Soveri,
A., Ahti, M., Hoffing, R.C., Ventus, D., Jaeggi, S.M., et al. (2017). A
latent factor analysis of working memory measures using large-scale
data. Frontiers in Psychology, 8 (Article no. 1062). Warren, D.E.,
Jones, S.H., Diff, M.C. & Tranel, D. (2014). False recall is reduced by
damage to the ventromedial prefrontal cortex: Implications for
understanding the neural correlates of schematic memory. Journal of
Neuroscience, 34, 7677--7682. Warren, R.M. & Warren, R.P. (1970).
Auditory illusions and confusions. Scientific American, 223, 30--36.
Watanabe, K. & Funahashi, S. (2018). Toward an understanding of the
neural mechanisms underlying dual-task performance: Contribution of
comparative approaches

910

References

using animal models. Neuroscience and Biobehavioral Reviews, 84, 12--28.
Waters, E.A. (2008). Feeling good, feeling bad, and feeling at risk: A
review of incidental affect's influence on likelihood estimates of
health hazards and life events. Journal of Risk Research, 11, 569--595.
Waters, F., Collerton, D., Ffytche, D.H., Jardri, R., Pins, D., Dudley,
R., et al. (2014). Visual hallucinations in the psychosis spectrum and
comparative information from neurodegenerative disorders and eye
disease. Schizophrenia Bulletin, 40, S233--S245. Watkins, E., Moulds, M.
& Mackintosh, B. (2005). Comparisons between rumination and worry in a
non-clinical population. Behaviour Research and Therapy, 43, 1577--1585.
Watson, D. (2009). Differentiating the mood and anxiety disorders: A
quadripartite model. Annual Review of Clinical Psychology, 5, 221--247.
Watson, D. & Tellegen, A. (1985). Toward a consensual structure of mood.
Psychological Bulletin, 98, 219--235. Watson, J.B. (1913). Psychology as
the behaviourist sees it. Psychological Review, 20, 158--177. Watson,
J.B. (1920). Is thinking merely the action of language mechanisms?
British Journal of Psychology, 11, 87--104. Watson, T.L. & Robbins, R.A.
(2014). The nature of holistic processing in face and object
recognition: Current opinions. Frontiers in Psychology, 5 (Article no.
3). Watt, C.A. & Kennedy, J.E. (2017). Options for prospective
meta-analysis and introduction of registration-based prospective
meta-analysis. Frontiers in Psychology, 7 (Article no. 2030). Webb,
M.E., Little, D.R. & Cropper, S.J. (2016a). Insight is not in the
problem: Investigating insight in problem solving across task types.
Frontiers in Psychology, 7 (Article no. 1424). Webb, T.L., Miles, E. &
Sheeran, P. (2012). Dealing with feeling: A meta-analysis of the
effectiveness of strategies derived from the process model of emotion
regulation. Psychological Bulletin, 138, 775--808. Webb, T.W. &
Graziano, M.S.A. (2015). The attention schema theory: A mechanistic
account of subjective awareness. Frontiers in Psychology, 6 (Article no.
500). Webb, T.W., Kean, H.H. & Graziano, M.S.A. (2016b). Effects of
awareness on the control of attention. Journal of Cognitive
Neuroscience, 28, 842--851. Weber, A. & Crocker, M.W. (2012). On the
nature of semantic constraints on lexical access. Journal of
Psycholinguistic Research, 41, 195--214. Webster, M.A. (2016).
Individual differences in colour vision. In A.J. Eliot, M.D. Fairchild &
A. Franklin (eds), Handbook of Colour Psychology (pp. 187--215).
Cambridge: Cambridge University Press. Webster, R.J. (2015). Does
disruptive camouflage conceal edges and features? Current Zoology, 61,
708--717.

Wegner, D.M. (2003). The mind's best trick: How we experience free will.
Trends in Cognitive Sciences, 7, 65--69. Wegner, D.M. & Wheatley, T.
(1999). Apparent mental causation: Sources of the experience of free
will. American Psychologist, 54, 480--492. Weibert, K., Harris, R.J.,
Mitchell, A., Byrne, H., Young, A.W. & Andrewsm T.J. (2016). An
image-invariant neural response to familiar faces in the human medial
temporal lobe. Cortex, 84, 34--42. Weidema, J.L., Roncaglia-Denissen,
M.P. & Honing, H. (2016). Top-down perception and categorisation of
identical pitch contours in speech and music. Frontiers in Psychology, 7
(Article no. 817). Weingarten, E., Chen, Q., McAdams, M., Hepler, J.,
Yi, J. & Albarracín, D. (2016). From primed concepts to action: A
meta-analysis of the behavioural effects of incidentally presented
words. Psychological Bulletin, 142, 472--497. Weisberg, R.W. (2018).
Problem solving. In L.J. Ball & V.A. Thompson (eds), Routledge
International Handbook of Thinking and Reasoning (pp. 607--623).
Abingdon, Oxon: Routledge. Weiskrantz, L. (1980). Varieties of residual
experience. Quarterly Journal of Experimental Psychology, 32, 365--386.
Weiskrantz, L. (1997). Consciousness: Lost and found: A
neuropsychological exploration. Oxford: Oxford University Press.
Weiskrantz, L. (2010). Looking Back: blindsight in hindsight. The
Psychologist, 23, 356--358. Weiskrantz, L., Warrington, E.K., Sanders,
M.D. & Marshall, J. (1974). Visual capacity in the hemianopic field
following a restricted occipital ablation. Brain, 97, 709--728. Weiss,
N., Mardo, E. & Avidan, G. (2016). Visual expertise for horses in a case
of congenital prosopagnosia. Neuropsychologia, 83, 63--75. Welch, R.B. &
Warren, D.H. (1980). Immediate perceptual response to intersensory
discrepancy. Psychological Bulletin, 88, 638--667. Weller, J.A., Levin,
I.P., Shiv, B. & Bechara, A. (2007). Neural correlates of adaptive
decision making for risky gains and losses. Psychological Science, 18,
958--964. Wells, G.L., Steblay, N.K. & Dysart, J.E. (2015). Doubleblind
photo lineups using actual eyewitnesses: An experimental test of a
sequential versus simultaneous lineup procedure. Law and Human Behavior,
39, 1--14. Wen, T., De-Cyuan, L. & Hsieh, S. (2018). Connectivity
patterns in cognitive control networks predict naturalistic multitasking
ability. Neuropsychologia, 114, 198--202. Wen, X., Liu, Y. & Ding, M.
(2012). Causal interactions in attention networks predict behavioural
performance. Journal of Neuroscience, 32, 1284--1292. Werner-Seidler,
A., Hitchcock, C., Bevan, A., McKinnon, A., Gillard, J., Dahm, T., et
al. (2018). A cluster randomised controlled platform trial comparing
group MEmory

References specificity training (MEST) to group psychoeducation and
supportive counselling (PSC) in the treatment of recurrent depression.
Behaviour Research and Therapy, 105, 1--9. Wessel, J.R., Haider, H. &
Rose, M. (2012). The transition from implicit to explicit
representations in incidental learning: More evidence from
high-frequency EEG coupling. Experimental Brain Research, 217, 153--162.
White, D., Kemp, R.I., Jenkins, R., Matheson, M. & Burton, A.M. (2014).
Passport officers' errors in face matching. PLoS ONE, 9 (Article no.
e103510). Whitwell, R.L. & Goodale, M.A. (2017). Real and illusory
issues in the illusion debate (Why two things are sometimes better than
one): Commentary on Kopiske et al. (2016). Cortex, 88, 205--209. Whorf,
B.L. (1956). Language, Thought, and Reality: Selected writings of
Benjamin Lee Whorf. New York: Wiley. Whyte, E.M. & Nelson, K.E. (2015).
Trajectories of pragmatic and nonliteral language development in
children with autism spectrum disorders. Journal of Communication
Disorders, 54, 2--14. Wickens, C.D. (1984). Processing resources in
attention. In R. Parasuraman & D.R. Davies (eds), Varieties of Attention
(pp. 63--101). London: Academic Press. Wickens, C.D. (2008). Multiple
resources and mental workload. Human Factors, 50, 449--455. Wieber, F.,
Thuermer, J.L. & Gollwitzer, P.M. (2015). Promoting the translation of
intentions into action by implementation intentions: Behavioural effects
and physiological correlates. Frontiers in Human Neuroscience, 9
(Article no. 395). Wiese, H., Wolff, N., Steffens, M.C. & Schweinberger,
S.R. (2013). How experience shapes memory for faces: An event-related
potential study on the own-age bias. Biological Psychology, 94,
369--379. Wig, G.S., Grafton, S.T., Demos, K.E. & Kelley, W.M. (2005).
Reductions in neural activity underlie behavioural components of
repetition priming. Nature Neuroscience, 8, 1228--1233. Wild, C., Davis,
M.H. & Johnsrude, J.S. (2012). The perceptual clarity of speech
modulates activity in primary auditory cortex: fMRI evidence of
interactive processes in speech perception. NeuroImage, 60, 1490--1502.
Wilf, M., Holmes, N.P., Schwartz, I. & Makin, T.R. (2013). Dissociating
between object affordances and spatial compatibility effects using early
response components. Frontiers in Psychology, 4 (Article no. 591).
Wilkie, R.M. & Wann, J.P. (2006). Judgements of path, not heading, guide
locomotion. Journal of Experimental Psychology: Human Perception and
Performance, 32, 88--96. Wilkie, R.M., Kountouriotis, G.K. & Merat, N.
(2010). Using vision to control locomotion: Looking where you want to
go. Experimental Brain Research, 204, 539--547.

911

Wilkins, N.J. & Rawson, K.A. (2011). Controlling retrieval during
practice: Implications for memory-based theories of automaticity.
Journal of Memory and Language, 65, 208--221. Wilkinson, L. & Shanks,
D.R. (2004). Intentional control and implicit sequence learning. Journal
of Experimental Psychology: Learning, Memory, and Cognition, 30,
354--369. Wilkinson, L., Khan, Z. & Jahanshahi, M. (2009). The role of
the basal ganglia and its cortical connections in sequence learning:
Evidence from implicit and explicit sequence learning in Parkinson's
disease. Neuropsychologia, 47, 2564--2573. Williams, C.R., Cook, A.E. &
O'Brien, E.J. (2018). Validating semantic illusions: Competition between
context and world knowledge. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 44, 1414--1429. Williams, J.H.G.
(2013). The mirror or portrait neuron system -- Time for a more organic
model of actioncoding? Cortex, 49, 2962--2963. Williams, J.M.G., Watts,
F.N., MacLeod, C.M. & Mathews, A. (1997). Cognitive Psychology and
Emotional Disorders (2nd edn). Chichester, UK: Wiley. Williford, J.R. &
von der Heydt, R. (2016). Figure-ground organisation in visual cortex
for natural scenes. eNeuro, 3, 1--16. Wilmer, J.B. (2017). Individual
differences in face recognition: A decade of discovery. Current
Directions in Psychological Science, 26 (Article no. 225230). Wilmer,
J.B., Germine, L., Chabris, C.F., Chatterjee, G., Williams, M., Loken,
E., Nakayama, K. & Duchaine, B. (2010). Human face recognition ability
is highly heritable. Proceedings of the National Academy of Sciences
U.S.A., 107, 5238--5241. Wilson, M.D., Farrell, S., Visser, T.A.W. &
Loft, S. (2018). Remembering to execute deferred tasks in simulated air
traffic control: The impact of interruptions. Journal of Experimental
Psychology: Applied, 24, 360--379. Wilson, M.P. & Garnsey, S.M. (2009).
Making simple sentences hard: Verb bias effects in simple direct object
sentences. Journal of Memory and Language, 60, 368--392. Winawer, J. &
Witthoft, N. (2015). Human V4 and ventral occipital retinotopic maps.
Visual Neuroscience, 32, 1--13. Winawer, J., Witthoft, N., Frank, M.C.,
Wu, L., Wade, A.R. & Boroditsky, L. (2007). Russian blues reveal effects
of language on colour discrimination. Proceedings of the National
Academy of Sciences of the United States of America, 104, 7780--7785.
Windmann, S. (2004). Effects of sentence context and expectation on the
McGurk illusion. Journal of Memory and Language, 50, 212--230. Winer,
E.S. & Salem, T. (2016). Reward devaluation: Dotprobe meta-analytic
evidence of avoidance of positive

912

References

information in depressed persons. Psychological Bulletin, 142, 18--78.
Wing, E.A., Ritchey, M. & Cabeza, R. (2015). Reinstatement of individual
past events revealed by the similarity of distributed activation
patterns during encoding and retrieval. Journal of Cognitive
Neuroscience, 27, 679--691. Winkielman, P., Berridge, K.C. & Wilbarger,
J.L. (2005). Unconscious affective reactions to masked happy versus
angry faces influence consumption behaviour and judgements of value.
Personality and Social Psychology Bulletin, 31, 121--135. Winlove,
C.I.P., Milton, F., Ranson, J., Fulford, J., MacKisack, M., Macpherson,
F., et al. (2018). The neural correlates of visual imagery: A
co-ordinate-based meta-analysis. Cortex, 105, 4--25. Wischgoll, A.
(2016). Combined training of one cognitive and one metacognitive
strategy improves academic writing skills. Frontiers in Psychology, 7
(Article no. 187). Withagen, R., de Poel, H.J., Araujo, D. & Pepping,
G.-J. (2012). Affordances can invite behaviour: Reconsidering the
relationship between affordances and agency. New Ideas in Psychology,
30, 250--258. Wixted, J.T. (2004). The psychology and neuroscience of
forgetting. Annual Review of Psychology, 55, 235--269. Wixted, J.T. &
Wells, G.L. (2017). The relationship between eyewitness confidence and
identification accuracy: A new synthesis. Psychological Science in the
Public Interest, 18, 10--65. Wixted, J.T., Mickes, L., Dunn, J.C.,
Clark, S.E. & Wells, S. (2016). Estimating the reliability of eyewitness
identifications from police lineups. Proceedings of the National
Association of Sciences, 113, 304--309. Woike, B., Gershkovich, I.,
Piorkowski, R. & Polo, M. (1999). The role of motives in the content and
structure of autobiographical memory. Journal of Personality and Social
Psychology, 76, 600--612. Wolfe, J.M., Võ, M.L.-H., Evans, K.K. &
Greene, M.R. (2011). Visual search in scenes involves selective and
nonselective pathways. Trends in Cognitive Sciences, 15, 77--84. Wolff,
P. & Gentner, D. (2011). Structure-mapping in metaphor comprehension.
Cognitive Science, 35, 1456--1488. Wolff, P. & Holmes, K.J. (2011).
Linguistic relativity. Wiley Interdisciplinary Reviews: Cognitive
Science, 2, 253--265. Won, E.J.S. (2012). A theoretical investigation on
the attraction effect using the elimination-by-aspects model
incorporating higher preference for shared features. Journal of
Mathematical Psychology, 56, 386--391. Wong, C.K. & Read, J.D. (2011).
Positive and negative effects of physical context reinstatement on
eyewitness recall and recognition. Applied Cognitive Psychology, 25,
2--11. Woods, K.J.P. & McDermott, J.H. (2018). Schema learning for the
cocktail party problem. Proceedings of the National Academy of Sciences,
115, E3313--E3322.

Woollams, A.M. & Patterson, K. (2012). The consequences of progressive
phonological impairment for reading aloud. Neuropsychologia, 50,
3469--3477. Woollams, A.M., Halai, A. & Lambon Ralph, M.A. (2018).
Mapping the intersection of language and reading: The neural bases of
the primary systems hypothesis. Brain Structure and Function, 223,
3769--3786. Woollams, A.M., Lambon Ralph, M.A., Plaut, D.C. & Patterson,
K. (2007). SD-squared: On the association between semantic dementia and
surface dyslexia. Psychological Review, 114, 316--339. Woollett, K. &
Maguire, E.A. (2009). Navigational expertise may compromise anterograde
associative memory. Neuropsychologia, 44, 1088--1095. Woollett, K. &
Maguire, E.A. (2011). Acquiring "the Knowledge" of London's layout
drives structural brain changes. Current Biology, 21, 2109--2114.
Woollett, K., Spiers, H.J. & Maguire, E.A. (2009). Talent in the taxi: A
model system for exploring expertise. Philosophical Transactions of the
Royal Society B: Biological Sciences, 364, 1407--1416. Wright, D.B. &
Loftus, E.F. (2008). Eyewitness memory. In G. Cohen & M.A. Conway (eds),
Memory in the Real World (3rd edn) (pp. 91--106). Hove, UK: Psychology
Press. Wright, D.B. & Stroud, J.N. (2002). Age differences in line-up
identification accuracy: People are better with their own age. Law and
Human Behavior, 26, 641--654. Wright, O., Davies, I.R.L. & Franklin, A.
(2015). Whorfian effects on colour memory are not reliable. Quarterly
Journal of Experimental Psychology, 68, 745--758. Wroe, A.L., Bhan, A.,
Salkovskis, P. & Bedford, H. (2005). Feeling bad about immunising our
children. Vaccine, 23, 1428--1433. Wu, L.L. & Barsalou, L.W. (2009).
Perceptual simulation in conceptual combination: Evidence from property
generation. Acta Psychologica, 132, 173--189. Wulff, D.U.,
Mergenthaler-Canseco, M. & Hertwig, R. (2018). A meta-analytic review of
two modes of learning and the description-experience gap. Psychological
Bulletin, 144, 140--176. Wurm, M.F., Ariani, G., Greenlee, M.W. &
Lingnau, A. (2016). Decoding concrete and abstract action
representations during explicit and implicit conceptual processing.
Cerebral Cortex, 26, 3390--3401. Wutzler, A., Becker, R., Lämmler, G.,
Haverkamp, W. & Steinhagen-Thiessen, E. (2013). The anticipatory
proportion as an indicator of language impairment in early-stage
cognitive disorder in the elderly. Dementia and Geriatric Cognitive
Disorders, 36, 300--309. Wynn, V.E. & Logie, R.H. (1998). The veracity
of long-term memories -- Did Bartlett get it right? Applied Cognitive
Psychology, 12, 1--20.

References Xie, Y., Hwang, S. & Pantelous, A.A. (2018). Loss aversion
around the world: Empirical evidence from pension funds. Journal of
Banking and Finance, 88, 52--62. Yacoub, R. & Ferrucci, S. (2011).
Charles Bonnet syndrome. Optometry, 82, 421--427. Yang, T.-X., Peng,
Z.W., Wang, Y., Geng, F.L., Miao, G.-D., Shum, D.H.K., et al. (2015).
The nature of prospective memory deficit in patients with
obsessivecompulsive disorder. Psychiatry Research, 230, 479--486.
Yardley, H., Perlovsky, L. & Bar, M. (2012). Predictions and
incongruency in object recognition: A cognitive neuroscience
perspective. In D. Weinshall, J. Anemuller & L. Vangool (eds), Detection
and Identification of Rare Audiovisual Cues, 384, 139--153. Yarkoni, T.
& Westfall, J. (2017). Choosing prediction over explanation in
psychology: Lessons from machine learning. Perspectives on Psychological
Science, 12, 1100--1122. Yarkoni, T., Poldrack, R.A., Nichols, T.E., Van
Essen, D.C. & Wager, T.D. (2011). Large-scale automated synthesis of
human functional neuroimaging data. Nature Methods, 8, 665--670.
Yarkoni, T., Poldrack, R.A., Van Essen, D.C. & Wager, T.D. (2010).
Cognitive neuroscience 2.0: Building a cumulative science of human brain
function. Trends in Cognitive Sciences, 14, 489--496. Ye, L., Cardwell,
W. & Mark, L.S. (2009). Perceiving multiple affordances for objects.
Ecological Psychology, 21, 185--217. Yechiam, E. (2018). Acceptable
losses: The debatable origins of loss aversion. Psychological Research
(Epub 16 April 2018). Yechiam, E. & Hochman, G. (2013). Losses as
mediators of attention: Review and analysis of the unique effects of
losses over gains. Psychological Bulletin, 139, 497--518. Yegiyan, N.S.
& Lang, A. (2010). Processing central and peripheral detail: How content
arousal and emotional tone influence encoding. Media Psychology, 13,
77--99. Yiend, J., Barnicot, K. & Koster, E.H.W. (2013). Attention and
emotion. In M.D. Robinson, E.R. Watkins & E. Harmon-Jones (eds),
Handbook of Cognition and Emotion (pp. 97--116). New York: Guilford
Publications. Yilmaz, E.H. & Warren, W.H. (1995). Visual control of
braking: A test of the "tau-dot" hypothesis. Journal of Experimental
Psychology: Human Perception and Performance, 21, 996--1014. Yip, J.A. &
Côté, S. (2013). The emotionally intelligent decision maker:
Emotion-understanding ability reduces the effect of incidental anxiety
on risk taking. Psychological Science, 24, 48--55. Yonelinas, A.P. &
Ritchey, M. (2015). The slow forgetting of emotional episodic memories:
An emotional binding account. Trends in Cognitive Sciences, 19,
259--267.

913

Yoon, J.-S., Ericsson, K.A. & Donatelli, D. (2018). Effects of 30 years
of disuse on exceptional memory performance. Cognitive Science, 42,
884--903. Yoon, S.O., Duff, M.C. & Brown-Schmidt, S. (2017). Learning
and using knowledge about what other people do and do not know despite
amnesia. Cortex, 94, 164--175. Young, A.H. & Hulleman, J. (2013). Eye
movements reveal how task difficulty moulds visual search. Journal of
Experimental Psychology: Human Perception and Performance, 39, 168--190.
Young, A.W. (2018). Faces, people and the brain: The 45th Sir Frederic
Bartlett lecture. Quarterly Journal of Experimental Psychology, 71,
569--594. Young, A.W. & Bruce, V. (2011). Understanding person
perception. British Journal of Psychology, 102, 959--974. Young, A.W. &
Burton, A.M. (2017). Recognising faces. Current Directions in
Psychological Science, 26, 212--217. Young, A.W. & Burton, A.M. (2018).
Are we face experts? Trends in Cognitive Sciences, 22, 100--110. Young,
A.W., Hay, D.C. & Ellis, A.W. (1985). The faces that launched a thousand
slips: Everyday difficulties and errors in recognizing people. British
Journal of Psychology, 76, 495--523. Young, S.G., Hugenberg, K.,
Bernstein, M.J. & Sacco, D.F. (2012). Perception and motivation in face
recognition: A critical review of theories of the cross-race effect.
Personality and Social Psychology Review, 16, 116--142. Yovel, G. &
O'Toole, A.J. (2016). Recognising people in motion. Trends in Cognitive
Sciences, 20, 383--395. Yurgil, K.A. & Golob, E.J. (2013). Cortical
potentials in an auditory oddball task reflect individual differences in
working memory capacity. Psychophysiology, 50, 1263--1274. Zachariou,
V., Nikas, C.V., Safiullah, Z.N., Gotts, S.J. & Ungerleider, L.G.
(2017). Spatial mechanisms within the dorsal visual pathway contribute
to the configural processing of faces. Cerebral Cortex, 27, 4124--4138.
Zacks, J.M., Speer, N.K., Swallow, K.M., Braver, T.S. & Reynolds, J.R.
(2007). Event perception: A mind-brain perspective. Psychological
Bulletin, 133, 273--293. Zahn, R., Green, S., Beaumont, H., Burns, A.,
Moll, J., Caine, D., et al. (2017). Frontotemporal lobar degeneration
and social behaviour: Dissociation between the knowledge of its
consequences and its conceptual meaning. Cortex, 93, 107--118. Zalla,
T., Amsellem, F., Chaste, P., Ervas, F., Leboyer, M. & Champagne-Lavau,
M. (2014). Individuals with autism spectrum disorders do not use social
stereotypes in irony comprehension. PLoS ONE, 9 (Article no. e95568).
Zander, T., Őllinger, M. & Volz, K.G. (2016). Intuition and insight: Two
processes that build on each other or fundamentally different? Frontiers
in Psychology, 7 (Article no. 1395).

914

References

Zatorre, R.J. (2013). Predispositions and plasticity in music and speech
learning: Neural correlates and implications. Science, 342, 585--589.
Zeidman, P. & Maguire, E.A. (2016). Anterior hippocampus: The anatomy of
perception, imagination and episodic memory. Nature Reviews
Neuroscience, 17, 173--182. Zeki, S. (1993). A Vision of the Brain.
Oxford: Blackwell. Zeki, S. (2001). Localisation and globalization in
conscious vision. Annual Review of Neuroscience, 24, 57--86. Zeki, S.
(2005). The Ferrier Lecture 1995. Behind the seen: The functional
specialisation of the brain in space and time. Philosophical
Transactions of the Royal Society B, 360, 1145--1183. Zeki, S. (2015).
Area V5 -- A microcosm of the visual brain. Frontiers in Integrative
Neuroscience, 9 (Article no. 21). Zeki, S. (2016). Multiple asynchronous
stimulus- and taskdependent hierarchies within the visual brain's
parallel processing systems. European Journal of Neuroscience, 44,
2515--2527. Zeman, A., Dewar, M. & Della Sala, S. (2015). Lives without
imagery -- Congenital aphantasia. Cortex, 73, 378--380. Zetsche, U. &
Joormann, J. (2011). Components of interference control predict
depressive symptoms and rumination cross-sectionally and at six months
follow-up. Journal of Behavior Therapy and Experimental Psychiatry, 42,
65--73. Zevin, J.D. & Seidenberg, M.S. (2006). Simulating consistency
effects and individual differences in non-word naming: A comparison of
current models. Journal of Memory and Language, 4, 145--160. Zhang, H.,
Eppes, A., Beatty-Martinez, A., Navarro-Torres, C. & Diaz, M.T. (2018).
Task difficulty modulates brain-behaviour correlations in language
production and cognitive control: Behavioural and fMRI evidence from a
phonological go/no-go picture-naming paradigm. Cognitive, Affective &
Behavioral Neuroscience, 18, 964--981. Zhang, T.R. & Chan, A.H.S.
(2016). The association between driving anger and driving outcomes: A
meta-analysis of evidence from the past twenty years. Accident Analysis
and Prevention, 90, 50--62. Zhang, X. & Samuel, A.G. (2018). Is speech
recognition automatic? Lexical competition, but not initial lexical
access, requires cognitive resources. Journal of Memory and Language,
100, 32--50. Zhuang, J., Randall, B., Stamatakis, E.A., Marslen-Wilson,
W.D. & Tyler, L.K. (2011). The interaction of lexical semantics and
cohort competition in spoken word recognition: An fMRI study. Journal of
Cognitive Neuroscience, 23, 3778--3790. Ziegler, J.C., Grainger, J. &
Brysbaert, M. (2010). Modelling word recognition and reading aloud.
European Journal of Cognitive Psychology, 22, 641--649.

Zihl, J. & Heywood, C.A. (2015). The contribution of LM to the
neuroscience of movement vision. Frontiers in Integrative Neuroscience,
9 (Article no. 6). Zihl, J. & Heywood, C.A. (2016). The contribution of
single case studies to the neuroscience of vision. Psych Journal, 5,
5--17. Zihl, J., von Cramon, D. & Mai, N. (1983). Selective disturbance
of movement vision after bilateral brain damage. Brain, 106, 313--340.
Zimmer, H.D. (2008). Visual and spatial working memory: From boxes to
networks. Neuroscience and Biobehavioral Reviews, 32, 1373--1395.
Zimmermann, F.G.S. & Eimer, M. (2013). Face learning and the emergence
of view-independent face recognition: An event-related brain potential
study. Neuropsychologiat 51, 1320--1329. Zogg, J.B., Woods, S.P.,
Sauceda, J.A., Wiebe, J.S. & Simoni, J.M. (2012). The role of
prospective memory in medication adherence: A review of an emerging
literature. Journal of Behavioral Medicine, 35, 47--62. Zuk, J. & Gaab,
N. (2018). Evaluating predisposition and training in shaping the
musician's brain: The need for a developmental perspective. Annals of
the New York Academy of Sciences, 1423, 4--60. Zwaan, R.A. (2014).
Embodiment and language comprehension: Reframing the discussion. Trends
in Cognitive Sciences, 18, 229--234. Zwaan, R.A. (2016). Situation
models, mental simulations, and abstract concepts in discourse
comprehension. Psychonomic Bulletin and Review, 23, 1028--1034. Zwaan,
R.A. & Madden, C.J. (2004). Updating situation models. Journal of
Experimental Psychology: Learning, Memory, and Cognition, 30, 283--288.
Zwaan, R.A. & Pecher, D. (2012). Revisiting mental simulation in
language comprehension: Six replication attempts. PLoS ONE, 7 (Article
no. e51382). Zwaan, R.A. & van Oostendorp, U. (1993). Do readers
construct spatial representations in naturalistic story comprehension?
Discourse Processes, 1, 125--143. Zwaan, R.A., Langston, M.C. &
Graesser, A.C. (1995). Dimensions of situation-model construction in
narrative comprehension. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 21, 386--397. Zwaan, R.A., Stanfield, R.A. &
Yaxley, R.H. (2002). Langue comprehenders mentally represent the shapes
of objects. Psychological Science, 13, 168--171. Zwitserlood, P. (1989).
The locus of the effects of sententialsemantic context in spoken-word
processing. Cognition, 32, 25--64.

Author index

Author index Aarts, H. 772 Abbott, R.D. 554 Abdellaoui, M. 645f, 646
Aberegg, S.K. 651 Ablinger, I. 432, 451 Abramov, I. 66 Achim, A.M. 545
Ackerman, P.L. 597, 619 Ackerman, R. 589, 590, 688, 689, 689f, 708
Aczel, B. 663 Adank, P. 516 Addis, D.R. 311, 358 Addyman, C. 33 Adelman,
J.S. 446 Adlam, A.-L.R. 303 Adolphs, R. 734 Adriaanse, M.A. 769
Aggleton, J.P. 297, 336 Ahtamad, M. 211 Aikin, S.F. 694 Ajina, S. 85
Akhtar, S. 351 Alain, C. 408 Alais, D. 210 Al-Azary, H. 482 Albarracin,
D. 651 Albo, Z. 290 Albouy, G. 330, 332 Albright, T.D. 372 Aldao, A. 729
Alea, N. 347 Alexander, M.P. 251, 260 Alexeeva, S. 410 Ali, S.S. 25, 26f
Allen, R.J. 252 Allison, M. 548 Allopenna, P.D. 422, 422f, 426
Al-Moteri, M.O. 605, 605f, 607 Alonso, J.M. 96 Alsius, A. 411 Altarriba,
J. 237 Altenberg, B. 518 Altmann, E.M. 379, 464, 591

Álvaro, L. 65 Alves, R.A. 552, 553f, 556 Aly, M. 297 Amado, S. 751 Amer,
T. 195, 586, 588 Ames, A. 79 Amir, N. 760 Amitani, Y. 632, 633 Anderson,
C.J. 651 Anderson, F.T. 376, 388 Anderson, J.R. 7, 27, 30, 31f, 32, 271
Anderson, M.C. 271, 285, 286, 286f, 287 Anderson, R.B. 635 Anderson,
R.C. 374, 500 Anderson, S.W. 329 Andrade, J. 132 Andrews, P.W. 751
Andrews, S. 439 Andrews-Hanna, J.R. 346, 347f Angele, B. 454, 456
Angelone, B.L. 171 Angie, A.D. 743 Ansorge, U. 230 Ardila, A. 51, 557
Armstrong, T. 757 Ask, K. 747 Atkins, J.E. 76 Atkinson, A.P. 160
Atkinson, R.C. 240, 240f, 241, 242, 243, 244, 296 Atkinson, R.L. 394
Auckland, M.E. 113 Augustine, A.A. 726 Avenanti, A. 162 Averell, L. 278
Awasthi, B. 104, 104f Awh, E. 184, 185, 185f Axelrod, R. 653 Axelrod, V.
121 Aydelott, J. 181 Azevedo, R.T. 113 Azuma, T. 406--407

Baars, B.J. 783 Baddeley, A.D. 132, 179, 238, 246, 246f, 247, 248, 248f,
249, 251, 252, 255, 262, 263f, 265, 288, 290, 293, 301, 310, 376, 557,
597, 617 Bader, M. 475 Badets, A. 143, 144 Bae, G.-Y. 400 Bagneux, V.
751 Baker, C.M. 55 Bakker, M. 672 Bakroon, A. 160 Baldassarre, A. 197
Baldassi, C. 50 Ball, F. 164, 167 Ball, L.J. 668, 679, 684 Balota, D.A.
434 Banks, M.S. 76 Bannard, C. 397 Bannert, M.M. 51, 68 Baptista, M. 395
Bar, M. 108, 114, 115, 115f Barense, M.D. 102, 102f Bargh, J.A. 229,
639, 640, 690 Bar-Haim, Y. 756 Barliya, A. 160 Baronchelli, A. 395
Barrett, L.F. 652, 716, 716f Barreyro, J.P. 494 Barriuso, T.A. 488
Barry, C. 165, 561 Barry, C. (with Martin) 561 Barry, S. 74 Barsalou,
L.W. 316--318, 321, 341, 481 Bartels, A. 51, 68 Barth, M. 272 Bartlett,
F.C. 364, 498--500, 501, 502 Bartley, J.E. 576, 577f Bartolo, A. 11, 12,
58 Bartolomeo, P. 11, 12, 136 Barton, J.J.S. 120 Bartsch, M.V. 188--189
Baruch, O. 115, 115f, 116, 116f, 138 Barzykowski, K. 358, 359

916

Author index

Basehore, Z. 635 Bastin, C. 337 Bauer, A.J. 314 Baum, S.R. 493
Baumeister, R.F. 768, 771, 772, 773, 781 Baumgartner, S.E. 213 Bäuml,
K.-H. 265, 281, 282, 282f Bäuml, K-H.T. 268, 268f Baurès, R. 150
Bavelas, J. 548 Baxendale, S. 296 Bayley, P.J. 302 Bayne, T. 767, 778,
793 Baynes, K. 794 Bays, P.M. 199 Beauvais, C. 552, 555 Beck, A.T. 753,
757 Beck, C. 413 Beck, S.M. 385 Becker, E.S. 736 Becker, M.W. 201, 201f
Beckers, G. 83 Beckmann, C.F. 63, 64 Beeke, S. 540 Beeman, M. 577, 578
Beer, J.S. 740 Behrmann, M. 119, 189 Beisswingert, B.M. 752 Bennett,
C.M. 25, 25f Bennett, P. 721 Benoit, R.G. 311--312, 312f Benton, C.P.
128 Bereiter, C. 554, 555 Beres, A.M. 475 Bergeron, V. 10 Berggren, N.
204 Bergman, E. 500 Bergmann, H.C. 245 Bergström, Z.M. 286, 287 Berisha,
V. 518 Berman, M.G. 242 Bermúdez-Rattoni, F. 293 Bernier, J. 561
Berninger, V.W. 554 Berntsen, D. 351, 353, 354, 354f, 355, 358 Berwick,
R.C. 536f Besson, G. 314 Beukema, P. 276, 276f, 333, 338 Bezdicek, O.
330 Bezuidenhout, A. 484 Bhatt, R.S. 101 Bi, Y.C. 436 Bialek, M. 626,
743 Bickerton, D. 396 Bidelman, G.M. 405 Biederman, I. 106--107, 107f,
108, 111, 137--138, 532 Bier, N. 323

Biggs, A.T. 190, 190f, 201, 201f, 368 Bilalić, M. 123, 585, 604 Binder,
E. 161 Binder, J.R. 300, 320, 337 Bindschaedler, C. 301--302 Binkofski,
F. 155 Bird, C.M. 308, 310, 336 Bischof, W.F. 146 Bisenius, S. 789
Bixler, R. 457 Blackmer, E.R. 525 Blackmon, J. 12, 794 Blanchette, I.
595, 730, 749 Blaney, P.H. 759 Blank, H. 367, 368f Blank, I.A. 537
Blanke, O. 769, 771 Bliss, D.P. 172 Block, N. 767, 776 Bluck, S. 347
Blumenthal, A. 302, 335 Bode, S. 774--775, 774f Bodien, Y.G. 791
Boettger, R. 653 Boiteau, T.W. 517 Bolden, G.B. 549 Boly, M. 782, 792
Bonato, M. 199, 200 Bonin, P. 533 Bonnefon, J.-F. 741, 742f Bonnefond,
M. 691--693 Booth, R.W. 760, 763 Bor, D. 767 Borges, J.L. 279
Borghesani, V. 318, 321 Borghi 317 Borhn 478--479 Bormann, T. 9, 431
Borst, G. 691, 693 Borst, J.P. 218--219 Bos, E.M. 771 Bose, A. 542
Bostyn, D.H. 743 Bourke, L. 557 Bourne, L.E. 600 Bouvier, S.E. 50
Bowden, E.M. 578 Bowen, H.J. 734 Bower, G.H. 322 Bowers, J.S. 28, 29,
336, 701 Bowles, B. 307 Bown, H.E. 532 Boyles, T. 647 Brainard, D.H.
67f, 68 Brainerd, C.J. 309, 311 Bramăo, I. 289 Bramão, I. 288
Braňas-Garza, P. 2 Brandt, A. 404

Brandt, K.R. 306, 307 Branigan, C. 731, 732, 733 Bransford, J.D. 491,
499, 500 Brase, G.L. 34 Braunstein, M. 725, 727, 728 Breitmeyer, B.G. 90
Bremmer, F. 146 Brendel, E. 152 Brenner, E. 77, 146 Brewer, N. 364, 370
Brewer, N.T. 651, 703 Brewin, C.R. 350 Bridge, H. 74, 86, 87, 136
Briggs, G.F 731 Broadbent, D.E. 180, 181f, 182 Brock, J. 4, 414f Bröder,
A. 636 Brooks, D.N. 310 Brooks, R. 647 Brosch, T. 719 Brothers, T. 456
Brown, A.S. 345 Brown, K.F. 651 Brown, R. 349 Brown, T.J. 371
Brown-Schmidt, S. 484, 487, 521, 545, 546 Bruce, V. 125, 125f, 127, 128,
129, 130, 138, 144 Bruner, J.S. 4, 59, 72f Brüning, J. 214 Bruno, N. 59,
75, 76 Brunyé, T.T. 607, 682 Brusovansky, M. 656 Bruyer, R. 117
Brysbaert, M. 435, 436, 443, 446, 470 Buchanan, L. 482 Buchanan, T.W.
359 Buckley, M.J. 298 Buckthought, A. 73 Buetler, K.A. 452 Bullmore, E.
8, 14, 14f Bülthoff, I. 74 Burdett, B.R.D. 215 Burgess, P.W. 261
Burgoyne, A.P. 604, 618 Burke, K.A. 494 Bürki, A. 531 Burman, J.T. 3
Burnham, B.R. 190--191 Burns, B.D. 576, 602, 603 Burr, D. 210 Burton,
A.M. 123, 127, 128, 129, 370 Busch, N.A. 167 Busigny, T. 119--120, 120f
Butterfield, S. 411 Butterworth, B. 542 Buxbaum, L.J. 155

Author index Byrne, M.D. 27 Byrne, R.M.J. 668--669, 670 Cabeza, R. 338,
339f Caccappolo-van Vliet, E. 445, 450 Caharel, S. 117 Cahill, L. 735
Cahir, C. 749 Cai, Z.G. 411, 412f, 469 Caird, J.K. 214, 215 Calder, A.J.
128 Calderwood, L. 128 Calet, N. 463--464 Caliglore, D. 276 Caltagirone,
C. 200 Calvillo, D.P. 584 Calvo, M.G. 494, 495 Camerer, C. 708 Campbell,
K.L. 398 Campbell, T.H. 695 Campitelli, G. 614, 615 Campos, B. 748
Campoy, G. 242, 748 Cane, J.E. 486 Cann, H.W. 695 Caparos, S. 191 Cappa,
S.F. 539 Caramazza, A. 32 Caravolas, M. 434, 434f Carbonell, K.M. 404
Carpenter, P.A. 255, 487--488, 489 Carpenter, S.K. 265 Carrasco-Ortiz,
H. 436 Carrera, E. 11 Carriedo, N. 482 Carter, O.L. 114 Cartmill, E.A.
548 Casasanto, D. 400 Casey, J.P. 694 Castillo, M.D. 758 Catmur, C. 771
Cattinelli, I. 446 Cavaco, S. 329 Cave, K.R. 184 Čavojová, V. 697 Ceci,
S.J. 618 Celeghin, A. 86, 87 Ceraso, J. 679 Cermak, L.S. 326 Chabanat,
E. 83 Chabris, C.F. 172, 172f, 173, 310, 363 Challis, B.H. 263
Challoner, J. 586 Chalmers, D. 768 Chamberlain, F. 251 Champod, C. 98
Chan, A.H.S. 730, 748 Chan, A.H.S. Tsang, S.N.H. 216 Chan, A.H.S. Zhang,
T.R. 730, 748

Chan, J. 593 Chan, J.C.K. 291--292, 310 Chang, E.F. 182 Chang, H. 207,
208, 208f Chang, J.Y. 602--603, 604 Changeux, J.P. 783, 784 Chaplin,
T.A. 52 Charness, N. 602 Charpentier, C.J. 649--650, 745 Chase, W.G. 614
Chater, N. 394, 395, 398, 401, 409, 516, 517, 521, 535, 564, 701 Chee,
Q.W. 263, 264, 264f Cheek, N.N. 656 Chen, C.C. 77 Chen, J. 60, 61f, 320
Chen, Q. 438 Chen, S. 778 Chen, X.-J. 387 Chen, Y. 189 Chen, Y.-C. 209,
210 Chen, Z. 184, 187f, 188, 242, 594 Chenoweth, N.A. 551, 556, 557
Cherry, E.C. 179--180 Cherubini, P. 669 Chiarello, C. 417 Chica, A.B.
193, 194 Chick, C.F. 643 Choe, H. 515 Cholewa, J. 560--561 Chomsky, N.
4, 393, 394, 395--398, 462, 465 Chouinard, B. 480, 480f Christiansen,
M.H. 394, 395, 398, 409, 517, 521, 535, 540, 564 Christianson, K.
441--442, 474 Christianson, S.A. 364 Christopher, E.A. 386, 386f
Christopher, M.E. 494 Christou, A.I. 270 Chrysikou, E.G. 587--588
Chukoskie, L. 205--206 Chun, M.M. 179 Chun, W.Y. 639, 640 Chung, S. 396
Church, B.A. 326, 327 Churchland, P.S. 17f Chuy, M. 555 Ciaraffa, F. 196
Cichy, R.M. 205 Cipiolotti, L. 258 Cisler, J.M. 756 Clancy, S.A. 285
Clark, C.M. 277, 598 Clark, I.A. 329 Clark, L.A. 745, 746, 755 Clarke,
J. 171, 240--241 Clarke, P. 763 Clarkson, G. 602

917

Clay, Z. 394 Clifton, C. 403, 466, 471 Clore, G.L. 734, 744 Close, J.
314 Coch, D. 181 Coco, M.I. 467 Coetzee, J.P. 690 Coget, J.-F. 748
Cohen, L.R. 159 Cohen, M.A. 170, 777, 790 Colavita, F.B. 209 Cole, J.
464 Collegio, A.J. 184 Collette, F. 259--260 Collin, G. 15 Collins, A.M.
315, 497 Collins, W.M. 497 Colman, A.M. 716, 767 Colomb, C. 374 Colombo,
L. 557 Coltheart, M. 7--8, 8f, 11, 27, 29, 406, 435, 442, 443, 444f,
445, 450, 452 Colvin, M.K. 590, 795 Cona, G. 377, 384--385 Connor, C.E.
50 Conway, A.R.A. 181, 255, 257 Conway, M.A. 353, 355--356, 356--357,
357f, 358f, 359, 362 Cook, A.E. 492, 504, 505--506, 506f Cook, G.I. 387
Cook, S.W. 548 Copeland, D.E. 682 Corbetta, M. 178, 191--193, 193f,
194--195, 196, 197, 198--199 Corkin, S. 297 Corley, M. 528 Cormack, L.K.
146 Cormier, D.C. 549 Corner, A. 700, 701f Corrow, S.L. 120 Cosentino,
S. 323 Coste, C.P. 195 Costello, F.J. 27 Côté, S. 744 Courage, M.L. 351,
352 Cowan, N. 242 Cowen, A.S. 716 Cowey, A. 52, 55 Cowley, M.B.
668--669, 669--670, 670 Cowley, S.J. 484 Cox, W.T.L. 113 Craik, F.I.M.
262, 264, 294 Crassini, B. 150, 150f Crawford, J.D. 57, 57f Crawford,
J.R. 376 Craycraft, N.N. 546 Creem, S.H. 61 Crescentini, C. 591 Crible,
L. 549

918

Author index

Crisp, J. 450--451 Cristea, I.A. 762 Crocker, M.W. 427, 428f Croskerry,
P. 625--626, 625f, 629, 708 Crupi, V. 626 Cruse, D. 778, 779f Cryder,
C.E. 746, 746f Crystal, D. 393, 515, 516 Curiel, J.M. 508 Curot, J. 302
Curran, T. 117 Curtis-Holmes, J. 685 Cusack, R. 131 Cutini, S. 199
Cutler, A. 411 Cutting, J.E. 75, 76 Cuttler, C. 380 Cvejic, E. 548
Dąbrowska, E. 465, 472 Dagher, A. 590--591, 590f Dalgleish, T. 361,
361f, 362--363, 362f, 713 Dalrymple, K.A. 95 Damian, M.F. 533 Danckert,
J. 197f Dando, C.J. 374 Dandolo, L.C. 293 Danek, A.H. 578, 582 Daneman,
M. 255 Daniel, F. 497 Darbor, K.E. 630, 745 Darling, S. 246f, 253, 253f
Das, T. 330 D'Avanzato, C. 729 Davare, M. 61 David, S.V. 182 Davies, A.
212, 216 Davies, B.L. 543 Davies, M. 10 Davies-Thompson, J. 126, 127f,
128--129 Davis, C.J. 701 Davis, D. 284 Davis, J.I. 722 Davis, M. 499
Dawes, R.M. 644, 704 Dawson, E. 677, 697 Day, M.V. 350 de Bode, S. 794
de Gardelle, V. 327, 777 de Graaf, T.A. 780, 788, 792 De Groot, A.D. 601
de Haan, E.H.F. 56f, 62, 64, 197, 199, 200 De Houwer, J. 228 de la Rosa,
S. 161 de Manzano, O. 610, 611, 618 De Martino 652

De Neys, W. 576, 637, 638, 640, 675, 685--686, 685f, 743 De Salvo, S.
778 de Schotten, M.T. 8--9 De Vries, J.V. 72, 72f De Vries, M. 749
Deady, D.K. 722 Dean, M. 651 Debelak, R. 591 Dębska 484 DeCaro, M.S 255,
257, 587, 587f Dede, A.J.O. 299, 331 Deffenbacher, K.A. 369 Degno, F.
456 Dehaene, S. 783, 784 DeHart, T. 736 Del Cul, A. 789 Del Guidice, M.
754 del Prete, F. 287 Delaney, P.F. 591 Dell, G.S. 29, 32, 514, 519,
521, 522, 525--526, 526--527, 528, 529--530, 533, 538, 539, 541, 564
DeLong, K.A. 440--441 DeLucia, P.R. 151 Demertzi, A. 792 DeMiguel, V.
655 Demiray, B. 347 den Ouden, D.-B. 467 Denison, R. 77 Dennis, N.A. 285
Derakshan, N. 761 Derryberry, D. 761 Desai, R.H. 300 Destrebecqz, A. 275
Deutsch, D. 180, 181f, 182 Deutsch, J.A. 180, 181f, 182 Devine, P.G. 113
Dew, I.T.Z. 338, 339f Dewar, M.T. 283 Di Lollo, V. 186 Di Russo, F. 198
Di Stasi, L.L. 142 Diana, R.A. 306, 307f, 308, 309--310 Diano, M. 198
Diao, L. 722--723 Dick, A.S. 537 Dick, F. 537 Didierjean, A. 584
Dijksterhuis, A. 662, 664 Dijkstra, K. 510 Dijkstra, N. 23, 134--136,
135f, 137 Ding, S. 95 Dismukes, K.R. 387 Dismukes, R.K. 378, 379, 387
Ditto, P.H. 628 D'Mello, S. 457 Dodhia, R.M. 387 Döhring, J. 330

Dolcos, F. 734, 735, 735f Domeier, M. 644, 644f Domini, F. 74 Domurat,
A. 632--633 Donovan, I. 187, 189 Dooling, D.J. 500 Doré, B.P. 727, 730
Dosenbach, N.U.F. 195--196 Douglass, A.B. 364 Downing, P.E. 24, 121
Doyon, J. 331 Dozois, D.J.A. 753, 757 Drews, F.A. 214, 215 Dreyer, F.R.
318 Dronkers, N.F. 536--537 Dror, I.E. 98--99, 98f Drummond, L. 187
Drury, J.E. 463, 466--467 Dubarry, A.-S. 534 Duchaine, B. 121f Dudai, Y.
311 Duff, M.C. 302, 545 Duffau, H. 9 Duffy, S.A. 463 Dufour, S. 423
Duggan, G.B. 590 Dugué, L. 197--198 Duin, R.P.W. 95 Dummel, S. 636
Dunbar, K. 595, 670 Duncan, J. 199, 203 Duncker, K. 585, 585f, 586, 594,
595 Dunlosky, J. 265 Dunn, J.C. 306 Dunning, D. 705 Duss, S.B. 335 Dux,
P.E. 222 Dyer, J.S. 656 Dysart, J.E. 370 Eagle, M.N. 162 Easterbrook,
J.A. 369, 731, 732, 734--735 Eaton, E. 542 Ebbinghaus, H. 58, 59, 59f,
278, 279f Ecker, U.K.H. 283 Edelson, M.G. 311, 367, 368 Edelstein, R.S.
733 Egly, R. 186--187, 187f, 188 Eherenfreund-Hager, A. 746, 749
Ehinger, K.A. 204, 204f, 206 Ehrenfreund-Hager, A. 746 Eich, E. 737
Eichenbaum, H. 297 Eil, D. 646 Eimer, M. 110, 119, 204, 209 Einstein,
G.O. 375, 382 Ekroll, V. 582, 582f Eldar, E. 716

Author index Elder, J.H. 100 Elliott, D. 154 Ellis, A.W. 430, 430f, 431,
515 Ellis, B.J. 754 Ellis, J. 345--346 Ellis, J.J. 437f, 579 Ellsworth,
P.C. 719 Elman, J.L. 417, 420 Elqayam, S. 694, 703 Elsey, J.W.B. 291,
292 Elward, R.L. 301 Endres, T. 266 Endress, A.D. 242, 243f Engbert, R.
455 Engel, P.J.H. 605 Engel, S. 539 Engel, S.A. 50 Engle, R.W. 254, 255,
488 Engstrom, J. 215 Enz, K.F. 355 Erdfelder, E. 636, 637 Ereku, M.H.
614 Erez, J. 110 Ericsson, K.A. 613--614, 616--617, 620 Eriksen, C.W.
184, 731 Eriksson, J. 791 Esteves-Sorenson, C. 651--652 Etchells, D.B.
110 Etkin, A. 725, 727, 729 Ettlinger, M. 423--424 Eustache, F. 347
Evans, J.St.B.T. 571, 592, 637, 667, 668, 683, 684, 685, 686, 689, 690,
694, 703, 704, 705 Evans, N. 396, 683--684 Evans, S. 183 Everaert, J.
758, 760, 761f, 763 Eysenck, M.C. 263 Eysenck, M.W. 4, 179, 264, 287,
289, 300, 443, 732, 754, 757, 758, 759, 761 Fabbro, F. 535 Fajkowska, M.
754, 757 Fama, R. 299 Farag, C. 323 Farah, M.J. 117, 118 Farmer, C.M.
214 Farmer, G.D. 219 Farmer, M.E 403 Faroqi-Shah, Y. 540 Faroqui-Shah,
Y. 541, 542 Fatania, J. 283 Fath, A.J. 150--151 Fattori, P. 46 Fawcett,
J.M. 369, 733 Fazekas, P. 768 Fazio, L.K. 629 Fecher, B. 33 Fedor, A.
581

Fedorenko, E. 461, 537 Fedzechkina, M. 396 Feeser, M. 728 Feinstein,
J.S. 735 Feist, G.J. 671 Feldman, A.G. 145 Feldman, G. 651 Feldman, J.
55, 241 Felleman, D.J. 44, 95 Femandes, M.A. 307, 336 Ferber, R. 521
Ferber, S. 197f Ferbinteanu, J. 338--339, 340 Fernandez, K.C. 729
Ferrari, P.F. 163 Ferrari, V. 327 Ferreira, F. 472--473, 473--474, 473f,
475, 520 Ferreira, V.S. 527, 544, 545, 546, 546f Ferrer, R.A. 747--748
Ferrucci, S. 131 Fetkewicz, J. 284 ffytche, D.H. 131 Fiedler, K. 630,
632, 633, 636, 637 Filmer, H.L. 221 Findlay, J.M. 165, 166f Fine, A.B.
469--470 Finn, E.S. 9 Firestone, C. 112, 113, 114 Fischer, J. 172
Fischer, P. 658--659, 659f Fischer, R. 214, 226 Fischer-Baum, S. 445
Fisher, D.L. 214, 215 Fisher, R.P. 373--374 Fisher, S.E. 397 Fisk, J.
361 Fitousi, D. 128 Fivush, R. 351, 352 Fleck, J.I. 581 Flegal, K.E. 271
Flevaris, A.V. 105 Flinker A. 537 Fodor, J.D. 463--464 Foerde, K. 325,
328 Foland-Ross, L.C. 759 Follmer, D.J. 504, 505 Fontaine, J.R.J. 720
Forbus, K. 593, 594f, 598--599 Ford, J.H. 359 Forster, S. 190 Fossett,
T.R.D. 530 Foster, D.H. 68--69, 70, 71 Foster, J.D. 647 Foulsham, T. 144
Fowlkes, C.C. 100 Fox, C.J. 128 Francesconi, M. 658 Frank, M.C. 400

919

Frankland, P.W. 279, 352, 352f Franklin, S. 431 Franz, V.H. 60 Fraser H.
21f, 413 Frässle, S. 780, 781f Frauenfelder, U.H. 423, 424, 426 Frazier,
L. 464, 465, 466 Frederick, S. 1, 592, 701, 708 Fredrickson, B.L. 731,
732 Freed, E.M. 489, 490 Freeman, J. 777, 777f French, R.M. 33 Freud, E.
62, 104 Freud, S. 284, 285, 351, 769 Freuenberger, D. 441 Frick-Horbury,
D. 548 Fried, I. 775 Friederici, A.D. 463 Friedman, L. 540 Friedman,
N.P. 257, 258--259, 259f, 260, 261, 262 Friedman-Hill, S.R. 202--203
Friedmann, N. 538 Friedrich, C.K. 427 Friedrich, T.E. 196 Friesen, L.K.
793 Frijda, N.H. 723 Frisson, S. 441 Froyen, V. 102 Fugelsang, J.A.
671--672 Fukumura, K. 546 Funahashi, S. 222 Funnell, M. 538 Futrell, R.
396 Gable, P.A. 731--732, 733--734 Gabrieli, J.D.E. 326 Gaeth, G.J. 704
Gilaie-Dotan, S. 53, 53f Gaillard, R. 54, 89, 272, 329, 789 Gainotti, G.
196 Gaissmaier, W. 624, 634 Gale, M. 668 Gallagher, S. 773 Gallese, V.
161, 163 Galletti, C. 46 Gallivan, J.P. 154 Gallo, D.A. 264--265
Galotti, K.M. 659--660, 660f Galton, F. 130 Gambetti, E. 745, 747 Gambi,
C. 517 Gandhi, T. 131 Gangemi, A. 2, 593 Ganong, W.F. 415--416 Gao, X.
97, 509 Garcea, F.E. 144 Garcia-Retamero, R. 647 Gardiner, J.M. 301

920

Author index

Garg, N. 746 Garner, K.G. 222 Garnsey, S.M. 469 Garrard, P. 466, 550
Garrett, B. 363--364 Garrett, M. 519--520 Garrod, S. 401, 494, 543
Garson, J. 29--30 Gaskell, M.G. 426, 427, 428, 429 Gathercole, S.E. 557
Gauld, A. 500 Gauthier, I. 110, 111 Gauvin, H.S. 525 Gavilán, J.M. 106
Gawronski, B. 740, 740f, 743 Gazzaniga, M.S. 691, 793, 794, 795
Gegenfurtner, A. 604, 607 Gegenfurtner, K.R. 60 Geiselman, R.E. 373--374
Geisler, W.S. 100 Gelade, G. 202, 203, 203f, 206 Gelbard-Sagiv, H. 88
Geng, J.J. 202 Genon, S. 11 Gentner, D. 481, 482, 483f Genty, E. 394
George, T. 480, 483 Geraerts, E. 284--285 Gerhardstein, P.C. 108
Germine, L. 119 Gerrig, R.J. 491, 545, 547 Gerwing, J. 548 Geskin, J.
119 Geurten, M. 309, 309f Ghafur, R.D. 724, 730 Gheysen, F. 276 Ghose,
G.M. 54 Ghosh, V.E. 322--323, 499, 501 Gibbs, R.W. 483 Gibson, B.S. 190,
191f Gibson, E. 488 Gibson, J.J. 72, 141--146, 142f, 148--149, 175 Gick,
M.L. 594--595 Gigerenzer, G. 631, 634, 635, 636, 637, 647, 655
Gilaie-Dotan, S. 50, 53--54, 53f, 159 Gilbert, C.D. 111 Gilboa, A. 304,
322, 499, 501 Gilden, D.L. 203, 207 Gilhooly, K.J. 584 Gillam, B. 77
Ginet, M. 374 Giorgetta, C. 649 Girotto, V. 677 Girshick, A.R. 76
Giusberti, F. 745, 747 Glennerster, A. 80 Glöckner, A. 636, 646

Glover, S. 152, 153, 154 Gobet, F. 4, 585, 588, 601, 602, 602f, 603,
614, 615 Godden, D.R. 288, 290 Godefroy, O. 251 Godwin, D. 89 Goel, V.
573, 574, 590, 691, 693 Goh, W.D. 263, 264, 264f, 289, 289f Goldberg, A.
558 Goldberg, I.I. 789 Goldberg, R.M. 100 Goldenberg, G. 131 Goldinger,
S.D. 125, 406--407 Goldrick, M. 398, 522, 526, 529, 536, 537, 543
Goldstein, D.G. 635 Gollwitzer, P. 387 Golob, E.J. 256 Golumbic, E.Z.
183 Gómez, A.T. 74 Gomulicki, B.R. 498 Gong, L. 326, 331 Gontar, P.
378--379 Goodale, M.A. 53, 55, 56--57, 56f, 58, 59, 61, 63--64, 63f, 91,
103--104, 141, 144, 152, 153, 155 Goodhew, S.C. 184 Goolkasian, P. 96,
111, 112f Gordon, J. 66 Gotlib, I.H. 757, 759 Gottfredson, L.S. 617, 618
Grabner, R.H. 604 Graesser, A.C. 492, 497 Graf, P. 375, 376, 380 Gräff,
J. 290 Grafman, J. 574, 590 Grafton, B. 762 Graham, M.E. 73 Graham, S.A.
397 Grainger, J. 438 Granhag, P.A. 747 Granzier, J.J.M. 68 Gras, D.
495--496, 496f Grassini, S. 88--89, 89f, 90, 786 Gray, C.M. 54 Gray, R.
211 Graziano, M.S.A. 770, 771, 771f, 784, 785f Green, A.E. 600 Green, C.
285 Greenberg, D.L. 304 Greenberg, J.H. 396 Greene, A.J. 336 Greene,
C.M. 191 Greene, J.D. 738--740 Greitemeyer, T. 658--659, 659f Grice,
H.P. 480, 484, 543--544 Griffin, Z.M. 527 Griffiths, J.D. 540--541, 540f

Grill-Spector, K. 23, 121, 123 Griskevicius, V. 750 Grisoni, L. 415,
416, 429 Groome, D. 4, 300 Groopman, J. 625, 629 Gross, J.J. 724, 725f,
729 Gross, S. 776 Grossman, E.D. 159 Grossnickle, E.M. 596, 597f Grot,
S. 253 Guan, C.Q. 557 Guardini, P. 142 Gueliai, B. 549 Guida, A. 613,
614 Güllich, A. 615 Gustavson, D.E. 259 Gutchess, A.H. 35
Gutierrez-Sigut, E. 436 Guttentag, R.E. 548 Gvion, A. 538 Gwilliams, L.
425 Haak, K.V. 63, 64 Haber, R.N. 78--79, 78f Hafenbrädl, S. 655
Hagoort, P. 469, 476, 476f, 477 Hahn, B. 193 Hahn, S. 146 Hahn, U. 694,
698--699, 701 Haider, H. 272, 273, 273f, 278 Haigh, M. 700 Hall, S. 705
Halle, M. 418 Hambrick, D.Z. 616, 618 Hamlin, J.K. 36, 672 Hamm, J.P.
109 Han, S. 751 Han, S.W. 225 Han, Z.Z. 436 Hanley, J.R. 128, 436, 444,
445, 560, 562 Hannula, D.E. 245, 336 Hansen, T. 70 Haque, S. 64 Harada,
Y. 369 Hardt, O. 280 Hardwicke, T.E. 292, 293 Hareli, S. 747 Harley,
T.A. 24, 393, 409, 413, 423, 424, 447, 449, 451, 468, 493, 501, 530,
531, 532, 534, 539, 541, 542 Harm, M.W. 442, 449 Harmon-Jones, E. 732,
733--734 Harris, A.J.L. 699, 700f, 701, 744 Harrison, H.S. 150, 151
Harrison, T.L. 598 Hart, W. 659 Hartwigsen, G. 12, 22 Harvey, L.O. 130

Author index Harvey, M.I. 484 Hashtroudi, S. 331 Haskell, T.R. 522
Hassabis, D. 312 Hassin, R.R. 569, 769 Hasson, U. 478 Hata, K. 549 Hauk,
O. 317 Häuser, K.I. 478 Havelka, J. 253, 253f Hayes, J.R. 514, 551,
552f, 553, 556, 557 Hayne, H. 351, 352, 353 Hayward, W.G. 109, 110
Healing, S. 548 Heathcote, A. 278 Heck, D.W. 636, 637 Hegdé, J. 43, 43f,
46, 48, 104 Heimler, B. 609--610 Held, R.T. 73 Helder, A. 492, 492f,
494, 495, 497--498 Heller, D. 484 Hellmann, J.H. 345 Hemenover, S.H. 726
Henderson, E.N. 499 Henderson, J.M. 168--169, 169f, 186 Henke, K. 276,
300f, 333--335, 334f, 336--337, 338, 342 Henry, M.L. 450 Hepner, C. 559,
560f, 562 Herholz, S.C. 609, 610, 611 Hering, E. 65--66 Herlihey, T.A.
146 Herrera, S. 759 Hertwig, R. 630 Hesse, C. 60, 153 Hesselmann, G. 62,
87, 90, 225, 570, 769, 795, 796f Heutink, J. 51--52 Heyman, T. 316
Heywood, C.A. 50, 51, 52, 55 Hibberd, D.L. 223 Hicks, J.L. 377 Higham,
P.A. 367 Hilbert, M. 634 Hilger, K. 15 Hilliard, C. 548 Himmelbach, M.
58 Hirsch, C.R. 759 Hirst, W. 350 Hitch, G.J. 246, 246f, 262, 263f, 265
Hitchcock, C. 363 Ho, C. 211 Hobbs, S. 3 Hobeika, L. 600 Hochman, G. 645
Hodgkinson, G.P. 707 Hodgson, C. 537 Hofer, F. 202

Hoffman, P. 442, 447, 448f, 449 Hoffrage, U. 631, 632f, 703 Hogarth,
R.B. 708 Holan, A.D. 544 Holland, A.C. 736, 759 Holland, R.W. 750, 750f
Holler, J. 548 Hollingworth, A. 168--169, 169f, 186, 187, 188f Holmes,
A. 754 Holmes, K.J. 400 Holmes, V.M. 519 Holyoak, K.J. 480, 594--595
Holzgrefe, J. 463 Hommel, B. 225 Hornikx, J. 699, 701 Hortensius, R. 734
Horton, C. 181--182 Horton, W.S. 545, 547 Hosking, S.G. 150, 150f Houdé,
O. 691, 693 Houston, A.I. 648 Howard, R.W. 615, 616f Howe, M.L. 351,
352, 353 Howe, P.D. 695 Howe, P.D.L. 114, 171 Howes, A. 603, 604, 658
Huang, J. 468 Huang, Y. 64 Hubel, D.H. 96 Huberdeau, D.M. 274
Huber-Huber, C. 230 Hübner, R. 213--214 Huddleston, E. 286, 286f Hudetz,
A.G. 788 Huestegge, L. 217 Huettel, S.A. 16t Huettig, F. 403, 416, 426
Huff, M. 509 Hugenberg, K. 371 Huijser, S. 219 Hulleman, J. 203,
207--208 Humphreys, G.W. 203 Hung, C.P. 19 Hunt, R.R. 263 Huntsinger,
J.R. 730--731, 732, 733f, 734 Huppert, J.D. 753 Hurme, M. 48, 85
Hurvich, L.M. 66 Huth, A.G. 19 Hyde, K.L. 610, 611f, 612f Hyman, I. 164,
164f Hyönä, J. 503, 504, 505 Ihlebaek, C. 372 Indefrey, P. 531, 532f,
533, 534 Inman, C.S. 360 Insausti, R. 326, 326f

Inzlicht, M. 249 Ioannides, A.A. 241 Ipser, A. 411 Irish, M. 303
Ishibashi, R. 320, 321f Itkonen, T. 147 Ittelson, W.H. 73 Ittelson, W.H.
78 Itzhak, I. 493 Iyilikci, E.A. 751 Izard, C.E. 716 J. McGurk, H. 411
J. Tsotsos, J. 27 Jaarsma, T. 607 Jack, F. 351, 352 Jacobs, A. 160
Jacobs, P. 631, 632 Jacobs, R.A. 75--76 Jacoby, L.L. 281, 282, 283, 369
Jacquemot, C. 248 Jaeger, T.F. 415, 467, 547 Jain, A.K. 95 Jäkel, F. 103
Jalbert, A. 248 James, D. 576 James, E.L. 351 James, G. 704 James, K.H.
562, 563f James, T.W. 58 James, W. 178, 722 Jameson, D. 66 Janczyk, M.
225 Janelle, C.M. 731 Jans, B. 184 Jansma, J.M. 227 Janssen, P. 64
Janssen, S.M.J. 347 Jantzen, M.G. 405 Jared, D. 435--436, 438, 451, 451f
Jarosz, A.F. 587 Jeneson, A. 245 Jenkins, R. 127 Jensen, M.S. 165, 174
Jiahui, G. 122 Jiang, T. 509 Jiang, Y. 790 Jiménez, L. 274 Joanisse,
M.F. 421--422, 424 Jobard, G. 445 Johannessen, K.B. 358 Johansson, G.
157--158 Johansson, M. 288, 289 John, L.K. 672 Johnson, M.K. 499, 500
Johnson-Laird, P.N. 501--502, 678, 680--682, 683, 705, 709, 751, 754
Jolicoeur, P. 314 Jones, E.B. 762

921

922

Author index

Jones, P.R. 75 Jones, S.P. 371, 371f Jongman, S.R. 535--536 Jonides, J.
244, 249 Joormann, J. 760, 761f Josselyn, S.A. 352, 352f Jun, S.A. 464
Juphard, A. 446 Juskenaite, A. 347 Just, M.A. 314, 487--488, 489
Kaakinen, J.K. 503, 504, 505 Kahan, D.M. 695, 696, 696f, 698, 707
Kahane, G. 740 Kahneman, D. 623, 624, 627, 630, 637, 637--640, 638, 640,
641, 642, 642f, 649, 683, 704 Kaiser, D. 205 Kaiser, E. 493 Kaland, N.
479 Kandasamy, N. 652 Kandil, F.I. 147 Kane, J. 671 Kane, M.J. 254, 255,
256, 488 Kanizsa, G. 73, 73f Kanwisher, N. 121 Kaplan, S. 657 Karimi, H.
472--473, 473f, 475 Karlen, Y. 555 Karlsson, J. 503 Kasselimis, D.S.
430--431 Kassin, S.M. 98 Kastner, S. 770, 771f Katidioti, I 219, 220
Katti, H. 206 Kauffmann, L. 105 Kay, A.C. 695 Kay, K. 19 Kazanas, S.A.
237 Keane, M. 595 Keane, M.T. 27 Keating, J. 370 Kelber, A. 65 Keller,
F. 467 Kellogg, R.T. 549, 554--555, 554f, 556, 556f, 557, 558 Keltner,
D. 716, 747, 751 Kemeny, F. 329, 330, 330f Kendeou, P. 509 Kenealy, P.M.
737, 737f Kenett, Y.N. 315 Kennedy, A. 456 Kennedy, J.E. 36, 672
Kensinger, E.A. 736, 759 Kent, S.C. 554 Kersten, A.W. 339 Kessler, B.
561 Kessler, J. 789 Keys, D.J. 704

Keysar, B. 484, 486, 545, 547 Keysers, C. 161, 161f Khemlani, S. 681,
682, 683 Kidd, E. 489 Kilpatrick, F.P. 78 Kim, D. 410 Kim, E.J. 432 Kim,
H. 327, 328, 328f, 337 Kim, J.H. 352 Kim, N.-G. 80, 81 Kim, P.Y. 377
Kim, S. 80, 337, 337f, 340 Kimchi, R. 170, 187 Kindt, M. 380 King, B.R.
270 King, J.-R. 787, 788, 788f, 791 Kingston, J. 415 Kingstone, A. 144
Kinoshita, S. 438 Kintsch, W. 481, 482, 501, 502f, 503, 503f, 510, 613
Kircanski, K. 757 Kizilirmak, J.M. 578 Klargaard, S.K. 117 Klauer, K.C.
250, 250f, 674, 678--679, 679f Klaus, J. 520 Klein, C. 24 Klein, G.
660--661, 661f Klein, R.M. 403 Kleinschmidt, A. 195 Kliegl, O. 265, 281,
282, 282f Kloeters, S. 160 Klooster, N.B. 302 Klumpp, H. 727--728
Knauff, M. 682--683 Knight, R.T. 537, 590, 591 Knoblich, G. 580, 581f,
587 Knol, H. 59 Knowlton, B.J. 325 Kocab, A. 396--397 Kocagoncu, E. 426
Koch, C. 790 Koch, I. 213, 217, 223 Koehler, D.J. 633 Koehler, D.J. 704
Koellinger, P. 749 Kohn, N. 728, 728f Koivisto, M. 21, 88--89, 89f, 90,
782, 783, 783f, 786 Kok, P. 116 Kondziella, D. 778--779 Konishi, M. 768
Konopka, A.E. 521 Koole, S.L. 725--726 Koornneef, A. 475 Kopiske, K.K.
60 Koppel, J. 353, 354f, 355 Koppenol-Gonzalez, G.V. 591

Kornell, N. 266 Kosslyn, S.M. 23, 131--132, 132f, 133, 137 Koster,
E.H.W. 756, 763 Kotseruba, I. 27 Kotz, S.A. 427 Kouider, S. 88, 89
Kounios, J. 577, 578 Kourtzi, Z. 50 Kovacs, G. 328 Kovacs, K. 255, 257
Kovera, M.B. 373 Kraft, J.M. 68 Kragel, J.E. 310 Kraus, N. 404 Krauss,
S. 575, 575f Kravitz, D.J. 48, 48f, 189 Krawczyk, D.C. 595, 599, 599f,
600 Kretz, D. 595 Kriengwatana, B. 409 Króliczak, G. 59, 60f, 61 Kroll,
J.F. 535 Kruger, J.M. 705 Kruglanski, A.W. 635, 639, 640 Krupinski, E.A.
606, 606f, 609 Krynski, T.R. 626--627, 627f, 631 Kubricht, J.R. 595
Kugler, T. 747 Kühberger, A. 643 Kuhn, G. 165, 166f, 167, 170
Kulatunga-Moruzi, C. 608, 609 Kulik, J. 349 Kundel, H.L. 122, 606
Kuperberg, G.R. 415, 467, 491, 496 Kuppens, P. 720, 723 Kurby, C.A. 508,
509 Kurt, S. 183 Kvavilashvili, L. 345--346 Kwon, M. 432 Kwon, Y. 417
Lacey, S. 481 Lacroix, A.N. 406, 406f Laeng, B. 133, 133f Lafer-Sousa,
R. 51 Laganaro, M. 538 Lahmer, M. 211 Lai, C.S.L. 397 Laird, J.E. 31--32
Lakatos, I. 671 Lakshminarayanan, V. 160 Lambe, K.A. 629 Lambon Ralph,
M.A. 11, 303, 313, 319, 319f, 322, 442, 537 Lamme, V.A.F. 21, 48, 90,
111, 776, 781, 782f, 784, 790, 791 Lamy, D. 786, 786f Land, E.H. 68
Land, M. 152

Author index Land, M.F. 147 Landin-Romero, R. 303 Landy, M.S. 75, 76, 77
Lane, D.M. 602--603, 604 Lane, P. 4, 588 Lane, R.D. 719, 720f Lang, A.
369 Langenburg, G. 99 Langer, M.S. 73 Langerock, N. 242, 244 Langille,
D. 746 LaPaglia, J.A. 291--292 Lappi, O. 147, 148, 148f Lasaponara, S.
198 Latorella, K.A. 378 Lau, H. 83 Lau, H. Ko, Y. 84--85 Lau, J.Y.F. 761
Laukkonen, R.E. 579 Launay, C. 367, 368f Launder, D. 661 Lavie, N.
189--190, 231 Lawrence, A. 637 Lawson, R.R. 274, 333 Lazarus, R.S. 720
Le, X. 550 Leach, F.R. 651 Leding, J.K. 237 Ledoux, J.E. 795 Lee, C.Y.
451 Lee, D.N. 147, 149--150, 151 Lee, E.K. 519 Lee, H. 134, 135f, 137,
727 Lee, J.-S. 762 Lee, P. 399 Lee, R.J. 71 Lee, S.-H. 45 Lee, W.E. 745
Légal, J.-B. 173 Lehar, S. 46f Lehle, C. 213--214 Leinenger, M. 435, 436
Leiserowitz, A. 695 Lench, H.C. 630, 731, 744, 745, 749 Lenton, A.P.
657, 658 Lenton-Brym, A. 358 Leonard, C.J. 186 Leonard, M.K. 414
Leopold, D.A. 45 LePort, A.K.R. 348--349, 348f Lerner, J.S. 738,
743--744, 746, 747, 748, 751, 752--753, 752f Lev-Ari, S. 409, 488
Levelt, W.J.M. 29, 523, 525--526, 527, 530--533, 534, 535, 537, 538, 539
Levin, C.A. 78--79, 78f Levin, D.T. 164, 777 Levin, I.P. 704 Levine,
D.N. 515, 589

Levine, L.J. 733, 744, 749 Levine, M. 589 Levinson, S. 396, 683--684
Levis, J. 488 Leviston, Z. 695 Levy, C.M. 552, 555 Levy, D.A. 326 Lewis,
P.A. 736 Li, H. 656 Li, O. 181 Li, P. 399 Li, V. 77 Li, W. 111 Liberman,
A.M. 417--418 Libet, B. 774 Lichtenstein, S. 628 Liden, C. 413
Liebenthal, E. 418--419 Lieberman, P. 403--404 Lief, H. 284 Lien, J.W.
646 Lieto, A. 31 Liker, J.K. 618 Limpo, T. 552, 553f, 556 Lin, S. 486
Lindholm, T. 364 Lindquist, K.A. 717--718, 717f Lindsay, D.S. 366,
367--368 Lingnau, A. 162, 163 Linhares, A. 603, 604 Linkovski, O. 380,
381f Linnell, K.J. 191 Lipka, K. 562 Lisanby, S.H. 21--22 List, A. 188
Litvak, P.M. 747, 748 Liu, H.N. 721, 762 Liu, S. 518 Livingstone, M.S.
105f Lleras, A. 583 Lockhart, R.S. 262, 264, 294 Loft, S. 379, 380
Loftus, E.F. 284, 315, 365, 366, 367, 368, 497 Logačev, P. 472 Logan,
G.D. 228, 271 Logie, R.H. 501 Long, G.M. 113 Long, M.R. 546 Longstaff,
M.G. 551, 555--556 Lotto, A.J. 404 Loukusa, S. 479 Lourenço, J.S.
385--386 Love, J. 493 Lovell, P.G. 76--77 Lovett, A. 593, 594f, 598--599
Lowder, M.W. 472, 474 Lowe, R. 721 Lu, H. 158, 158f

923

Lu, S.A. 216 Lu, S.H.X. 289, 289f Luan, M. 656 Luber, B. 21--22 Luchins,
A.S. 584 Ludwig, K. 62 Luk, K.K.S. 486 Luka, B.J. 440 Luke, S.G.
441--442, 455 Lupyan, G. 113, 114 Luria, A.R. 280 Lustig, C. 283 Lyn, H.
394 MacDonald, M.C. 365, 411, 468, 475, 477, 522, 535 Mace, J.H. 333
Macerollo, A. 163 MacGregor, J.N. 590 Mack, A. 142, 171, 240--241, 791
MacLeod, A.K. 313 MacLeod, C. 763 Macnamara, B.N. 614--615, 616, 617
Macoir, J. 561 MacPherson, S.E. 212 Madden, C.J. 508 Mädebach, A. 529,
533 Madore, K.P. 311, 312 Madsen, H.B. 352 Maffei, C. 431 Magalhaes, P.
644 Magliano, J. 498, 504, 507, 510 Magnuson, J.S. 409 Maguire, E.A.
329, 610 Mahon, B.Z. 144 Mahowald, K. 518 Maier, N.R.F. 583 Maiworm, M.
210 Makovski, T. 80, 81f Mallow, J. 288, 290 Mallpress, D.E.W. 648
Maloney, L.T. 67f, 68 Mamede, S. 608, 629 Manassi, M. 172 Mandel, D.R.
643, 667 Manfredi, D.A. 481 Mani, N. 416 Manning, D. 607 Manns, J.R.
290, 302 Manstead, A.S.R. 723 Manzy, D. 214 Margolin, S.J. 498 Marien,
H. 769, 770f Marinelli, L. 277 Marinsek, N.L. 793 Mark, V. 794
Markovits, H. 675--676, 676f, 685 Markowitsch, H.J. 789 Marlatte, H.
304, 322, 501

924

Author index

Marois, R. 225 Marques, J.F. 321, 473 Marques, L.M. 411 Marr, D.
105--106, 111 Marrero, H. 677--678 Marsh, E.J. 346 Marslen-Wilson, W.D.
417, 425--426, 427, 428, 429 Martin, C.D. 156 Martin, D.H. 165, 561
Martin, P.R. 66, 67 Martin, R.C. 519 Martinez, A. 189 Martinez, L.M. 96,
165 Mashour, G.A. 788 Masicampo, E.J. 768, 781 Mather, G. 47f, 66, 106
Mather, M. 22 Mathews, A. 758 Mathy, F. 241 Matsushima, K. 555 Mattys,
S.L. 408, 410--411, 410f Maule, A.J. 707 Mauss, I.B. 726 Mayberry, E.J.
319--320, 324f Mayer, K.M. 159 Mayhorn, C.B. 377 Maylor, E.A. 530 Mayor,
J. 30 Mazzi, C. 82, 85, 87 McAlpine, D. 183 McAndrew, S. 393 McBride,
P.M. 376 McCabe, D.P. 255 McCaffrey, T. 586 McCarthy, R. 444 McClain, R.
398, 536, 537, 543 McClelland, J.L. 5, 29, 417, 420, 421--422, 424, 437,
437f, 438, 443, 457, 528 McCormick, C. 339, 340, 358, 610 McCright, A.M.
695 McCrudden, M.T. 697 McDaniel, M.A. 375, 376, 382, 383f, 384, 385f,
503 McDermott, J.H. 179, 183, 648 McDermott, K.B. 346 McDermott, R. 648
McDonald, J.L. 522 McDonnell, V. 436 McDowell, M. 631, 632 McEachrane,
M. 723 McFall, T.A. 646 McGaugh, J.L. 293 McGlone, M.S. 481 McGregor,
S.J. 603, 604 McGugin, R.W. 123 McIntosh, R.D. 56 McKeeff, T.J. 123

McKeefry, D.J. 51 McKone, E. 117, 122--123 McKoon, G. 491, 493, 494
McLaughlin, K. 606 McLeod, P. 87--88, 90, 212, 216 McMillan, B.D. 488
McMullen, P.A. 109 McNally, R.J. 285 McNamara, D.S. 498, 504, 507, 510
McNeil, M.R. 537 McNerney, M.W. 508, 510 McQueen, J.M. 423, 424, 426
McRae, K. 730 McVay, J.C. 256 Meador, K.J. 794 Medimorec, S. 552 Meehan,
T.P. 194 Megreya, A.M. 365f, 371 Meiser, T. 7 Melara, R.D. 173--174,
174f Melby-Lervag, A. 435 Melinger, A. 533 Melloni, L. 54, 89, 90, 786,
787, 787f Mello-Thoms, C. 607 Melnikoff, D.E. 229, 639, 640, 690 Melo,
M. 607--608, 608f Mély, D.A. 100 Memon, A. 374 Meng, M. 475 Menneer, T.
202 Mennin, D.S. 729 Mercer, T. 283 Mercier, H. 694--695, 697, 707
Mesgarani, N. 182 Messina, I. 729 Mesulam, M.M. 322 Metcalfe, J. 578,
737 Metzner, P. 478 Meyer, A.S. 533 Meyer, B.T. 182, 543 Meyer, D.E. 439
Meyer, K.N. 194 Mickes, L. 310 Migo, E.M. 306 Milivojevic, B. 109--110
Milkowski, M. 33 Miller, G.A. 4 Miller, J. 223, 225, 317, 318 Mills,
W.P.C. 108 Milner, A.D. 53, 55, 56--57, 56f, 59, 61, 63--64, 63f, 91,
103--104, 141, 144, 152, 153, 155, 297 Minervino, R.A. 595 Miozzo, M.
514--515 Mirković, J. 522 Mirman, D. 438 Mischel, W. 7 Misra, M. 282
Mitchell, A.S. 298

Mitchell, D.B. 280 Mitchell, D.C. 470 Mitchell, D.J. 131 Mitroff, S.R.
201, 201f Mittelstädt, V. 223 Mitterer, H. 407, 408 Mitton, J.L. 525
Miyake, A. 5--6, 257, 258--259, 259--260, 259f, 260, 261, 262 Mogensen,
J. 85 Mohamed, T. 471 Moisala, M. 213 Mojardin, A.H. 309 Mole, C.D. 147,
148, 149 Molenberghs, P. 197 Momma, S. 468--469 Monahan, P.J. 405, 418
Monin, B. 629 Monti, M.M. 690, 778 Moore, A.T. 435, 509 Moore, J.W. 773
Moore, R. 394 Moore-Berg, S. 113 Moors, A. 228, 229--231, 229f, 233,
570, 769 Moors, P. 570, 769 Morawetz, C. 185 Moray, N. 180 Morcom, A.M.
370 Morewedge, C.K. 638, 640 Morey, C.C. 250, 254 Morgan, C.A. 369
Morgan, P.H. 592 Morgenstern, O. 641, 753 Moro, V. 136 Morris, C.D. 263,
264, 287, 410 Morrison, R.G. 597 Morrone, M.C. 86f Moscovitch, M.
118--119, 304, 305f, 339, 340, 376 Moser, J.S. 495, 758--759 Mosing,
M.A. 616 Moss, J. 581 Most, S.B. 173 Motley, M.T. 521 Motta, M. 251, 705
Mottaghy, F.M. 251 Möttönen, R. 418--419 Moulton, P.L. 291 Moulton, S.T.
131 Mousikou, P. 446--447 Moxley, J.H. 603--604, 603f Moyes, J. 384
Mozuraitis, M. 487 Mueller, K.D. 518 Mueller, K.L. 397 Mueller, S. 558
Müller, N.G. 184 Munding, D. 534, 534f

Author index Murphy, C. 320 Murphy, G. 191 Murphy, G.L. 27 Murray, J.D.
494 Murty, V.P. 735 Musel, B. 104 Mustanski, B. 749 Muter, P. 288 Myers,
J.L. 504, 505--506, 506f Naccache, L. 87, 90, 768 Nachar, R.A. 97
Nairne, J.S. 237, 290, 300 Nakayama, K. 155 Namdar, G. 153 Nardo, D. 538
Nascimento, S.M.C. 68--69, 70 Naselaris, T. 133 Nation, K. 413--414,
414f Navarrete, G. 667 Navarro, D.J. 669 Navarro-Torres, C. 535 Navon,
D. 95, 95f, 223 Nee, D.E. 261 Neely, J.H. 439, 440f Neghavi, H.R.
778--779 Neisser, U. 344, 345 Nelson, K.E. 479 Nelson, L.D. 36, 414f,
479 Neumann, M.F. 370 Newell, A. 588, 588--589, 591, 593 Newell, B. 647,
648--649 Newell, B.R. 636, 637 Newman, I.R. 639--640, 686--687, 688,
704--705 Newman-Toker, D.E. 655 Newsome, M.R. 682 Newstead, S.E. 682
Nguyen, K. 503 Nicolle, A. 651 Niebergall, R. 185 Niendam, T.A. 260,
260f Nieuwenstein, M.R. 662, 663 Nieuwland, M.S. 427, 440, 441, 477, 493
Nijboer, M. 217, 218, 219, 220f Nisbett, R.E. 769 Nitsche, M.A. 22
Nitschke, K. 591 Nodine, C. 607 Nodine, C.F. 606 Nooteboom, S.G. 523,
525, 528 Nørby, S. 278--279 Nordgren, L.F. 662--663 Norman, D.A. 33
Norman, E. 269 Norris, D. 245, 423, 438, 442 Novick, J. 523 Nowinski,
J.L. 378

Nozari, N. 523--524, 524f, 525, 529 Nurullah, A.S. 214 Nusbaum, H.C. 409
Nuttall, H.E. 419 Nuzzo, R. 671 Nyberg, L. 778--779 Nyholm, S. 741--742
Oaksford, M. 677, 693, 694, 698--699, 705 Oatley, K. 751, 754 Oberauer,
K. 246 O'Brien, E.J. 491, 492, 505--506, 506f, 508 O'Brien, G.E. 403
Ochsner, K.N. 718, 718f O'Craven, K. 186 Odinot, G. 370 O'Donnell, K.
435--436, 438 Oeberst, A. 367 Oh, H. 655, 656 Ohlsson, S. 579 Okala,
B.M. 405 Olatunji, B.O. 757 Olguin, A. 182 Olive, T. 557--558 Oliveri,
M. 200 Olivers, C.N.L. 203, 207--208 Olkoniemi, H. 480 Öllinger, M. 579,
582 Olson, J.A. 773 Open Science Collaboration 34, 670 Ophir, E. 213
Oppenheimer, D.M. 629 Orchard-Mills, E. 210--211 O'Reilly, R.C. 781
Ormerod, T.C. 583--584 Ortega, J. 166 Ortony, A. 490 Osiurak, F. 143,
144, 155, 157 Osman, M. 331 O'Toole, A.J. 160 Otworowska, M. 655 Oudman,
E. 277, 325, 329 Over, D.E. 637 Overgaard, M. 84, 85, 87, 768 Pachur, T.
628, 628f, 636, 645, 648, 650, 661 Painter, D.R. 131 Pakhomov, S. 550
Paller, K.A. 291 Palmer, J.C. 365, 366 Palmer, S.E. 101, 115 Palmeri,
T.J. 220 Palombo, D.J. 349 Pan, S.C. 265, 266, 266f, 268 Panouilleres,
M.T.N. 419 Papageorgiou, C. 754

925

Papagno, C. 248--249 Papesh, M.H. 125 Papo, D. 693 Pappas, Z. 142
Parasuraman, R. 52, 159 Parfitt, P.R. 41 Park, D.C. 35 Parker, E.S. 348
Parker, S.M. 107--108 Parketny, J. 129 Parkinson, B. 720, 723, 724
Parks, C.M. 263 Pashler, H. 184, 185, 185f, 223 Passerault, J.-M. 557
Pastötter, B. 268, 268f Patal, E.Z. 310 Patihis, L. 346 Patrick, J. 592
Patsenko, E.G. 591 Pattamadilok, C. 417 Patterson, K. 12, 136, 314, 319,
442, 450 Patterson, R. 661 Pauker, E. 463, 466 Paulo, R.M. 375 Pavan, A.
50 Pavlova, M.A. 52 Payne, B.K. 113 Payne, J. 657 Payne, S.J. 590
Paynter, C.A. 592 Pearson, J. 131--132 Pecher, D. 509 Peckham, A.D. 757
Pedrazzini, E. 196--197 Pellicano, A. 156 Peltier, C. 201, 201f
Penaloza, A.A. 584 Peng, P. 489 Penhune, V.B. 275, 275f, 278, 331
Pennycook, G. 638, 640, 688 Perenin, M.-T. 57 Peretz, I. 406 Perfetti,
C. 433f Perfors, A.F. 669 Perkins, A.M. 739--740 Perretti, F. 651--652
Perry, A. 161 Perry, C. 27, 32, 446, 661 Persaud, N. 83--84, 84f,
87--88, 90 Persuh, M. 173--174, 174f Pessoa, L. 717 Peters, M.A.K. 90
Petris, S. 162, 163 Petrone, C. 463 Pezdek, K. 250 Pham, M.T. 745--746,
745f Phelps, E.A. 350 Phillips, C. 468--469

926

Author index

Phillips, J.D. 373 Phillips, W.J. 759 Piai, V. 535 Piantadosi, S.T. 462
Piazza, M. 318 Pichert, J.W. 374, 500 Pickel, K.L. 369 Pickering, M.J.
401, 517, 543 Pilkington, E. 542 Pilz, K.S. 187, 189 Pinker, S. 768
Pinna, D. 101, 101f Pinto, J. 158 Pinto, Y. 797, 797f Pirkner 170
Pirogovsky-Turk, E. 329 Pisella, A. 58 Pisella, L. 57 Pisoni, D.B. 463
Pitcher, D. 128 Pitts, M.A. 173, 174, 790, 791 Plait, P. 114f Plaks,
J.E. 651 Planton, S. 558--559, 559f Plaut, D.C. 12, 27, 29, 442, 447,
448, 449 Pleskac, T.J. 634 Plessow, F. 214 Pleydell-Pearce, C.W.
355--356, 359, 362 Pobric, G. 320 Poeppel, D. 418 Pohl, R.F. 636
Poldrack, R.A. 22--23, 24--25, 328, 405 Polyn, S.M. 310 Pope, D.G. 646
Pope, S.M. 586--587, 703--704 Popov, V. 19 Popper, K.R. 667, 670, 671
Posner, M.I. 184, 191--192 Post, L. 510 Postle, B.R. 254 Pothos, E.M.
314 Potter, M.C. 242, 243f Pourtois, G. 732 Power, M. 713 Pozzulo, J.D.
372 Prado, J. 690--691, 690f, 693 Prass, M. 314, 314f Pratte, M.S. 19
Prebble, S.C. 347 Precht, L. 215 Principe, A. 529 Proffitt, D.R. 61
Provitera, A. 679 Prull, M.W. 368 Purcell, J.J. 563 Purdon, C. 381
Putnam, A.L. 366, 366f

Puvvada, K.C. 182 Pyc, M.A. 267, 267f Pylyshyn, Z.W. 130, 132, 134f, 138
Qian, Z. 467, 475 Qu, W. 730 Quamme, J.R. 335 Quené, H. 523, 525, 528
Quinlan, T. 553, 558 Quinn, P.C. 101 Quiroga, R.Q. 17, 29 Rabin, J. 69f
Rabovsky, M. 435, 476 Race, E. 327 Rączaszek-Leonardi, J. 484 Radach, R.
451, 456 Radomsky, A.S. 381 Radonjić, A. 68 Radvansky, G.A. 507, 508,
682 Raghunathan, R. 745--746, 745f Ragni, M. 677--678, 682--683 Rahnev,
D. 77 Raichle, M.E. 25 Raizada, R.D.S. 405 Rajaram, S. 306 Rakow, T. 629
Ramsey, L.E. 197 Ramsey, R. 163 Ranganath, C. 297 Ransdell, S. 552, 555
Rao, K.V. 597 Rao, R.P.N. 64 Raposo, A. 473 Rapp, B. 515, 561, 562
Rashal, E. 102, 103 Rastle, K. 435, 436, 446 Ratcliff, R. 491, 494
Raven, J. 593, 594f, 595, 597--598, 600 Rawson, K.A. 228, 267, 267f Ray,
C. 731, 732, 733f, 734 Raymond, L. 695 Rayner, K. 403, 438, 453, 456,
464, 465, 466, 470 Read, J.D. 375 Reber, A.S. 269, 270 Reber, P.J. 276,
329 Recanzone, G.H. 209 Redelmeier, C. 633 Redfern, A.S. 128 Reed,
M.A. 761 Rees, G. 89, 90 Reeves, A.J. 68 Regier, T. 400 Rego, S. 644
Reichle, E.D. 454, 455f, 505 Reingold, E.M. 454, 455, 457, 602, 606
Reiss, J.P. 274 Remez, R.E. 409

Remington, R.W. 379 Renkl, A. 266 Renna, M.E. 729 Renoult, L. 303, 338,
347 Rens, N. 775 Rensink, R.A. 167, 168, 168f Resnik, K. 532--533
Reuland, E. 475 Reverberi, C. 691 Reverberi, D.J. 581 Rhys, C.S. 540
Rice, G.E. 319 Richards, A. 730, 749 Richards, B.A. 279 Richler, J.J.
117 Richter, T. 636 Rickard, T.C. 265, 266, 266f, 268 Riddoch, M.J. 200
Riege, A.H. 633, 634 Rientamo, E. 783 Ries, S.K. 535 Rigoli, F. 314
Riley, J.G.A. 181 Rimmele, U. 350 Rinck, M. 736 Risko, E.F. 552 Ritchey,
M. 734 Ritchie, S.J. 707 Rizio, A.A. 285 Rizzolatti, G. 162 Robbins,
R.A. 116 Robbins, T. 216--217, 247 Roberts, J. 154 Robertson, D.J. 125
Robertson, I.H. 199 Robertson, L.C. 105, 188 Robin, J. 304, 305f, 312
Robinson, B.L. 183 Robinson, G.A. 542 Robison, M.W. 256 Rock, I. 101
Rock, P.B. 152 Rodgers, J.L. 34 Roediger, H.L. 238, 264--265, 346, 499,
500 Roeham, D. 441 Rogers, B. 73 Rogers, T.T. 314 Rohde, H. 423--424
Rohde, M. 75 Rolls, E.T. 108 Rorden, C. 196 Rosch, E. 313--314 Rose,
N.S. 262 Rose, S.B. 315 Rosenbaum, R.S. 357 Rosenbloom, P.S. 27, 31
Rosenholtz, R. 65, 167, 170, 172, 206, 207, 208, 208f, 777

Author index Rosenthal, G. 117 Ross, C.T. 113 Ross, D.A. 117 Ross, D.F.
370 Ross, M. 350 Rossetti, Y. 46, 58, 62, 63f, 64 Rossion, B. 117
Rossit, S. 58 Rothkirch, M. 90 Rounis, E. 789 Roussel, M. 277, 330 Roux,
S. 533 Rowe, M.L. 397 Rowland, C.A. 265, 266--267 Roy, D.F. 374 Rubin,
D.C. 278, 350, 351, 352f, 354, 607 Ruffieux, N. 158 Rumelhart, D.E. 29,
437, 437f, 443, 457, 490, 528 Rummel, J. 384, 387, 388 Rusconi, E. 202
Rushton, S.K. 146 Russell, J.A. 716, 716f Rustemeier, M. 329 Rusting,
C.L. 736 Ruthruff, E. 223 Ryskin, R. 488 Ryu, J. 45 Sabri, M. 190 Sadeh,
T. 280--281, 333 Saenen, L. 576 Sævland, W. 269 Sakreida, K. 62--63, 64,
155, 156, 156f, 157 Sala, G. 601, 603 Salem, T. 757 Salvucci, D.D. 217,
220 Sampson, M. 541, 542 Samuel, A.G. 424 Samuelson, W. 651 Sanbonmatsu,
D.M. 214, 671 Sanborn, A.N. 701 Sand, K. 437 Sandberg, K. 88 Sandler, W.
396 Sanocki, T. 108 Santangelo, V. 348--349 Saposnik, G. 626 Sari, D.A.
763 Sarri, M. 198 Sato, K. 555 Savage, L.J. 641 Savelsbergh, G.J.P. 150
Savitsky, K. 487 Saygin, A.P. 160 Scalici, F. 308, 309f Scardamalia, M.
554

Schacter, D.L. 296, 311--312, 312, 312f, 326, 327 Schad, D.J. 455
Schartau, P.E.S. 721, 721f Schatzberg, A.F. 729 Schechter, E. 793
Schenk, T. 56 Scherer, K.R. 719 Scherer, L.D. 629 Scherman, A.Z.
354--355 Schiffer, F. 794 Schmeichel, B.J. 719 Schmidt, J.R. 679
Schmidt, S. 249 Schmidtmann, G. 108 Schneider, W. 226--228, 227f, 230,
233 Schnuerch, R. 173 Scholl, B.J. 112, 113, 114, 164, 174 Scholte, H.S.
783 Schotter, E.R. 456 Schouten, D.I. 291 Schraagen, J.M. 662, 702
Schröder, E. 209 Schulkind, M.D. 352f Schulz, D.P.A. 96 Schumacher, E.H.
224--225 Schvaneveldt, R.W. 439 Schwabe, L. 293 Schwaninger, A. 202
Schwark, J. 202 Schwartz, B. 656, 704 Schwartz, B.L. 331 Schwartz, J.
653 Schwartz, S. 190 Schwartz, Z.P. 182 Schwarz, N. 744 Schweinberger,
S.R. 128, 328 Schweitzer, M.E. 646 Schweizer, T.A. 221, 221f Schweppe,
J. 248 Schwieren, J. 265 Schwitzgebel, E. 435, 509 Scott-Phillips, T.C.
394 Scoville, W.B. 297 Scullin, M.K. 379, 382, 383f, 384, 385, 387, 388,
388f Scully, I.D. 292 Searston, R.A. 99 Sebastianelli, L. 794 Sedgwick,
H.A. 77 Segaert, K. 331 Seidenberg, M.S. 442, 449, 452 Sejnowski, T.J.
17f Sekeres, M.J. 304 Senghas, A. 396 Seo, M.-G. 652 Seoane, L.F. 462
Serre, T. 107--108 Seth, A.K. 767

927

Seymour, K. 54 Seymour, K.J. 54 Shafir, E. 641 Shallice, T. 7, 9, 11,
172, 243, 258 Shamma, S.A. 183 Shanks, D.R. 87, 90, 271, 272, 272f, 278
Sharan, L. 167, 170, 170f, 171 Share, D.L. 433, 435 Sharma, T. 44
Sharot, T. 349, 350, 734, 735 Sharpe, D. 762 Sharpe, L. 36 Sheffer, L.
653--654, 654f Shelton, J.R. 560 Shelton, J.T. 379, 382, 383f, 384, 386,
386f, 387, 388 Shen, W. 179, 579 Sheppes, G. 725 Sheridan, H. 454, 455f,
505, 602, 606 Shevell, S.K. 66, 67 Shifferman, E. 20 Shiffrar, M. 157f,
159, 160 Shiffrin, R.M. 226--228, 227f, 230, 233, 240, 240f, 241, 242,
243, 244, 296 Shimizu, R.E. 275 Shiota, M.N. 748--749, 748f Shipstead,
Z. 593, 597--598, 598f Shiv, B. 652 Shomstein, S. 187, 194 Shrem, T. 210
Shrout, P.E. 34 Shulman, G.L. 178, 191--193, 193f, 194--195, 196, 197,
198--199 Shwartz, B. 656 Siciliano, R.A. 73 Sides, A. 625 Sidi, Y. 498
Siebert, M. 735 Siegel, E.H. 722 Siegert, R. 277 Sigurdardottir, H.M.
452 Silbert, L.J. 418, 516, 517f Silvanto, J. 254 Simion, F. 158
Simmons, J.P. 34 Simmons, S.M. 215 Simon, D. 658 Simon, H.A. 241, 584,
588--589, 591, 593, 602, 660, 702, 707 Simon, J.Z. 182 Simoncelli, E.P.
777, 777f Simons, D.J. 172, 172f, 173, 310, 363 Simonson, I. 644, 653
Sinai, M.J. 73 Singer, W. 54 Singmann, H. 674, 675 Sinigaglia, C. 162,
163 Sio, U.N. 583--584 Sitek, E.J. 557

928

Author index

Skinner, B.F. 393 Skinner, E.I. 307, 336 Skipper, J.I. 418, 419--420
Slater, J. 404 Slevc, L.R. 405, 431 Slezak, P. 134, 134f Sliwinska, M.W.
128, 436 Sloman, S. 634 Small, D.A. 748 Smallwood, J. 768 Smeets, J.B.J.
77 Smith, C.A. 720 Smith, C.N. 263, 298, 308 Smith, E.E. 249 Smith, E.R.
508 Smith, R. 286, 719, 720f Smith, R.E. 263 Smith, T.J. 166, 170 Snell,
J. 438, 453, 457 Snider, N.E. 547 Snyder, J.J. 146 Snyder, K.M.
270--271, 270f, 277f Sohoglu, E. 416 Sokol-Hessner, P. 652 Sokolov, A.A.
159f Solé, R.V. 462 Söllner, A. 636 Solomon, S.H. 482, 482f Song, J.-H.
155 Soni, M. 538--539 Sörqvist, P. 191, 256 Sotiropoulos, A. 444, 445,
560, 562 Soto, D. 254 Soto-Faraco, S. 411 Soukup, G.R. 128 Sowden, S.
771 Spaar, M. 661 Spanel, K. 350 Späth, P. 636 Spelke, E.S. 212 Spence,
C. 209, 210, 211 Spence, J.R. 34 Sperber, D. 677 Sperling, G. 776, 777,
790 Sperry, L.L. 498 Sperry, R.W. 793, 794 Spiers, H.J. 243, 246, 301,
329, 333 Spiers, M.V. 296 Spille, C. 182 Sporns, O. 8, 14, 14f Squire,
L.R. 245, 290, 291, 299, 331 St. Jacques, P.L. 360, 360f St. James, J.D.
184, 731 St. John, M.F. 271 Stafura, J. 433f Stagg, C.J. 22 Stamenković,
D. 480 Stanford Encylopedia of Philosophy 593 Stange, J.P. 361

Stanley, D.J. 34 Stanley, T.D. 34 Stanovich, K.E. 592, 683--684, 685,
686, 696--697, 698, 703, 704, 705--706, 706f, 707, 708 Staub, A. 440
Staudigl, T. 288 Staugaard, S.R. 358, 359 Staw, B.M. 644, 653 Steblay,
N.K. 364, 370, 373 Steblay, N.M. 373 Steele, C.J. 275, 275f, 278, 331
Steiger, A. 643 Steinborn, M.B. 217 Steinhauer, K. 463 Steinmetz, K.R.M.
733 Stephens, R.G. 666--667 Stephenson, G.M. 500 Sternberg, R.J. 703
Stevens, K. 418 Stewart, A. 657 Stivers, T. 517 St-Laurent, M. 304
Storm, J.F. 780 Strayer, D.L. 214, 215 Strick, M. 662 Strobach, T. 221,
222, 224--225, 224f Strong, S.L. 145, 198 Stroud, J.N. 370 Studer, B.
652 Stupple, E.J.N. 679 Stuss, D.T. 251, 260--261 Sulin, R.A. 500
Summerfield, C. 77 Suri, G. 724, 730 Surloff, C. 557 Suter, R.S. 649,
650, 650f Sutter, M.L. 209 Svoboda, E. 359 Sweller, J. 589 Swets, B.
508, 520 Sylark, W.J. 629 Sylvester, C.M. 195, 195f Szabó, S. 242
Szczepanski, S. 590, 591 Taatgen, N.A. 26, 32, 33, 217, 218f, 219, 220
Tadmor, Y. 144 Tajadura-Jiménez, A. 81 Talarico, J.M. 350, 733 Tambini,
A. 734 Tamietto, M. 86f, 722 Tanaka, J.W. 314 Tang, D. 719 Tangen, J.M.
98, 579 Tanguay, A.N. 303 Tanovic, E. 760 Tarenskeen, S. 544, 544f

Tarr, M.J. 109, 110, 111 Tassy, S. 739 Taubman-Ben-Ari, O. 749 Taylor,
C.T. 761 Taylor, J.A. 274 Taylor, M.E. 314 Taylor, T. 215 Techer, F. 748
Tellegen, A. 716, 716f Tenenbaum, J.B. 626--627, 627f, 631 Tentori, K.
625, 626 Terras, M. 494 Terzi, A. 648 Tetlock, P.E. 653, 664, 703, 707
Thagard, P. 695 Thakral, P.P. 336 Theeuwes, J. 188 Thibaut, M. 207
Thomas, B.C. 739 Thomas, C. 584 Thomas, J.P. 157f, 159, 160 Thomas, K.
749 Thomas, L.E. 583 Thompson, J. 52, 159 Thompson, M.B. 98 Thompson,
R.A. 724, 725f Thompson, V.A. 589, 590, 638, 640, 677, 679, 684, 687,
687f, 688, 689, 689f, 708 Thompson, W.L. 23, 132f, 133 Thompson-Schill,
S.L. 482, 482f Thomsen, D.K. 356, 359 Thomson, J.A. 751 Thornton, T.L.
203, 207 Thorpe, S. 44 Tiedens, L.Z. 747, 751 Tiegen, K.H. 633, 634
Tierney, A. 405 Tijtgat, P. 151 Tindle, R. 551, 555--556 Tinkelenberg,
C.E. 660 Toba, M.N. 198, 199--200 Todorović, D. 72f Toffolo, M.B.J.
380--381 Toglia, M.P. 237 Toli, A. 773 Tollestrup, P.A. 372 Tolman, E.C.
3 Tong, F. 19 Tononi, G. 11 Toplak, M.E. 593, 705, 707 Toppino, T.C. 113
Trabasso, T. 498 Tranel, D. 329 Trapp, S. 108, 115 Travaglia, A. 352
Travers, E. 593 Traxler, M.J. 462, 464 Treffers, T. 749

Author index Treiman, R. 561, 562 Treisman, A.M. 180--181, 181f, 202,
203, 203f, 206, 212, 216 Tremblay, P. 537 Trench, M. 596 Tresilian, J.R.
149 Tressoldi, P.E. 24 Triesch, J. 76 Trigg, D. 773 Trippas, D. 684,
686, 687, 691, 704--705 Troiani, V. 790 Trouche, E. 698 Trout, J.D. 404
Troy, A.S. 726, 727f Tsano, S.H. 44 Tsarfaty, R. 462 Ts'o, D.Y. 54
Tsuchiya, N. 790 Tsujii, T. 691, 692f Tubau, E. 576 Tucker-Drob, E.M.
618 Tuckey, M.R. 364 Tullett, A.M. 249 Tulving, E. 262, 287, 287f,
289--290, 296, 300--301, 302, 374, 736 Turano, M.T. 125 Turner, R. 20
Tustin, K. 353 Tversky, A. 623, 624, 627, 630, 633, 637, 638, 641, 642,
642f, 657 Twedt, E. 41 Tweney, R.D. 668 Tyler, C.W. 72, 77 Tyler, L.K.
398, 417, 425, 429 Tyszka, J.M. 792 Tzourio-Mazoyer, N. 9 Uchino, B.N.
671 Ucros, C.G. 736--737 Uddén, J. 540 Uddin, L.Q. 792, 794 Uddin, S.
419--420, 420f, 423, 424 Ueno, T. 449 Ulicheva, A. 452 Ullén, F. 610,
611, 617, 617f, 618 Uncapher, M.R. 213 Unsworth, N. 256, 256f, 257, 283,
488 Urbanski, M. 600, 691 Uttal, W.R. 24 Vadillo, M.A. 271--272 Vahdat,
S. 292 Vaina, L.M. 52, 159 Valentine, T. 370 Valero-Cabré, A. 22
Vallée-Tourangeau, F. 584 van Atteveldt, N. 212 Van Belle, G. 120 van
Berkum, J.J.A. 415, 477, 493

Van Bockstaele, B. 758 van den Berg, A.V. 146 van den Bos, K 772 Van den
Brink, D. 477, 497 van den Broek 492, 492f, 494, 495, 497--498 Van den
Hout, M. 380 van der Hoort, B. 80, 81, 81f van der Schuur, W.A. 213 Van
der Steen, S. 557, 558 van der Weiden, A. 772 Van Dyke, J.A. 490 Van
Essen, D.C. 44, 46, 95 van Gaal, S. 111, 789 van Gompel, R.P.G. 470,
471, 471f, 546 van Harreveld, F. 602, 604 van Kesteren, M.T.R. 501 van
Oostendorp, U. 510 van Orden, G.C. 435 van Petten, C. 427, 440 van
Polanen, V. 61 van Turennout, M. 531 van Velzen, M.H. 550 Vandenbroucke,
A.R.E. 70 Vanlancker-Sidtis, D. 794 Vanlessen, N. 732 Vannuscorps, G.
160, 318 Vaquero, L. 612 Varakin, D.A. 171 Vargha-Khadem, F. 301
Vasilev, M.R. 454, 456 Vasishth, S. 472 Vázquez, G.A. 274 Vendetti, M.S.
596, 597 Vergauwe, E. 242, 244, 250 Verleger, R. 795 Verschueren, N.
576, 674, 675, 689 Verstynen, T. 276, 276f, 333, 338 Vesia, M. 57, 57f
Vetter, P. 51 Vidal-Pineiro, D. 297 Viggiano, M.P. 112 Vighetto, A. 57
Vigliocco, G. 532 Virtue, S. 492 Visted, E. 729 Viviani, R. 719 Võ,
M.L.-H. 205 Volden, J. 479 Volz, L.J. 793, 798 von der Heydt, R. 101 Von
Neumann, J. 641, 753 von Sydow, M. 630, 636, 637 Voss, J.L. 337, 337f,
340 Vossel, S. 194 Vousden, J.I. 530 Vranić, A. 347 Vuilleumier, P 198

929

Wachtel, P.L. 6 Waechter, R. 691, 693 Wagemans, J. 97--98, 99, 100, 103
Wagman, J.B. 586 Wagner, A.D. 20, 213 Wagner, V. 520 Wagoner, B. 501
Waldum, E.R. 376 Walker, B.S. 405 Wallas, G. 583 Wallis, G. 122
Wallisch, P. 69, 69f Walsh, J.J. 1, 495, 758 Walter, S. 186 Walton, D.
694, 700 Wang, M. 654 Wang, P. 119, 122 Wang, S. 141 Wang, X.T. 575,
575f, 643 Wang, Y. 727 Wann, J.P. 146--147, 147f Wanzek, J. 554 Ward,
E.J. 164, 174 Ward, J. 14, 96 Waris, O. 261 Warren, D.E. 323 Warren,
D.H. 210 Warren, R.M. 414 Warren, R.P. 414 Warren, W.H. 151 Warrington,
E.K. 7, 243, 444 Watanabe, K. 222 Watanabe, S. 691, 692f Waters, A.J.
601 Waters, E.A. 745, 747 Waters, F. 130 Watkins, E. 754 Watson, D. 716,
716f, 745, 746, 755 Watson, J.B. 3, 714 Watson, T.L. 116 Watt, C.A. 36,
672 Webb, M.E. 171, 578 Webb, T.L. 726 Webb, T.W. 784, 785f, 791 Weber,
A. 427, 428f Webster, G.A. 671 Webster, M.A. 71 Webster, R.J. 97, 108
Wegner, D.M. 772, 773 Weibert, K. 110 Weidema, J.L. 405 Weiller, C. 431
Weiner, B. 747 Weingarten, E. 769 Weinrich, M. 560 Weisberg, R.W. 581
Weiskrantz, L. 82, 83 Weiss, N. 117, 120 Welch, R.B. 210

930

Author index

Weller, J.A. 652 Wells, G.L. 364f, 370, 373 Wen, T. 222 Wen, X. 194
Wenger, M.J. 128 Wenzel, A.E. 278 Werner-Seidler, A. 362--363, 362f
Wessel, J.R. 274, 278 West, R.F. 696--697, 698 Westfall, J. 33 Wheatley,
T. 772 White, D. 124--125 White, K.G. 644 Whiteford, A.P. 549, 554--555
Whitney, D. 172 Whitwell, R.L. 59 Whorf, B.L. 398--399 Whyte, E.M. 479
Wicherts, J.M. 672 Wickens, C.D. 215, 216, 216f, 218 Wiebe, D. 578
Wieber, F. 773 Wiese, H. 370 Wiesel, T.N. 96 Wieth, M. 576 Wig, G.S. 327
Wild, C. 23, 416, 429 Wiley, J. 480, 483, 578 Wilf, M. 142, 143f Wilkie,
R.M. 146--147, 147f Wilkin, K. 548 Wilkins, N.J. 228 Wilkinson, L. 272,
272f, 277 Willems, S. 309, 309f Williams, C.R. 505, 506 Williams, J.H.G.
161 Williams, J.M.G. 755, 759 Williford, J.R. 101 Wilmer, J.B. 125, 130
Wilson, M.D. 379--380, 379f Wilson, M.P. 469 Wilson, T.D. 769

Winawer, J. 51, 399, 400 Windmann, S. 412 Winer, E.S. 757 Wing, E.A. 288
Winkielman, P. 722 Winlove, C.I.P. 133 Wischgoll, A. 555 Withagen, R.
142 Witthoft, N. 51 Wixted, J.T. 290, 291, 364, 364f, 370, 373 Woike, B.
358 Wolfe, J.M. 204, 205, 205f Wolff, P. 400, 481, 482, 483f Won, E.J.S.
658 Wong, C.K. 375 Woodberry, C. 96, 111, 112f Woods, K.J.P. 183
Woollams, A.M. 450, 452 Woollett, K. 610 Workman, R.A. 376 Wright, D.B.
368, 370 Wright, O. 399 Wroe, A.L. 651 Wu, L.L. 317 Wulff, D.U. 646, 648
Wurm, M.F. 162--163 Wutzler, A. 530 Wynn, V.E. 501 Xie, Y. 654 Xu, Y.
400 Xuebing, L. 727 Yacoub, R. 131 Yang, T.-x. 380 Yardley, H. 111, 114,
115f Yarkoni, T. 8, 22--23, 24, 33 Ye, L. 585 Yechiam, E. 644, 645, 648
Yegiyan, N.S. 369 Yeung, K.L. 265

Yiend, J. 755--756 Yilmaz, E.H. 151 Yip, J.A. 744 Yockelson, M.B. 368
Yonelinas, A.P. 734, 735 Yoon, J.-S. 614 Yoon, S.O. 547 Young, A. 125,
125f, 127, 128, 129, 130, 138 Young, A.H. 207 Young, A.W. 123, 127, 128,
129, 370, 430, 430f, 431, 515 Yovel, G. 121, 121f, 160 Yurgil, K.A. 256
Zachariou, V. 62 Zacks, J.M. 507, 508, 509 Zahn, R. 324 Zalla, T. 479
Zander, T. 578 Zatorre, R.J. 609, 611 Zeckhauser, R.J. 651 Zeidman, P.
610 Zeki, S. 48--50, 49f, 51, 54, 55, 83, 91 Zelinsky, G.J. 189 Zeman,
A. 130 Zetsche, U. 760 Zevin, J.D. 452 Zhang, H. 543 Zhang, T.R. 730,
748 Zhang, X. 424 Zhao, Z. 250, 250f Zhuang, J. 429 Ziegler, J.C. 33
Zihl, J. 50, 51 Zimmer, H.D. 250 Zimmermann, F.G.S. 110 Zogg, J.B. 377,
378f Zwaan, R.A. 507--508, 508, 508--509, 509, 510 Zwitserlood, P. 427

Subject index

Subject index Note: Page numbers pointing to figures are set in italics
and or tables in bold. 2½-D sketch, object recognition 106 3-D model
representation, object recognition 106 9/11 World Trade Centre attack,
flashbulb memory 349--350, 349 access consciousness 768, 776, 781, 784;
see also phenomenal consciousness accommodation, depth cues 74--75
achromatopsia 50--51 acoustic cues 410 action: automaticity 227,
228--229, 231; control 771--775, 774; perception 161 ad hominem fallacy
695, 701 Adaptive Control of Thought-Rational (ACT-R) 30--32, 31
additivity, cue combination 75, 76 affect 716, 716; and cognition
730--734; judgement, decision making 650, 650, 738--750; mood congruity,
memory 736; see also emotion and cognition affect heuristic, reasoning
628, 628 affective blindsight 722 affordances 141, 142--144, 143, 151,
154 afterimages, colour vision 65--66 ageing, and memory 369--370
agentic personality type 358 agrammatism, speech production 539--541,
540 agraphia, dysexecutive 557 airport security checks, visual search
201--202, 202 akinetopsia 51 alcohol, influence on memory 291, 297
algorithm, in computational cognitive science 3, 589 algorithm language
processing 473--474, 473, 475 algorithmic mind 706, 706 allocentric
coding, visual perception 56; see also egocentric coding

allocentric neglect, visual perception 196--197 allophones 407--408,
410--411; see also phonemes Alzheimer's disease 518, 550, 561 ambiguity:
ambiguous sentences 462--463, 465--467, 469, 471, 471, 474, 758;
ambiguous phoneme, Ganong effect 415, 422--423, 424; depth perception
cues 71, 75; interpretive bias 721; object/pattern recognition 100, 111,
112, 141; real-world example: anxiety and inference drawing 495;
real-world example: "The dress" colour illusion 69; schema interference
364; see also inferences; parsing amblyopia (lazy eye) 74 Ames room
79--80, 79 amnesia 296--299, 298; causes 127, 296--297; developmental
301; episodic memory 301; infantile/childhood 351--353; Korsakoff's
syndrome 296--298, 325; prosopagnosia, personspecific 118--121, 120,
127, 128--129; real-world example: patient HM (Henry Gustav Molaison)
297, 297; retrograde 290, 292, 298, 302, 357; semantic dementia 303,
304, 319--320, 323--324, 324 amygdala: appraisal theories 720, 722--723,
727--728, 728, 729; attention and memory 734--736, 735; autobiographical
memory 349--350, 351, 359, 367; cognition and emotions 717, 718--719;
conscious awareness 198; decision making 652; global workspace theories
790 analogical problem solving/reasoning 593--600, 593--601; brain areas
599--600, 599; fluid intelligence advantage 593, 595, 597, 597--598;

four-term analogy problems 596; problem similarities: superficial,
structural, procedural 594--595; sequential processing stages (encoding,
inferring, mapping, applying) 596--597, 597, 600 anaphor/anaphor
resolution 493 anarchic-hand syndrome 795 anatomical modularity 8, 12;
see also cognitive neuropsychology anchoring-and-adjustment heuristic
630 anger 720--721, 747--748, 751, 752; see also emotion and cognition
anomia, speech production 319, 537--539 anterograde amnesia 298
anti-cascade task, task-impurity problem 5 anticipatory errors,
spreadingactivation theory 528, 529 Anton's syndrome 131 anxiety:
attention 731, 732; and cognition 744--745, 745, 750, 752; and cognitive
bias 753--755, 757, 758, 759, 761; eyewitness testimony (weapon/violence
focus) 368--369, 374; generalised anxiety disorder 758;
obsessive-compulsive disorder (OCD) 380--381, 381; real world example:
reducing anxiety and depression 762; real-world example: anxiety and
inference drawing 495; real-world example: emotion regulation and mental
disorders 729; trait anxiety 753, 758, 760; see also emotion and
cognition aphasia 536--537; agrammatic aphasia 539; Broca's aphasia
536--537, 536; jargon aphasia 541--543; transcortical sensory aphasia
432; Wernicke's aphasia 536--537; see also anomia

932

Subject index

appraisal: affective blindsight 722; appraisal-tendency framework
751--752; automatic/deliberate, controlled 719; conscious appraisal and
emotions 720--722, 721; emotion generation 719, 720; non-conscious
emotional processing 722--723; theories 719--723 apraxia 161--162; limb
apraxia 156--157 argumentative theory 697--698; see also informal
reasoning articulatory similarity, phonological loop 248 articulatory
suppression 242, 247, 248, 249, 557; see also phonological loop
artificial intelligence 41; vs computational modelling 26--27, 27;
General Problem Solver (Newell and Simon) 588 Asperger's syndrome 479;
see also autism spectrum disorder attention: active/passive (top-down/
bottom-up) 178; affect and cognition 730--734, 733; automatic processing
226--231; cognitive bottleneck 180, 181, 222--226, 224, 535; and
consciousness (selective attention) 790--791; covert 165, 167, 170, 192,
455; cross-modal 208--209; defined 178; divided/focuses (see divided
attention; focused auditory attention; focused visual attention);
external/ internal 178; feature-based 186, 188--189; space-/object-based
attention 186--187, 187, 188, 189 attentional bias 753, 755--758, 757,
760, 761, 762--763, 763; cognitive, attention control 760--761, 761;
real world example: cognitive bias modification 762 audience design
544--547, 546 auditory analysis system, speech perception 430--431, 430
auditory input lexicon 430, 430, 431 autism spectrum disorder 160, 479,
705 autobiographical memory 346--351; direct (cue-triggered) retrieval
356, 358--359, 360; emotional, involved brain networks 360, 360;
emotional, involved brain networks 360, 360; and episodic memory
346--347, 347; episodic/semantic autobiographical memory 347; flashbulb
memories 349--351, 734; functions of 347; generative (goal-based)
retrieval 356, 358--359, 360, 360; knowledge base and working self
355--357, 357, 358; memory bias 759; and mood 734--736; real-world
example: depression and

autobiographical memory 361--363, 361, 363; real-world example: highly
superior autobiographical memory 348--349, 348; theoretical approaches
(see autobiographical memory, theoretical approaches) autobiographical
memory knowledge base, self-memory system model 355--357, 357, 358
autobiographical memory, theoretical approaches 355--363; cognitive
neuroscience 359--363, 360; selfmemory system model 355--359, 357, 358
automatic processing: automaticity of action 228--229; controlled vs
automatic process 226--228; decompositional approach 229--231, 229;
traditional approach: controlled vs automatic process 227 automaticity
of action 227, 228--229, 231 autostereogram 74 availability heuristic,
judgement 628--629, 628, 629--630, 630, 633 back-propagation 28, 29--30
backward crosstalk effect 225--226 backward masking 781--782, 783 base
rate: benign cyst scenario, task 625--627, 627; dual-process theory 639,
640; heeding 626--628; natural frequency hypothesis 631, 632; neglect,
science research/medical practice 624--628, 627, 638; syllogistic
reasoning 679, 679 Bayes, Thomas 623 Bayesian inference theorem,
judgement 102, 623--624 behaviourism 3, 37, 714; see also cognitive
psychology belief bias 678--679, 679, 684--685, 686, 687, 691, 695
biased stimuli competition hypothesis 199, 200 Biederman, Irving,
recognition-bycomponents theory 106--109, 107, 108 binding problem
54--55 binding-by synchrony hypothesis, binding problem 54 binocular
cues, depth perception 71, 74--75 binocular disparity 52, 74, 76--77,
146, 150--151; see also stereopsis binocular rivalry 132, 780, 781
blindness: blindness denial (Anton's syndrome) 131; change blindness
164--167, 169, 170, 171--172, 777; colour blindness 44; face blindness
(prosopagnosia) 118--121, 120, 127,

128--129; inattentional blindness 164, 165--166, 172--174, 172, 174
blindsight 82--87, 86; affective blindsight 722; brain damage,
reorganisation 85--86; vs degraded conscious vision 84--85; evidence
83--84; experience 83; forced-choice test 82; real-world example:
patient DB 82, 83--84, 84 "blobology" approach, neuroscience 24
blue-yellow deficiency, visual perception 66 blur, depth perception cue
73 bodily self-consciousness 769 body size effect 80--81, 81 BOLD (blood
oxygen- level-dependent contrast) 19, 20; see also functional magnetic
resonance imaging (fMRI) Bonini's paradox 33 bonobo ape, language
acquisition 393--394 Borges, Jorge Luis 279 bottom-up processing:
(visual) word recognition 437, 437, 438; attention 193, 197, 198;
defined 4; emotional experience 718--719, 718, 735--736, 735;
human-motion perception 158--159; information processing approach 4;
memory/retrieval 382, 383, 384, 385, 386; object recognition 111, 114,
115, 115, 116; pattern recognition 96; speech perception 408, 409, 417,
420--421, 421, 425--426; visual perception 132, 135--136, 135 bounded
rationality 660, 702, 707 brain: activity studies: cognitive
neuroscience, research techniques 15--26, 16; integrated brain
functioning 787--788 brain, organisation/anatomy (for topic-specific
involved brain areas/ parts: see chapter subheadings "Brain mechanisms",
Findings", "Evaluation"): brain areas 13--14; brain locations, terms
(dorsal/ superior, ventral/inferior, anterior/ rostral, posterior,
lateral, medial) 13; connectome 14; default mode network 25, 195;
grooves/sulci (sulcus) 13; hemispheres 13; lobes 13--14, 13; ridges/gyri
(gyrus) 13, 13, 563 brain, visual cortex; see visual cortex brain
areas/mechanism, involvement in cognitive functions: action, visually
guided 156, 156; analogical problem solving 599--600, 599; brain,
organisation/anatomy 13--14; Brodmann brain areas 13--14, 13, 24, 322,
739; consciousness 788--790; decision making, social/emotional

Subject index factors 352; deductive reasoning 690--693, 690, 692;
emotions, emotional regulation 717--718, 717, 727--728, 728; episodic
memory 306--308, 307, 337--338, 337; explicit learning 274--276, 278;
implicit learning 274--276, 274, 275, 276, 278; long-term memory and
emotions 734--735, 735; major attention networks 192--193, 193, 195,
195; memory systems/processes 337--338, 337; motion perception 159, 159;
perception without awareness, subliminal perception 87--89, 89;
planning-control model, visually guided action 153; pragmatics, language
comprehension (figurative/ literal processing) 478; priming 337--338;
reasoning, analogical 690--693, 692; recognition memory 306--310, 309;
risk (financial decision making) 652; speech perception 405--406;
spelling, writing and reading 562--563, 563; visual pathways/processing
46--48, 48 brain damage/brain-damaged patients: amnesia 296--299, 312;
attention and performance 194, 196, 197; central-executive 251;
cognitive neuropsychology 7--9, 12, 22, 32, 35; consciousness 778--779,
782--783, 787, 788, 789, 792; decision making/ problem solving 574, 581,
599, 652, 742; declarative (explicit) memory 301--302; episodic memory
307, 308; face/object-recognition 118--119, 136; motion-perception
156--157, 161--162; semantic memory 318, 320--321, 322, 323, 324;
non-declarative (implicit) memory 325, 329, 331, 332; reading 443--444,
445, 450; short-term vs long-term memory 243; reasoning 691; speech
perception 406, 419, 429--430; speech production 515, 521, 525, 536,
537; visual imagery 131; visual perception 50, 57--58, 57, 64, 85;
visuo-spatial sketchpad 250, 251; working memory 257, 258, 260, 261;
writing 557, 560, 561, 562 brain mechanism: top-down processing 599,
emotion 717 brain networks: autobiographical memory, emotional 360, 360;
schema 322--323 brain plasticity 12, 35, 299, 609--612, 794; causality
610--611, 611, 612; defined 609; "The Knowledge," London taxi driver
test 610; research evaluation 611--612

breast cancer diagnosis, base rate/ frequency sampling 625--627, 627,
632 bridging (backwards) inferences 490, 493--494; see also discourse
processing, inferences broad vs instrumental rationality 703, 704
Broca's aphasia 536--537, 536 Broca's area 248, 249, 406, 537, 539, 540
Brodmann, Korbinian 13--14, 13 Brodmann brain areas 13--14, 13, 24, 322,
739 CAPTCHA 97, 97 Carlsen, Magnus 613--614, 613 cascade processing
4--5, 443, 444 categorical perception, speech perception 399, 405, 415
categorisation 109, 111, 314, 315 category-specific deficits 320--321
central coherence 479 central executive 246--247, 246, 251, 254, 255,
556--557, 556; dysexecutive syndrome 251, 260, 277, 557; episodic buffer
and 252--253; language production 553; see also working memory component
change blindness 163--174; attentional approach (target fixation) 168,
168, 169, 169; causes 167--171, 168, 169, 170; defined 164; vs
inattentional blindness 164--167; peripheral vision approach 170--171,
170; real-world example: inattentional blindness and magicians 166--167,
166; serial dependence 172; token and type changes 168, 168, 169; visual
processing and 167; see also inattentional blindness change blindness
164, 164 Chaplin, Charlie 160 Charles Bonnet syndrome 131 checking
behaviour 380--381 chess expertise, deliberate practice 615--616, 616
chess expertise 601--604; vs medical expertise 609; real-world example:
Magnus Carlson 613--614, 613 child-directed speech 397, 545 childhood
amnesia; see infantile/ childhood amnesia Chomsky, Noam 4, 393, 394,
395, 397--398 Christie, Agatha 550 chromatic adaptation, colour vision
70--71 chunking/chunks, integrated information units 241--242, 252, 535

933

climate change, reasoning 680, 695--696, 696, 698 coarse-to-fine
processing, spatial frequency 104--105 coarticulation, listening
409--410, 410--411 cocktail party problem, focused auditory attention
179--180, 182--183 cognition, main approaches to 2, 3; cognitive
neuropsychology 7--12; cognitive neuroscience 12--26; cognitive
psychology 3--7; comparison of 33--34; computational cognitive science
26--33; replication crisis 34--36 cognition and emotion; see emotion and
cognition cognitive appraisal; see appraisal cognitive architecture
27--28, 31, 31, 32, 35, 560 cognitive bias: attentional bias 753,
755--758, 760, 761, 762--763, 763; cognitive bias modification 761--764;
explicit memory bias 754; impact bias 650; implicit memory bias 754;
interpretive bias 754 cognitive bottleneck 180, 181, 222--226, 224, 535;
see also divided attention cognitive control 760--761, 761, 762--763
cognitive impairment 10, 518, 550, 557 cognitive interviews (eyewitness
testimony) 373--375 cognitive load 190, 191, 408, 424, 639 cognitive
miserliness/miser 592--593 cognitive neuropsychology 3, 7--12, 35;
defined, history 7; limitations 12; research, problems/methods 9--10;
single case studies vs case series 10--11; strengths 11; theoretical
assumptions 8--9 cognitive neuroscience 1--2, 3, 12--26, 35; brain areas
13--14; brain organisation 14; defined 12; limitations 23--25, 25, 26;
research areas 2; research techniques, brain activity studies 15--26,
16; strengths 22--23 cognitive psychology 1, 3--7, 3, 35; behaviourism
(Watson, Tolman) 3; defined 1; history of 3--4; information processing
approach 4, 4; limitations 6--7; strengths 6; task processing 4, 4
Cognitive Reflection Test 1--2, 592--593 cognitive self 356, 358--359,
360 coherence: central coherence 479; coherence threshold 505--506, 506;
standards of 492, 492 cohort model, speech perception 425--429, 428, 429

934

Subject index

colour constancy 67--71, 67; chromatic adaptation, colour vision 70--71;
familiarity effect 70; local colour contrast 68--70; real-world example:
"The dress" colour illusion 69; scene illumination, estimate 68 colour
vision/processing 50--51, 64--71; colour constancy 67--71, 67;
dualprocess theory 66--67, 66; negative afterimages 65--66;
opponent-process theory, vision 65--66; trichromacy theory 65, 66
Coltheart, Max, cognitive neuropsychology 7--8 common ground, language
comprehension/production: audience design 544--547; defined 484;
gestures 548; pragmatics 484--487, 485, 486 communal personality type
358 communication: social 770--771, 771; speech as 543--549 comorbidity
753 compartmentalisation 362, 362 compensatory strategies 12, 35
comprehension; see discourse comprehension, theoretical approaches;
language comprehension computational cognitive science 3, 26--33, 35;
Adaptive Control of Thought-Rational (ACT-R) 30--32, 31; cognitive
architecture 27--28, 31, 31, 32, 35, 560; computational modelling (see
computational modelling); connectionism/ connectionist models 28--30,
28, 442, 447--449, 728, 728; limitations 33; production systems 30--32,
318, 502; strengths 32 computational modelling 3, 26--33, 35, 442;
Adaptive Control of ThoughtRational (ACT-R) 30--32, 31; vs artificial
intelligence 26--27, 27; connectionist models/neural network models
28--30, 28; interactive activation model 437--439, 437; Weaver++
530--535, 532, 534 conceptual priming 325--326, 327; see also priming
conditional reasoning 673--676, 676, 686--687 cones, colour vision 44,
45, 65, 66--67 confirmation, hypothesis testing 667, 671 confirmation
bias: eyewitness accuracy 364--365, 365; forensic 98--99; hypothesis
testing 668, 670, 671--672 conflict-based monitoring theory, speech
errors 523--525, 524 conjunction/double conjunction fallacy, judgement
624--626

connectionism, connectionist models 447--449, 728, 728; dual-process
theory (see dual-process theory); neural network models 28--30, 28, 360;
triangle model 442, 447--453, 448 connectome 14 conscious awareness
61--62, 88, 89, 89, 198 consciousness: assessing 775--783; and attention
(selective attention) 790--791; bodily self-consciousness 769; conscious
content vs conscious level 767; forms (access/phenomenal) 768, 776, 781,
784; forms (phenomenal/conscious thought) 768, 771; functions 768--775;
key brain areas 788--790; theories (global/ global neural workspace)
783--792; unconsciousness, "Yes It Can" principle 769, 770;
unitary/separate consciousnesses 792--798 (see also split-brain
patients) consciousness, assessing 775--783; braindamaged patients 778;
feedforward/ recurrent processing 781--783, 782; neural correlates of
consciousness 779--783; over-reporting of conscious experiences
777--778, 777; real-world example: vegetative state patients and
consciousness 778--779; underreporting of conscious experiences 776--777
consciousness, functions 768--775; cognitive neuroscience findings
774--775; controlling actions: consciousness in decision making 774,
774; controlling actions: free will 771--775, 774; sense of agency 773;
social communication 770--771, 771; "Yes It Can" principle 769, 770
consistent mapping 226, 227 consolidation theory, memory 290, 291, 293
constraint-based model, language comprehension 468--470
construction-integration model 501--505, 502, 503 context effects:
memory/forgetting 287--288, 306, 307, 308, 312; reading 440--442; speech
reception 412--416 converging operations 34 cortex: cerebral 13, 13;
inferotemporal cortex, form/colour processing 46; parietal cortex,
motion processing 46, 46; visual (see visual cortex)
counterexample/counterexample strategy 674--676, 676, 678, 681, 682
covert attention 165, 167, 170, 192, 455 Croskerry, Pat, 625, 625

cross-cueing between brain hemispheres 793, 797--798 cross-modal
attention 208--209 cross-modal effects, perception/ attention 208--212;
real-world example: warning signals promote safe driving 211; temporal
ventriloquism 210--211, 210; ventriloquism effect 209--210, 210
crosstalk/backward crosstalk effect 224, 225--226 crystallised
intelligence 225 cues, listening/speech comprehension: acoustic,
lexical, segmental, metrical prosody 410--411, 410; prosodic cues 404,
463--464, 466--467, 540, 548--549 cues, memory: cued recalls 305, 305;
cue-dependent forgetting 287--288; detection 377, 378, 385;
moodstate-dependent memory 737, 737; prospective memory 377, 378,
379--380, 382, 385, 386; retrieval cues 265, 267, 267, 285--286, 289,
289 cues, reasoning/judgement 631--632, 632, 635, 636, 637 cues, visual:
binocular cues, depth perception 71, 74--75; blur, depth perception 73;
covert attention 192; figure-ground segmentation 100--101; monocular
(pictorial) cues, depth perception 71, 72--74, 72, 73; oculomotor cues,
depth perception 75; visual attention 186--187 cues
combination/integration 75--77 cylinder depth cues, visual perception 76
decay, memory 242, 280--281 decision making 640--663; complications
(preference changes, selective exposure) 658--659, 659;
description-experience gap 646--647; emotional factors (biases:
loss/risk aversion, impact, omission, status quo) 649--652; emotional
factors (loss aversion, omission bias, status quo bias) 650;
fast-and-frugal heuristics (applied decision-making) 655;
multi-attribute utility theory (complex decision making) 655--658;
naturalistic decision-making theory 659--662, 660, 661; prospect theory
642--645, 642, 644; real-world example: expert loss/risk (golfing,
finance) 645--646, 645; real-world example: politicians 653--654, 654;
real-world example: tightrope walking decisions, Nik Wallenda 647, 647;
social functionalist approach (social factors) 653--654; sunk-cost

Subject index effect 644--645; unconscious thought theory 662--663;
utility theories 641, 655--658 declarative (explicit) memory 263, 280,
300--301, 300; explicit and implicit learning 269--278; explicit memory
bias 754, 755, 759; levelsof-processing effect on 263; vs
non-declarative (implicit) memory 299--300, 328, 332--333; types (see
episodic memory; semantic memory) decoding/neural decoding 19, 95, 406,
774 deductive reasoning 570, 571, 666--667, 672, 690; brain regions in
690--693, 690, 692; conditional reasoning 673--676, 676, 686--687; and
informal reasoning 694--695; normativism 703; syllogistic reasoning
678--679, 679; Wason selection task 676--678, 676 deductive reasoning,
theories 680--690; dual-process approach 680--681, 683--690, 685, 687;
mental model theory 680--683 (see also working memory) Deep Blue vs
Garry Kasparov chess match 26 deep dyslexia 445, 448, 450--451 deep
dysphasia 432 default mode network 25, 195 deliberate practice,
expertise 613, 613--617, 616; chess 615--616, 616; innate talent and
613, 615; long-term working memory 613; music 616 dementia; see
Alzheimer's disease; fronto-temporal dementia; semantic dementia deontic
rules 677 deontological judgements 739--740, 743; see also moral
dilemma; utilitarian judgements depictive representation, visual imagery
131--132 depression: appraisal 727; cognitive bias 753--757, 757, 758,
759, 761, 761, 763; real world example: reducing anxiety and depression
762; real-world example: depression and autobiographical memory
361--363, 362; real-world example: emotion regulation and mental
disorders 729 depth perception 71--81; binocular cues 71, 74--75;
combination/integration 75--76; cues combination/integration 75--77;
cues conflict 76; cues reliability 75; haptic 76; monocular cues 71,
72--74, 72, 73; oculomotor cues 71, 75; size constancy/size judgements
78--81, 78, 79, 81

developmental amnesia 301 diagnosis/diagnostic errors, judgement
607--609, 608, 633--634; breast cancer diagnosis, inference 632, 632;
realworld example: availability heuristic in medical diagnosis 629;
realworld example: heuristic in medical diagnosis 625--626 diaschisis 11
dichotic listening/shadowing task 179--180 dichromacy 65 digit span,
short term memory 241, 249, 249, 298, 614 direct (visual) perception:
affordances 141, 142--144, 143, 151, 154; defined 141; evaluation of
144--145; focus of expansion 141--142, 142, 145--146; invariants, optic
array 142, 144; optic flow 141--142, 142, 145--146, 147, 148--149; see
also motion perception; visual perception direct retrieval 356,
358--359, 360; see also generative retrieval directed forgetting
250--251 directed retrospection 552 discourse comprehension, theoretical
approaches 498--510; constructionintegration model 501--505, 502, 503;
event-indexing model, and event-segmentation theory 507--510; Kintsch's
construction-integration model 501--504, 502, 503; RI-Val model
505--507, 506; Schema theory 498--501; see also language comprehension
discourse markers 549 discourse processing, inferences 490--498; anaphor
resolutions 493; bridging (backwards) inferences 490, 493--494;
discourse vs single sentence comprehension 490; inference drawing
(passive, "automatic" vs reader-initiated) 491--492; logical
interferences 490; predictive interferences 495--496, 495; realworld
example: anxiety and inference drawing 495; theories, research findings
491--492, 492, 495--498; see also language comprehension dissociation;
see double dissociation; process-dissociation procedure distinctiveness,
memory traces 263--264, 263 distraction; see also emotion regulation
distraction/distractors: dual/multitasking, divided attention 213, 221,
221; emotion regulation 724--726; in focused attention 185, 189--191

935

divided attention, dual-task performance/multi-tasking 178, 212--226;
cognitive neuroscience findings 220--222, 220, 221; multiple resource
theory 215--217, 216; psychological refractory period, cognitive
bottleneck 222--226, 224; serial vs parallel processing 213--215;
threaded cognition 217--220, 218; see also cross-modal effects; focused
auditory attention; focused visual attention dorsal stream, visual
perception 53, 56--57, 56, 57, 62--63, 63; action guidance 155--157,
156; egocentric coding 56; see also two-pathway action-perception model;
ventral stream double conjunction/conjunction fallacy, judgement
624--626 double dissociation 10, 64, 119, 243, 303, 304--305, 308,
331--332 dual-pathways model 204--206, 204, 205, 382, 383, 384, 385
dual-process theory: emotion and cognition 738--739, 742--743; judgement
637--640; memory 308; reasoning 675, 704--705; visual perception 66--67,
66 dual-route cascaded model, reading 443--477, 444 dual-system theory;
see dual-process theory dual-task performance/multi-tasking; see divided
attention Dunning-Kruger effect 705, 708 dynamic multiprocess framework
382--383, 383, 386, 386, 387 dysexecutive agraphia 557 dysexecutive
syndrome 251, 260, 277, 557 dysgraphia (surface, phonological) 560--561,
562 dyslexia (surface, phonological, deep) 444--445, 448, 449--451, 452,
562 dysphasia (surface, phonological) 432, 560--562 Ebbinghaus, Hermann
278 Ebbinghaus illusion 58--59, 59 echoic memory 241 ecological validity
6, 25, 148, 345, 408, 487 EEG; see electroencephalography efference copy
145, 153 efMRI; see event-related functional magnetic resonance imaging
egocentric coding 56

936

Subject index

egocentric heuristic 484--487, 485, 486 egocentric neglect,
vision/attention 196--197, 197 elaborative inferences 491
electroencephalography (EEG) 17--18, 779, 787--788, 788
elimination-by-aspects theory, judgement 657--658 emotion: affect and
attention 731--734, 733; affect and memory 734--738, 735, 737;
bottom-up/top-down processes 718, 719; brain mechanisms 717; defined
716; regulation 723--730; structure 716, 716 emotion, regulation
723--730; distraction 725; neural network for 728; process model
724--726; real-world example: emotion regulation and mental disorders
729; reappraisal 724, 725, 726, 727--728, 727, 730; strategies 724--727,
725, 729, 730 emotion and cognition: anger 720--721, 747--748, 751, 752;
anxiety 744--745, 745, 750; appraisal theories 719--723; emotion
regulation 723--730; emotion vs judgement in decision making 743--744;
emotion-imbued choice model 752, 752--753; mood states and decision
making 743--750, 745, 746, 750; moral dilemma: emotion vs cognition
(reason) 738--740, 743; optimism bias 744; positive mood 748--750, 750;
real-world example: driverless cars, moral dilemmas 741--742, 742;
sadness 745--746, 746 emotion-imbued choice model 752, 752--753; see
also emotion and cognition encoding 127; vs decoding 95; defined 95;
focal/non-focal tasks, dual pathway model 382, 383; inference and
impaired encoding 282, 283--284; language, speech 546; learning, memory
239--240, 245, 333--335, 334, 734, 735; problem solving/reasoning 597
encoding specificity principle 287--288, 289--290, 289, 736, 737;
encoding specificity principle 287--288, 289--290, 289, 736, 737;
encodingretrieval overlap 289, 289, 295 encoding-retrieval overlap 289,
289, 295 endogenous spatial attention 211 energetic masking, listening
408 episodic buffer 247, 252--253, 253; see also working memory
components episodic memory 300--301, 300, 305--313, 305, 312, 339; brain
damage, amnesia, dementia 297,

301, 301--304, 307, 308; constructive character 310--313, 312, 345, 737,
737; defined 300; recall memory (cued, free serial) 253, 253, 305, 310,
315, 737, 737, 759; recognition memory 305, 306--310, 307; vs semantic
memory 301--305; semanticisation 304, 305; see also declarative
(explicit) memory; longterm memory ERP; see event-related potentials
event-based prospective memory 376--377, 381; see also time-based
prospective memory event-indexing model, and eventsegmentation theory
507--510 event-related functional magnetic resonance imaging (efMRI) 16,
19--20 event-related potentials (ERPs) 16, 17--18, 35; attention,
auditory/ visual 181, 189, 198, 209, 214, 225; consciousness 774, 786,
786, 789, 796, 797; language comprehension/ production 475--478,
496--497, 531, 534, 538; memory/forgetting 256, 282, 303, 317; motion
perception 167, 173; N400 component of 18, 417, 426--427, 435, 440--441,
475--477, 476, 496--497; object/face recognition 109, 129, 204; problem
solving/reasoning 592, 693; speech perception/reading 415, 417,
418--419, 423, 426, 435, 440, 463; visual perception 44, 88
event-segmentation theory, and eventindexing model 507--510 everyday
memory: autobiographical memory 346--351, 355--363 (see also
autobiographical memory); ecological-validity demand, memory research
344--346; eyewitness testimony 363--372, 623 (see also eyewitness
testimony, accuracy); memories across lifetime 351--355; prospective
memory 375--389 (see also prospective memory) executive functions:
dysexecutive agraphia 557; language 504; Parkinson's disease 330; unity/
diversity framework 258--259, 259; working memory 251, 254, 255,
257--262, 259, 260 executive processes 221, 251, 254, 260--262 exogenous
spatial attention 211 expertise 600--619; brain plasticity 609--612,
611, 612; chess: template theory 601--604, 603; defined 600; deliberate
practice 613, 613--617, 616; medical 604--609, 605, 606, 608;

multifactorial gene-environment interaction model 617--619, 617 explicit
(declarative) memory; see declarative (explicit) memory explicit and
implicit reasoning 605--606, 607--608 explicit learning: brain areas
274--276, 278; brain-damaged patients 276, 277; vs implicit learning
269--278 explicit memory; see declarative (explicit) memory extinction,
visual attention disorder 197--198, 199, 200; biased stimuli competition
hypothesis 199, 200 eyewitness testimony, accuracy/ impairments
363--375, 623; age and memory, own-age bias 369--370; anxiety, stress
369, 731; confirmation bias 364, 365; eyewitness identification
370--372, 371; laboratory vs real-life findings 372; misinformation
effect 365--368, 366, 368; other-race effect 370--371; schemas 364, 365;
unconscious transference 370; weapon focus 368--369, 733 eyewitness
testimony, memory enhancing 372--375; cognitive interviews 373--375;
line-up administration 372--373 E-Z Reader model 454, 455--456, 455 face
inversion effect 117 face recognition: face inversion effect 17;
fusiform face area 24, 121--123, 121, 127; holistic processing,
expertise hypothesis 116--117, 120, 122; vs object recognition 116--117;
part-whole effect 117; prosopagnosia 118--121, 120, 127, 128--129;
realworld example: passport checks example 121; super-recognisers 125;
theoretical approaches 125--127, 126, 127; viewpoint, influence on 110,
335, 335 faces--goblet illusion, object recognition 100, 100 false
positive scenario, reasoning 625--627 falsification, hypothesis testing
667, 670, 671 familiarity: effects, visual perception 70; E-Z Reader
model, language 454, 455, 455; recollection, memory 306--310, 309, 336
fast-and-frugal heuristics 634--637, 655 fear 651--652, 717, 722, 744,
747, 751; see also anxiety feature detectors, pattern recognition 96

Subject index feature integration theory 202--204, 203, 207
feature-based attention 186, 188--189 figurative language, metaphors,
language comprehension 478--479, 480, 480--483, 482, 483; metaphor
interference effect 480; prediction model 481; research findings,
evaluation 481--483; standard pragmatic model 480 figure-ground
segmentation, object recognition 99, 102 fingerprint matching, pattern
recognition 98--99, 98 flashbacks 350--351 flashbulb memories 349--351,
734; 9/11 World Trade Centre attack 349--350, 349; and flashbacks
350--351 fluid intelligence 255, 257, 593, 595, 597--598, 597, 706 fMRI;
see functional magnetic resonance imaging focal/non-focal tasks 382,
384--385, 385 focus of expansion, direct (visual) perception 141--142,
142, 145--146 focused auditory attention: cocktail party problem
179--180, 182--183; early vs late input selection 180, 181; processing
bottleneck 180 (see also cognitive bottleneck); sound segregation
179--180; target input 181, 183; top-down processing 180, 182--183;
unattended input 180--182 focused visual attention 183--196; attention
focus: zoom-lens/spotlight/ split attention 184--185, 185, 186;
feature-based 186, 188--189; load theory (perceptual, cognitive)
189--191, 190; major attention networks 191--196; object-/spacebased
186--187, 187, 188; unattended, distracting stimuli 185, 189--191, 256
forgetting, from long-term memory 278--293; consolidation theory
290--291, 292; interferences (proactive, retroactive) 281--284; memory
decay 242, 280--281; motivated 284--290 (see also motivated forgetting);
real-world example: perfect memory 279--280; reconsolidation 290,
291--293, 367; recovered memories, truthfulness of 284--285 form
processing, visual 50 fovea, foveal (central) vision 56, 105; see also
lexical parafoveal-on-foveal effects framing effect, decision making
642--643, 704 free recall 305, 310, 345, 737, 737, 759

free will 771--772, 773, 775 Freud, Sigmund 284, 769 Freudian slip 521
Friends (TV series) 128 fronto-parietal network 192, 195--196, 195, 337,
360, 371, 789 fronto-temporal dementia 323--324, 324 functional
fixedness, problem solving 585--586, 585, 587; see also mental set,
problem solving functional magnetic resonance imaging (fMRI) 16, 19--20,
23, 25, 693 functional specialisation, brain 23, 35, 48--55, 49; binding
problem 54--55; colour processing 50--51; form processing 50; motion
processing 52, 53 fusiform face area 24, 121--123, 121 future
path/heading, visually guided movement 146--147, 147, 149 gambling,
emotion/decision making 649, 652, 744, 749; Iowa Gambling Task 751
Ganong effect 415, 422--423, 423 garden-path model, language
comprehension 465--468 gaze/gaze pattern, motion perception 147, 148
gene-environment correlation 618 gene-environment interaction model
617--619, 617 General Problem Solver, software 4, 588 generalisability,
ecological validity 345--346 generalised anxiety disorder 758 generative
retrieval, memory 356, 358--359, 360, 360; see also direct retrieval
generic-parts technique, problem solving 586 Gestalt theories, laws of
perceptual organisation 96--102, 99, 100, 101; evaluation of 100--102,
102, 103; figure-ground segmentation 99--100, 100--101, 102, 102; law of
Prägnanz 97 Gestalt theories, problem solving 576--588; functional
fixedness 585--588, 585, 587; hints, incubations 583--584, 583; insight
577--579, 577; past experience 584--585; real-world example: magic
tricks 582, 582; representational change theory 579--583, 580, 581;
reproductive thinking 576--577 gestures, speech 547--548, 549 Gibson,
James 141--146, 148--149

937

global workspace/global neuronal workspace theories, consciousness
783--792; early stimulus processing and consciousness 785--786, 786;
integrated brain functioning 787--788; integrated information theory
784--785, 785; integrated synchronised brain activity 787, 788;
selective attention Gobet, Fernand 601--603, 602 good-enough language
processing account 472--475 good-enough language processing account,
language comprehension 474 grammar: agrammatism 539--541, 540;
inflections 461, 462, 522; syntax and 461, 462--463; universal innate
grammar 395, 396; see also parsing; syntax grapheme 396, 443 grapheme
buffer (orthographic working memory) 560, 560 grapheme--phoneme
conversion 443--444, 444, 445 grasping/graspability 56, 58--59, 60--61,
61, 142--143, 143, 153 "gut feeling" 637 gyrus/guri 12, 13, 13; in
cerebral cortex 13, 13; inferior frontal gyrus 52, 121, 135, 159, 159,
161, 193, 197, 406; superior temporal 13, 52, 161, 193, 197, 406, 418,
517, 536, 537, 578, 728 Hall, Monty 575, 575 hallucinations 114,
130--131 haptic sense 76 hemifield 186 hemispherectomy 12, 793--794, 797
Henke's processing-based theoretical account 333--335, 334, 336
heuristic: affect 628, 628; availability 628--629, 628, 629--630, 630,
633; defined 576; egocentric 484--487, 485, 486; fast-and-frugal 655;
heuristic route 473--474, 473, 475; hill-climbing 589; recognition
635--636, 637; representativeness 624--625 highly superior
autobiographical memory (HSAM) 348--349, 348 hill-climbing heuristic,
problem solving 589 hint, problem solving 583 hippocampal neurogenesis
352, 353 holistic processing 116--117, 120, 122--123, 609 hollow-face
illusion 59, 60 homophones 435--436, 758 Honi phenomenon 80

938

Subject index

hub-and-spoke model, semantic memory 318--320, 319 hubs, prefrontal
cortex regions 15, 319, 320 human cognition; see cognition; emotion and
cognition human motion perception; see motion perception human
rationality 701--708; bounded rationality 660, 702, 707; dualsystem
theory; instrumental vs broad rationality 702--704; intuitive vs
rational processes; limitations: cognitive miserliness 707--708;
limitations: dual-process approach 704--705; limitations: DunningKruger
effect 705; social rationality 703 (see also social functionalist
approach); tripartite model of reasoning (individual rationality
differences) 705--706, 706 hypothesis testing: confirmation bias 668,
670, 671--672; confirmatory approach (non-absolute hypotheses) 667, 671;
falsificatory approach (absolute/universal hypotheses) 667, 671;
real-world example: hypothesis testing by scientists 670--672; simulated
and real research environments 670--672; Wason's 2-4-6 task 666--670
iconic memory 240--241, 790--791 illuminant 67--68, 69--70 illusion,
free will 771--775, 774 illusions, auditory, Moses illusion 473
illusions, visual 58--61, 59, 60, 61, 64, 153; body-size-effect 80--81,
81; Ebbinghaus illusion 58--59, 59; facesgoblet illusion 100, 100;
hollow-face illusion 59, 60; Kanizsa's illusory square 73, 73;
Müller-Lyer illusion 58, 58, 59, 60, 154; negative afterimages 65--66;
open-object illusion 4--5, 4, 12, 80, 443; ventriloquist illusion/effect
209--210, 209--212; vertical-horizontal illusion 106 illusory
conjunctions 202--203 illusory square, interposition 73, 73 impact bias
650 impasse, problem solving 579, 580, 581 implacable experimenter 6
implementation intentions 387, 773 implicit (non-declarative) memory;
see non-declarative (implicit) memory implicit and explicit reasoning
605--606, 607--608 implicit learning 269--278, 274; assessing: research
findings 272--276,

273, 274, 275, 277--278; assessing: theory 271--272; brain areas
274--276, 274, 275, 276, 278; brain-damaged patients 277; defined 269;
real world example: keyboard typing and 270--271, 270, 277 implicit
memory; see non-declarative (implicit) memory inattentional blindness
73, 164--167, 164, 165--166, 172--174, 790; causes 172--174, 172, 173,
174; vs change blindness 164--167; defined 164; real-world example:
magicians 165--166; see also change blindness incidental emotions 744
incremental validity 707 incubation, problem solving 583--584 inductive
reasoning 571, 666, 667; see also deductive reasoning; deductive
reasoning, theories inductive reasoning 666--667 infantile/childhood
amnesia 351--353, 352 inferotemporal cortex, form/colour processing 46
inflections, grammar 461, 462, 522 informal reasoning 570, 571, 667,
694--708; bounded rationality 702; motivation for 695--698, 696;
probabilities in 698--701, 700 informational overlap, memory 290
informativeness, memory traces 314 inhibition of return, visual
perception 187--188, 188 inner scribe, visuo-spatial sketchpad 249 inner
voice, inner speech 249, 435, 463, 515, 523, 528 insight, problem
solving 577, 577--578, 577 instrumental vs broad rationality 702--704
integral emotions 744 integrated brain functioning 787--788
intelligence: crystallised intelligence 255; fluid intelligence 255,
257, 593, 595, 597--598, 706; tripartite model 705--706, 706, 707
interactive activation model 437--439, 437 interactive-iterative
framework, object recognition 115--116, 115, 116 interferences,
retention/forgetting 208--209, 281--284; proactive 281--282, 281, 282,
283; retroactive 281, 281, 282--283, 291, 292, 368 (see also proactive
interference) interoception 652 interpretive bias 721, 754, 758--759,
760, 763; real world example:

reducing anxiety and depression 762 intuition, "gut feeling" 637;
logical intuition model 640, 685, 686 invariants, optic array 142, 144
Iowa Gambling Task 751 jargon aphasia 541--543; see also aphasia
Jeopardy (computer vs human) 26 Joyce, James 569, 570 judgement: defined
622; judgement vs decision making 622; research 623--633 (see also
judgement research); theories 633--640 (see also judgement theories)
judgement, research: availability heuristic 628--629, 628, 629--630,
630, 633; base-rate neglection 624--626, 627; Bayesian inference theorem
623--624; double conjunction fallacy 626; natural frequency hypothesis
631--633, 632; real-world example: availability heuristic in medical
diagnosis 629; real-world example: heuristic in medical diagnosis
625--626, 625; representativeness heuristic 624--625; taxi cab problem
623--624 judgement, theories 633--640; dualprocess theory 637--640;
fast-andfrugal heuristics 634--637; recognition heuristic 635--636, 637;
subadditivity effect 633; support theory 633--634 Kasparov, Garry vs
Deep Blue computer chess match 26 Kay, Peter 413 Kintsch's
construction-integration model; see construction integration model know
procedure, memory 306, 310 "Knowledge, The", London taxi driver test
610; see also brain plasticity knowledge effect, writing 555 Korsakoff's
syndrome 296--297, 325 language: innateness of 395--397; language
comprehension (see language comprehension); language production (speech,
writing) (see language production); reading (see reading); speech
perception (see speech perception); unique-to-humans question 393--394;
universal grammar, linguistic universals 395, 397, 398; Whorfian
hypothesis 398--400 language comprehension: discourse comprehension (see
discourse

Subject index comprehension, theoretical approaches); individual
differences (working memory capacity) 487--490; parsing 462--464;
pragmatics 478--487; theoretical approaches: parsing, prediction
464--478 language processing: algorithmic route 473--474, 473, 475;
heuristic route 473, 473 language production: easing of: preformulation
518; easing of: syntactic priming 518, 547; easing of:
underspecification 518; real-world example: mild cognitive impairment
518; speech errors 521--525; speech planning 519--521; speech production
(see speech production); speech production vs speech comprehension
516--517, 517; stages of speech production 519; writing (see writing)
lateral inhibition 46, 46 law of Prägnanz 97 learning: implicit learning
(see implicit learning); retrieval through (testing effect) 265--269,
266, 267, 268 lemmas 530--532, 533, 534, 535, 538 lesion, brain 7, 12,
57, 608; diaschisis 11 levels-of-processing approach, memory 262--265,
263, 264 lexical access 417; E-Z Reader model 454, 455--456, 455 lexical
bias effect 528 lexical decision task 434 lexical parafoveal-on-foveal
effects 455, 456 lexicalisation 531 lexicon 430, 431, 433, 433, 445,
527, 528; auditory input lexicon 430, 430, 431; orthographic lexicon
562--563; phonological output lexicon 538 lexigrams 393--394 life script
354--355 lifetime memories 351--355 lifetime period, memory 356, 359
limb apraxia 156--157 linear perspective 72, 72, 74 line-ups (eyewitness
testimony) 372--373 linguistic relativity 399 linguistic universals 395,
396 listening, speech perception: coping with listening problems
409--412; difficulties, speech masking 408; McGurk effect 411--412, 412;
model of speech comprehension 412; speaker variability 411; speech
segmentation 408--409, 409--411, 410; speech signal problems 408--409
load theory 189--191; cognitive load 190, 191, 408, 520, 639; perceptual

load 190, 190, 191; real-world example: driving and mobile phone use
214--215 lobes, brain 13--14 logical interferences 490 logical intuition
model 640, 685, 686 London taxi driver test "The Knowledge" 610
long-term memory 300; declarative (explicit) memory (see declarative
(explicit) memory); level of processing 262; in multi-store model 240;
non-declarative memory (see non-declarative (implicit) memory) loss
aversion, decision making 642, 644--646, 645, 648, 650, 652 loss
neutrality, prospect theory 645 luminance 52--53, 100 magnetic resonance
imaging (MRI) 18, 19--20, 25, 655 magneto-encephalography (MEG) 16, 20,
136, 426, 532--533, 691--692 magnocellular (M) visual pathway 45, 104
major attention networks 191--196; brain areas 192--193, 193, 195, 195;
cingulo-opercular network 195, 195; default mode network 25, 195, 195;
endogenous/goal directed network (dorsal) 192, 193, 193, 194, 209, 211;
exogenous/stimulus-driven network (ventral) 192, 193, 193, 211;
frontoparietal network 192, 195--196, 195; interactions 193, 194, 196,
200; realworld example: car warning systems 209 major depressive
disorder 361, 361, 362, 729 Marr, David, computational approach to
object recognition 105--106 Mars Rover Mission 593 masking, auditory
408, 523 matching bias 677 matchstick problem, problem solving 580, 581,
581 maximisers vs satisfiers, decision making 656--657 McGurk effect
411--412 means-ends analysis 589 means--ends analysis, problem solving
589 mediator effectiveness hypothesis 265, 267 medical diagnosis
625--626; real-world example: availability heuristic in medical
diagnosis 629; real-world example: heuristic in medical diagnosis
625--626, 625

939

medical expertise 604--609, 605, 606, 608; vs chess expertise 609 MEG;
see magneto-encephalography memories across lifetime 351--355;
infantile/childhood amnesia 351--353, 352; reminiscence bump 351, 352,
353--355, 354 memory: affect and memory 734--738, 735, 737; everyday
memory (see everyday memory); memory bias (implicit, explicit) 754, 759,
760, 761 (see also cognitive bias); mood congruity 736, 737--738;
mood-statedependent memory 288, 736--738, 737; sensory stores 240--242,
240; synaesthesia and 280; see also amnesia; memory systems/processes;
memory traces memory decay 242, 280--281 memory systems/processes 300;
component-process models 338--340, 339; declarative/explicit vs
nondeclarative/implicit (see declarative (explicit) memory;
non-declarative (implicit) memory); episodic vs semantic
(non-declarative) (see episodic memory; semantic memory); Henke's
processing-based theoretical account 333--335, 334, 336; memory
system--brain area dependency 337--338, 337; short-term vs longterm (see
long-term memory; short term memory) memory traces, retrieval 268, 280,
287; distinctiveness 263--264, 264; dual-memory theory 265, 266;
encoding specificity principle 287, 287--288, 289--290; eyewitness
testimony, accuracy 367; familiarity and recollection 306;
reconsolidation 289--290, 291--293 mental models 491, 681--683 mental
set, problem solving 584--588, 587, 704; see also functional fixedness
mentalising 346, 347 meta-analysis 36 meta-cognition 149, 384, 385--386,
555, 590 meta-memory 380--381 metaphor interference effect 480, 480
meta-reasoning 589--590, 688, 689, 690 mindware 706 minimalist
hypothesis 491--492, 494, 495, 497 minimally conscious state 778 mirror
neuron system 161--163, 161 misery-is-not-miserly effect 746; see also
emotion and cognition

940

Subject index

misinformation/misleading effect, eyewitnesses' memory 365--368, 366,
368 mixed-error effect, speech error 527 modularity, cognitive system 8,
12; see also cognitive neuropsychology modularity/anatomical modularity,
assumption 8 Molaison, Henry Gustav (HM) 297, 297 Mona Lisa (Leonardo da
Vinci) 105, 105 monocular (pictorial) cues, depth perception 71, 72--74,
72, 73 mood congruity, memory 736, 737--738 mood states:
judgement/decision making 743--750, 745, 746, 750 (see also emotion and
cognition); mood-state-dependent memory 288, 736--738, 737 moral
dilemma: emotion vs cognition (reason) 738, 738--740, 743; deontological
judgements 739--740, 743; real-world example: driverless cars 741--742,
742; utilitarian judgements 739--740, 741--742, 742, 743 (see also
deontological judgements) morpheme-exchange errors, speech errors 522
morphemes 519, 522 morphological level, speech production 519 morphology
433, 462 motion parallax 73, 80 motion perception 157--163; biological
motion 160; brain areas 159, 159; human motion 157--160, 157, 158;
mirror neuron system 161--163, 161; top-down/bottom-up processes
158--159 motion processing, visual 51--54, 52, 53 motivated forgetting
284--290; cuedependent forgetting 286--287; directed forgetting 285;
recovered memories, truthfulness of 284--285; repression 284--285, 351;
suppression, think/no-think paradigm 285--286, 286 motivation,
reasoning, decision making 577, 658--659, 677, 695--697, 708, 746
motivational intensity, attention 731--732, 733--734, 737 motor sequence
learning 275, 275, 276, 330--331, 332 motor theory, speech perception
417--410 MRI; see magnetic resonance imaging Müller-Lyer illusion,
visual perception 58, 58, 59, 60, 154

multi-attribute utility theory, decision making 656, 657, 658
multifactorial gene-environment interaction model, expertise 617--619,
617 multiple resource theory 215--217, 216 multiple spotlights theory,
split attention 184, 185 multiprocess framework, memory 382 multi-store
model, memory 240--244 multi-tasking; see divided attention Murdoch,
Iris 550, 550 music perception 404--406; see also speech perception
mutilated draughtboard problem 577--578, 577 myopic misery 746; see also
emotion and cognition myside bias 696--697; see also informal reasoning
naming task 434, 534, 535, 538, 543 narcissism 747 narrative text 507,
510 natural frequency hypothesis 631--633, 632 natural sampling 631, 632
naturalistic decision-making theory 659--662, 660, 661; bounded
rationality 660; decision structuring 659--660; recognition-primed
decision-making model (expert decisions) 660--662, 660 negative
afterimages, colour vision 65--66 neglect, visual attention disorder
196--197, 197, 198, 199, 200; allocentric/object-based 196--197;
egocentric/space-based 196--197; pseudo-neglect 196; ventral attention
network damage 198, 199--200 neologisms 541--542 nested incremental
modelling, computational modelling 32 neural correlates of consciousness
779--783, 781, 782, 783 neural decoding 19 neural network models; see
connectionism, connectionist models neuroenchantment 25--26, 26
neurogenesis, hippocampal 352, 353 neurons 16, 29; brain, organisation
14; motion perception, mirror neuron system 161--163; object recognition
111; pattern recognition 96; visual form processing 50; visual
processing (lateral inhibition) 45--46, 46; see also single-unit
recording

nine-dot problem, representational change theory 579, 580 nodes 14, 15,
15, 28, 29; Spreadingactivation theory 526--527; TRACE model 420--421,
421 non-accidental (invariant) properties, object recognition 107--108
non-declarative (implicit) memory 269, 280, 325--332; vs declarative
(explicit) memory 299--300, 300, 328, 332--333; implicit and explicit
learning 269--278; implicit memory bias 754, 755, 759;
levels-of-processing effect 263; procedural memory/skill learning
328--332, 330; repetition priming 325--328, 328 non-focal/focal task
382, 384--385, 385 normativism 703 object recognition: bottom-up process
111 (see also bottom-up processing); vs face recognition 116--117;
holistic processing, expertise hypothesis 122--123;
interactive-iterative framework 115--116, 115, 116; Marr's computational
approach 105--106; perception-action model (see twopathway
action-perception model); real-world example: shooter bias by skin
colour 113; recognition-bycomponents theory, Irving Biederman 106--109,
107; spatial frequency, coarse-to-fine processing 104--105, 104, 105;
top-down processing 111--116, 112, 114, 115, 116 (see also top-down
processing); viewpoint, influence on 108, 109--111; see also face
recognition object-based neglect, visual perception 196--197
object-/space-based attention 186--187, 187, 188, 189
obsessive-compulsive disorder (OCD) 380--381, 381 oculomotor cues, depth
perception 75 omission bias 651 ongoing task, prospective memory 377,
381--382, 383, 384--385, 386, 387, 388 open-object illusion 4--5, 4, 12,
80, 443 operation span 255, 488--489 opponent-process theory, colour
vision 65--66 optic array 141; see also invariants, optic array optic
ataxia 57--58, 57, 64, 156--157 optic chiasm 44 optic flow 141--142,
142, 145--146, 147, 148--149 optimism bias 744, 749

Subject index orthographic lexicon 562--563 orthographic neighbours 248,
417, 437--438 orthographic neighbours/ neighbourhood; see also
phonological neighbours/neighbourhood orthographic working memory
(grapheme buffer) 560, 560 orthography 417, 434, 447, 448 other-race
effect 370--371 out-of-body experiences, consciousness 771
overadditivity/underadditivity 221, 221, 222 overconfidence, cognition/
comprehension 498, 749 overt attention 165, 167, 170 own-age bias 370
paradigm specificity 7, 25, 35 parafovea, parafoveal processing 453,
455, 455, 456; see also lexical parafoveal-on-foveal effects parallel
processing 4, 32, 35, 48; language comprehension 464--465; reading 437,
446, 455; reasoning 685, 685; vs serial processing 213--214; visual
perception 49, 202, 203, 204, 207, 208, 225; see also serial processing
parietal cortex, motion processing 46 Parkinson's disease 160, 277,
329--330, 330, 332 parsing, language comprehension: defined 462; inner
voice, implicit prosody 463; prosodic cues 404, 463--464, 466--467, 540,
548--549; syntax and grammar 398, 433, 461, 462--463 parsing and
prediction, theoretical approaches: constraint-based model 468--470;
event-related potentials (ERP) studies 475--478, 476; gardenpath model
465--468; good-enough language processing account 472--475, 474;
prediction through top-down processes 476; unrestricted race model
470--472, 471 part-whole effect, face recognition 117 part-whole effect,
object recognition 117 parvocellular (P) visual pathway 45, 104 past
experience: functional fixedness 585--586, 585, 587; mental set
584--588, 587, 704; see also top-down processing Patient DB 82 Patient
GY 83--84, 84, 86 pattern recognition 95--96, 95, 607--608; defined 95,
239; expert

decision-making 660--661, 661; feature detectors 96; real-world example:
forensic fingerprint matching 98; real-world example: spammer protection
97 pendulum/two-string problem, insight 383, 385 perception: backward
masking 780--781, 782; categorical perception 399, 405; cross-modal
effects 208--212; music 404--406; speech (see speech perception); visual
(see visual perception); Whorfian hypothesis 398--400; without awareness
and subliminal perception 81--90, 714 perception without awareness,
subliminal perception 81--90, 714; blindsight 82--86, 84, 86; real-world
example: blindsight patient DB 82, 89; subliminal perception 87--90, 89
perception-action model; see twopathway action-perception model
perceptual awareness 88, 89; see also perception without awareness,
subliminal perception Perceptual Awareness Scale, subliminal perception
84, 85, 88 perceptual loop theory, speech errors 523 perceptual
organisation 96--103; figure-ground segmentation 99--100, 100--101, 102,
102; Gestalt laws of perceptual organisation, law of Prägnanz 97, 99,
100, 101; research findings, evaluation 100--103; uniform connectedness
101, 103 perceptual priming 325--327; see also priming perceptual span
453 peripheral vision 73, 165--166, 167, 170--171, 170, 207--208, 437
personal semantics 303 personality: agentic personality type 358;
communal personality type 358; everyday memory 344, 358; expertise,
multifactorial geneenvironment interaction model 617, 618;
judgement/decision making 743, 752, 752 phenomenal consciousness 768,
776, 781, 784; see also access consciousness phonemes 405, 406--408,
408--409, 418, 519, 542; dual-route cascaded model 443; dual-route
theory 559--560; Ganong effect 415; TRACE model 420, 423, 423 phonemic
restoration effect 414--415, 416

941

phonological dysgraphia 560--561 phonological dyslexia 445, 448, 450
phonological level, speech production 519, 520, 526, 527, 537, 538
phonological loop: components 247--248, 248; working memory and
forgetting 246, 247--249, 248, 249, 252, 253; working memory and writing
556--557, 556, 558; see also working memory component phonological
neighbours/ neighbourhood 417, 436; see also orthographic neighbours/
neighbourhood phonological output lexicon 445, 538 phonological priming
434--435, 436 phonological processes, reading 435--436 phonological
similarity effect, phonological loop 248 phonology 433--434, 433, 436,
447, 448 phrase 519--520, 522 pictorial (monocular) cues, depth
perception 71, 72--74, 72, 73 picture naming tasks, speech production
534, 535, 538, 543 planning-control model, visually guided action
152--155; brain areas 153; evaluation of 154; planning and control
systems 152--153; see also two-pathway action-perception model
plasticity, brain; see brain plasticity Popper, Karl 667 positron
emission tomography (PET) 16, 18 pragmatics 478--487; common ground
484--487, 485, 486; figurative language, metaphors 480--483, 480, 482,
483; real-world example: autistic spectrum disorder 479 pragmatics,
language comprehension: brain areas (figurative/literal processing) 478;
common ground 484--487, 485, 486; common ground-- egocentric heuristic
simultaneity 486, 487; egocentric heuristic 484--486, 487; figurative
language, metaphors 480--484, 480, 482, 483; intended vs literal meaning
478--479, 480; realworld example: autistic spectrum disorders 479
predictive inferences 491, 494, 495--496, 495, 497 preformulation,
speech production 518 Price, Jill, highly superior autobiographical
memory (HSAM) 348 primal sketch, object recognition 105

942

Subject index

priming 300, 325--328, 326, 434--435; brain areas 337--338; conceptual
priming 325--326, 327; motor priming 142; perceptual priming 325--327;
phonological 436; priming processes 327--328; priming--skill learning
differences 331; reading research 434; repetition priming 299, 325--328,
328; semantic priming 316, 439, 440, 440; syntactic priming 518, 547
principle of truth 681, 682 proactive interferences, retention
forgetting 281--282, 281, 282, 283 problem solving 574--600; analogical
problem solving (see analogical problem solving and reasoning);
facilitating insights (hints, incubations) 583--584, 583; functional
fixedness, past experience 585--586, 585, 587; Gestalt approach (see
problem solving, Gestalt theories); mental set, past experiences
584--588, 587, 704; problem types (well/ill-defined, knowledge-rich/
lean) 574, 576; real-world example: Monty Hall problem 575--576, 575;
representational change theory 579--583; strategies 588--593 problem
solving, Gestalt theories 576--588; functional fixedness 585--588, 585,
587; hints, incubations 583--584, 583; insight 577--579, 577; past
experience 584--585; real-world example: magic tricks 582, 582;
representational change theory 579--583, 580, 581 problem-solving
strategies 588--593; cognitive miserliness/cognitive reflection test
1--2, 592--593; hillclimbing heuristic 589; means--ends analysis 589;
meta-reasoning 589--590; planning, sequential processing stages 590--592
problem space 588 problems: knowledge-lean/knowledgerich 574, 588, 588;
well-defined / ill-defined 574, 589 procedural memory 31--32, 31, 299,
300; and skill learning 325, 328--331 procedural similarity, problem
solving 594 process-dissociation procedure 272, 273, 275
processing-based theoretical account, memory 333--335, 334, 336
production rules 30 production systems, computational cognitive science
30--32, 318, 502

pronunciation: phonemes 409; word/ irregular word/non-word 11, 263, 435,
442, 443--444, 447, 451--452 proposition, propositional logic 501--502,
503, 504--505, 673, 696--697 proprioception 60, 61, 153 prosodic cues,
language comprehension 404, 463--464, 466--467, 540, 548--549
prosopagnosia 118--121, 120, 127, 128--129; real-world example: Heather
Sellers 118 prospect theory, decision making 642--648, 642, 649, 650,
650; description-experience gap 646--647; framing effect 642; individual
differences 647--648; loss aversion 644--645; real-world example: expert
loss/risk (golfing, finance) 645, 645--646, 647; sunk-cost effect 644,
644 prospective memory 375--389; air traffic accidents 378--379, 379;
evaluation 387--388; event based vs time based 376--377; improving 387;
obsessivecompulsive disorder (OCD) 380--381, 381; real-world example:
failures of 378--381, 379; research findings 384--386; vs retrospective
376; stages 377--378, 378; theoretical perspective 381--389, 381; see
also retrospective memory pseudo-neglect 196 pseudowords 442
psychological refractory period, cognitive bottleneck 222--226, 224
psychological refractory period (PRP) 222--226, 224; see also divided
attention, dual-task performance/ multi-tasking psychological refractory
period (PRP) effect 223 pure alexia 9, 12 pure word deafness 430--431
rationalisation 499, 770 rationality; see human rationality Raven's
Progressive Matrices 593, 594, 595; see also fluid intelligence reaction
time: real-world example: driving and mobile phone use 214--215;
real-world example: warning signals promote safe driving 211; serial
reaction time task, memory 272--273, 273, 274, 274, 330 reading:
"anglocentricities" in reading research 433--434; eye-movement research
453--454; general framework, processes/structures 433, 433; phonological
processes 435--436; pure

alexia 9, 12; reading aloud 442--453; research methods 434--435, 434;
word recognition 436--442 reading, eye-movement research: basic
processes 453--454; E-Z Reader model 454--457, 455; lexical
parafoveal-on-foveal effects 455; parafovea, parafoveal processing 453,
455, 455, 456; perceptual span 453; saccades 453; serial vs parallel
processing 455 reading aloud: connectionist triangle model 447--449,
448; deep dyslexia 445, 448, 450--451; dual-route cascaded model
443--477, 444; general vs language-specific processes 452;
grapheme--phoneme conversion rules 443--445; lexical/non-lexica routes
443, 444; orthography--phonology/ phonology--orthography pathways 447;
phonological dyslexia (lexical route) 445, 448, 450; pronouncing
non-words 442, 451--452; surface dyslexia (non-lexical route) 444--445,
448, 449--450; word regularity vs word consistency 451, 451 reading span
255 real-world example: tightrope walking decisions, Nik Wallenda 647,
647 reappraisal, emotion regulation 724, 725, 726, 727--728, 727, 730;
real world: emotion regulation and mental disorder 729 reasoning:
analogical (see analogical problem solving/reasoning); brain systems
690--693; deductive (see deductive reasoning; deductive reasoning,
theories); human rationality 701--708; inductive vs deductive 571, 666,
667; informal 694--701 recall, memory/learning: cued recall 267, 305,
315, 737, 737, 759; free recall 305, 310, 345, 737, 737, 759; serial
recall 241, 253, 253, 305 receptive field 45, 96 recognition heuristic
635--636, 637 recognition memory 305, 306--310, 307, 335; brain
areas/mechanisms 306--310, 309; levels-of-processing, depth 262, 263
recognition test, episodic memory 310 recognition-by-components theory
106--109, 107, 108 recognition-primed decision-making model 660--662,
660 reconsolidation, memory 290, 291--293; see also consolidation
theory, memory

Subject index recovered memories 284--285 recursion 395, 396 reflective
mind 706, 706, 708 remember/know procedure, memory 306, 310 reminiscence
bump 351, 352, 353--355, 354 Remote Associates Test 578--579, 587
repetition enhancement 327--328, 328, 331 repetition priming; see
priming repetition suppression 327--328, 328 repetitive transcranial
magnetic stimulation (rTMS) 16, 21, 50, 112, 159, 478--479 replication
crisis, science 34--36, 35; see also meta-analysis representational
change theory, problem solving 578--583, 580, 581, 583
representativeness, ecological validity 345--346 representativeness
heuristic 624--625, 624--626, 638--639; real-world example: heuristics
in medical diagnosis 625--626 repression, retention/forgetting 284--285,
351 reproductive thinking, reasoning 576--577 research techniques, brain
activity studies 15--26; see also also eventrelated functional magnetic
resonance imaging (efMRI); event-related potentials (ERPs); functional
magnetic resonance imaging (fMRI); magnetoencephalography (MEG);
positron emission tomography (PET); single-unit recording; transcranial
direct current stimulation (tDCS); transcranial magnetic stimulation
(TMS) response bias 88--89, 89, 90; real-world example: fingerprinting
98, 99; realworld example: shooter bias 113 response modulation, emotion
regulation 725, 725, 726 retina-geniculate-striate pathway/ system, eye
44--45 retinal displacement 146 retinal flow field 145 retinal ganglion
cells 44 retinex theory 68--69 retinopy 44 retrieval: direct 356,
358--359; generative 356, 358--359, 360, 360 retroactive interferences,
retention/ forgetting 281, 281, 282--283, 291, 292, 368

retrograde amnesia 290, 292, 298, 302, 357 retrospective memory 375,
377, 380; prospective vs retrospective memory 376 reverse inference 24,
35 risk: brain areas (financial decision making) 652; decision-making
(mood) 745--747, 745, 751; framing effect and risk taking 642--644;
losses/ gains 641; loss/risk aversion 642, 642, 645--646, 645, 743;
omission bias 651; risk taking, individual differences 647--648 RI-Val
model 505--507, 506 rTMS; see repetitive transcranial magnetic
stimulation Russell, Bertrand 666 Rutherford, Ernest 593 saccades 543
sadness 732, 743, 745--746, 745, 746, 751; see attention; emotion and
cognition satisficing 656 savings method 278 saying-is-believing effect
345 schema 71; brain networks 322--323; defined; double dissociation
323--325; eyewitness testimony, influence on 364; Schema theory 498--501
Scrabble 795 script/life script 354--355 segmentation: auditory 179,
408--409; auditory/speech 409--411, 410; event-segmentation theory
507--510; realCAPTCHA, pattern recognition 99; visual/figure-ground 99,
100--101, 102 selective exposure 658--659, 659 self-memory system model,
autobiographical memory 355--359 semantic dementia 303, 304, 314,
319--320, 323--324, 323--325, 324 semantic level, speech production 519,
537 semantic memory 313--325, 333--335; autobiographical memory 347;
Barsalou's approach, concept use 316--318; defined 313; hierarchy/
organisation, concepts 313--315, 315; hub-and-spoke model, concept use
318--320, 319; schemas vs concepts 322--325 (see also schema; Schema
theory); semantic distance, concepts 315--316; see also episodic memory

943

semantic priming 316, 435--436, 439, 440, 440 semantic substitutions,
speech errors 521--522 semanticisation, of episodic memory 304 semantics
434, 447, 448, 448 sense of agency 773, 775 sentential context effects
(anticipatory processing) 440--442 serial dependence 172 serial
processing 4, 8, 32, 225, 454--455; language comprehension 464; vs
parallel processing 213--214; reading 445--446, 454--455; reasoning 685,
685; visual perception 125, 202, 207, 225; see also parallel processing
serial reaction time task 272--273, 273, 274, 274, 330 serial recall
248, 305 sexual abuse, motivated forgetting 284, 285 shadowing/dichotic
listening task 179--180 Shereshevskii, Solomon 280 shooter bias 113
short-term memory: chunking/chunks 241--242, 252, 535; echoic memory
241; iconic memory 240--241; information decay 242; interferences,
retention 242--243, 243; vs long-term memory 240--246; in multi-store
model 240, 241--243; see also working memory short-term/long-term
memory, comparison 240--246; multi-store model 240--244; unitary-store
model 244--246 signal-detection therapy 98 single case studies vs case
series, research 10--11 single-unit recording 16, 17, 47 size constancy,
depth perception 78--81, 78, 79, 81 skill learning 328--332, 330
slippery slope argument 700 social cognition 1 social functionalist
approach, decision making 653--654 social rationality 703
social-cultural developmental theory, memory 351 solution aversion 696
sound segregation 179 space-/object-based attention 189 spatial
attention 196, 211 spatial frequency/coarse-to-fine processing, object
recognition 104--105, 104, 105

944

Subject index

speech and music perception 404--408; differences (brain area
activation) 405--406; processing stages perception/comprehension
406--408, 406, 407; similarities (categorial perception) 404, 405 speech
as communication 543--549; audience design 543--549, 544--547, 546;
common ground 544--545; discourse markers 549; gesture 547--548;
prosodic cues 548--549 speech errors, language production:
conflict-based monitoring theory 523--525, 524, 525; error types
521--523; Freudian slip 521; mixederror effect 527; morpheme-exchange
errors 522; perceptual loop theory 523; semantic substitutions 521--522;
spoonerism 521; subject-verb agreement errors 522 speech output lexicon
430, 431 speech perception: basic units (phonemes vs syllables) 406,
407; brain areas 405--406; categorical perception 405; cognitive
neuropsychology research 429--432; context effects 412--416; listening
as 408--417; processing stages 406--408, 406, 407; speech and music
perception 404--408; theories about 417--429 speech perception,
cognitive neuropsychology research 429--432; auditory analysis system
430--431; deep dysphasia 432; pure word deafness 430--431; three-route
framework 430, 430, 431--432; transcortical sensory aphasia 432; word
meaning deafness 431, 432 speech perception, context effects:
distraction/distractors influence 413--414, 414; Ganong effect 415,
422--423; Interactionist vs autonomous accounts 415--416; phonemic
restoration effect 414--415, 416; real-world misheard lyrics and
miscarriages of justice 413 speech perception, theories: cohort model
425--429, 428, 429; motor theory (perception--production coupling)
417--420, 420; orthographic influences on 417; TRACE model 420--425,
421, 422, 423 speech production: cognitive neuropsychological approach
536--543; speech as communication 543--549; speech production vs
comprehension 517; stages/levels

of speech production 519 (see also morphological level; phonological
level; semantic level; syntactic level); theories 525--536 speech
production, cognitive neuropsychological approach: agrammatism 539--541,
540; anomia 537--539; aphasia (Broca's, Wernicke's, jargon) (see
aphasia) speech production theories: Dell's spreading-activation theory
519, 526--530, 533, 536, 538; general cognitive processes 535--536;
WEAVER++ 526, 530--536, 534 spelling: brain areas, writing and reading
562--563, 563; dual-route theory (lexical/non-lexical) 559--562, 559,
560; lexical-route damage, phonological dysgraphia 560; nonlexical-route
damage effects, surface dysgraphia 561; orthographic lexicon 562--563;
orthographic working memory (graphemic buffer) 560 SPIDER model 214--215
spillover effect 454--455 split attention 184, 184--186, 185 split-brain
patients 792--798; crosscueing and unified control 793, 797;
hemispherectomy and brain plasticity 793--794; left hemisphere
(interpreter) dominance 795--796, 796; research limitations 796; two
stream consciousness 793, 794, 797, 797; Wada test 794 spoonerism,
speech error 521 spotlight attention 184--185, 186 spreading activation
theories 315--316, 502, 519, 526--530, 533, 536, 538 standards of
coherence 492, 492 status quo bias 651--652, 653; real-world example:
politicians' decision-making 653--654, 654 stereopsis 74, 77 stimulus
onset asynchrony (SOA) 223, 706 stop-signal task, task-impurity problem
5 straw man fallacy 694 stray-light hypothesis, blindsight 82 striatum
274--275, 274, 276, 331--332, 333; Parkinson's disease 277, 329 Stroop
task, task-impurity problem 5, 5, 258, 756, 756 structural similarity,
problem solving 594 subadditivity effect 633, 634 subject-verb agreement
errors, speech errors 522

subliminal perception; see perception without awareness/subliminal
perception subtractivity assumption 9, 12; see also cognitive
neuropsychology; plasticity, brain sulcus 13, 13 sunk-cost effect,
decision making 644, 653, 704; real-world example: politicians'
decision-making 653--654, 654 superficial similarity, problem solving
594 super-recognisers 125 support theory, judgement 633--634
suppression, think/no-think paradigm, memory 285--286, 286 surface
dysgraphia 561 surface dyslexia 444--445, 448, 449--450 SWIFT model,
reading 455, 456, 457 syllogism/syllogistic reasoning 678--680, 679,
684, 686, 687, 697, 698; see also deductive reasoning synaesthesia 280
synchrony, binding-by synchrony hypothesis 54 syndrome: anarchic-hand
syndrome 795; Anton's syndrome 131; Asperger syndrome 479; Charles
Bonnet syndrome 131; defined 10; dysexecutive syndrome 251, 260, 277,
557; Korsakoff's syndrome 297--298, 325 syntactic level, speech
production 519, 527 syntactic priming, speech production 518, 547
syntactic processing, language 398, 467 syntax 398, 433, 461; grammar
and 462--463; see also grammar; parsing tacit knowledge, visual
perception 182 take-the-best strategy, heuristics 635, 636, 637 tangent
point 147, 147, 149; real-world example: on-road driving 148, 148 task
processing 4, 4, 16 task-impurity problem 5 tau/tau-dot hypothesis,
motion perception 149, 151, 152 taxi cab problem, judgement 623--624
taxi driver test "The Knowledge" (London), brain plasticity 610 template
theory, chess 601--604, 603 temporal coherence 183 temporal
ventriloquism 210--211, 210; real-world example: warning signals promote
safe driving 210

Subject index temporal ventriloquism effect 210--211, 210 testing effect
265--269, 266, 267, 268 texture tiling model, visual search 206--208
texture/texture gradient, depth perception 72--73, 72, 76 thinking and
reasoning: decisionmaking 640--663; expertise 600--618; judgement,
research and theories 623--639; problem solving 574--600; reasoning
666--708; see also under their own entries think/no-think paradigm,
suppression memory 285--286, 286 threaded cognition 217--220, 218
three-route framework, speech perception 430, 430, 431--432 time to
contact, visually guided movement 149--152, 152 time-based prospective
memory 376--377; see also event-based prospective memory
tip-of-the-tongue state 531--533, 538 TMS; see transcranial magnetic
stimulation Tolman, Edward C. 3 top-down processing: (visual) word
recognition 436, 437, 437, 438; attention 178, 182--183, 192, 193--194,
196, 197; bilinguality/ understanding non-native speaker 409, 488, 535;
brain mechanism 599; comprehension 499; conscious experience 777, 781;
defined 4, 4; emotional experience 718--719, 718; human-motion
perception 158--159; inattentional blindness 173; information processing
approach 4; memory/retrieval 382, 383, 384--385, 386; object recognition
111--116, 115; pattern recognition 96, 98--99; speech perception 408,
412, 413, 416, 417, 420--421, 421, 422--423, 424; visual
imagery/perception 48, 132, 135--136, 135, 137; visual search 204, 204
Tower of Hanoi, problem solving task 588, 588, 590, 591, 592 Tower of
London, problem solving task 590--591, 590 TRACE model, speech
perception 420--425, 421, 422, 423 trait anxiety 753, 758, 760
transcortical sensory aphasia 432 transcranial direct current
stimulation (tDCS) 16, 22, 162, 221--222, 320, 728 transcranial magnetic
stimulation (TMS) 16, 20--22, 21, 35; attention 194, 196; consciousness
782; memory

forming 320, 327; speech perception, reading 418, 436, 449; visual
perception 48, 50, 51, 62, 145--146 transference, unconscious 370
transparency assumption 9, 12; see also cognitive neuropsychology;
plasticity, brain traumatic memory 284, 285; see also flashbacks;
recovered memories; repression triangle model, connectionism 442,
447--453, 448 trichromacy theory, colour vision 65, 66 tripartite model
of reasoning 705--706, 706 Tulving, Endel 287 twins/twin studies 125,
258, 259, 610, 611, 616, 618 two-pathway action-perception model 46, 46,
55--64, 63, 103--104, 155--157; action planning/motor responses 61;
conscious awareness (dorsal/ ventral\|) 61--62; differences 56; research
findings 57--58, 58, 62--63, 63; vision-for-action system (dorsal
stream) 56, 57; vision-for-reception system (ventral stream) 55, 58;
visual illusions 58--61, 59, 60, 61, 64, 153; see also dorsal stream;
ventral stream two-string problem, insight 383, 385 Ulysses (James
Joyce) 569 unconscious processing; see subliminal perception unconscious
thought theory, decision making 662--663 unconscious transference 370
underadditivity/overaddivity 221, 221, 222 underspecification, speech
production 518 uniform connectedness 101, 103 uniqueness point 425,
426--427 unitary-store model, memory 244--246 universal grammar,
linguistic universals 395, 397, 398 universality assumption 8--9, 12;
see also cognitive neuropsychology unrestricted race model, language
comprehension 470--472, 471 Urbach-Wiethe disease 735 utilitarian
judgements 739--740, 741--742, 742, 743; see also deontological
judgements utility, utility theory 641, 655--656, 657; see also
instrumental vs broad rationality

945

valence 716 vegetative state, consciousness 778, 782, 787, 788;
real-world example: vegetative state patients and consciousness
778--779, 779; see also brain damage/brain-damaged patients ventral
stream/pathway, visual perception: action planning/motor responses
62--63, 63; allocentric coding 56; brain-damaged patients 58, 540, 540;
object recognition 104, 155, 156; perception-action model 55--57, 56;
visual brain, organisation of 47--48, 47, 48; visual motion 53; see also
dorsal stream; two-pathway action-perception model ventriloquism effect
209--210, 209--212; real-world example: warning signals promote safe
driving 210; temporal ventriloquism 210--211, 210 verb bias 469 vergence
74, 75 vergence, depth cues 74--75 viewpoint, influence on object/face
recognition 81, 106, 107, 108, 109--111, 335, 335 vision-for-action
system 59--60 visuo-spatial sketchpad 246, 247, 249--251, 252--253, 556,
557--558; see also working model components visual attention, disorders:
biased stimuli competition hypothesis 199, 200; conscious stimuli
awareness and stimuli processing 198; extinction 197--198, 199, 200;
neglect 196--197, 197, 198, 199, 200; ventral attention network damage
198, 199--200; see also focused visual attention visual buffer 132, 132
visual cache, visuo-spatial sketchpad 249 visual cortex 45, 339; damage,
blindsight 82, 83, 85, 136; neuron types in 96; object recognition 104,
111; V1, BA17 (primary), V2, BA18 (secondary) 14, 45--46, 48, 48, 49,
49, 52, 53, 54; V3 (form processing), V4 (colour processing), V5/MT
(motion processing) 46--47, 47, 48, 49, 49, 50--54, 52, 53; visual
imagery, hallucinations 130--131, 132, 133--134, 134--135, 135 visual
crowding 170, 207; see also change blindness visual form agnosia 58
visual illusions 58--61, 59, 60, 61, 64, 153

946

Subject index

visual imagery 130--137; Anton's syndrome, blindness denial 131;
functions of 131; hallucinations/ Charles Bonnet syndrome 114, 130, 131;
impairment/lack of (aphantasia) 130; theories: depictive representation,
visual buffer 131--132, 132; visual perception, resemblances/
differences 130, 132--136, 133, 134, 135 visual pathways/processing
44--55, 781, 782; brain, areas involved 49; brain, functional
specialisation 48--55; brain areas involved 46--48, 48; early processing
(V1, V2) 45--46, 46; feedforward sweep 21, 48, 49, 781--782;
retina-geniculate-striate pathway (eye to cortex) 44--45; two-pathway
model (vision for perception/vision for action) 46, 46, 55--64, 56, 63,
103--104, 155--157 visual perception: brain systems involved in 44--55;
colour vision/ processing 50--51, 64--71; depth perception 71--81;
perception without awareness, subliminal perception 81--90; two-pathway
actionperception model 55--64, 63, 103--104, 155--157 visual receptor
cells: cones 44, 45, 65, 66--67; rods 44, 45 visual search 200--208;
dual-pathways model 204--206, 204, 205; feature integration theory
202--204, 203, 207; real world example: airport security checks.
201--202, 202; texture tiling model (foveal/ peripheral vision)
206--208, 208; visual crowding 208 visually guided action 152--157;
action plan changes 155; brain pathways (dorso-dorsal, ventro-dorsal)
155--157, 156; planning-control model 152--155 visually guided movement
145--152; eye and head movements 145, 146, 147, 148; heading and
steering 145--148; optic flow information 145--146; path and heading
judgements 146, 147,

147; real-world example: on-road driving, drivers' gaze pattern 148,
148; retinal object displacement 146; tangent point 147, 147, 148; time
to contact 149--152, 150 visuo-spatial sketchpad: language 556, 557,
558; mental models 682; working memory 245, 249--251, 250, 252; see also
working memory components Wada test 794 Waldo Emerson, Ralph 748
Wallenda, Nik 647 War of the Ghosts, The (North American Indian culture)
449, 500 Wason's selection task 676--678, 676; see also deductive
reasoning Wason's 2-4-6 task 666--670 Watson, IBM, AI computer 26, 27
Watson, John 3, 714 WEAVER++ 526, 530--536, 534, 537, 538 Wernicke's
aphasia 536--537 Who Wants to be a Millionaire (TV show) 649 Whorf,
Benjamin Lee 398 Whorfian hypothesis, language 398--400 word consistency
vs word regularity 451, 451 word meaning deafness 431, 432 word
regularity vs word consistency 451, 451 word superiority effect 437, 438
word-length effect, phonological loop 248 word-recognition, reading
453--454; interactive activation model 437, 437--439; semantic priming
439, 440; sentential context effects (anticipatory processing) 440--442
working memory 246--254, 487--490; Adaptive Control of ThoughtRational
(ACT-R) 31--32; components (see working memory components);
connectionism/ connectionist models 28; deliberate practice 613--614;
executive functions 251, 254, 255, 257--262, 259; individual differences
254--257,

487--490 (see also working memory capacity); production systems 30;
reasoning 597--598, 681--682; spelling/ orthography 560, 560; threaded
cognition 217--218, 218, 219; writing 552, 553, 555--558, 556 working
memory capacity 254--257; implicit learning 270; inferences, dealing
with 493; language comprehension differences 487--490; parsing and
prediction 474--475; problem solving/reasoning 587, 587; writing
expertise 494 working memory components: central executive 246--247,
246, 251, 252--255, 260, 277, 556--557, 556; episodic buffer 247,
252--253, 253; phonological loop 246, 247--249, 248, 252, 253, 556--557,
556, 558; visuo-spatial sketchpad 245, 249--251, 250, 252, 556, 557,
558, 682; see also short-term memory working memory model 246--254, 246;
see also central executive; episodic buffer; phonological loop;
visuospatial sketchpad; working memory components working self,
self-memory system model 356, 357, 358 World Trade Centre attack,
flashbulb memory 349--350, 349 writing: correlation writing/cognitive
abilities 549; dysexecutive agraphia 557; individual differences,
expertise development 553--555, 554; key processes, writing models
551--553, 552, 553; process switching 550, 552--553, 553; real-world
example: Iris Murdoch, Alzheimer's and novel writing 550, 550; spelling
(see spelling); spelling/orthography 558--563; word processing software
vs by-hand writing 558; working memory influence 555--558, 556 "Yes It
Can" principle, unconsciousness 769 zoom-lens attention 184--185, 186

Achieve Optimal Anatomy Learning Outcomes with Next Generation Primal
Pictures Next Generation Primal Pictures is the cutting-edge suite of
digital anatomy solutions for education that saves you time, increases
engagement, and advances learning outcomes. Primal brings
evidenced-based accuracy to a wide range of offerings that help students
in over 1500 colleges and universities around the world grasp course
material, prepare for lab time, and study for exams with confidence. -
Empower confidence through evidence-based accuracy with the world's most
detailed, researched, and verified 3D reconstruction of human anatomy. -
Access, source and integrate flexible and dynamic 3D anatomy content
across the spectrum of gross anatomy, physiology, biomechanics and
medical specialties. Save, share, or embed in your own online learning
environment. - Drive highly engaged learning and better outcomes with
vividly detailed interactive images, movies, slides and animations. -
Anytime, anywhere access on any device for learning on-the-go, flipped
classroom and distance learning, review and assessment.

To learn how Next Generation Primal Pictures can help you master anatomy
and physiology visit www.primalpictures.com/students


